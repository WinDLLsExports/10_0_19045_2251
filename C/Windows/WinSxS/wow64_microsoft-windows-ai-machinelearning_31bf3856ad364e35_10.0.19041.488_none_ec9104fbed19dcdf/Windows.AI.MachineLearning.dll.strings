        
        <requestedExecutionLevel level='asInvoker' uiAccess='false' />
      </requestedPrivileges>
      <requestedPrivileges>
    </security>
    <security>
   ' 0 8 ; > A C G Q S S U ^ 
    Carries out batch normalization as described in the paper
    https://arxiv.org/abs/1502.03167. Depending on the mode it is being run,
    Output case #1: Y, mean, var, saved_mean, saved_var (training mode)
    Output case #2: Y (test mode)
    there are multiple cases for the number of outputs, which we list below:
   ~09AZ__az09AZ__azaz09
  - Ct = ft (.) Ct-1 + it (.) ct
  - ct = g(Xt*(Wc^T) + Ht-1*(Rc^T) + Wbc + Rbc)
  - ft = f(Xt*(Wf^T) + Ht-1*(Rf^T) + Pf (.) Ct-1 + Wbf + Rbf)
  - Ht = (1 - zt) (.) ht + zt (.) Ht-1
  - Ht = f(Xt*(Wi^T) + Ht-1*(Ri^T) + Wbi + Rbi)
  - ht = g(Xt*(Wh^T) + (rt (.) (Ht-1*(Rh^T) + Rbh)) + Wbh) # when linear_before_reset != 0
  - ht = g(Xt*(Wh^T) + (rt (.) Ht-1)*(Rh^T) + Rbh + Wbh) # default, when linear_before_reset = 0
  - Ht = ot (.) h(Ct)
  - it = f(Xt*(Wi^T) + Ht-1*(Ri^T) + Pi (.) Ct-1 + Wbi + Rbi)
  - ot = f(Xt*(Wo^T) + Ht-1*(Ro^T) + Po (.) Ct + Wbo + Rbo)
  - rt = f(Xt*(Wr^T) + Ht-1*(Rr^T) + Wbr + Rbr)
  - zt = f(Xt*(Wz^T) + Ht-1*(Rz^T) + Wbz + Rbz)
  (NOTE: Below are optional)
  </trustInfo>
  <trustInfo xmlns="urn:schemas-microsoft-com:asm.v3">
 ' 0 C E Q S ^ } ~ 
  09AFaf
  Affine(x)              - alpha*x + beta
  AZazAZ
  Else: pads[start_i] = total_padding[i] - (total_padding[i]/2); pads[end_i] = (total_padding[i]/2).
  Elu(x)                 - x if x >= 0 else alpha*(e^x - 1)
  HardSigmoid(x)         - min(max(alpha*x + beta, 0), 1)
  If (auto_pads != SAME_UPPER): pads[start_i] = total_padding[i]/2; pads[end_i] = total_padding[i] - (total_padding[i]/2)
  LeakyRelu(x)           - x if x >= 0 else alpha * x
  output_shape[i] = stride[i] * (input_size[i] - 1) + output_padding[i] + kernel_shape[i] - pads[start_i] - pads[end_i]
  Relu(x)                - max(0, x)
  ScaledTanh(x)          - alpha*Tanh(beta*x)
  shape(A) = (2, 3, 4, 5), shape(B) = (,), i.e. B is a scalar tensor
  shape(A) = (2, 3, 4, 5), shape(B) = (1, 1), i.e. B is an 1-element tensor
  shape(A) = (2, 3, 4, 5), shape(B) = (2), with axis=0
  shape(A) = (2, 3, 4, 5), shape(B) = (3, 4), with axis=1
  shape(A) = (2, 3, 4, 5), shape(B) = (4, 5)
  shape(A) = (2, 3, 4, 5), shape(B) = (5,)
  Sigmoid(x)             - 1/(1 + e^{-x})
  Softplus(x)            - log(1 + e^x)
  Softsign(x)            - x/(1 + |x|)
  Tanh(x)                - (1 - e^{-2x})/(1 + e^{-2x})
  ThresholdedRelu(x)     - x if x >= alpha else 0
  total_padding[i] = stride[i] * (input_size[i] - 1) + output_padding[i] + kernel_shape[i] - output_shape[i]
 ( ) / / _ _ 
 (domain: 
 (node 
 (num_rois, channels, pooled_shape[0], pooled_shape[1]).
 * . ` d f o 
 * pad_shape[i] is sum of pads along axis i
 * Rh^T
 *!+!2!2!N!N!`!
 *0-0
 . Got: 
 / / _ _ 
 : : 
 [seqno=
 [truncated]
 `auto_pad` is a DEPRECATED attribute. If you are using them currently, the output spatial shape will be following:
 {additionalDescription}
 {name} consumes an input tensor X and applies {opName} pooling across
 {name} consumes an input tensor X and applies Lp pooling across
 {opName} pooling consisting of computing the {opName} on all values of a
 |,},o-o-/./.
 ~z/$
 000<0d0p0
 0L0p0
 1*1;1u1
 5$5(5,5D5H5X5\5d5|5
 9 9 
 Actual: 
 allocator already registered.
 already exist.
 and 
 And pad shape will be following if `SAME_UPPER` or `SAME_LOWER`:
' appeared multiple times.
 apply {name} pooling across each RoI, to produce output 4-D tensor of shape
 arg 
 as there's no execution provider allocated.
 at pos=
' attribute.
 Axis is 
 axis value 
 Axis=
 BackUp() can only be called after Next().
 but 
 but expected 
 but has 
 but input '
 but ngram_indexes size: 
 but subgraphs produce 
 but the actually size is: 
 bytes).  To increase the limit (or to disable these warnings), see CodedInputStream::SetTotalBytesLimit() in google/protobuf/io/coded_stream.h.
 bytes.
 cannot be safely updated in one of the subgraphs.
 Can't back up over more bytes than were returned by the last call to Next().
 Char embedding size: 
 char_embedding_size attribute: 
 conv filter size: 
 conv kernal size 1: 
 Conv kernal size 2 : 
 conv_window_size attribute: 
 d f p t ~ 
 data into the output tensor Y for further processing.
 data into the output tensor Y for further processing. The output spatial shape will be following:
 data_dim=
 device_id:
 did not match batch size of 
 did not.
' dimension 
 Dimension=
 dimensions or more but input had shape of 
 dimensions.
 does not align with rank of input data: 
 does not contain a graph.
 does not match existing output type of 
 does not match its type.
 does not specify a valid type.
' doesn't support memcpy 
 Domain mismatch: 
 E E } } 
 elements.
 else=
 embedding_size attribute: 
 Encountered following errors: 
 entries which doesn't match the number of fetches the frame was initialized with of 
 equal to the spatial dimension of input tensor.
 Execution provider mismatch.
 exists in this graph's initializers but it is not used by any node
 Expected 
 Expected DENSE or SPARSE
 Expected std::map<int64_t, float> or std::map<int64_t, std::string>
 expected to be a registered ONNX type
 expected to have tensor type
 Expected TO_FLOAT, TO_STRING or TO_INT64
 Expected:
 Expected: 
 experimental ops. In the future, we may directly 
 fail, errcode =
 fail: unexpected end
 failed
' failed
 failed.
 failed: 
 filter_number: 
 for attribute 
 for operator 
 for SizeFromDimension. Tensor has 
 found!
 found.
 Global{op_type} consumes an input tensor X and applies {op} pooling across
 Got:
 got: 
 Graph may not conform to the ONNX spec and contain initializers that are not graph inputs.
 group: 
 has already been loaded.
 has already been registered.
 has batch size of 
' has been deprecated since version 
' has been used as graph input names multiple times.
' has been used as output names multiple times.
 has length of 
 has mismatched dimensions of 
 has unknown expected type
 hLb.
 if ceil_mode is enabled
 Implicit input name 
 in AddToThreadq
 in ComputeFirstByte
 in initializer but not in graph input
 in KernelRegistryManager
 in node 
 in node (
 in step
 Incompatible types.
 inferred=
 Input shape=
 Input=
 inputs and requires 
 inputs but 
 inputs but Scan was only given 
 inputs but subgraph has 
 inputs. Either provide all subgraph inputs, or just the required inputs.
 inputs. Found:
' instead of '
 Invalid value for input index of node 
 is depracted in domain_version of 
' is expected to have field 'f'
' is expected to have field 'floats'
' is expected to have field 'g'
' is expected to have field 'graphs'
' is expected to have field 'i'
' is expected to have field 'ints'
' is expected to have field 's'
' is expected to have field 'strings'
' is expected to have field 't'
' is expected to have field 'tensors'
 is greater than input dim=
 is invalid for a tensor of rank 
 is marked single but has an empty string in the graph
' is missing.
 is NaN
 is not a registered function/op
 is not associated with a node. 
 is not compatible with 
 is not currently registered or supported
 is not found
' is not found
 is not implemented
 is not in (0, 
 is not in valid range [-
 is not output of any previous nodes.
 is not registered
 is not supported
 is out of bounds
 is outside range.
 is repeated.
 is required but missing.
 is required to be non-empty.
 is tensor type, but provided type is 
 is unrecognized, acceptable values are TF,IDF,TFIDF
 is used by node 
 kernel channels: 
 kernel is not supported in 
 kernel start version: 
 kernel_end_version: 
 kernel_shape: 
 line 
 Lp pooling consisting of computing the Lp norm on all values of a subset
 mem_type:
 memory_type:
 message of type "
 Microsoft Corporation. All rights reserved.
 must be 1 instead of 
 must be either specified in graph inputs or graph initializers.
 must be of equal size
 name:
 node_version: 
 not found.
 not in allowed input sizes.
 not in allowed output sizes.
 not in range [min=
 not specified
 Num entries in 'split' (must equal number of outputs) was 
 num_input_channels: 
 NumOutputs=
' of 
' of input parameter (
' of node: 
 of the given input. The input is a 2-D tensor (Tensor<float>) of size
 of the input tensor according to the kernel size and downsampling the
 Operating System
 output_spatial_shape[i] = ceil((input_spatial_shape[i] + pad_shape[i] - kernel_spatial_shape[i]) / strides_spatial_shape[i] + 1)
 output_spatial_shape[i] = floor((input_spatial_shape[i] + pad_shape[i] - kernel_spatial_shape[i]) / strides_spatial_shape[i] + 1)
 outputs but Scan expects 
 outputs so the subgraph requires 
 outputs which doesn't match the subgraph's 
 outputs.
 outputs. Expected 
 P!_!
 pad_shape[i] = (output_spatial_shape[i] - 1) * strides_spatial_shape[i] + kernel_spatial_shape[i] - input_spatial_shape[i]
 Parameter to BackUp() can't be negative.
 Requested shape:
 ROI {name} pool consumes an input tensor X and region of interests (RoIs) to
 row[
 rows[
 SAME_UPPER or SAME_LOWER: output_spatial_shape[i] = ceil(input_spatial_shape[i] / strides_spatial_shape[i])
 should be of integer type and specify a type.
' should be stored in field '
 should be unidirectional broadcastable to 
 should specify a shape
 since it was ill-formed during registration
 size=
 specified. It should be either avg or max
 Status Message: 
 subset of the input tensor according to the kernel size and downsampling the
 Sum of sizes in 'split' (must equal size of selected axis) was 
 Target=
 the tensor according to kernel sizes, stride sizes, and pad lengths.
 the values in the same channel. This is equivalent to {op_type} with kernel size
 then=
 type:
 unknown
 VALID: output_spatial_shape[i] = ceil((input_spatial_shape[i] - kernel_spatial_shape[i] + 1) / strides_spatial_shape[i])
 value type: 
 Version mismatch.
 version: 
 vs. 
 was 
' was 
 was a removed 
 was false.
 was modified concurrently during serialization.
 was not
 was not a tensor.
 were provided
 Windows
 Windows::AI::MachineLearning::TensorBase<short,short,struct winrt::Windows::AI::MachineLearning::implementation::TensorInt16Bit,struct winrt::Windows::AI::MachineLearning::ITensorInt16Bit,struct winrt::Windows::AI::MachineLearning::implementation::TensorInt16Bit_base<struct winrt::Windows::AI::MachineLearning::implementation::TensorInt16Bit,struct ITensorNative,struct Windows::AI::MachineLearning::ILotusValueProviderPrivate> >::GetCpuResource
 with domain_version of 
 with error: 
 with type 
!#!%!%!'!'!)!)!.!.!:!;!@!D!J!M!O!O!
!#!%!%!'!'!)!)!.!.!:!;!J!J!L!M!O!O!
!#%'**,,./:;?@\\
!#%*,/:;?@[]__{{}}
!$!$!&!&!(!(!*!-!/!9!<!?!E!I!N!N!
!$!$!&!&!(!(!*!-!0!3!>!?!E!E!
!%!'!)!,!1!3!M!O!_!
!&$@$J$`$
!(it.GetName().empty())
!/!/!4!4!9!9!<!=!F!I!N!N!
!/:@[`{~!~
!@!D!K!K!
!0(0>0X0_0u0
!0,^,a,a,e,f,h,h,j,j,l,l,q,q,s,t,v,{,
!020>0J0a0m0
!020D0T0~0
!0Y0`0
!1=1k1t1
!c->in_use() && (c->bin_num != kInvalidBinNum)
!c->in_use() && (c->bin_num == kInvalidBinNum)
!c1->in_use() && !c2->in_use()
!char_tokenezation_ || mincharnum_ < 2
!chunk->in_use()
!coefficients_.empty()
!FxPh
!has_axes || attr_axes_.size() == attr_starts_.size()
!impl_->pool_strings_.empty()
!is_concrete_shape_
!nodes_treeids_.empty()
!normalize_
!scale_.empty()
!separators.empty()
!sw.empty()
!This program cannot be run in DOS mode.
!tokenexp.empty()
" #!#|#|#
" : "
" because it is missing required fields: 
";2t8
"0,0A0V0j0
"7Windows::AI::MachineLearning::TensorBase<unsigned int,unsigned int,struct winrt::Windows::AI::MachineLearning::implementation::TensorUInt32Bit,struct winrt::Windows::AI::MachineLearning::ITensorUInt32Bit,struct winrt::Windows::AI::MachineLearning::implementation::TensorUInt32Bit_base<struct winrt::Windows::AI::MachineLearning::implementation::TensorUInt32Bit,struct ITensorNative,struct Windows::AI::MachineLearning::ILotusValueProviderPrivate> >::GetCpuResource
"args" : {
"dur" :
"h441
"name" :"
"ph" : "X",
"pid" :
"tid" :
"ts" :
#"#(#+#{#}#
#&$@$J$
#(#+#&$@$J$
#)#)#h'h'j'j'l'l'n'n'p'p'r'r't't'
#)#*#h'u'
#*#*#i'i'k'k'm'm'o'o'q'q's's'u'u'
#=4B:
#0:0g0
#0-0T0^0
#020V0j0
#0E0P0c0
#0O4{4
#0S0}0
#9} u
$$++<>^^``||~~
$_^[]
$0,040@0`0h0p0x0
$0L0t0
$0P0U0Z0l0q0v0
$0T0d0t0x0
$2h2/3
$Element
$h(m1
-%-'-'-----
%.0Lf
%~3a*
-%-'-'-----0-g-o-o-
-%-'-'-----A
%b %d %H : %M : %S %Y
%d / %m / %y
%H : %M
%H : %M : %S
%hh1.
%hs!%p: 
%hs(%d) tid(%x) %08X %ws
%hs(%d)\%hs!%p: 
%I : %M : %S %p
%m / %d / %y
%o&o&
%VhL61
%Y-%m-%d_%H-%M-%S
&!&!e
&0:0q0
&080t0
&1{1S3$5
&n&p&g'
(&Z2{x
(([[{{
((scales[0] == 1) && (scales[1] == 1))
(){}[]*+?|.^$\
(?HaveMatch:%d)
(?-m:$)
(?-m:^)
(-@"2
(-@$2
(\$0f
(~]GS
(0*131I1
(0:0?0D0
(0B0\0y0
(0H0P0\0|0
(0L0v0
(batch_size x input_feature_dimensions). The output tensor has the same shape
(before_insert + ngrams) == impl_->int64_set_.size()
(before_insert + ngrams) == impl_->str_set_.size()
(caller: %p) 
(cannot determine missing fields for lite message)
(default) or 
(float, default 0.5) the ratio of random dropout
(fmod == 0) || (fmod == 1)
(hLq/
(input_shape.Size() % size) == 0
(inputs_.size() - 1) == i
(int, default 0) if nonzero, run dropout in test mode where the output is simply Y = X.
(items % ngram_size == 0)
(nodes_id_size == nodes_hitrates_.size()) || (nodes_hitrates_.empty())
(nodes_nodeids_.size() == nodes_hitrates_.size()) || (nodes_hitrates_.empty())
(null)
(op_type:
(Optional) A scalar or rank 1 tensor containing a single value to be filled if the mode chosen is `constant` (by default it is 0.0).
(Optional) Axis along which one-hot representation in added. Default: axis=-1. axis=-1 means that the additional dimension will be inserted as the innermost/last dimension in the output tensor.
(Optional) Axis along which to take slices. If not specified, input is flattened before elements being selected.
(Optional) Index of the diagonal to be populated with ones. Default is 0. If T2 is the output, this op sets T2[i, i+k] = 1. k = 0 populates the main diagonal, k > 0 populates an upper diagonal,  and k < 0 populates a lower diagonal.
(Optional) Seed to the random generator, if not specified we will auto generate one.
(Optional) Specify which axis is batch axis. Must be one of 1 (default), or 0.
(Optional) Specify which axis is time axis. Must be one of 0 (default), or 1.
(Optional) The data type for the elements of the output tensor, if not specified, we will use int32.
(Optional) The data type for the elements of the output tensor, if not specified, we will usethe data type of the input tensor.
(Optional) The data type for the elements of the output tensor. If not specified,the data type of the input tensor T1 is used. If input tensor T1 is also notspecified, then type defaults to 'float'.
(Optional) The value of the output elements.Should be a one-element tensor. If not specified, it defaults to a tensor of value 0 and datatype float32
(Optional) Whether map negative infinity to true. Default to 1 so that negative infinity induces true. Set this attribute to 0 if negative infinity should be mapped to false.
(Optional) Whether map positive infinity to true. Default to 1 so that positive infinity induces true. Set this attribute to 0 if positive infinity should be mapped to false.
(outputs_.size() - 1) == i
(UINT32)message.Severity()
) != (
) , expected: (
) + (
) + bottomBorder (
) + rightBorder (
) + scale_[0] (
) + scale_[1] (
) and node 
) attribute (
) bound to different types (
) does not exist in the graph.
) does not have type information set by parent node.
) does not have type information.
) does not match expected type (
) does not match number of inputdimensions values (
) does not match the data size(
) does not match the number of channels (
) for attribute 'axis'
) from file 
) has input size 
) has more inputs (
) has more outputs (
) has output size 
) has zero input and zero output.
) in node (
) in op definition.
) in proto
) input arg (
) is 0-element but contains data!
) is invalid.
) is not equal to number of scan inputs (
) is not equal to number of scan outputs (
) is not equal to the existing dim value (
) is required but not specified.
) is stored externally and should not have data field.
) is stored externally but doesn't have a location.
) needs to be greater than the leftBorder (
) needs to be greater than the topBorder (
) of node (
) of operator (
) of output arg (
) or 1
) output arg (
) should be stored in 
) should contain one and only one value field.
) should not be stored in raw_data field
) should not contain more than one value field.
) should refer to attribute in parent node.
) than declared (
) to UNDEFINED is not allowed
) type inference failed
) vs (
)".".$.$.&.&.(.(.B.B.
)#.#.%.%.'.'.).).
))]]}}
); for more details please check [the doc](Broadcasting.md).
)\$09t$
)0Y0n0t0
)98&F
)D$DP
)f90u
)'s input 
)'s output 
)s+v+
-*0/0
*0+D+G+L+)
-*0-0
*1E1.2
*L$,SPR
*out_size >= 0
*QQRQ
, am_attn_size}, Got:
, aw_attn_size}. Got:
, block in memory pattern size is: 
, block not found in target location. fall back to default allocation behavior
, but it doesn't exist or is not accessible.
, but it is already registered from file 
, but it its domain is not
, but it its version is higher
, but it its version is not 
, fall back to default allocation behavior
, Got 
, got 
', location: 
, max=
, name:
, requested shape:
, type: 
,.,`,`,b,d,g,g,i,i,k,k,m,p,r,r,u,u,~,
,.,0,^,
,.,0,^,`,
,p-p-
. . .P
'. 0 == forward. 1 == reverse.
. batch_size=
. Dimension 0 is 
. Do you have duplicated calls to SessionState::AddInitializedTensor function?
. Initializers may not be overridden by feeds if model IR version is less than 4.
. Input rank=
. Input tensor rank was 
. It can only be 
. Must be 0 or 1
'. Must be one of 'forward', 'reverse', or 'bidirectional'.
. Num args is 
. Output tensor rank was 
. Shape:
. shape=
.!.!.@
.*...0.9.<.?.A.A.C.N.
...0.N.
.:.;.@.@.
.?AU?$default_delete@VBFCArena@onnxruntime@@@std@@
.?AU?$default_delete@VDummyArena@onnxruntime@@@std@@
.?AU?$default_delete@VIDeviceAllocator@onnxruntime@@@std@@
.?AU?$DefaultKernel@U?$BitDepthParams@U?$OperandRange@$0A@$0PP@@gemmlowp@@U12@@gemmlowp@@@gemmlowp@@
.?AU?$DefaultKernelImpl@$0A@$0A@@gemmlowp@@
.?AU?$GemmWithPackedRhsTask@U?$KernelFormat@U?$KernelSideFormat@U?$CellFormat@$03$0BA@$00@gemmlowp@@$00@gemmlowp@@U12@@gemmlowp@@EEU?$BitDepthParams@U?$OperandRange@$0A@$0PP@@gemmlowp@@U12@@2@$00$00$00V?$VectorDup@$$CBH$0A@@2@V?$VectorDup@$$CBH$00@2@V?$tuple@U?$OutputStageBiasAddition@V?$VectorMap@$$CBH$0A@@gemmlowp@@@gemmlowp@@UOutputStageQuantizeDownInt32ByFixedPoint@2@UOutputStageSaturatingCastToUint8@2@@std@@VGemmContext@2@@gemmlowp@@
.?AU?$GemmWithPackedRhsTask@U?$KernelFormat@U?$KernelSideFormat@U?$CellFormat@$03$0BA@$00@gemmlowp@@$00@gemmlowp@@U12@@gemmlowp@@EEU?$BitDepthParams@U?$OperandRange@$0A@$0PP@@gemmlowp@@U12@@2@$00$00$00V?$VectorDup@$$CBH$0A@@2@V?$VectorDup@$$CBH$00@2@V?$tuple@UOutputStageQuantizeDownInt32ByFixedPoint@gemmlowp@@UOutputStageSaturatingCastToUint8@2@@std@@VGemmContext@2@@gemmlowp@@
.?AU?$GemmWithPackedRhsTask@U?$KernelFormat@U?$KernelSideFormat@U?$CellFormat@$03$0BA@$00@gemmlowp@@$00@gemmlowp@@U12@@gemmlowp@@EEU?$BitDepthParams@U?$OperandRange@$0A@$0PP@@gemmlowp@@U12@@2@$0A@$0A@$0A@V?$VectorDup@$$CBH$00@2@V?$VectorDup@$$CBH$0A@@2@V?$tuple@U?$OutputStageBiasAddition@V?$VectorMap@$$CBH$00@gemmlowp@@@gemmlowp@@UOutputStageQuantizeDownInt32ByFixedPoint@2@UOutputStageSaturatingCastToUint8@2@@std@@VGemmContext@2@@gemmlowp@@
.?AU?$GemmWithPackedRhsTask@U?$KernelFormat@U?$KernelSideFormat@U?$CellFormat@$03$0BA@$00@gemmlowp@@$00@gemmlowp@@U12@@gemmlowp@@EEU?$BitDepthParams@U?$OperandRange@$0A@$0PP@@gemmlowp@@U12@@2@$0A@$0A@$0A@V?$VectorDup@$$CBH$00@2@V?$VectorDup@$$CBH$0A@@2@V?$tuple@UOutputStageQuantizeDownInt32ByFixedPoint@gemmlowp@@UOutputStageSaturatingCastToUint8@2@@std@@VGemmContext@2@@gemmlowp@@
.?AU?$GemmWithPackedRhsTask@U?$KernelFormat@U?$KernelSideFormat@U?$CellFormat@$03$0BA@$00@gemmlowp@@$00@gemmlowp@@U12@@gemmlowp@@EHU?$BitDepthParams@U?$OperandRange@$0A@$0PP@@gemmlowp@@U12@@2@$00$00$00V?$VectorDup@$$CBH$0A@@2@V?$VectorDup@$$CBH$00@2@V?$tuple@$$V@std@@VGemmContext@2@@gemmlowp@@
.?AU?$GemmWithPackedRhsTask@U?$KernelFormat@U?$KernelSideFormat@U?$CellFormat@$03$0BA@$00@gemmlowp@@$00@gemmlowp@@U12@@gemmlowp@@EHU?$BitDepthParams@U?$OperandRange@$0A@$0PP@@gemmlowp@@U12@@2@$0A@$0A@$0A@V?$VectorDup@$$CBH$00@2@V?$VectorDup@$$CBH$0A@@2@V?$tuple@$$V@std@@VGemmContext@2@@gemmlowp@@
.?AU?$ImplementsHelper@U?$RuntimeClassFlags@$01@WRL@Microsoft@@$00$$V@Details@WRL@Microsoft@@
.?AU?$ImplementsHelper@U?$RuntimeClassFlags@$01@WRL@Microsoft@@$00UIWinmlExecutionProvider@implementation@MachineLearning@AI@Windows@winrt@@@Details@WRL@Microsoft@@
.?AU?$ImplementsHelper@U?$RuntimeClassFlags@$01@WRL@Microsoft@@$0A@UIExecutionProvider@Dml@@UIWinmlExecutionProvider@implementation@MachineLearning@AI@Windows@winrt@@@Details@WRL@Microsoft@@
.?AU?$ImplementsHelper@U?$RuntimeClassFlags@$01@WRL@Microsoft@@$0A@UIMLOperatorKernel@@@Details@WRL@Microsoft@@
.?AU?$ImplementsHelper@U?$RuntimeClassFlags@$01@WRL@Microsoft@@$0A@UIMLOperatorKernelFactory@@@Details@WRL@Microsoft@@
.?AU?$ImplementsHelper@U?$RuntimeClassFlags@$01@WRL@Microsoft@@$0A@UIMLOperatorShapeInferrer@@@Details@WRL@Microsoft@@
.?AU?$ImplementsHelper@U?$RuntimeClassFlags@$01@WRL@Microsoft@@$0A@UIUnknown@@@Details@WRL@Microsoft@@
.?AU?$Pad@M@contrib@onnxruntime@@
.?AU?$Pad@M@onnxruntime@@
.?AU?$ReferenceKernel@U?$KernelFormat@U?$KernelSideFormat@U?$CellFormat@$03$0BA@$00@gemmlowp@@$00@gemmlowp@@U12@@gemmlowp@@@gemmlowp@@
.?AU?$RuntimeClassFlags@$03@WRL@Microsoft@@
.?AU?$Slice@_J$00@onnxruntime@@
.?AU?$Slice@_J$0A@@onnxruntime@@
.?AU?$Slice@_K$00@onnxruntime@@
.?AU?$Slice@_K$0A@@onnxruntime@@
.?AU?$Slice@_N$00@onnxruntime@@
.?AU?$Slice@_N$0A@@onnxruntime@@
.?AU?$Slice@C$00@onnxruntime@@
.?AU?$Slice@C$0A@@onnxruntime@@
.?AU?$Slice@E$00@onnxruntime@@
.?AU?$Slice@E$0A@@onnxruntime@@
.?AU?$Slice@F$00@onnxruntime@@
.?AU?$Slice@F$0A@@onnxruntime@@
.?AU?$Slice@G$00@onnxruntime@@
.?AU?$Slice@G$0A@@onnxruntime@@
.?AU?$Slice@H$00@onnxruntime@@
.?AU?$Slice@H$0A@@onnxruntime@@
.?AU?$Slice@I$00@onnxruntime@@
.?AU?$Slice@I$0A@@onnxruntime@@
.?AU?$Slice@M$00@onnxruntime@@
.?AU?$Slice@M$0A@@onnxruntime@@
.?AU?$Slice@N$00@onnxruntime@@
.?AU?$Slice@N$0A@@onnxruntime@@
.?AU?$Slice@TMLFloat16@onnxruntime@@$00@onnxruntime@@
.?AU?$Slice@TMLFloat16@onnxruntime@@$0A@@onnxruntime@@
.?AU?$Slice@V?$basic_string@DU?$char_traits@D@std@@V?$allocator@D@2@@std@@$00@onnxruntime@@
.?AU?$Slice@V?$basic_string@DU?$char_traits@D@std@@V?$allocator@D@2@@std@@$0A@@onnxruntime@@
.?AU_Crt_new_delete@std@@
.?AUContainer@?$InternalMetadataWithArenaBase@V?$basic_string@DU?$char_traits@D@std@@V?$allocator@D@2@@std@@VInternalMetadataWithArenaLite@internal@protobuf@google@@@internal@protobuf@google@@
.?AUctype_base@std@@
.?AUfail_fast@gsl@@
.?AUhresult_access_denied@winrt@@
.?AUhresult_canceled@winrt@@
.?AUhresult_changed_state@winrt@@
.?AUhresult_class_not_available@winrt@@
.?AUhresult_error@winrt@@
.?AUhresult_illegal_delegate_assignment@winrt@@
.?AUhresult_illegal_method_call@winrt@@
.?AUhresult_illegal_state_change@winrt@@
.?AUhresult_invalid_argument@winrt@@
.?AUhresult_no_interface@winrt@@
.?AUhresult_not_implemented@winrt@@
.?AUhresult_out_of_bounds@winrt@@
.?AUhresult_wrong_thread@winrt@@
.?AUIExecutionProvider@Dml@@
.?AUIMLOperatorKernel@@
.?AUIMLOperatorKernelFactory@@
.?AUIMLOperatorShapeInferrer@@
.?AUInferenceContext@onnx@@
.?AUInferenceContextImpl@shape_inference@onnx@@
.?AUIUnknown@@
.?AUIWinmlExecutionProvider@implementation@MachineLearning@AI@Windows@winrt@@
.?AUKernelBase@gemmlowp@@
.?AUmessages_base@std@@
.?AUmoney_base@std@@
.?AUnarrowing_error@gsl@@
.?AUNodeCompare@onnxruntime@@
.?AUOrtValue@@
.?AUSequentialExecutionPlan@onnxruntime@@
.?AUTask@gemmlowp@@
.?AUTile@onnxruntime@@
.?AUtime_base@std@@
.?AV?$_Associated_state@H@std@@
.?AV?$_Binder@U_Unforced@std@@A6AXJ_NV?$function@$$A6AXJ@Z@2@@ZABU?$_Ph@$00@2@ABU?$_Ph@$01@2@AAV32@@std@@
.?AV?$_Binder@U_Unforced@std@@A6AXJUILearningModelFeatureValue@MachineLearning@AI@Windows@winrt@@UILearningModelFeatureDescriptor@4567@@ZABU?$_Ph@$00@2@AAU34567@AAU84567@@std@@
.?AV?$_Binder@U_Unforced@std@@A6AXJV?$function@$$A6AXJ@Z@2@@ZABU?$_Ph@$00@2@AAV32@@std@@
.?AV?$_Binder@U_Unforced@std@@AAV?$function@$$A6AXH@Z@2@AAH@std@@
.?AV?$_Func_base@_NH@std@@
.?AV?$_Func_base@_NI@std@@
.?AV?$_Func_base@_NPBVNode@onnxruntime@@PBV12@@std@@
.?AV?$_Func_base@HPAUComputeContext@onnxruntime@@PAPAX@std@@
.?AV?$_Func_base@HPAXPBUOrtCustomOpApi@@PAUOrtKernelContext@@@std@@
.?AV?$_Func_base@MMMM@std@@
.?AV?$_Func_base@PAVOpKernel@onnxruntime@@ABVOpKernelInfo@2@@std@@
.?AV?$_Func_base@V?$ComPtr@UIMLOperatorTensor@@@WRL@Microsoft@@I@std@@
.?AV?$_Func_base@V?$unique_ptr@VIDeviceAllocator@onnxruntime@@U?$default_delete@VIDeviceAllocator@onnxruntime@@@std@@@std@@H@std@@
.?AV?$_Func_base@VStatus@common@onnxruntime@@AAV?$shared_ptr@VModel@onnxruntime@@@std@@@std@@
.?AV?$_Func_base@VStatus@common@onnxruntime@@AAVGraph@3@@std@@
.?AV?$_Func_base@VStatus@common@onnxruntime@@ABVNode@3@AAVGraph@3@ABV?$vector@PBVTypeProto@onnx@@V?$allocator@PBVTypeProto@onnx@@@std@@@std@@AAV67@@std@@
.?AV?$_Func_base@VStatus@common@onnxruntime@@ABVNodeArg@3@I@std@@
.?AV?$_Func_base@VStatus@common@onnxruntime@@ABVTensorShape@3@ABUOrtAllocatorInfo@@AAUOrtValue@@AA_N@std@@
.?AV?$_Func_base@X$$QAVOpSchema@onnx@@@std@@
.?AV?$_Func_base@X$$V@std@@
.?AV?$_Func_base@XAAUInferenceContext@onnx@@@std@@
.?AV?$_Func_base@XAAVNodeConnection@MLGraph@@@std@@
.?AV?$_Func_base@XAAVOpSchema@onnx@@@std@@
.?AV?$_Func_base@XABVNodeArg@onnxruntime@@_N@std@@
.?AV?$_Func_base@XH@std@@
.?AV?$_Func_base@XPAH@std@@
.?AV?$_Func_base@XPAM@std@@
.?AV?$_Func_base@XPAUILogger@CommonLogging@@@std@@
.?AV?$_Func_base@XPAX@std@@
.?AV?$_Func_base@XPBUNodeConnectionCompileState@Compilation@MLGraph@@@std@@
.?AV?$_Func_base@XPBVDataTypeImpl@onnxruntime@@@std@@
.?AV?$_Func_base@XPBVNode@onnxruntime@@@std@@
.?AV?$_Func_base@XV?$Map@V?$Matrix@M$0?0$00$0A@$0?0$00@Eigen@@$0A@V?$Stride@$0A@$0A@@2@@Eigen@@V?$Map@$$CBV?$Matrix@M$0?0$00$0A@$0?0$00@Eigen@@$0A@V?$Stride@$0A@$0A@@2@@2@M@std@@
.?AV?$_Func_impl_no_alloc@P6A?AVStatus@common@onnxruntime@@ABVNode@3@AAVGraph@3@ABV?$vector@PBVTypeProto@onnx@@V?$allocator@PBVTypeProto@onnx@@@std@@@std@@AAV67@@ZV123@ABV43@AAV53@ABV67@AAV67@@std@@
.?AV?$_Func_impl_no_alloc@P6AMMMM@ZMMMM@std@@
.?AV?$_Func_impl_no_alloc@P6APAVOpKernel@onnxruntime@@ABVOpKernelInfo@2@@ZPAV12@ABV32@@std@@
.?AV?$_Func_impl_no_alloc@P6AX$$QAVOpSchema@onnx@@@ZX$$QAV12@@std@@
.?AV?$_Func_impl_no_alloc@P6AXAAUInferenceContext@onnx@@@ZXAAU12@@std@@
.?AV?$_Func_impl_no_alloc@UNodeCompare@onnxruntime@@_NPBVNode@2@PBV32@@std@@
.?AV?$_Func_impl_no_alloc@V?$_Binder@U_Unforced@std@@AAV?$function@$$A6AXH@Z@2@AAH@std@@X$$V@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_006f042491572090b778a6887556c541>@@XAAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_00bc1d3067b0daca44118c6bf6182fe6>@@XAAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_00c87c7b53d371a1cf60b7c0c451f8f8>@@XAAVOpSchema@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_010a062bd559bce238b9185468d50447>@@XPBVNode@onnxruntime@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_01985760e667ba58bff711ef31d8e638>@@XAAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_027f0b72d20b824e4e30fa2ccfde3681>@@XAAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_03f9a416ba9956cce684677e892ba331>@@VStatus@common@onnxruntime@@ABVNodeArg@4@I@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_05139462a1d0ad358a8c7449ca410e71>@@XAAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_054344795ce74e2e037e3c05c0b91898>@@XAAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_06f0a46d4083d6cb6bc408c03994b5c5>@@XAAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_0778a4cf53183ad367a412434c098397>@@XAAVOpSchema@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_08accd2c56d1c3539bdbe39ead72e813>@@XAAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_12614fe07b000bac4d9f90f7d831265d>@@XAAVOpSchema@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_12c274da604ed254f4e0fb7954f6465d>@@XAAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_1476157c6a284e4f379191854345eea5>@@XAAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_1557398f94c0db7066f5e254ef45fbcc>@@XAAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_15ecc8429525df8ca256030db21f49bc>@@_NH@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_1c332c1005d61c8e735e119b3884fbef>@@_NI@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_1c7f9a84db6055efdbcae32649cc172f>@@XABVNodeArg@onnxruntime@@_N@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_1cfe3ee5b20ff1a1b7aabf8562b20997>@@XPAX@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_1e45319bac0025a63dcec33b3529d969>@@XAAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_2061574dcd3884bcc7418dd15f1c1551>@@XH@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_221457049dd6e599b1e592be3898266a>@@XAAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_229b57b9a061962ff9594124af885d82>@@XAAVOpSchema@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_24a4d3258ed26385b9a2a41ae6641dc4>@@XAAVOpSchema@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_26620886b575de26166e451d44bc7aeb>@@XPAM@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_27eb941e257b57f9cf2ee9f3ef3087b3>@@XAAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_29460ba72c9a9f61937f695b212c2385>@@XAAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_2997ea06f466f3cb7af7580139e0e9b1>@@XAAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_2a231a5ff616b0ae2274b38ac58ff666>@@XAAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_2a39988023ade309aa40582a95355447>@@XAAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_2a3b1f1fbc2b924051eedcd518441330>@@XAAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_2c336c69e37df1f232f1301ffdf6cbc8>@@XAAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_2cc340efac7f4d4dbbf5e840712c9235>@@XAAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_2cda3ec4180407fdb66cae08f370124f>@@XAAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_2e19a35e43fa3cd8cc3946e0a5442052>@@XH@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_2ff8e0e61b396ff915eaef7150818ea5>@@XAAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_3045925fc9d28d7c90e23d8477212aa5>@@XAAVNodeConnection@MLGraph@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_30c3e62ccde4a098c007b12bb428e908>@@XAAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_3354f944db7877754471d985be3fe29b>@@XAAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_3395043349d35d848478e0474916ca12>@@HPAXPBUOrtCustomOpApi@@PAUOrtKernelContext@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_36061226c6fd19f4bdb6137e32da6056>@@XABVNodeArg@onnxruntime@@_N@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_39ab4e523a93c974831bf3e5838f7482>@@XAAVNodeConnection@MLGraph@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_404084d3edacc8294adecb096c00b5ef>@@XAAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_423c7f4514cb0f580d17c1969d94ab4d>@@XAAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_44f740f4362270fce5c964ebb50cbf77>@@XAAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_4895a69c6e2d4d3665d84240b52946d2>@@XAAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_493755c0718e549fc6eb6376aaf1c076>@@XAAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_4a5350b0e7409384ce33fe3ccb0d5596>@@XH@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_4fa0c6ad40015df7a4b742afad148021>@@XAAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_51e7ce4347ad68176c6a114dbe1a7fb9>@@XAAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_53958a524045125d538038a834c170f9>@@XAAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_554a630e87be704853cdb4d6e278622f>@@VStatus@common@onnxruntime@@ABVNodeArg@4@I@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_55e8e059d201c280196491784367b3c1>@@PAVOpKernel@onnxruntime@@ABVOpKernelInfo@3@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_56616cb04d479ecbbef60d16cb985ff3>@@XAAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_5865299a878cc4536f06dd6ac2dafee9>@@XAAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_59c4d05489433c3097fa1fd13c659c8e>@@XAAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_5a03cad439a535c73c9479bab198ff8a>@@XAAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_5d21b43612adc0e2b6ba128e18c7d8b6>@@XAAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_5df3894d1af0aab9723a608826cf16dc>@@XAAVOpSchema@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_5f1d94f8ca558702930bc8409fa6a0fd>@@XAAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_62ff4f86733dccc387694342e1e25828>@@XAAVOpSchema@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_65fcd2258b74fe5b669ce1eba7885536>@@XABVNodeArg@onnxruntime@@_N@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_6a32611970906250c6b47d8292ad00e7>@@XAAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_6a6f0a3ba850801745b0c94cd2f39bc9>@@XABVNodeArg@onnxruntime@@_N@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_6b96036581b66cdf82b5f39e2bc23e66>@@XABVNodeArg@onnxruntime@@_N@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_6bd810bb96d3f9038457669c0e958c1e>@@XAAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_6ca09521f0419cdfacda156e3fc4c98d>@@XAAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_6f80d65fbc6388042df99a3b220305d1>@@XAAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_70bcac305cb640939927fb5ceed26972>@@V?$unique_ptr@VIDeviceAllocator@onnxruntime@@U?$default_delete@VIDeviceAllocator@onnxruntime@@@std@@@std@@H@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_72ca09e2fd79e9e358b3e3ba19c9ad25>@@VStatus@common@onnxruntime@@AAVGraph@4@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_747f5a5054cea5042105b3988bb8e54a>@@XAAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_7b78813024b920efef438001345229c7>@@XAAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_7bf0c45af15d48ff0bf3482d9ab1530d>@@XAAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_7d18ce867b586dae3ed4309094f85b3d>@@XAAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_82b1543f521b28b3e70914f128f825eb>@@XAAVOpSchema@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_82fc727948fa2cc155864c30c0053c56>@@XAAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_87377fe9a7b55ca099852704c7649a37>@@XAAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_87c68c0967c94d566f6bd8e49e4156e6>@@XAAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_891134c426edf12026f17cb0f2078fd3>@@V?$ComPtr@UIMLOperatorTensor@@@WRL@Microsoft@@I@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_8a3605e32b16eedb239f2cdd6ac9b967>@@VStatus@common@onnxruntime@@AAVGraph@4@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_8a3f03cf93ba764f7eebf7fd98d3a893>@@XAAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_8d7ff4e398bab3b109ccce388181bf44>@@XAAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_8d8272b50dd604dacd546ce94def4111>@@XAAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_8e3498b106c5788a8387a435fcfed696>@@XAAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_8e59199324395720fba09bee90960ebd>@@XAAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_8ff3f73c945873491aaa70354b23f874>@@XAAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_9239155d58e7ea4f2b7e8d2c9c494e5c>@@XAAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_932c34c02ec00a70f1fdb6bbb19ccddc>@@VStatus@common@onnxruntime@@ABVNodeArg@4@I@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_9381c167dbf89081cfa0e8790a4e25ab>@@HPAUComputeContext@onnxruntime@@PAPAX@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_961060303c5a5a6cf5cad068e6081a1d>@@XABVNodeArg@onnxruntime@@_N@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_96977307008117beb1e0c08617e9e024>@@XAAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_96d3b593d5201521d990452d7883196b>@@VStatus@common@onnxruntime@@ABVNodeArg@4@I@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_974421a2166ea3684014171d0d75f69e>@@XAAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_977aa0989600c553e6ad21ef5f183702>@@XAAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_98813516cd70625548f3dca86c17f6e0>@@XAAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_991d63fb8a809dc84e4e523068ce486a>@@XAAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_99a813c0737ae897b47e9765a72f7f54>@@XV?$Map@V?$Matrix@M$0?0$00$0A@$0?0$00@Eigen@@$0A@V?$Stride@$0A@$0A@@2@@Eigen@@V?$Map@$$CBV?$Matrix@M$0?0$00$0A@$0?0$00@Eigen@@$0A@V?$Stride@$0A@$0A@@2@@3@M@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_9a80c5c6458e824bfa0876a779605b0b>@@XAAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_9abb244ecf1fe7549bfa1b3b46427d69>@@XAAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_9baa1cdad376a56943ca503609534da1>@@XAAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_9c3e860ddd71320745f67b50702ebd1c>@@XAAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_9d3d7084367d9c69100d1b294ff81141>@@XAAVOpSchema@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_9df4f2e35c1c7422103cfd601a9bcf0a>@@XAAVOpSchema@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_9ecca3786d31dc5e5f01e690b2595c13>@@XAAVOpSchema@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_a0e644278ef4f4a57b9573e7ded643ef>@@XAAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_a30982bdf1dc90ee13caf4d420ec5e7f>@@XAAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_a4a8f47c88f81824ff45fecdeb8c2272>@@XAAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_a4fe3bd39dcd0107f90455cb45c21429>@@_NH@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_a54be6033497fa554a72d4e91b445475>@@XPBUNodeConnectionCompileState@Compilation@MLGraph@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_a7d04b0fd0d89810819d0e2c9abbe002>@@XAAVOpSchema@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_a849a50c5a3c22fd47c8e79fa702e0a3>@@XAAVOpSchema@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_a8dc603fd8183714a0dc357fc9b787c1>@@XAAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_aa8e087667c023378c6f91514203b485>@@XAAVOpSchema@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_ad2c1540175e880a19f24b36af249c6b>@@XAAVOpSchema@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_ae345cbcfe8c11e85db446885ca97c11>@@XAAVOpSchema@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_ae651a2f316754e5b872f0242e285a17>@@XAAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_af2c39467b4484bc2a2f611cf533daa7>@@XAAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_afa56d0a59b7519296bd96a3f73f6a6d>@@XAAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_b39fcf5d316099631cb4151a025dde22>@@XAAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_b43d1a9e0f80c81cf46233421502eec9>@@XAAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_b5052b92f0971a85fe617ac12b65bf30>@@XAAVOpSchema@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_b51428820b3477616d25ebf36e7dd645>@@XAAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_b5a8e22fc972999c473eeef0d861144d>@@XAAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_b6384ac1cdd5bb196d6db0f3469d6bd1>@@VStatus@common@onnxruntime@@ABVNodeArg@4@I@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_b937f7d4f097577d4fa0e0107ad25600>@@XAAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_b9f88ddcdec88010c219cbe673399be3>@@XAAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_bb49b7cc5cd2d94ca99a48a4c0d13f14>@@XAAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_bc9a9f99cbeabaf2d0a936a0cad6b782>@@XAAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_bd360832f28382f5f21b2ebf873809d4>@@X$$V@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_bd5b9427a54fdb45586e1dbfc607a955>@@XAAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_bdb2783b16b3d1693e3b68280088cba9>@@XAAVOpSchema@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_bed28cc9642f1fb2f87171613a105a9c>@@VStatus@common@onnxruntime@@ABVTensorShape@4@ABUOrtAllocatorInfo@@AAUOrtValue@@AA_N@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_c332dd4138e096b0ec5e0eae392e23e1>@@XPBVDataTypeImpl@onnxruntime@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_c3c25e82dec0fc98e0076356943111e7>@@XAAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_c5cebd529b61d3173fae5d666977fc08>@@XAAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_c903e10f9792b7526fde45e82dd96aa5>@@XAAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_c992598cf8c136d6154948ffea1cabd3>@@XAAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_ca87e505bf8a7e1f26579083c3683d94>@@_NH@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_ce473b479310095c7321cd7e93391654>@@XAAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_cee41185b89a07016645dc0ce475cceb>@@XAAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_d01cb7d72935562762275ef2725e3ce2>@@XAAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_d2f05bbc4387bd7b157c2e5e8105db99>@@XAAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_d67cddb616713624f417e1920c5d4f1a>@@XPAH@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_d67f1edeb5a550a32b15eb0a8d7351da>@@XV?$Map@V?$Matrix@M$0?0$00$0A@$0?0$00@Eigen@@$0A@V?$Stride@$0A@$0A@@2@@Eigen@@V?$Map@$$CBV?$Matrix@M$0?0$00$0A@$0?0$00@Eigen@@$0A@V?$Stride@$0A@$0A@@2@@3@M@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_d8797e74ae02acf212ef74610c438126>@@XAAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_d8b06a4dd6f551b1fc6c7009ad0ed428>@@XAAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_dda5ab6aaf4f2b6f6f3016e64f840ab7>@@XAAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_df8dc5d18b005334d023e86e4d511fb0>@@XAAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_e0a736eca6c1c042feb9e04770980ed3>@@XPAUILogger@CommonLogging@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_e0b2d86bba8462f4713d43f91e59ae58>@@XAAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_e4ee4ab01ca4c57467e724753c8bc334>@@XH@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_e846bfa317962339550ea10eeefad57e>@@VStatus@common@onnxruntime@@AAV?$shared_ptr@VModel@onnxruntime@@@std@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_e9b670853bb4fec4f493fcbcf0e350fb>@@VStatus@common@onnxruntime@@ABVNodeArg@4@I@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_ea73e250586924fb71aef6e9068c74b3>@@XAAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_ebf6ceac8f542e669deada19cbe0c1f1>@@XAAVOpSchema@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_edc5c5fafd47e3dd4a73efbd3e01dc01>@@XAAVOpSchema@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_ee3ccfb20f4bc599b4a53d7477866c58>@@VStatus@common@onnxruntime@@ABVTensorShape@4@ABUOrtAllocatorInfo@@AAUOrtValue@@AA_N@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_eedfabccf04dae8365cd4a4775f4c12a>@@XAAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_ef66392a9526daf4e7c269a18cebdf85>@@XV?$Map@V?$Matrix@M$0?0$00$0A@$0?0$00@Eigen@@$0A@V?$Stride@$0A@$0A@@2@@Eigen@@V?$Map@$$CBV?$Matrix@M$0?0$00$0A@$0?0$00@Eigen@@$0A@V?$Stride@$0A@$0A@@2@@3@M@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_efb13713d16ec9cd372290e4d816e310>@@XAAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_f075aa67626267fd6c7787bb3fe85619>@@XAAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_f238f1dfa23d313b56abeb489e569e80>@@X$$V@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_f78d8769dd40946ef61ad5956cbf10fe>@@XAAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_fab0569e655d52f18af3ccf270ee645c>@@XAAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_fbbfb9d846057a1988e21a7503609aa5>@@XAAVOpSchema@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_fc6f8774bf46030d1ec702a838d79614>@@VStatus@common@onnxruntime@@AAVGraph@4@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_fd66f022da42b8a18d5e26e8560bfb59>@@XAAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_fe5896b63222887f4439a4ae3de8a244>@@XAAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_ff02a1c545380d90edd1bec0e08a1239>@@XAAUInferenceContext@onnx@@@std@@
.?AV?$_Iosb@H@std@@
.?AV?$_Mpunct@_W@std@@
.?AV?$_Mpunct@D@std@@
.?AV?$_Mpunct@G@std@@
.?AV?$_Packaged_state@$$A6AXXZ@std@@
.?AV?$_Ref_count@VModel@onnxruntime@@@std@@
.?AV?$_Ref_count_obj@V?$unordered_map@V?$basic_string@DU?$char_traits@D@std@@V?$allocator@D@2@@std@@UFuncInfo@FuncManager@onnxruntime@@U?$hash@V?$basic_string@DU?$char_traits@D@std@@V?$allocator@D@2@@std@@@2@U?$equal_to@V?$basic_string@DU?$char_traits@D@std@@V?$allocator@D@2@@std@@@2@V?$allocator@U?$pair@$$CBV?$basic_string@DU?$char_traits@D@std@@V?$allocator@D@2@@std@@UFuncInfo@FuncManager@onnxruntime@@@std@@@2@@std@@@std@@
.?AV?$_Ref_count_obj@V?$unordered_map@V?$basic_string@DU?$char_traits@D@std@@V?$allocator@D@2@@std@@VTensorProto@onnx@@U?$hash@V?$basic_string@DU?$char_traits@D@std@@V?$allocator@D@2@@std@@@2@U?$equal_to@V?$basic_string@DU?$char_traits@D@std@@V?$allocator@D@2@@std@@@2@V?$allocator@U?$pair@$$CBV?$basic_string@DU?$char_traits@D@std@@V?$allocator@D@2@@std@@VTensorProto@onnx@@@std@@@2@@std@@@std@@
.?AV?$_Ref_count_obj@V__ExceptionPtr@@@std@@
.?AV?$_Ref_count_obj@VBarrierAssignment@Compilation@MLGraph@@@std@@
.?AV?$_Ref_count_obj@VBucketizedBufferAllocator@Dml@@@std@@
.?AV?$_Ref_count_obj@VBucketizedTensorAllocationAssignment@Compilation@MLGraph@@@std@@
.?AV?$_Ref_count_obj@VCommandQueue@Dml@@@std@@
.?AV?$_Ref_count_obj@VCompileOperators@Compilation@MLGraph@@@std@@
.?AV?$_Ref_count_obj@VCPUAllocator@Dml@@@std@@
.?AV?$_Ref_count_obj@VCustomRegistry@onnxruntime@@@std@@
.?AV?$_Ref_count_obj@VDMLOpaqueOperationDesc@DML@MLGraph@@@std@@
.?AV?$_Ref_count_obj@VExecutionContext@Dml@@@std@@
.?AV?$_Ref_count_obj@VExecutionOrder@Compilation@MLGraph@@@std@@
.?AV?$_Ref_count_obj@VExecutionPlan@DMLExecutionPlan@@@std@@
.?AV?$_Ref_count_obj@VInitializeLayout@Compilation@MLGraph@@@std@@
.?AV?$_Ref_count_obj@VKernelRegistry@onnxruntime@@@std@@
.?AV?$_Ref_count_obj@VLayoutAssignment@Compilation@MLGraph@@@std@@
.?AV?$_Ref_count_obj@VLiveness@Compilation@MLGraph@@@std@@
.?AV?$_Ref_count_obj@VNode@MLGraph@@@std@@
.?AV?$_Ref_count_obj@VNoOpRemoval@Compilation@MLGraph@@@std@@
.?AV?$_Ref_count_obj@VOnnxRuntimeOpSchemaRegistry@onnxruntime@@@std@@
.?AV?$_Ref_count_obj@VSchemaRegistryManager@onnxruntime@@@std@@
.?AV?$_Ref_count_obj@VTensor@MLGraph@@@std@@
.?AV?$_Ref_count_obj@VTensorAlignment@Compilation@MLGraph@@@std@@
.?AV?$_Ref_count_obj@VTensorAssignment@Compilation@MLGraph@@@std@@
.?AV?$_Ref_count_obj@VTensorConstness@Compilation@MLGraph@@@std@@
.?AV?$_Ref_count_obj_alloc@V__ExceptionPtr@@U?$_StaticAllocator@H@@@std@@
.?AV?$_Ref_count_resource@PAVBFCArena@onnxruntime@@U?$default_delete@VBFCArena@onnxruntime@@@std@@@std@@
.?AV?$_Ref_count_resource@PAVDummyArena@onnxruntime@@U?$default_delete@VDummyArena@onnxruntime@@@std@@@std@@
.?AV?$_Ref_count_resource@PAVIDeviceAllocator@onnxruntime@@U?$default_delete@VIDeviceAllocator@onnxruntime@@@std@@@std@@
.?AV?$_Ref_count_resource@PAXP6AXPAX@Z@std@@
.?AV?$Abs@_J@onnxruntime@@
.?AV?$Abs@_K@onnxruntime@@
.?AV?$Abs@C@onnxruntime@@
.?AV?$Abs@E@onnxruntime@@
.?AV?$Abs@F@onnxruntime@@
.?AV?$Abs@G@onnxruntime@@
.?AV?$Abs@H@onnxruntime@@
.?AV?$Abs@I@onnxruntime@@
.?AV?$Abs@M@onnxruntime@@
.?AV?$Abs@N@onnxruntime@@
.?AV?$Acos@M@onnxruntime@@
.?AV?$Acosh@M@onnxruntime@@
.?AV?$Add@_J@onnxruntime@@
.?AV?$Add@H@onnxruntime@@
.?AV?$Add@M@onnxruntime@@
.?AV?$Affine@M@contrib@onnxruntime@@
.?AV?$ArgMax@H@onnxruntime@@
.?AV?$ArgMax@M@onnxruntime@@
.?AV?$ArgMin@H@onnxruntime@@
.?AV?$ArgMin@M@onnxruntime@@
.?AV?$ArrayFeatureExtractorOp@_J@ml@onnxruntime@@
.?AV?$ArrayFeatureExtractorOp@H@ml@onnxruntime@@
.?AV?$ArrayFeatureExtractorOp@M@ml@onnxruntime@@
.?AV?$ArrayFeatureExtractorOp@N@ml@onnxruntime@@
.?AV?$ArrayFeatureExtractorOp@V?$basic_string@DU?$char_traits@D@std@@V?$allocator@D@2@@std@@@ml@onnxruntime@@
.?AV?$Asin@M@onnxruntime@@
.?AV?$Asinh@M@onnxruntime@@
.?AV?$Atan@M@onnxruntime@@
.?AV?$Atanh@M@onnxruntime@@
.?AV?$AttentionWrapper@M@contrib@onnxruntime@@
.?AV?$BahdanauAttention@M@contrib@onnxruntime@@
.?AV?$basic_filebuf@DU?$char_traits@D@std@@@std@@
.?AV?$basic_ifstream@DU?$char_traits@D@std@@@std@@
.?AV?$basic_ios@_WU?$char_traits@_W@std@@@std@@
.?AV?$basic_ios@DU?$char_traits@D@std@@@std@@
.?AV?$basic_iostream@DU?$char_traits@D@std@@@std@@
.?AV?$basic_istream@DU?$char_traits@D@std@@@std@@
.?AV?$basic_ofstream@DU?$char_traits@D@std@@@std@@
.?AV?$basic_ostream@_WU?$char_traits@_W@std@@@std@@
.?AV?$basic_ostream@DU?$char_traits@D@std@@@std@@
.?AV?$basic_ostringstream@_WU?$char_traits@_W@std@@V?$allocator@_W@2@@std@@
.?AV?$basic_ostringstream@DU?$char_traits@D@std@@V?$allocator@D@2@@std@@
.?AV?$basic_streambuf@_WU?$char_traits@_W@std@@@std@@
.?AV?$basic_streambuf@DU?$char_traits@D@std@@@std@@
.?AV?$basic_string@DU?$char_traits@D@std@@V?$allocator@D@2@@std@@
.?AV?$basic_stringbuf@_WU?$char_traits@_W@std@@V?$allocator@_W@2@@std@@
.?AV?$basic_stringbuf@DU?$char_traits@D@std@@V?$allocator@D@2@@std@@
.?AV?$basic_stringstream@DU?$char_traits@D@std@@V?$allocator@D@2@@std@@
.?AV?$BatchNorm@M@onnxruntime@@
.?AV?$BinarizerOp@M@ml@onnxruntime@@
.?AV?$Cast@_J@onnxruntime@@
.?AV?$Cast@_K@onnxruntime@@
.?AV?$Cast@_N@onnxruntime@@
.?AV?$Cast@C@onnxruntime@@
.?AV?$Cast@E@onnxruntime@@
.?AV?$Cast@F@onnxruntime@@
.?AV?$Cast@G@onnxruntime@@
.?AV?$Cast@H@onnxruntime@@
.?AV?$Cast@I@onnxruntime@@
.?AV?$Cast@M@onnxruntime@@
.?AV?$Cast@N@onnxruntime@@
.?AV?$Cast@TMLFloat16@onnxruntime@@@onnxruntime@@
.?AV?$Cast@V?$basic_string@DU?$char_traits@D@std@@V?$allocator@D@2@@std@@@onnxruntime@@
.?AV?$Ceil@M@onnxruntime@@
.?AV?$Clip@M@onnxruntime@@
.?AV?$codecvt@_WDU_Mbstatet@@@std@@
.?AV?$codecvt@DDU_Mbstatet@@@std@@
.?AV?$codecvt@GDU_Mbstatet@@@std@@
.?AV?$codecvt_utf8@_W$0BAPPPP@$0A@@std@@
.?AV?$collate@_W@std@@
.?AV?$collate@D@std@@
.?AV?$collate@G@std@@
.?AV?$Conv@M@onnxruntime@@
.?AV?$ConvTranspose@M@onnxruntime@@
.?AV?$Cos@M@onnxruntime@@
.?AV?$Cosh@M@onnxruntime@@
.?AV?$Crop@M@contrib@onnxruntime@@
.?AV?$ctype@_W@std@@
.?AV?$ctype@D@std@@
.?AV?$ctype@G@std@@
.?AV?$DepthToSpace@M@onnxruntime@@
.?AV?$DequantizeLinear@C@onnxruntime@@
.?AV?$DequantizeLinear@E@onnxruntime@@
.?AV?$DictVectorizerOp@_JM@ml@onnxruntime@@
.?AV?$DictVectorizerOp@_JN@ml@onnxruntime@@
.?AV?$DictVectorizerOp@_JV?$basic_string@DU?$char_traits@D@std@@V?$allocator@D@2@@std@@@ml@onnxruntime@@
.?AV?$DictVectorizerOp@V?$basic_string@DU?$char_traits@D@std@@V?$allocator@D@2@@std@@_J@ml@onnxruntime@@
.?AV?$DictVectorizerOp@V?$basic_string@DU?$char_traits@D@std@@V?$allocator@D@2@@std@@M@ml@onnxruntime@@
.?AV?$DictVectorizerOp@V?$basic_string@DU?$char_traits@D@std@@V?$allocator@D@2@@std@@N@ml@onnxruntime@@
.?AV?$Div@_J@onnxruntime@@
.?AV?$Div@H@onnxruntime@@
.?AV?$Div@M@onnxruntime@@
.?AV?$DmlOperatorActivationTemplate@$0CD@@Dml@@
.?AV?$DmlOperatorActivationTemplate@$0CE@@Dml@@
.?AV?$DmlOperatorActivationTemplate@$0CF@@Dml@@
.?AV?$DmlOperatorActivationTemplate@$0CG@@Dml@@
.?AV?$DmlOperatorActivationTemplate@$0CH@@Dml@@
.?AV?$DmlOperatorActivationTemplate@$0CJ@@Dml@@
.?AV?$DmlOperatorActivationTemplate@$0CK@@Dml@@
.?AV?$DmlOperatorActivationTemplate@$0CL@@Dml@@
.?AV?$DmlOperatorActivationTemplate@$0CM@@Dml@@
.?AV?$DmlOperatorActivationTemplate@$0CN@@Dml@@
.?AV?$DmlOperatorActivationTemplate@$0CO@@Dml@@
.?AV?$DmlOperatorActivationTemplate@$0CP@@Dml@@
.?AV?$DmlOperatorActivationTemplate@$0DA@@Dml@@
.?AV?$DmlOperatorActivationTemplate@$0DB@@Dml@@
.?AV?$DmlOperatorActivationTemplate@$0DC@@Dml@@
.?AV?$DmlOperatorActivationTemplate@$0DD@@Dml@@
.?AV?$DmlOperatorActivationTemplate@$0DE@@Dml@@
.?AV?$DmlOperatorActivationTemplate@$0FK@@Dml@@
.?AV?$DmlOperatorConvolutionTemplate@$00$00@Dml@@
.?AV?$DmlOperatorConvolutionTemplate@$00$0A@@Dml@@
.?AV?$DmlOperatorElementwiseBinary@UDML_ELEMENT_WISE_ADD_OPERATOR_DESC@@@Dml@@
.?AV?$DmlOperatorElementwiseBinary@UDML_ELEMENT_WISE_ADD1_OPERATOR_DESC@@@Dml@@
.?AV?$DmlOperatorElementwiseBinary@UDML_ELEMENT_WISE_DIVIDE_OPERATOR_DESC@@@Dml@@
.?AV?$DmlOperatorElementwiseBinary@UDML_ELEMENT_WISE_LOGICAL_AND_OPERATOR_DESC@@@Dml@@
.?AV?$DmlOperatorElementwiseBinary@UDML_ELEMENT_WISE_LOGICAL_EQUALS_OPERATOR_DESC@@@Dml@@
.?AV?$DmlOperatorElementwiseBinary@UDML_ELEMENT_WISE_LOGICAL_GREATER_THAN_OPERATOR_DESC@@@Dml@@
.?AV?$DmlOperatorElementwiseBinary@UDML_ELEMENT_WISE_LOGICAL_LESS_THAN_OPERATOR_DESC@@@Dml@@
.?AV?$DmlOperatorElementwiseBinary@UDML_ELEMENT_WISE_LOGICAL_OR_OPERATOR_DESC@@@Dml@@
.?AV?$DmlOperatorElementwiseBinary@UDML_ELEMENT_WISE_LOGICAL_XOR_OPERATOR_DESC@@@Dml@@
.?AV?$DmlOperatorElementwiseBinary@UDML_ELEMENT_WISE_MULTIPLY_OPERATOR_DESC@@@Dml@@
.?AV?$DmlOperatorElementwiseBinary@UDML_ELEMENT_WISE_SUBTRACT_OPERATOR_DESC@@@Dml@@
.?AV?$DmlOperatorElementwiseBinaryLoop@UDML_ELEMENT_WISE_ADD_OPERATOR_DESC@@@Dml@@
.?AV?$DmlOperatorElementwiseBinaryLoop@UDML_ELEMENT_WISE_ADD1_OPERATOR_DESC@@@Dml@@
.?AV?$DmlOperatorElementwiseBinaryLoop@UDML_ELEMENT_WISE_MAX_OPERATOR_DESC@@@Dml@@
.?AV?$DmlOperatorElementwiseBinaryLoop@UDML_ELEMENT_WISE_MIN_OPERATOR_DESC@@@Dml@@
.?AV?$DmlOperatorElementwiseQLinear@UDML_ELEMENT_WISE_DEQUANTIZE_LINEAR_OPERATOR_DESC@@@Dml@@
.?AV?$DmlOperatorElementwiseQLinear@UDML_ELEMENT_WISE_QUANTIZE_LINEAR_OPERATOR_DESC@@@Dml@@
.?AV?$DmlOperatorElementwiseUnary@UDML_ELEMENT_WISE_ABS_OPERATOR_DESC@@@Dml@@
.?AV?$DmlOperatorElementwiseUnary@UDML_ELEMENT_WISE_ACOS_OPERATOR_DESC@@@Dml@@
.?AV?$DmlOperatorElementwiseUnary@UDML_ELEMENT_WISE_ACOSH_OPERATOR_DESC@@@Dml@@
.?AV?$DmlOperatorElementwiseUnary@UDML_ELEMENT_WISE_ASIN_OPERATOR_DESC@@@Dml@@
.?AV?$DmlOperatorElementwiseUnary@UDML_ELEMENT_WISE_ASINH_OPERATOR_DESC@@@Dml@@
.?AV?$DmlOperatorElementwiseUnary@UDML_ELEMENT_WISE_ATAN_OPERATOR_DESC@@@Dml@@
.?AV?$DmlOperatorElementwiseUnary@UDML_ELEMENT_WISE_ATANH_OPERATOR_DESC@@@Dml@@
.?AV?$DmlOperatorElementwiseUnary@UDML_ELEMENT_WISE_CEIL_OPERATOR_DESC@@@Dml@@
.?AV?$DmlOperatorElementwiseUnary@UDML_ELEMENT_WISE_COS_OPERATOR_DESC@@@Dml@@
.?AV?$DmlOperatorElementwiseUnary@UDML_ELEMENT_WISE_COSH_OPERATOR_DESC@@@Dml@@
.?AV?$DmlOperatorElementwiseUnary@UDML_ELEMENT_WISE_ERF_OPERATOR_DESC@@@Dml@@
.?AV?$DmlOperatorElementwiseUnary@UDML_ELEMENT_WISE_EXP_OPERATOR_DESC@@@Dml@@
.?AV?$DmlOperatorElementwiseUnary@UDML_ELEMENT_WISE_FLOOR_OPERATOR_DESC@@@Dml@@
.?AV?$DmlOperatorElementwiseUnary@UDML_ELEMENT_WISE_IS_NAN_OPERATOR_DESC@@@Dml@@
.?AV?$DmlOperatorElementwiseUnary@UDML_ELEMENT_WISE_LOG_OPERATOR_DESC@@@Dml@@
.?AV?$DmlOperatorElementwiseUnary@UDML_ELEMENT_WISE_LOGICAL_NOT_OPERATOR_DESC@@@Dml@@
.?AV?$DmlOperatorElementwiseUnary@UDML_ELEMENT_WISE_RECIP_OPERATOR_DESC@@@Dml@@
.?AV?$DmlOperatorElementwiseUnary@UDML_ELEMENT_WISE_SIGN_OPERATOR_DESC@@@Dml@@
.?AV?$DmlOperatorElementwiseUnary@UDML_ELEMENT_WISE_SIN_OPERATOR_DESC@@@Dml@@
.?AV?$DmlOperatorElementwiseUnary@UDML_ELEMENT_WISE_SINH_OPERATOR_DESC@@@Dml@@
.?AV?$DmlOperatorElementwiseUnary@UDML_ELEMENT_WISE_SQRT_OPERATOR_DESC@@@Dml@@
.?AV?$DmlOperatorElementwiseUnary@UDML_ELEMENT_WISE_TAN_OPERATOR_DESC@@@Dml@@
.?AV?$DmlOperatorPoolingTemplate@$0DI@$00@Dml@@
.?AV?$DmlOperatorPoolingTemplate@$0DI@$0A@@Dml@@
.?AV?$DmlOperatorPoolingTemplate@$0DJ@$00@Dml@@
.?AV?$DmlOperatorPoolingTemplate@$0DJ@$0A@@Dml@@
.?AV?$DmlOperatorPoolingTemplate@$0DK@$00@Dml@@
.?AV?$DmlOperatorPoolingTemplate@$0FL@$0A@@Dml@@
.?AV?$DmlOperatorReduceTemplate@$00@Dml@@
.?AV?$DmlOperatorReduceTemplate@$01@Dml@@
.?AV?$DmlOperatorReduceTemplate@$02@Dml@@
.?AV?$DmlOperatorReduceTemplate@$03@Dml@@
.?AV?$DmlOperatorReduceTemplate@$04@Dml@@
.?AV?$DmlOperatorReduceTemplate@$05@Dml@@
.?AV?$DmlOperatorReduceTemplate@$06@Dml@@
.?AV?$DmlOperatorReduceTemplate@$07@Dml@@
.?AV?$DmlOperatorReduceTemplate@$08@Dml@@
.?AV?$DmlOperatorReduceTemplate@$09@Dml@@
.?AV?$DmlOperatorReduceTemplate@$0A@@Dml@@
.?AV?$DmlOperatorReduceTemplate@$0L@@Dml@@
.?AV?$Elu@M@onnxruntime@@
.?AV?$Equal@_J@onnxruntime@@
.?AV?$Equal@_N@onnxruntime@@
.?AV?$Equal@H@onnxruntime@@
.?AV?$Erf@M@onnxruntime@@
.?AV?$Exp@M@onnxruntime@@
.?AV?$Expand_8@_J@onnxruntime@@
.?AV?$Expand_8@_K@onnxruntime@@
.?AV?$Expand_8@_N@onnxruntime@@
.?AV?$Expand_8@C@onnxruntime@@
.?AV?$Expand_8@E@onnxruntime@@
.?AV?$Expand_8@F@onnxruntime@@
.?AV?$Expand_8@G@onnxruntime@@
.?AV?$Expand_8@H@onnxruntime@@
.?AV?$Expand_8@I@onnxruntime@@
.?AV?$Expand_8@M@onnxruntime@@
.?AV?$Expand_8@N@onnxruntime@@
.?AV?$Expand_8@TMLFloat16@onnxruntime@@@onnxruntime@@
.?AV?$Floor@M@onnxruntime@@
.?AV?$FusedConv@M@contrib@onnxruntime@@
.?AV?$FusedGemm@MMMM@contrib@onnxruntime@@
.?AV?$Gemm@MMMM@onnxruntime@@
.?AV?$Greater@H@onnxruntime@@
.?AV?$Greater@M@onnxruntime@@
.?AV?$Hardmax@M@onnxruntime@@
.?AV?$HardSigmoid@M@onnxruntime@@
.?AV?$IAttentionMechanism@M@contrib@onnxruntime@@
.?AV?$IdentityOp@$00@onnxruntime@@
.?AV?$IdentityOp@$0A@@onnxruntime@@
.?AV?$ImageScaler@M@contrib@onnxruntime@@
.?AV?$InstanceNorm@M@onnxruntime@@
.?AV?$IsNaN@M@onnxruntime@@
.?AV?$IsNaN@TMLFloat16@onnxruntime@@@onnxruntime@@
.?AV?$LeakyRelu@M@onnxruntime@@
.?AV?$Less@H@onnxruntime@@
.?AV?$Less@M@onnxruntime@@
.?AV?$LinearClassifier@_J@ml@onnxruntime@@
.?AV?$LinearClassifier@H@ml@onnxruntime@@
.?AV?$LinearClassifier@M@ml@onnxruntime@@
.?AV?$LinearClassifier@N@ml@onnxruntime@@
.?AV?$LinearRegressor@M@ml@onnxruntime@@
.?AV?$Log@M@onnxruntime@@
.?AV?$LogSoftmax@M@onnxruntime@@
.?AV?$LpNorm@M@onnxruntime@@
.?AV?$LRN@M@onnxruntime@@
.?AV?$map@_JMU?$less@_J@std@@V?$allocator@U?$pair@$$CB_JM@std@@@2@@std@@
.?AV?$map@V?$basic_string@DU?$char_traits@D@std@@V?$allocator@D@2@@std@@MU?$less@V?$basic_string@DU?$char_traits@D@std@@V?$allocator@D@2@@std@@@2@V?$allocator@U?$pair@$$CBV?$basic_string@DU?$char_traits@D@std@@V?$allocator@D@2@@std@@M@std@@@2@@std@@
.?AV?$MapType@V?$map@_J_JU?$less@_J@std@@V?$allocator@U?$pair@$$CB_J_J@std@@@2@@std@@@onnxruntime@@
.?AV?$MapType@V?$map@_JMU?$less@_J@std@@V?$allocator@U?$pair@$$CB_JM@std@@@2@@std@@@onnxruntime@@
.?AV?$MapType@V?$map@_JNU?$less@_J@std@@V?$allocator@U?$pair@$$CB_JN@std@@@2@@std@@@onnxruntime@@
.?AV?$MapType@V?$map@_JV?$basic_string@DU?$char_traits@D@std@@V?$allocator@D@2@@std@@U?$less@_J@2@V?$allocator@U?$pair@$$CB_JV?$basic_string@DU?$char_traits@D@std@@V?$allocator@D@2@@std@@@std@@@2@@std@@@onnxruntime@@
.?AV?$MapType@V?$map@V?$basic_string@DU?$char_traits@D@std@@V?$allocator@D@2@@std@@_JU?$less@V?$basic_string@DU?$char_traits@D@std@@V?$allocator@D@2@@std@@@2@V?$allocator@U?$pair@$$CBV?$basic_string@DU?$char_traits@D@std@@V?$allocator@D@2@@std@@_J@std@@@2@@std@@@onnxruntime@@
.?AV?$MapType@V?$map@V?$basic_string@DU?$char_traits@D@std@@V?$allocator@D@2@@std@@MU?$less@V?$basic_string@DU?$char_traits@D@std@@V?$allocator@D@2@@std@@@2@V?$allocator@U?$pair@$$CBV?$basic_string@DU?$char_traits@D@std@@V?$allocator@D@2@@std@@M@std@@@2@@std@@@onnxruntime@@
.?AV?$MapType@V?$map@V?$basic_string@DU?$char_traits@D@std@@V?$allocator@D@2@@std@@NU?$less@V?$basic_string@DU?$char_traits@D@std@@V?$allocator@D@2@@std@@@2@V?$allocator@U?$pair@$$CBV?$basic_string@DU?$char_traits@D@std@@V?$allocator@D@2@@std@@N@std@@@2@@std@@@onnxruntime@@
.?AV?$MapType@V?$map@V?$basic_string@DU?$char_traits@D@std@@V?$allocator@D@2@@std@@V12@U?$less@V?$basic_string@DU?$char_traits@D@std@@V?$allocator@D@2@@std@@@2@V?$allocator@U?$pair@$$CBV?$basic_string@DU?$char_traits@D@std@@V?$allocator@D@2@@std@@V12@@std@@@2@@std@@@onnxruntime@@
.?AV?$MatMul@_J@onnxruntime@@
.?AV?$MatMul@_K@onnxruntime@@
.?AV?$MatMul@H@onnxruntime@@
.?AV?$MatMul@I@onnxruntime@@
.?AV?$MatMul@M@onnxruntime@@
.?AV?$MatMul@N@onnxruntime@@
.?AV?$MatMulInteger@EEH@onnxruntime@@
.?AV?$Max_6@M@onnxruntime@@
.?AV?$Max_8@M@onnxruntime@@
.?AV?$Mean_6@M@onnxruntime@@
.?AV?$Mean_8@M@onnxruntime@@
.?AV?$MeanVarianceNormalization_0@M@onnxruntime@@
.?AV?$MeanVarianceNormalization_1@M@onnxruntime@@
.?AV?$messages@_W@std@@
.?AV?$messages@D@std@@
.?AV?$messages@G@std@@
.?AV?$Min_6@M@onnxruntime@@
.?AV?$Min_8@M@onnxruntime@@
.?AV?$MLOperatorKernel@V?$DmlOperatorActivationTemplate@$0CD@@Dml@@@@
.?AV?$MLOperatorKernel@V?$DmlOperatorActivationTemplate@$0CE@@Dml@@@@
.?AV?$MLOperatorKernel@V?$DmlOperatorActivationTemplate@$0CF@@Dml@@@@
.?AV?$MLOperatorKernel@V?$DmlOperatorActivationTemplate@$0CG@@Dml@@@@
.?AV?$MLOperatorKernel@V?$DmlOperatorActivationTemplate@$0CH@@Dml@@@@
.?AV?$MLOperatorKernel@V?$DmlOperatorActivationTemplate@$0CJ@@Dml@@@@
.?AV?$MLOperatorKernel@V?$DmlOperatorActivationTemplate@$0CK@@Dml@@@@
.?AV?$MLOperatorKernel@V?$DmlOperatorActivationTemplate@$0CL@@Dml@@@@
.?AV?$MLOperatorKernel@V?$DmlOperatorActivationTemplate@$0CM@@Dml@@@@
.?AV?$MLOperatorKernel@V?$DmlOperatorActivationTemplate@$0CN@@Dml@@@@
.?AV?$MLOperatorKernel@V?$DmlOperatorActivationTemplate@$0CO@@Dml@@@@
.?AV?$MLOperatorKernel@V?$DmlOperatorActivationTemplate@$0CP@@Dml@@@@
.?AV?$MLOperatorKernel@V?$DmlOperatorActivationTemplate@$0DA@@Dml@@@@
.?AV?$MLOperatorKernel@V?$DmlOperatorActivationTemplate@$0DB@@Dml@@@@
.?AV?$MLOperatorKernel@V?$DmlOperatorActivationTemplate@$0DC@@Dml@@@@
.?AV?$MLOperatorKernel@V?$DmlOperatorActivationTemplate@$0DD@@Dml@@@@
.?AV?$MLOperatorKernel@V?$DmlOperatorActivationTemplate@$0DE@@Dml@@@@
.?AV?$MLOperatorKernel@V?$DmlOperatorActivationTemplate@$0FK@@Dml@@@@
.?AV?$MLOperatorKernel@V?$DmlOperatorConvolutionTemplate@$00$00@Dml@@@@
.?AV?$MLOperatorKernel@V?$DmlOperatorConvolutionTemplate@$00$0A@@Dml@@@@
.?AV?$MLOperatorKernel@V?$DmlOperatorElementwiseBinary@UDML_ELEMENT_WISE_ADD_OPERATOR_DESC@@@Dml@@@@
.?AV?$MLOperatorKernel@V?$DmlOperatorElementwiseBinary@UDML_ELEMENT_WISE_ADD1_OPERATOR_DESC@@@Dml@@@@
.?AV?$MLOperatorKernel@V?$DmlOperatorElementwiseBinary@UDML_ELEMENT_WISE_DIVIDE_OPERATOR_DESC@@@Dml@@@@
.?AV?$MLOperatorKernel@V?$DmlOperatorElementwiseBinary@UDML_ELEMENT_WISE_LOGICAL_AND_OPERATOR_DESC@@@Dml@@@@
.?AV?$MLOperatorKernel@V?$DmlOperatorElementwiseBinary@UDML_ELEMENT_WISE_LOGICAL_EQUALS_OPERATOR_DESC@@@Dml@@@@
.?AV?$MLOperatorKernel@V?$DmlOperatorElementwiseBinary@UDML_ELEMENT_WISE_LOGICAL_GREATER_THAN_OPERATOR_DESC@@@Dml@@@@
.?AV?$MLOperatorKernel@V?$DmlOperatorElementwiseBinary@UDML_ELEMENT_WISE_LOGICAL_LESS_THAN_OPERATOR_DESC@@@Dml@@@@
.?AV?$MLOperatorKernel@V?$DmlOperatorElementwiseBinary@UDML_ELEMENT_WISE_LOGICAL_OR_OPERATOR_DESC@@@Dml@@@@
.?AV?$MLOperatorKernel@V?$DmlOperatorElementwiseBinary@UDML_ELEMENT_WISE_LOGICAL_XOR_OPERATOR_DESC@@@Dml@@@@
.?AV?$MLOperatorKernel@V?$DmlOperatorElementwiseBinary@UDML_ELEMENT_WISE_MULTIPLY_OPERATOR_DESC@@@Dml@@@@
.?AV?$MLOperatorKernel@V?$DmlOperatorElementwiseBinary@UDML_ELEMENT_WISE_SUBTRACT_OPERATOR_DESC@@@Dml@@@@
.?AV?$MLOperatorKernel@V?$DmlOperatorElementwiseBinaryLoop@UDML_ELEMENT_WISE_ADD_OPERATOR_DESC@@@Dml@@@@
.?AV?$MLOperatorKernel@V?$DmlOperatorElementwiseBinaryLoop@UDML_ELEMENT_WISE_ADD1_OPERATOR_DESC@@@Dml@@@@
.?AV?$MLOperatorKernel@V?$DmlOperatorElementwiseBinaryLoop@UDML_ELEMENT_WISE_MAX_OPERATOR_DESC@@@Dml@@@@
.?AV?$MLOperatorKernel@V?$DmlOperatorElementwiseBinaryLoop@UDML_ELEMENT_WISE_MIN_OPERATOR_DESC@@@Dml@@@@
.?AV?$MLOperatorKernel@V?$DmlOperatorElementwiseQLinear@UDML_ELEMENT_WISE_DEQUANTIZE_LINEAR_OPERATOR_DESC@@@Dml@@@@
.?AV?$MLOperatorKernel@V?$DmlOperatorElementwiseQLinear@UDML_ELEMENT_WISE_QUANTIZE_LINEAR_OPERATOR_DESC@@@Dml@@@@
.?AV?$MLOperatorKernel@V?$DmlOperatorElementwiseUnary@UDML_ELEMENT_WISE_ABS_OPERATOR_DESC@@@Dml@@@@
.?AV?$MLOperatorKernel@V?$DmlOperatorElementwiseUnary@UDML_ELEMENT_WISE_ACOS_OPERATOR_DESC@@@Dml@@@@
.?AV?$MLOperatorKernel@V?$DmlOperatorElementwiseUnary@UDML_ELEMENT_WISE_ACOSH_OPERATOR_DESC@@@Dml@@@@
.?AV?$MLOperatorKernel@V?$DmlOperatorElementwiseUnary@UDML_ELEMENT_WISE_ASIN_OPERATOR_DESC@@@Dml@@@@
.?AV?$MLOperatorKernel@V?$DmlOperatorElementwiseUnary@UDML_ELEMENT_WISE_ASINH_OPERATOR_DESC@@@Dml@@@@
.?AV?$MLOperatorKernel@V?$DmlOperatorElementwiseUnary@UDML_ELEMENT_WISE_ATAN_OPERATOR_DESC@@@Dml@@@@
.?AV?$MLOperatorKernel@V?$DmlOperatorElementwiseUnary@UDML_ELEMENT_WISE_ATANH_OPERATOR_DESC@@@Dml@@@@
.?AV?$MLOperatorKernel@V?$DmlOperatorElementwiseUnary@UDML_ELEMENT_WISE_CEIL_OPERATOR_DESC@@@Dml@@@@
.?AV?$MLOperatorKernel@V?$DmlOperatorElementwiseUnary@UDML_ELEMENT_WISE_COS_OPERATOR_DESC@@@Dml@@@@
.?AV?$MLOperatorKernel@V?$DmlOperatorElementwiseUnary@UDML_ELEMENT_WISE_COSH_OPERATOR_DESC@@@Dml@@@@
.?AV?$MLOperatorKernel@V?$DmlOperatorElementwiseUnary@UDML_ELEMENT_WISE_ERF_OPERATOR_DESC@@@Dml@@@@
.?AV?$MLOperatorKernel@V?$DmlOperatorElementwiseUnary@UDML_ELEMENT_WISE_EXP_OPERATOR_DESC@@@Dml@@@@
.?AV?$MLOperatorKernel@V?$DmlOperatorElementwiseUnary@UDML_ELEMENT_WISE_FLOOR_OPERATOR_DESC@@@Dml@@@@
.?AV?$MLOperatorKernel@V?$DmlOperatorElementwiseUnary@UDML_ELEMENT_WISE_IS_NAN_OPERATOR_DESC@@@Dml@@@@
.?AV?$MLOperatorKernel@V?$DmlOperatorElementwiseUnary@UDML_ELEMENT_WISE_LOG_OPERATOR_DESC@@@Dml@@@@
.?AV?$MLOperatorKernel@V?$DmlOperatorElementwiseUnary@UDML_ELEMENT_WISE_LOGICAL_NOT_OPERATOR_DESC@@@Dml@@@@
.?AV?$MLOperatorKernel@V?$DmlOperatorElementwiseUnary@UDML_ELEMENT_WISE_RECIP_OPERATOR_DESC@@@Dml@@@@
.?AV?$MLOperatorKernel@V?$DmlOperatorElementwiseUnary@UDML_ELEMENT_WISE_SIGN_OPERATOR_DESC@@@Dml@@@@
.?AV?$MLOperatorKernel@V?$DmlOperatorElementwiseUnary@UDML_ELEMENT_WISE_SIN_OPERATOR_DESC@@@Dml@@@@
.?AV?$MLOperatorKernel@V?$DmlOperatorElementwiseUnary@UDML_ELEMENT_WISE_SINH_OPERATOR_DESC@@@Dml@@@@
.?AV?$MLOperatorKernel@V?$DmlOperatorElementwiseUnary@UDML_ELEMENT_WISE_SQRT_OPERATOR_DESC@@@Dml@@@@
.?AV?$MLOperatorKernel@V?$DmlOperatorElementwiseUnary@UDML_ELEMENT_WISE_TAN_OPERATOR_DESC@@@Dml@@@@
.?AV?$MLOperatorKernel@V?$DmlOperatorPoolingTemplate@$0DI@$00@Dml@@@@
.?AV?$MLOperatorKernel@V?$DmlOperatorPoolingTemplate@$0DI@$0A@@Dml@@@@
.?AV?$MLOperatorKernel@V?$DmlOperatorPoolingTemplate@$0DJ@$00@Dml@@@@
.?AV?$MLOperatorKernel@V?$DmlOperatorPoolingTemplate@$0DJ@$0A@@Dml@@@@
.?AV?$MLOperatorKernel@V?$DmlOperatorPoolingTemplate@$0DK@$00@Dml@@@@
.?AV?$MLOperatorKernel@V?$DmlOperatorPoolingTemplate@$0FL@$0A@@Dml@@@@
.?AV?$MLOperatorKernel@V?$DmlOperatorReduceTemplate@$00@Dml@@@@
.?AV?$MLOperatorKernel@V?$DmlOperatorReduceTemplate@$01@Dml@@@@
.?AV?$MLOperatorKernel@V?$DmlOperatorReduceTemplate@$02@Dml@@@@
.?AV?$MLOperatorKernel@V?$DmlOperatorReduceTemplate@$03@Dml@@@@
.?AV?$MLOperatorKernel@V?$DmlOperatorReduceTemplate@$04@Dml@@@@
.?AV?$MLOperatorKernel@V?$DmlOperatorReduceTemplate@$05@Dml@@@@
.?AV?$MLOperatorKernel@V?$DmlOperatorReduceTemplate@$06@Dml@@@@
.?AV?$MLOperatorKernel@V?$DmlOperatorReduceTemplate@$07@Dml@@@@
.?AV?$MLOperatorKernel@V?$DmlOperatorReduceTemplate@$08@Dml@@@@
.?AV?$MLOperatorKernel@V?$DmlOperatorReduceTemplate@$09@Dml@@@@
.?AV?$MLOperatorKernel@V?$DmlOperatorReduceTemplate@$0A@@Dml@@@@
.?AV?$MLOperatorKernel@V?$DmlOperatorReduceTemplate@$0L@@Dml@@@@
.?AV?$MLOperatorKernel@VDmlOperatorAffine@Dml@@@@
.?AV?$MLOperatorKernel@VDmlOperatorBatchNormalization@Dml@@@@
.?AV?$MLOperatorKernel@VDmlOperatorCast@Dml@@@@
.?AV?$MLOperatorKernel@VDmlOperatorConcat@Dml@@@@
.?AV?$MLOperatorKernel@VDmlOperatorConstantOfShape@Dml@@@@
.?AV?$MLOperatorKernel@VDmlOperatorCopy@Dml@@@@
.?AV?$MLOperatorKernel@VDmlOperatorCrop@Dml@@@@
.?AV?$MLOperatorKernel@VDmlOperatorDepthToSpace@Dml@@@@
.?AV?$MLOperatorKernel@VDmlOperatorElementwiseClip@Dml@@@@
.?AV?$MLOperatorKernel@VDmlOperatorElementwiseIf@Dml@@@@
.?AV?$MLOperatorKernel@VDmlOperatorElementwiseMean@Dml@@@@
.?AV?$MLOperatorKernel@VDmlOperatorElementwisePow@Dml@@@@
.?AV?$MLOperatorKernel@VDmlOperatorExpand@Dml@@@@
.?AV?$MLOperatorKernel@VDmlOperatorEyeLike@Dml@@@@
.?AV?$MLOperatorKernel@VDmlOperatorGatedRecurrentUnit@Dml@@@@
.?AV?$MLOperatorKernel@VDmlOperatorGather@Dml@@@@
.?AV?$MLOperatorKernel@VDmlOperatorGemm@Dml@@@@
.?AV?$MLOperatorKernel@VDmlOperatorInstanceNormalization@Dml@@@@
.?AV?$MLOperatorKernel@VDmlOperatorLocalResponseNormalization@Dml@@@@
.?AV?$MLOperatorKernel@VDmlOperatorLongShortTermUnit@Dml@@@@
.?AV?$MLOperatorKernel@VDmlOperatorLpNormalization@Dml@@@@
.?AV?$MLOperatorKernel@VDmlOperatorMatMul@Dml@@@@
.?AV?$MLOperatorKernel@VDmlOperatorMaxUnpool@Dml@@@@
.?AV?$MLOperatorKernel@VDmlOperatorMeanVarNormalization@Dml@@@@
.?AV?$MLOperatorKernel@VDmlOperatorMemcpy@Dml@@@@
.?AV?$MLOperatorKernel@VDmlOperatorNeg@Dml@@@@
.?AV?$MLOperatorKernel@VDmlOperatorOneHot@Dml@@@@
.?AV?$MLOperatorKernel@VDmlOperatorPadding@Dml@@@@
.?AV?$MLOperatorKernel@VDmlOperatorRecurrentNeuralNetwork@Dml@@@@
.?AV?$MLOperatorKernel@VDmlOperatorRegionOfInterestPooling@Dml@@@@
.?AV?$MLOperatorKernel@VDmlOperatorResize@Dml@@@@
.?AV?$MLOperatorKernel@VDmlOperatorScatter@Dml@@@@
.?AV?$MLOperatorKernel@VDmlOperatorSlice@Dml@@@@
.?AV?$MLOperatorKernel@VDmlOperatorSpaceToDepth@Dml@@@@
.?AV?$MLOperatorKernel@VDmlOperatorSplit@Dml@@@@
.?AV?$MLOperatorKernel@VDmlOperatorTile@Dml@@@@
.?AV?$MLOperatorKernel@VDmlOperatorTopK@Dml@@@@
.?AV?$MLOperatorKernel@VDmlOperatorTranspose@Dml@@@@
.?AV?$MLOperatorKernel@VDmlOperatorValueScale2d@Dml@@@@
.?AV?$money_get@_WV?$istreambuf_iterator@_WU?$char_traits@_W@std@@@std@@@std@@
.?AV?$money_get@DV?$istreambuf_iterator@DU?$char_traits@D@std@@@std@@@std@@
.?AV?$money_get@GV?$istreambuf_iterator@GU?$char_traits@G@std@@@std@@@std@@
.?AV?$money_put@_WV?$ostreambuf_iterator@_WU?$char_traits@_W@std@@@std@@@std@@
.?AV?$money_put@DV?$ostreambuf_iterator@DU?$char_traits@D@std@@@std@@@std@@
.?AV?$money_put@GV?$ostreambuf_iterator@GU?$char_traits@G@std@@@std@@@std@@
.?AV?$moneypunct@_W$00@std@@
.?AV?$moneypunct@_W$0A@@std@@
.?AV?$moneypunct@D$00@std@@
.?AV?$moneypunct@D$0A@@std@@
.?AV?$moneypunct@G$00@std@@
.?AV?$moneypunct@G$0A@@std@@
.?AV?$Mul@_J@onnxruntime@@
.?AV?$Mul@H@onnxruntime@@
.?AV?$Mul@M@onnxruntime@@
.?AV?$Mul@N@onnxruntime@@
.?AV?$Neg@C@onnxruntime@@
.?AV?$Neg@H@onnxruntime@@
.?AV?$Neg@M@onnxruntime@@
.?AV?$NonOnnxType@_J@onnxruntime@@
.?AV?$NonOnnxType@_K@onnxruntime@@
.?AV?$NonOnnxType@_N@onnxruntime@@
.?AV?$NonOnnxType@C@onnxruntime@@
.?AV?$NonOnnxType@E@onnxruntime@@
.?AV?$NonOnnxType@F@onnxruntime@@
.?AV?$NonOnnxType@G@onnxruntime@@
.?AV?$NonOnnxType@H@onnxruntime@@
.?AV?$NonOnnxType@I@onnxruntime@@
.?AV?$NonOnnxType@M@onnxruntime@@
.?AV?$NonOnnxType@N@onnxruntime@@
.?AV?$NonOnnxType@TMLFloat16@onnxruntime@@@onnxruntime@@
.?AV?$NonOnnxType@UBFloat16@onnxruntime@@@onnxruntime@@
.?AV?$NonOnnxType@V?$basic_string@DU?$char_traits@D@std@@V?$allocator@D@2@@std@@@onnxruntime@@
.?AV?$NonTensorType@V?$map@_J_JU?$less@_J@std@@V?$allocator@U?$pair@$$CB_J_J@std@@@2@@std@@@onnxruntime@@
.?AV?$NonTensorType@V?$map@_JMU?$less@_J@std@@V?$allocator@U?$pair@$$CB_JM@std@@@2@@std@@@onnxruntime@@
.?AV?$NonTensorType@V?$map@_JNU?$less@_J@std@@V?$allocator@U?$pair@$$CB_JN@std@@@2@@std@@@onnxruntime@@
.?AV?$NonTensorType@V?$map@_JV?$basic_string@DU?$char_traits@D@std@@V?$allocator@D@2@@std@@U?$less@_J@2@V?$allocator@U?$pair@$$CB_JV?$basic_string@DU?$char_traits@D@std@@V?$allocator@D@2@@std@@@std@@@2@@std@@@onnxruntime@@
.?AV?$NonTensorType@V?$map@V?$basic_string@DU?$char_traits@D@std@@V?$allocator@D@2@@std@@_JU?$less@V?$basic_string@DU?$char_traits@D@std@@V?$allocator@D@2@@std@@@2@V?$allocator@U?$pair@$$CBV?$basic_string@DU?$char_traits@D@std@@V?$allocator@D@2@@std@@_J@std@@@2@@std@@@onnxruntime@@
.?AV?$NonTensorType@V?$map@V?$basic_string@DU?$char_traits@D@std@@V?$allocator@D@2@@std@@MU?$less@V?$basic_string@DU?$char_traits@D@std@@V?$allocator@D@2@@std@@@2@V?$allocator@U?$pair@$$CBV?$basic_string@DU?$char_traits@D@std@@V?$allocator@D@2@@std@@M@std@@@2@@std@@@onnxruntime@@
.?AV?$NonTensorType@V?$map@V?$basic_string@DU?$char_traits@D@std@@V?$allocator@D@2@@std@@NU?$less@V?$basic_string@DU?$char_traits@D@std@@V?$allocator@D@2@@std@@@2@V?$allocator@U?$pair@$$CBV?$basic_string@DU?$char_traits@D@std@@V?$allocator@D@2@@std@@N@std@@@2@@std@@@onnxruntime@@
.?AV?$NonTensorType@V?$map@V?$basic_string@DU?$char_traits@D@std@@V?$allocator@D@2@@std@@V12@U?$less@V?$basic_string@DU?$char_traits@D@std@@V?$allocator@D@2@@std@@@2@V?$allocator@U?$pair@$$CBV?$basic_string@DU?$char_traits@D@std@@V?$allocator@D@2@@std@@V12@@std@@@2@@std@@@onnxruntime@@
.?AV?$NonTensorType@V?$vector@_JV?$allocator@_J@std@@@std@@@onnxruntime@@
.?AV?$NonTensorType@V?$vector@MV?$allocator@M@std@@@std@@@onnxruntime@@
.?AV?$NonTensorType@V?$vector@NV?$allocator@N@std@@@std@@@onnxruntime@@
.?AV?$NonTensorType@V?$vector@V?$basic_string@DU?$char_traits@D@std@@V?$allocator@D@2@@std@@V?$allocator@V?$basic_string@DU?$char_traits@D@std@@V?$allocator@D@2@@std@@@2@@std@@@onnxruntime@@
.?AV?$NonTensorType@V?$vector@V?$map@_JMU?$less@_J@std@@V?$allocator@U?$pair@$$CB_JM@std@@@2@@std@@V?$allocator@V?$map@_JMU?$less@_J@std@@V?$allocator@U?$pair@$$CB_JM@std@@@2@@std@@@2@@std@@@onnxruntime@@
.?AV?$NonTensorType@V?$vector@V?$map@V?$basic_string@DU?$char_traits@D@std@@V?$allocator@D@2@@std@@MU?$less@V?$basic_string@DU?$char_traits@D@std@@V?$allocator@D@2@@std@@@2@V?$allocator@U?$pair@$$CBV?$basic_string@DU?$char_traits@D@std@@V?$allocator@D@2@@std@@M@std@@@2@@std@@V?$allocator@V?$map@V?$basic_string@DU?$char_traits@D@std@@V?$allocator@D@2@@std@@MU?$less@V?$basic_string@DU?$char_traits@D@std@@V?$allocator@D@2@@std@@@2@V?$allocator@U?$pair@$$CBV?$basic_string@DU?$char_traits@D@std@@V?$allocator@D@2@@std@@M@std@@@2@@std@@@2@@std@@@onnxruntime@@
.?AV?$NonZero@_J@onnxruntime@@
.?AV?$NonZero@_N@onnxruntime@@
.?AV?$NonZero@H@onnxruntime@@
.?AV?$NonZero@M@onnxruntime@@
.?AV?$num_get@_WV?$istreambuf_iterator@_WU?$char_traits@_W@std@@@std@@@std@@
.?AV?$num_get@DV?$istreambuf_iterator@DU?$char_traits@D@std@@@std@@@std@@
.?AV?$num_get@GV?$istreambuf_iterator@GU?$char_traits@G@std@@@std@@@std@@
.?AV?$num_put@_WV?$ostreambuf_iterator@_WU?$char_traits@_W@std@@@std@@@std@@
.?AV?$num_put@DV?$ostreambuf_iterator@DU?$char_traits@D@std@@@std@@@std@@
.?AV?$num_put@GV?$ostreambuf_iterator@GU?$char_traits@G@std@@@std@@@std@@
.?AV?$numpunct@_W@std@@
.?AV?$numpunct@D@std@@
.?AV?$numpunct@G@std@@
.?AV?$OneHotEncoderOp@_J@ml@onnxruntime@@
.?AV?$OneHotEncoderOp@M@ml@onnxruntime@@
.?AV?$OneHotEncoderOp@N@ml@onnxruntime@@
.?AV?$OneHotEncoderOp@V?$basic_string@DU?$char_traits@D@std@@V?$allocator@D@2@@std@@@ml@onnxruntime@@
.?AV?$OneHotOp@_J_J_J@onnxruntime@@
.?AV?$OneHotOp@_JHM@onnxruntime@@
.?AV?$OneHotOp@_JM_J@onnxruntime@@
.?AV?$OneHotOp@_JV?$basic_string@DU?$char_traits@D@std@@V?$allocator@D@2@@std@@_J@onnxruntime@@
.?AV?$OneHotOp@M_J_J@onnxruntime@@
.?AV?$OneHotOp@MMM@onnxruntime@@
.?AV?$OneHotOp@MV?$basic_string@DU?$char_traits@D@std@@V?$allocator@D@2@@std@@_J@onnxruntime@@
.?AV?$ParametricSoftplus@M@onnxruntime@@
.?AV?$Pool@MV?$MaxPool@$00@onnxruntime@@@onnxruntime@@
.?AV?$Pool@MV?$MaxPool@$07@onnxruntime@@@onnxruntime@@
.?AV?$Pool@MVAveragePool@onnxruntime@@@onnxruntime@@
.?AV?$Pool@MVLpPool@onnxruntime@@@onnxruntime@@
.?AV?$Pow@M@onnxruntime@@
.?AV?$PRelu@M@onnxruntime@@
.?AV?$QLinearMatMul@EEE@onnxruntime@@
.?AV?$QuantizeLinear@C@onnxruntime@@
.?AV?$QuantizeLinear@E@onnxruntime@@
.?AV?$Reciprocal@M@onnxruntime@@
.?AV?$ReduceKernel@$00@onnxruntime@@
.?AV?$ReduceKernel@$0A@@onnxruntime@@
.?AV?$ReduceKernelBase@$00@onnxruntime@@
.?AV?$ReduceKernelBase@$0A@@onnxruntime@@
.?AV?$ReduceL1@H@onnxruntime@@
.?AV?$ReduceL1@M@onnxruntime@@
.?AV?$ReduceL2@H@onnxruntime@@
.?AV?$ReduceL2@M@onnxruntime@@
.?AV?$ReduceLogSum@H@onnxruntime@@
.?AV?$ReduceLogSum@M@onnxruntime@@
.?AV?$ReduceLogSumExp@H@onnxruntime@@
.?AV?$ReduceLogSumExp@M@onnxruntime@@
.?AV?$ReduceMax@H@onnxruntime@@
.?AV?$ReduceMax@M@onnxruntime@@
.?AV?$ReduceMean@H@onnxruntime@@
.?AV?$ReduceMean@M@onnxruntime@@
.?AV?$ReduceMin@H@onnxruntime@@
.?AV?$ReduceMin@M@onnxruntime@@
.?AV?$ReduceProd@H@onnxruntime@@
.?AV?$ReduceProd@M@onnxruntime@@
.?AV?$ReduceSum@H@onnxruntime@@
.?AV?$ReduceSum@M@onnxruntime@@
.?AV?$ReduceSumSquare@H@onnxruntime@@
.?AV?$ReduceSumSquare@M@onnxruntime@@
.?AV?$Relu@M@onnxruntime@@
.?AV?$Resize@E@onnxruntime@@
.?AV?$Resize@H@onnxruntime@@
.?AV?$Resize@M@onnxruntime@@
.?AV?$RNN@M@onnxruntime@@
.?AV?$RoiAlign@M@onnxruntime@@
.?AV?$RoiAlign@N@onnxruntime@@
.?AV?$RoiPool@M@onnxruntime@@
.?AV?$RuntimeClass@U?$RuntimeClassFlags@$01@WRL@Microsoft@@UIExecutionProvider@Dml@@UIWinmlExecutionProvider@implementation@MachineLearning@AI@Windows@winrt@@@WRL@Microsoft@@
.?AV?$RuntimeClass@U?$RuntimeClassFlags@$01@WRL@Microsoft@@UIMLOperatorKernel@@@WRL@Microsoft@@
.?AV?$RuntimeClass@U?$RuntimeClassFlags@$01@WRL@Microsoft@@UIMLOperatorKernelFactory@@@WRL@Microsoft@@
.?AV?$RuntimeClass@U?$RuntimeClassFlags@$01@WRL@Microsoft@@UIMLOperatorShapeInferrer@@@WRL@Microsoft@@
.?AV?$RuntimeClass@U?$RuntimeClassFlags@$01@WRL@Microsoft@@UIUnknown@@@WRL@Microsoft@@
.?AV?$RuntimeClassBaseT@$01@Details@WRL@Microsoft@@
.?AV?$RuntimeClassImpl@U?$RuntimeClassFlags@$01@WRL@Microsoft@@$00$0A@$00UIExecutionProvider@Dml@@UIWinmlExecutionProvider@implementation@MachineLearning@AI@Windows@winrt@@@Details@WRL@Microsoft@@
.?AV?$RuntimeClassImpl@U?$RuntimeClassFlags@$01@WRL@Microsoft@@$00$0A@$00UIMLOperatorKernel@@@Details@WRL@Microsoft@@
.?AV?$RuntimeClassImpl@U?$RuntimeClassFlags@$01@WRL@Microsoft@@$00$0A@$00UIMLOperatorKernelFactory@@@Details@WRL@Microsoft@@
.?AV?$RuntimeClassImpl@U?$RuntimeClassFlags@$01@WRL@Microsoft@@$00$0A@$00UIMLOperatorShapeInferrer@@@Details@WRL@Microsoft@@
.?AV?$RuntimeClassImpl@U?$RuntimeClassFlags@$01@WRL@Microsoft@@$00$0A@$00UIUnknown@@@Details@WRL@Microsoft@@
.?AV?$SampleOp@M@contrib@onnxruntime@@
.?AV?$Scale@M@contrib@onnxruntime@@
.?AV?$ScaledTanh@M@contrib@onnxruntime@@
.?AV?$ScalerOp@_J@ml@onnxruntime@@
.?AV?$ScalerOp@H@ml@onnxruntime@@
.?AV?$ScalerOp@M@ml@onnxruntime@@
.?AV?$ScalerOp@N@ml@onnxruntime@@
.?AV?$Scan@$07@onnxruntime@@
.?AV?$Scan@$08@onnxruntime@@
.?AV?$Selu@M@onnxruntime@@
.?AV?$SequenceType@V?$vector@_JV?$allocator@_J@std@@@std@@@onnxruntime@@
.?AV?$SequenceType@V?$vector@MV?$allocator@M@std@@@std@@@onnxruntime@@
.?AV?$SequenceType@V?$vector@NV?$allocator@N@std@@@std@@@onnxruntime@@
.?AV?$SequenceType@V?$vector@V?$basic_string@DU?$char_traits@D@std@@V?$allocator@D@2@@std@@V?$allocator@V?$basic_string@DU?$char_traits@D@std@@V?$allocator@D@2@@std@@@2@@std@@@onnxruntime@@
.?AV?$SequenceType@V?$vector@V?$map@_JMU?$less@_J@std@@V?$allocator@U?$pair@$$CB_JM@std@@@2@@std@@V?$allocator@V?$map@_JMU?$less@_J@std@@V?$allocator@U?$pair@$$CB_JM@std@@@2@@std@@@2@@std@@@onnxruntime@@
.?AV?$SequenceType@V?$vector@V?$map@V?$basic_string@DU?$char_traits@D@std@@V?$allocator@D@2@@std@@MU?$less@V?$basic_string@DU?$char_traits@D@std@@V?$allocator@D@2@@std@@@2@V?$allocator@U?$pair@$$CBV?$basic_string@DU?$char_traits@D@std@@V?$allocator@D@2@@std@@M@std@@@2@@std@@V?$allocator@V?$map@V?$basic_string@DU?$char_traits@D@std@@V?$allocator@D@2@@std@@MU?$less@V?$basic_string@DU?$char_traits@D@std@@V?$allocator@D@2@@std@@@2@V?$allocator@U?$pair@$$CBV?$basic_string@DU?$char_traits@D@std@@V?$allocator@D@2@@std@@M@std@@@2@@std@@@2@@std@@@onnxruntime@@
.?AV?$Sigmoid@M@onnxruntime@@
.?AV?$Sin@M@onnxruntime@@
.?AV?$Sinh@M@onnxruntime@@
.?AV?$Softmax@M@onnxruntime@@
.?AV?$Softsign@M@onnxruntime@@
.?AV?$SpaceToDepth@M@onnxruntime@@
.?AV?$Sqrt@M@onnxruntime@@
.?AV?$Sub@_J@onnxruntime@@
.?AV?$Sub@H@onnxruntime@@
.?AV?$Sub@M@onnxruntime@@
.?AV?$Sum_6@M@onnxruntime@@
.?AV?$Sum_8@M@onnxruntime@@
.?AV?$SVMClassifier@_J@ml@onnxruntime@@
.?AV?$SVMClassifier@H@ml@onnxruntime@@
.?AV?$SVMClassifier@M@ml@onnxruntime@@
.?AV?$SVMClassifier@N@ml@onnxruntime@@
.?AV?$SVMCommon@_J@ml@onnxruntime@@
.?AV?$SVMCommon@H@ml@onnxruntime@@
.?AV?$SVMCommon@M@ml@onnxruntime@@
.?AV?$SVMCommon@N@ml@onnxruntime@@
.?AV?$SVMRegressor@M@ml@onnxruntime@@
.?AV?$Tan@M@onnxruntime@@
.?AV?$Tanh@M@onnxruntime@@
.?AV?$TensorType@_J@onnxruntime@@
.?AV?$TensorType@_K@onnxruntime@@
.?AV?$TensorType@_N@onnxruntime@@
.?AV?$TensorType@C@onnxruntime@@
.?AV?$TensorType@E@onnxruntime@@
.?AV?$TensorType@F@onnxruntime@@
.?AV?$TensorType@G@onnxruntime@@
.?AV?$TensorType@H@onnxruntime@@
.?AV?$TensorType@I@onnxruntime@@
.?AV?$TensorType@M@onnxruntime@@
.?AV?$TensorType@N@onnxruntime@@
.?AV?$TensorType@TMLFloat16@onnxruntime@@@onnxruntime@@
.?AV?$TensorType@UBFloat16@onnxruntime@@@onnxruntime@@
.?AV?$TensorType@V?$basic_string@DU?$char_traits@D@std@@V?$allocator@D@2@@std@@@onnxruntime@@
.?AV?$ThresholdedRelu@M@onnxruntime@@
.?AV?$time_get@_WV?$istreambuf_iterator@_WU?$char_traits@_W@std@@@std@@@std@@
.?AV?$time_get@DV?$istreambuf_iterator@DU?$char_traits@D@std@@@std@@@std@@
.?AV?$time_get@GV?$istreambuf_iterator@GU?$char_traits@G@std@@@std@@@std@@
.?AV?$time_put@_WV?$ostreambuf_iterator@_WU?$char_traits@_W@std@@@std@@@std@@
.?AV?$time_put@DV?$ostreambuf_iterator@DU?$char_traits@D@std@@@std@@@std@@
.?AV?$time_put@GV?$ostreambuf_iterator@GU?$char_traits@G@std@@@std@@@std@@
.?AV?$TopK@$08M@onnxruntime@@
.?AV?$TopK@$09M@onnxruntime@@
.?AV?$TreeEnsembleClassifier@_J@ml@onnxruntime@@
.?AV?$TreeEnsembleClassifier@H@ml@onnxruntime@@
.?AV?$TreeEnsembleClassifier@M@ml@onnxruntime@@
.?AV?$TreeEnsembleClassifier@N@ml@onnxruntime@@
.?AV?$TreeEnsembleRegressor@M@ml@onnxruntime@@
.?AV?$Unique@M@contrib@onnxruntime@@
.?AV?$Upsample@E@onnxruntime@@
.?AV?$Upsample@H@onnxruntime@@
.?AV?$Upsample@M@onnxruntime@@
.?AV?$Walker@H@Regexp@re2@@
.?AV?$Walker@PAVRegexp@re2@@@Regexp@re2@@
.?AV?$Walker@UFrag@re2@@@Regexp@re2@@
.?AV?$Where@H@onnxruntime@@
.?AV?$Where@M@onnxruntime@@
.?AV?$Where@V?$basic_string@DU?$char_traits@D@std@@V?$allocator@D@2@@std@@@onnxruntime@@
.?AV?$wstring_convert@V?$codecvt_utf8@_W$0BAPPPP@$0A@@std@@_WV?$allocator@_W@2@V?$allocator@D@2@@std@@
.?AV_Facet_base@std@@
.?AV_Future_error_category@std@@
.?AV_Generic_error_category@std@@
.?AV_Iostream_error_category@std@@
.?AV_Locimp@locale@std@@
.?AV_Ref_count_base@std@@
.?AV_System_error@std@@
.?AV_System_error_category@std@@
.?AV<lambda_006f042491572090b778a6887556c541>@@
.?AV<lambda_00bc1d3067b0daca44118c6bf6182fe6>@@
.?AV<lambda_00c87c7b53d371a1cf60b7c0c451f8f8>@@
.?AV<lambda_010a062bd559bce238b9185468d50447>@@
.?AV<lambda_01985760e667ba58bff711ef31d8e638>@@
.?AV<lambda_027f0b72d20b824e4e30fa2ccfde3681>@@
.?AV<lambda_03f9a416ba9956cce684677e892ba331>@@
.?AV<lambda_05139462a1d0ad358a8c7449ca410e71>@@
.?AV<lambda_054344795ce74e2e037e3c05c0b91898>@@
.?AV<lambda_065b736e14c0a7e0e54f780ff5ff8570>@@
.?AV<lambda_0694ea05552b0a9881da068d49a8f534>@@
.?AV<lambda_06f0a46d4083d6cb6bc408c03994b5c5>@@
.?AV<lambda_0778a4cf53183ad367a412434c098397>@@
.?AV<lambda_080c558b14f0136c6a1d29b6b83b56e4>@@
.?AV<lambda_08accd2c56d1c3539bdbe39ead72e813>@@
.?AV<lambda_12614fe07b000bac4d9f90f7d831265d>@@
.?AV<lambda_12c274da604ed254f4e0fb7954f6465d>@@
.?AV<lambda_1476157c6a284e4f379191854345eea5>@@
.?AV<lambda_1557398f94c0db7066f5e254ef45fbcc>@@
.?AV<lambda_15ecc8429525df8ca256030db21f49bc>@@
.?AV<lambda_1acf207e1008ef2b4bbaec5c680559c2>@@
.?AV<lambda_1c332c1005d61c8e735e119b3884fbef>@@
.?AV<lambda_1c7f9a84db6055efdbcae32649cc172f>@@
.?AV<lambda_1cfe3ee5b20ff1a1b7aabf8562b20997>@@
.?AV<lambda_1e45319bac0025a63dcec33b3529d969>@@
.?AV<lambda_2061574dcd3884bcc7418dd15f1c1551>@@
.?AV<lambda_221457049dd6e599b1e592be3898266a>@@
.?AV<lambda_229b57b9a061962ff9594124af885d82>@@
.?AV<lambda_24a4d3258ed26385b9a2a41ae6641dc4>@@
.?AV<lambda_26620886b575de26166e451d44bc7aeb>@@
.?AV<lambda_27eb941e257b57f9cf2ee9f3ef3087b3>@@
.?AV<lambda_29460ba72c9a9f61937f695b212c2385>@@
.?AV<lambda_2997ea06f466f3cb7af7580139e0e9b1>@@
.?AV<lambda_2a231a5ff616b0ae2274b38ac58ff666>@@
.?AV<lambda_2a39988023ade309aa40582a95355447>@@
.?AV<lambda_2a3b1f1fbc2b924051eedcd518441330>@@
.?AV<lambda_2b48646c29570f8c367f2979f62b4a3d>@@
.?AV<lambda_2c1cf63ce334288350db032b6e744e65>@@
.?AV<lambda_2c336c69e37df1f232f1301ffdf6cbc8>@@
.?AV<lambda_2cc340efac7f4d4dbbf5e840712c9235>@@
.?AV<lambda_2cda3ec4180407fdb66cae08f370124f>@@
.?AV<lambda_2e19a35e43fa3cd8cc3946e0a5442052>@@
.?AV<lambda_2ff8e0e61b396ff915eaef7150818ea5>@@
.?AV<lambda_3045925fc9d28d7c90e23d8477212aa5>@@
.?AV<lambda_30c3e62ccde4a098c007b12bb428e908>@@
.?AV<lambda_3354f944db7877754471d985be3fe29b>@@
.?AV<lambda_337f2ca3a8f058eb26b2ffadb44de7f6>@@
.?AV<lambda_3395043349d35d848478e0474916ca12>@@
.?AV<lambda_36061226c6fd19f4bdb6137e32da6056>@@
.?AV<lambda_386473780c4dbba8a4606090f17d3c7e>@@
.?AV<lambda_39ab4e523a93c974831bf3e5838f7482>@@
.?AV<lambda_404084d3edacc8294adecb096c00b5ef>@@
.?AV<lambda_41132be6176b0ad1c30bb9b261bf309c>@@
.?AV<lambda_423c7f4514cb0f580d17c1969d94ab4d>@@
.?AV<lambda_44f740f4362270fce5c964ebb50cbf77>@@
.?AV<lambda_476392fa06bbb2566b8ba86eba327f57>@@
.?AV<lambda_4895a69c6e2d4d3665d84240b52946d2>@@
.?AV<lambda_493755c0718e549fc6eb6376aaf1c076>@@
.?AV<lambda_49a440fc7629118ae9d2f59fb796a043>@@
.?AV<lambda_4a5350b0e7409384ce33fe3ccb0d5596>@@
.?AV<lambda_4fa0c6ad40015df7a4b742afad148021>@@
.?AV<lambda_51e7ce4347ad68176c6a114dbe1a7fb9>@@
.?AV<lambda_53958a524045125d538038a834c170f9>@@
.?AV<lambda_554a630e87be704853cdb4d6e278622f>@@
.?AV<lambda_55e8e059d201c280196491784367b3c1>@@
.?AV<lambda_56616cb04d479ecbbef60d16cb985ff3>@@
.?AV<lambda_5865299a878cc4536f06dd6ac2dafee9>@@
.?AV<lambda_59c4d05489433c3097fa1fd13c659c8e>@@
.?AV<lambda_5a03cad439a535c73c9479bab198ff8a>@@
.?AV<lambda_5d21b43612adc0e2b6ba128e18c7d8b6>@@
.?AV<lambda_5df3894d1af0aab9723a608826cf16dc>@@
.?AV<lambda_5f1d94f8ca558702930bc8409fa6a0fd>@@
.?AV<lambda_5ff1311c2565159dd82227496522cf9d>@@
.?AV<lambda_62ff4f86733dccc387694342e1e25828>@@
.?AV<lambda_64300823f523450b95308ffba054eba3>@@
.?AV<lambda_65fcd2258b74fe5b669ce1eba7885536>@@
.?AV<lambda_6812ff5d543ffb19aab4643fc8537ca9>@@
.?AV<lambda_6a32611970906250c6b47d8292ad00e7>@@
.?AV<lambda_6a6f0a3ba850801745b0c94cd2f39bc9>@@
.?AV<lambda_6b96036581b66cdf82b5f39e2bc23e66>@@
.?AV<lambda_6bd810bb96d3f9038457669c0e958c1e>@@
.?AV<lambda_6ca09521f0419cdfacda156e3fc4c98d>@@
.?AV<lambda_6f27585b124916f1c56bce8af77fb03f>@@
.?AV<lambda_6f80d65fbc6388042df99a3b220305d1>@@
.?AV<lambda_70bcac305cb640939927fb5ceed26972>@@
.?AV<lambda_72ca09e2fd79e9e358b3e3ba19c9ad25>@@
.?AV<lambda_747f5a5054cea5042105b3988bb8e54a>@@
.?AV<lambda_75315bcc601c4374ad650d6d72e12b12>@@
.?AV<lambda_7b78813024b920efef438001345229c7>@@
.?AV<lambda_7bf0c45af15d48ff0bf3482d9ab1530d>@@
.?AV<lambda_7d18ce867b586dae3ed4309094f85b3d>@@
.?AV<lambda_82b1543f521b28b3e70914f128f825eb>@@
.?AV<lambda_82fc727948fa2cc155864c30c0053c56>@@
.?AV<lambda_87377fe9a7b55ca099852704c7649a37>@@
.?AV<lambda_87c68c0967c94d566f6bd8e49e4156e6>@@
.?AV<lambda_891134c426edf12026f17cb0f2078fd3>@@
.?AV<lambda_8a3605e32b16eedb239f2cdd6ac9b967>@@
.?AV<lambda_8a3f03cf93ba764f7eebf7fd98d3a893>@@
.?AV<lambda_8d7ff4e398bab3b109ccce388181bf44>@@
.?AV<lambda_8d8272b50dd604dacd546ce94def4111>@@
.?AV<lambda_8e3498b106c5788a8387a435fcfed696>@@
.?AV<lambda_8e59199324395720fba09bee90960ebd>@@
.?AV<lambda_8f781274a152279f4b36822825d1530a>@@
.?AV<lambda_8ff3f73c945873491aaa70354b23f874>@@
.?AV<lambda_9239155d58e7ea4f2b7e8d2c9c494e5c>@@
.?AV<lambda_932c34c02ec00a70f1fdb6bbb19ccddc>@@
.?AV<lambda_9381c167dbf89081cfa0e8790a4e25ab>@@
.?AV<lambda_961060303c5a5a6cf5cad068e6081a1d>@@
.?AV<lambda_96977307008117beb1e0c08617e9e024>@@
.?AV<lambda_96d3b593d5201521d990452d7883196b>@@
.?AV<lambda_974421a2166ea3684014171d0d75f69e>@@
.?AV<lambda_977aa0989600c553e6ad21ef5f183702>@@
.?AV<lambda_98813516cd70625548f3dca86c17f6e0>@@
.?AV<lambda_991d63fb8a809dc84e4e523068ce486a>@@
.?AV<lambda_99a813c0737ae897b47e9765a72f7f54>@@
.?AV<lambda_9a80c5c6458e824bfa0876a779605b0b>@@
.?AV<lambda_9abb244ecf1fe7549bfa1b3b46427d69>@@
.?AV<lambda_9baa1cdad376a56943ca503609534da1>@@
.?AV<lambda_9c3e860ddd71320745f67b50702ebd1c>@@
.?AV<lambda_9d3d7084367d9c69100d1b294ff81141>@@
.?AV<lambda_9df4f2e35c1c7422103cfd601a9bcf0a>@@
.?AV<lambda_9ecca3786d31dc5e5f01e690b2595c13>@@
.?AV<lambda_9ffa1ea875a9a1e0d26e503db16b9ec4>@@
.?AV<lambda_a0e644278ef4f4a57b9573e7ded643ef>@@
.?AV<lambda_a30982bdf1dc90ee13caf4d420ec5e7f>@@
.?AV<lambda_a4a8f47c88f81824ff45fecdeb8c2272>@@
.?AV<lambda_a4fe3bd39dcd0107f90455cb45c21429>@@
.?AV<lambda_a54be6033497fa554a72d4e91b445475>@@
.?AV<lambda_a7d04b0fd0d89810819d0e2c9abbe002>@@
.?AV<lambda_a849a50c5a3c22fd47c8e79fa702e0a3>@@
.?AV<lambda_a8dc603fd8183714a0dc357fc9b787c1>@@
.?AV<lambda_aa8e087667c023378c6f91514203b485>@@
.?AV<lambda_ac25d09018c4332f946f6c34f171cb49>@@
.?AV<lambda_ad2c1540175e880a19f24b36af249c6b>@@
.?AV<lambda_ae345cbcfe8c11e85db446885ca97c11>@@
.?AV<lambda_ae651a2f316754e5b872f0242e285a17>@@
.?AV<lambda_af2c39467b4484bc2a2f611cf533daa7>@@
.?AV<lambda_afa56d0a59b7519296bd96a3f73f6a6d>@@
.?AV<lambda_b39fcf5d316099631cb4151a025dde22>@@
.?AV<lambda_b43d1a9e0f80c81cf46233421502eec9>@@
.?AV<lambda_b5052b92f0971a85fe617ac12b65bf30>@@
.?AV<lambda_b51428820b3477616d25ebf36e7dd645>@@
.?AV<lambda_b5a8e22fc972999c473eeef0d861144d>@@
.?AV<lambda_b6384ac1cdd5bb196d6db0f3469d6bd1>@@
.?AV<lambda_b937f7d4f097577d4fa0e0107ad25600>@@
.?AV<lambda_b9c105cae4698131e1de0f4a11b59d30>@@
.?AV<lambda_b9f88ddcdec88010c219cbe673399be3>@@
.?AV<lambda_bb49b7cc5cd2d94ca99a48a4c0d13f14>@@
.?AV<lambda_bc9a9f99cbeabaf2d0a936a0cad6b782>@@
.?AV<lambda_bd360832f28382f5f21b2ebf873809d4>@@
.?AV<lambda_bd5b9427a54fdb45586e1dbfc607a955>@@
.?AV<lambda_bdb2783b16b3d1693e3b68280088cba9>@@
.?AV<lambda_bed28cc9642f1fb2f87171613a105a9c>@@
.?AV<lambda_c332dd4138e096b0ec5e0eae392e23e1>@@
.?AV<lambda_c3c25e82dec0fc98e0076356943111e7>@@
.?AV<lambda_c5cebd529b61d3173fae5d666977fc08>@@
.?AV<lambda_c67f85aaa1b4500d807071468ee2a524>@@
.?AV<lambda_c903e10f9792b7526fde45e82dd96aa5>@@
.?AV<lambda_c992598cf8c136d6154948ffea1cabd3>@@
.?AV<lambda_ca87e505bf8a7e1f26579083c3683d94>@@
.?AV<lambda_ccac63f7df9933ddfaba28b63f139a1b>@@
.?AV<lambda_ce473b479310095c7321cd7e93391654>@@
.?AV<lambda_cee41185b89a07016645dc0ce475cceb>@@
.?AV<lambda_d01cb7d72935562762275ef2725e3ce2>@@
.?AV<lambda_d2f05bbc4387bd7b157c2e5e8105db99>@@
.?AV<lambda_d48614e49eeb364014c105b2ad0f724a>@@
.?AV<lambda_d5d144ae42b578f39265873b98925836>@@
.?AV<lambda_d67cddb616713624f417e1920c5d4f1a>@@
.?AV<lambda_d67f1edeb5a550a32b15eb0a8d7351da>@@
.?AV<lambda_d8797e74ae02acf212ef74610c438126>@@
.?AV<lambda_d8b06a4dd6f551b1fc6c7009ad0ed428>@@
.?AV<lambda_da429b7ed1fb0e9970f7f34c5fcb029f>@@
.?AV<lambda_db7b633e35029a3bbec6f104f8732ca0>@@
.?AV<lambda_dda5ab6aaf4f2b6f6f3016e64f840ab7>@@
.?AV<lambda_df8dc5d18b005334d023e86e4d511fb0>@@
.?AV<lambda_e0a736eca6c1c042feb9e04770980ed3>@@
.?AV<lambda_e0b2d86bba8462f4713d43f91e59ae58>@@
.?AV<lambda_e1c7a398f08bdd5dfce4cdea2bca15a0>@@
.?AV<lambda_e28ac12b58fea114769e90ea9f16bc88>@@
.?AV<lambda_e29af161a492bf1391ff2e0f512dd650>@@
.?AV<lambda_e4ee4ab01ca4c57467e724753c8bc334>@@
.?AV<lambda_e846bfa317962339550ea10eeefad57e>@@
.?AV<lambda_e9b670853bb4fec4f493fcbcf0e350fb>@@
.?AV<lambda_ea73e250586924fb71aef6e9068c74b3>@@
.?AV<lambda_ebf6ceac8f542e669deada19cbe0c1f1>@@
.?AV<lambda_edc5c5fafd47e3dd4a73efbd3e01dc01>@@
.?AV<lambda_ee3ccfb20f4bc599b4a53d7477866c58>@@
.?AV<lambda_eedfabccf04dae8365cd4a4775f4c12a>@@
.?AV<lambda_ef66392a9526daf4e7c269a18cebdf85>@@
.?AV<lambda_efb13713d16ec9cd372290e4d816e310>@@
.?AV<lambda_f075aa67626267fd6c7787bb3fe85619>@@
.?AV<lambda_f238f1dfa23d313b56abeb489e569e80>@@
.?AV<lambda_f78d8769dd40946ef61ad5956cbf10fe>@@
.?AV<lambda_fab0569e655d52f18af3ccf270ee645c>@@
.?AV<lambda_fbbfb9d846057a1988e21a7503609aa5>@@
.?AV<lambda_fc6f8774bf46030d1ec702a838d79614>@@
.?AV<lambda_fd66f022da42b8a18d5e26e8560bfb59>@@
.?AV<lambda_fe5896b63222887f4439a4ae3de8a244>@@
.?AV<lambda_fe72b7a6aa1ad391993bd3b271dad913>@@
.?AV<lambda_ff02a1c545380d90edd1bec0e08a1239>@@
.?AVAllocationInfo@Dml@@
.?AVAnd@onnxruntime@@
.?AVArrayOutputStream@io@protobuf@google@@
.?AVAttributeProto@onnx@@
.?AVbad_alloc@std@@
.?AVbad_array_new_length@std@@
.?AVbad_cast@std@@
.?AVbad_exception@std@@
.?AVbad_function_call@std@@
.?AVbad_optional_access@std@@
.?AVbad_variant_access@std@@
.?AVbad_weak_ptr@std@@
.?AVBarrierAssignment@Compilation@MLGraph@@
.?AVBatchNormalizationAddFusion@onnxruntime@@
.?AVBatchNormalizationMulFusion@onnxruntime@@
.?AVBFCArena@onnxruntime@@
.?AVBucketizedBufferAllocator@Dml@@
.?AVBucketizedTensorAllocationAssignment@Compilation@MLGraph@@
.?AVCastMap@ml@onnxruntime@@
.?AVCategoryMapper@ml@onnxruntime@@
.?AVCoalesceWalker@re2@@
.?AVcodecvt_base@std@@
.?AVCompileOperators@Compilation@MLGraph@@
.?AVCompiler@re2@@
.?AVCompress@onnxruntime@@
.?AVConcat@onnxruntime@@
.?AVConcatBase@onnxruntime@@
.?AVConcatHelper@OperatorHelper@@
.?AVConcatNodeImpl@MLGraph@@
.?AVConstantFolding@onnxruntime@@
.?AVConstantOfShape@onnxruntime@@
.?AVConstantOfShapeHelper@OperatorHelper@@
.?AVControlNodeImpl@MLGraph@@
.?AVConvActivationFusion@onnxruntime@@
.?AVConvAddFusion@onnxruntime@@
.?AVConvBase@onnxruntime@@
.?AVConvBNFusion@onnxruntime@@
.?AVConvInteger@onnxruntime@@
.?AVConvMulFusion@onnxruntime@@
.?AVConvolutionHelperBase@OperatorHelper@@
.?AVConvTransposeBase@onnxruntime@@
.?AVCopyingFileInputStream@FileInputStream@io@protobuf@google@@
.?AVCopyingInputStream@io@protobuf@google@@
.?AVCopyingInputStreamAdaptor@io@protobuf@google@@
.?AVCopyNodeImpl@MLGraph@@
.?AVCPUAllocator@Dml@@
.?AVCPUAllocator@onnxruntime@@
.?AVCPUDataTransfer@onnxruntime@@
.?AVCPUExecutionProvider@onnxruntime@@
.?AVCropBase@contrib@onnxruntime@@
.?AVCropHelper@OperatorHelper@@
.?AVDataTransfer@Dml@@
.?AVDataTypeImpl@onnxruntime@@
.?AVDeepCpuAttnLstmOp@contrib@onnxruntime@@
.?AVDeepCpuGruOp@onnxruntime@@
.?AVDeepCpuLstmOp@onnxruntime@@
.?AVDepthToSpaceHelper@OperatorHelper@@
.?AVDmlCommandRecorder@Dml@@
.?AVDMLOpaqueOperationDesc@DML@MLGraph@@
.?AVDmlOperator@Dml@@
.?AVDmlOperatorActivation@Dml@@
.?AVDmlOperatorAffine@Dml@@
.?AVDmlOperatorBatchNormalization@Dml@@
.?AVDmlOperatorCast@Dml@@
.?AVDmlOperatorConcat@Dml@@
.?AVDmlOperatorConstantOfShape@Dml@@
.?AVDmlOperatorConvolution@Dml@@
.?AVDmlOperatorCopy@Dml@@
.?AVDmlOperatorCrop@Dml@@
.?AVDmlOperatorDepthToSpace@Dml@@
.?AVDmlOperatorElementwiseClip@Dml@@
.?AVDmlOperatorElementwiseIf@Dml@@
.?AVDmlOperatorElementwiseMean@Dml@@
.?AVDmlOperatorElementwisePow@Dml@@
.?AVDmlOperatorExpand@Dml@@
.?AVDmlOperatorEyeLike@Dml@@
.?AVDmlOperatorGatedRecurrentUnit@Dml@@
.?AVDmlOperatorGather@Dml@@
.?AVDmlOperatorGemm@Dml@@
.?AVDmlOperatorInstanceNormalization@Dml@@
.?AVDmlOperatorLocalResponseNormalization@Dml@@
.?AVDmlOperatorLongShortTermUnit@Dml@@
.?AVDmlOperatorLpNormalization@Dml@@
.?AVDmlOperatorMatMul@Dml@@
.?AVDmlOperatorMaxUnpool@Dml@@
.?AVDmlOperatorMeanVarNormalization@Dml@@
.?AVDmlOperatorMemcpy@Dml@@
.?AVDmlOperatorNeg@Dml@@
.?AVDmlOperatorOneHot@Dml@@
.?AVDmlOperatorPadding@Dml@@
.?AVDmlOperatorPooling@Dml@@
.?AVDmlOperatorRecurrentBase@Dml@@
.?AVDmlOperatorRecurrentNeuralNetwork@Dml@@
.?AVDmlOperatorReduce@Dml@@
.?AVDmlOperatorRegionOfInterestPooling@Dml@@
.?AVDmlOperatorResize@Dml@@
.?AVDmlOperatorScatter@Dml@@
.?AVDmlOperatorSlice@Dml@@
.?AVDmlOperatorSpaceToDepth@Dml@@
.?AVDmlOperatorSplit@Dml@@
.?AVDmlOperatorTile@Dml@@
.?AVDmlOperatorTopK@Dml@@
.?AVDmlOperatorTranspose@Dml@@
.?AVDmlOperatorValueScale2d@Dml@@
.?AVDontUseNewUseMake@Details@WRL@Microsoft@@
.?AVDummyArena@onnxruntime@@
.?AVEliminateDropout@onnxruntime@@
.?AVEliminateIdentity@onnxruntime@@
.?AVEliminateSlice@onnxruntime@@
.?AVEnv@onnxruntime@@
.?AVEnvTime@onnxruntime@@
.?AVerror_category@std@@
.?AVexception@std@@
.?AVExecutionFrame@onnxruntime@@
.?AVExecutionOrder@Compilation@MLGraph@@
.?AVExecutionPlanBase@onnxruntime@@
.?AVExecutionProvider@Dml@@
.?AVExecutionProviderImpl@Dml@@
.?AVExLibLoader@onnxruntime@@
.?AVExpandDims@contrib@onnxruntime@@
.?AVExpandHelper@OperatorHelper@@
.?AVEyeLike@onnxruntime@@
.?AVfacet@locale@std@@
.?AVfailure@ios_base@std@@
.?AVFatalException@protobuf@google@@
.?AVFeatureVectorizer@ml@onnxruntime@@
.?AVFileInputStream@io@protobuf@google@@
.?AVFlatten@onnxruntime@@
.?AVFunction@onnxruntime@@
.?AVFunctionImpl@onnxruntime@@
.?AVFunctionKernel@onnxruntime@@
.?AVFunctionProto@onnx@@
.?AVFusedGraphKernel@Dml@@
.?AVfuture_error@std@@
.?AVGather@onnxruntime@@
.?AVGatherBase@onnxruntime@@
.?AVGatherHelper@OperatorHelper@@
.?AVGatherND@contrib@onnxruntime@@
.?AVGatherNDBase@contrib@onnxruntime@@
.?AVGemmActivationFusion@onnxruntime@@
.?AVGemmHelper@OperatorHelper@@
.?AVGraph@onnxruntime@@
.?AVGraphEdgeNodeImpl@MLGraph@@
.?AVGraphInferencer@onnx@@
.?AVGraphInferencerImpl@onnxruntime@@
.?AVGraphInferencerImpl@shape_inference@onnx@@
.?AVGraphProto@onnx@@
.?AVGraphTransformer@Dml@@
.?AVGraphTransformer@onnxruntime@@
.?AVIAllocator@onnxruntime@@
.?AVIArenaAllocator@onnxruntime@@
.?AVICommandRecorder@Dml@@
.?AVIDataTransfer@onnxruntime@@
.?AVIDeviceAllocator@onnxruntime@@
.?AVIExecutionFrame@onnxruntime@@
.?AVIExecutionProvider@onnxruntime@@
.?AVIExecutor@onnxruntime@@
.?AVIf@onnxruntime@@
.?AVImputerOp@ml@onnxruntime@@
.?AVInferenceContextImpl@onnxruntime@@
.?AVInferenceError@onnx@@
.?AVInferenceSession@onnxruntime@@
.?AVInitializeLayout@Compilation@MLGraph@@
.?AVInsertCastTransformer@onnxruntime@@
.?AVinvalid_argument@std@@
.?AVIOnnxRuntimeOpSchemaCollection@onnxruntime@@
.?AVIOpaqueOperator@MLGraph@@
.?AVIOperatorCompilationContext@MLGraph@@
.?AVIOperatorContext@MLGraph@@
.?AVIOperatorLayoutContext@MLGraph@@
.?AVios_base@std@@
.?AVIPass@MLGraph@@
.?AVISchemaRegistry@onnx@@
.?AVISequentialPlannerContext@onnxruntime@@
.?AVIsInf@onnxruntime@@
.?AVITensorAllocator@onnxruntime@@
.?AVLabelEncoder@ml@onnxruntime@@
.?AVLayoutAssignment@Compilation@MLGraph@@
.?AVlength_error@std@@
.?AVLiveness@Compilation@MLGraph@@
.?AVlogic_error@std@@
.?AVLoop@onnxruntime@@
.?AVMatMulAddFusion@onnxruntime@@
.?AVMaxpoolWithMask@contrib@onnxruntime@@
.?AVMaxUnpool@onnxruntime@@
.?AVMemcpyTransformer@onnxruntime@@
.?AVMessageLite@protobuf@google@@
.?AVMLOperatorKernelFactory@@
.?AVMLOperatorShapeInferrer@@
.?AVMod@onnxruntime@@
.?AVModelProto@onnx@@
.?AVMultinomial@onnxruntime@@
.?AVMurmurHash3@contrib@onnxruntime@@
.?AVNodeConnection@MLGraph@@
.?AVNodeEdgeInputConnection@MLGraph@@
.?AVNodeEdgeOutputConnection@MLGraph@@
.?AVNodeImpl@MLGraph@@
.?AVNodeProto@onnx@@
.?AVNonMaxSuppression@onnxruntime@@
.?AVNonTensorTypeBase@onnxruntime@@
.?AVNoOpRemoval@Compilation@MLGraph@@
.?AVNormalizer@ml@onnxruntime@@
.?AVNot@onnxruntime@@
.?AVNotImplementedException@onnxruntime@@
.?AVNumCapturesWalker@re2@@
.?AVOneHotHelper@OperatorHelper@@
.?AVOnnxRuntimeException@onnxruntime@@
.?AVOnnxRuntimeOpSchemaRegistry@onnxruntime@@
.?AVOpaqueOperationDesc@MLGraph@@
.?AVOperationDesc@MLGraph@@
.?AVOperationNodeImpl@MLGraph@@
.?AVOperatorContext@MLGraph@@
.?AVOperatorSetIdProto@onnx@@
.?AVOpKernel@onnxruntime@@
.?AVOpKernelContext@onnxruntime@@
.?AVOpKernelContextInternal@onnxruntime@@
.?AVOpSchemaRegistry@onnx@@
.?AVOptimizerExecutionFrame@onnxruntime@@
.?AVOr@onnxruntime@@
.?AVout_of_range@std@@
.?AVPadBase@onnxruntime@@
.?AVPaddingHelper@OperatorHelper@@
.?AVParallelExecutor@onnxruntime@@
.?AVPoolBase@onnxruntime@@
.?AVPoolingHelperBase@OperatorHelper@@
.?AVQLinearConv@onnxruntime@@
.?AVRandomNormal@onnxruntime@@
.?AVRandomNormalLike@onnxruntime@@
.?AVRandomUniform@onnxruntime@@
.?AVRandomUniformLike@onnxruntime@@
.?AVRange@contrib@onnxruntime@@
.?AVrange_error@std@@
.?AVRecurrentHelper@OperatorHelper@@
.?AVReduceHelperBase@OperatorHelper@@
.?AVRemoveDuplicateCastTransformer@onnxruntime@@
.?AVRepetitionWalker@re2@@
.?AVReshape@onnxruntime@@
.?AVReshape_1@onnxruntime@@
.?AVResizeHelper@OperatorHelper@@
.?AVResultException@wil@@
.?AVReverseSequenceOp@onnxruntime@@
.?AVRewriteRule@onnxruntime@@
.?AVRoiPoolingHelper@OperatorHelper@@
.?AVRuleBasedGraphTransformer@onnxruntime@@
.?AVruntime_error@std@@
.?AVRuntimeClassBase@Details@WRL@Microsoft@@
.?AVScatter@onnxruntime@@
.?AVSchemaError@onnx@@
.?AVSchemaRegistryManager@onnxruntime@@
.?AVSequentialExecutor@onnxruntime@@
.?AVSequentialPlannerContext@onnxruntime@@
.?AVShape@onnxruntime@@
.?AVShrink@onnxruntime@@
.?AVSign@onnxruntime@@
.?AVSimpleTensorAllocator@onnxruntime@@
.?AVSimplifyWalker@re2@@
.?AVSize@onnxruntime@@
.?AVSliceBase@onnxruntime@@
.?AVSliceHelper@OperatorHelper@@
.?AVSpaceDepthBase@onnxruntime@@
.?AVSpaceToDepthHelper@OperatorHelper@@
.?AVSplit@onnxruntime@@
.?AVSplitBase@onnxruntime@@
.?AVSplitHelper@OperatorHelper@@
.?AVSplitNodeImpl@MLGraph@@
.?AVSqueeze@onnxruntime@@
.?AVSqueezeBase@onnxruntime@@
.?AVstl_condition_variable_interface@details@Concurrency@@
.?AVstl_condition_variable_win7@details@Concurrency@@
.?AVstl_critical_section_interface@details@Concurrency@@
.?AVstl_critical_section_win7@details@Concurrency@@
.?AVStringNormalizer@onnxruntime@@
.?AVStringOutputStream@io@protobuf@google@@
.?AVStringStringEntryProto@onnx@@
.?AVsystem_error@std@@
.?AVTensorAlignment@Compilation@MLGraph@@
.?AVTensorAllocationAssignment@Compilation@MLGraph@@
.?AVTensorAllocatorWithMemPattern@onnxruntime@@
.?AVTensorAnnotation@onnx@@
.?AVTensorAssignment@Compilation@MLGraph@@
.?AVTensorConstness@Compilation@MLGraph@@
.?AVTensorProto@onnx@@
.?AVTensorProto_Segment@onnx@@
.?AVTensorShapeProto@onnx@@
.?AVTensorShapeProto_Dimension@onnx@@
.?AVTensorTypeBase@onnxruntime@@
.?AVTfIdfVectorizer@onnxruntime@@
.?AVTileHelper@OperatorHelper@@
.?AVTokenizer@contrib@onnxruntime@@
.?AVTopKHelper@OperatorHelper@@
.?AVToStringWalker@re2@@
.?AVTranspose@onnxruntime@@
.?AVTransposeBase@onnxruntime@@
.?AVTransposeHelper@OperatorHelper@@
.?AVtype_info@@
.?AVTypeProto@onnx@@
.?AVTypeProto_Map@onnx@@
.?AVTypeProto_Opaque@onnx@@
.?AVTypeProto_Sequence@onnx@@
.?AVTypeProto_SparseTensor@onnx@@
.?AVTypeProto_Tensor@onnx@@
.?AVUnpoolingHelper@OperatorHelper@@
.?AVUnsqueeze@onnxruntime@@
.?AVUnsqueezeBase@onnxruntime@@
.?AVUnsqueezeElimination@onnxruntime@@
.?AVUpsampleBase@onnxruntime@@
.?AVValidationError@checker@onnx@@
.?AVValueInfoProto@onnx@@
.?AVWindowsEnv@?A0xb80a4b33@onnxruntime@@
.?AVWindowsEnvTime@?A0x1fdd7d4f@onnxruntime@@
.?AVWordConvEmbedding@contrib@onnxruntime@@
.?AVXor@onnxruntime@@
.?AVZeroCopyInputStream@io@protobuf@google@@
.?AVZeroCopyOutputStream@io@protobuf@google@@
.?AVZipMapOp@ml@onnxruntime@@
.0/0#
.0/011
.0=0T0
.00cfg
.0H0m0
.CRT$XCA
.CRT$XCC
.CRT$XCL
.CRT$XCU
.CRT$XCZ
.CRT$XIA
.CRT$XIC
.CRT$XIZ
.CRT$XLA
.CRT$XLZ
.CRT$XPA
.CRT$XPZ
.CRT$XTA
.CRT$XTZ
.data
.data$r
.didat
.didat$2
.didat$3
.didat$4
.didat$5
.didat$6
.didat$7
.edata
.gfids
.giats
.idata$2
.idata$3
.idata$4
.idata$5
.idata$6
.json
.P6A?AVStatus@common@onnxruntime@@ABVNode@2@AAVGraph@2@ABV?$vector@PBVTypeProto@onnx@@V?$allocator@PBVTypeProto@onnx@@@std@@@std@@AAV56@@Z
.P6AMMMM@Z
.P6APAVOpKernel@onnxruntime@@ABVOpKernelInfo@1@@Z
.P6AX$$QAVOpSchema@onnx@@@Z
.P6AXAAUInferenceContext@onnx@@@Z
.P6AXPAX@Z
.rdata
.rdata$r
.rdata$sxdata
.rdata$T
.rdata$zETW0
.rdata$zETW1
.rdata$zETW2
.rdata$zETW9
.rdata$zzzdbg
.rsrc
.rsrc$01
.rsrc$02
.rtc$IAA
.rtc$IZZ
.rtc$TAA
.rtc$TZZ
.stls
.text
.text$di
.text$mn
.text$x
.text$yd
.tls$
.tls$ZZZ
.xdata$x
-/./.
/0=0m0{0
/0>0C0
/0C0M0V0
/0f0x0
/0O0\0s0
/0U0_0
/D$,v#
: :$:(:,:0:4:8:<:@:D:H:L:P:T:h:l:
: :$:(:,:0:4:8:<:@:D:H:L:P:T:X:\:`:d:h:l:p:t:x:|:
: :$:(:,:4:L:\:`:d:h:l:
: :$:(:0:H:L:d:t:
: :$:(:0:H:L:P:T:h:l:p:
: :$:8:<:@:D:X:\:`:d:h:|:
: :$:8:<:L:P:T:X:l:p:
: :%:0:6:@:K:P:X:\:c:m:s:w:~:
: :(:@:P:T:X:l:p:
: :(:\:l:x:
: :(:0:<:\:h:p:
: :(:0:8:@:H:X:|:
: :(:0:8:@:L:l:t:
: :(:0:8:@:L:l:t:|:
: :(:4:T:\:d:l:x:
: :(:4:T:\:d:p:
: :,:4:T:p:
: :,:8:H:X:`:l:p:|:
: :,:I:\:z:
: :,:L:X:|:
: :@:H:h:p:
: :@:H:P:X:`:h:x:
: :@:P:t:|:
: :0:4:D:T:X:\:t:
: :4:D:H:`:d:h:l:p:t:x:|:
: :5:A:Z:`:d:n:
: :8:?:F:Q:Z:a:
: :8:H:L:P:d:h:x:|:
: :K:e:
: ;,;1;E;M;R;d;i;{;
: ;H;
: ;X;
: ;z;
: Conflicting with a registered kernel with op versions.
: failed validating the check: 
:!:):3:7:=:G:K:Q:[:a:i:r:x:|:
:!:/:;:L:
:!:-:9:E:a:
:!:-:9:U:
:!:+:;:E:U:_:o:
:!:1:6:J:W:c:t:
:!:A:u:
:!:b:s:
:!:c:
:!:E:K:_:
:!;(;=;R;t;
:!;/;M;];
:":(:2:8:B:H:t:~:
:":/:7:=:A:\:d:t:{:
:":':@:Q:W:d:
:":3:9:>:J:\:c:p:|:
:":3:i:
:":H:i:
:":l:
:";/;x;
:";==R>m>V?h?
:";M;x;
:";O<U?\?u?
:";Z;%<
:"<.<0>
:#:.:O:X:a:j:|:
:#:;:B:^:f:
:#:^:
:#:|:
:#:6:U:
:#:A:M:Y:e:
:#:A:M:Y:h:
:#:P:p:
:#:y:
:#;*;R;
:#;S;q;
:$:(:,:4:8:<:@:H:L:T:X:\:d:h:l:x:
:$:(:@:D:\:`:x:|:
:$:(:@:P:T:X:\:`:t:x:|:
:$:(:8:<:@:X:h:x:
:$:):A:M:S:X:u:
:$:,:<:D:L:X:x:
:$:,:4:@:`:h:p:x:
:$:,:4:@:`:p:
:$:,:4:<:D:L:\:d:l:|:
:$:,:4:<:D:L:T:\:d:l:
:$:,:4:<:D:L:T:\:d:l:t:|:
:$:,:4:<:D:L:T:\:d:p:
:$:,:4:<:D:L:T:\:h:
:$:,:4:<:D:L:T:`:
:$:,:4:<:D:L:T:`:h:
:$:,:4:<:D:P:p:|:
:$:,:4:<:D:P:p:x:
:$:,:4:<:H:h:p:|:
:$:,:7:<:B:H:N:S:Y:_:f:m:t:|:
:$:,:8:X:`:h:p:x:
:$:,:8:X:`:l:
:$:,:D:T:\:d:l:
:$:,:D:T:\:x:
:$:.:C:X:v:c<
:$:?:j:
:$:?:r:
:$:@:P:\:d:
:$:@:P:`:h:
:$:=:N:T:Y:e:w:
:$:0:P:X:`:h:p:x:
:$:7:<:A:Z:k:q:v:
:$:D:L:X:`:
:$:X:b:w:
:$;(;,;0;4;8;<;@;D;H;L;P;T;X;\;`;d;h;l;p;t;x;|;
:$;-;<;c;y;
:$;+;C;V;u;
:$;H;
:$;L;t;
:%:/:
:%:>:W:
:%:9:E:Q:]:y:
:%:g:p:
:%:u:
:%=7=P=}=
:&:-:F:u:|:
:&:>:[:
:&:0:<:W:a:m:
:&:H;M;~;
:&:K:
:&:Y:
:&;a;
:&;L;s;
:(:,:<:@:X:\:t:
:(:,:<:L:P:h:x:|:
:(:,:0:8:P:T:X:`:d:l:
:(:?:
:(:0:@:H:X:`:p:x:
:(:0:d:t:
:(:1:H:Q:h:q:
:(:2:7:=:A:G:Q:W:[:a:h:t:y:
:(:4:<:p:
:(:8:<:T:d:h:x:|:
:(:8:H:l:t:|:
:(:8:H:X:h:x:
:(:F:W:
:(:H:T:t:
:(:j:
:(:J:o:
:(;7<k<
:(;8;D;L;l;t;|;
:(;C;J;_;t;
:(;D;K;p;
:):::u:
:):@:
:):8:@:L:X:d:p:|:
:):B:`:
:):N:`:d:h:l:p:t:x:|:
:):P:";>;t;
:):W:|:
:);K;U;j;
:)=D=N=
:*:/:G:L:s:x:
:*:\:f:{:
:*:0:5:A:K:W:h:
:*:s:
:,:<:D:L:T:\:d:l:t:|:
:,:<:L:P:T:X:`:d:l:p:x:
:,:0:@:D:\:`:h:
:,:0:4:8:<:D:L:d:t:x:
:,:0:4:8:<:P:T:X:p:
:,:0:H:X:h:l:p:t:
:,:0:H:X:h:x:|:
:,:4:<:D:L:T:\:d:l:t:|:
:,:4:<:D:L:T:\:d:l:x:
:,:5:<:C:I:V:]:g:
:,:8:X:d:
:,:C:0;:;O;d;
:,:N;~;
:,:P:t:
:,:X:
:,;<;H;h;t;
:,;5;
:,;B;};
:,;V;l;z;
:,u0B
:.:@:
:.:3:}:
:.:h:
:.:L:o:
:.;j;
:.;Q;
:/:`:
:/:A:
:/:c:
:/:D:[:
:/:F:
:/;L;
:::]:
:::A:H:
:::E:
:::h:
:::j:v:}:
:::N:g:
::;A;W;
::;n;
:-:]:
:-:<:A:K:W:h:
:-:2:9:@:G:N:U:\:c:j:q:x:
:-:8:x:
:';,;6;H;M;m;r;
:';,;B;G;L;_;d;i;
:;:H:V:[:m:r:w:
:;;E;Z;o;
:;;f;
:;;X<R=k={=
:';B;];
:-;e;
:';F;X;
:-;i;n;
:?:\:
:?;P;];~;
:?<K<v=
:@:p:
:@:P:\:d:|:
:@;b;
:@;P;\;d;
:[:b:{:
:\;c;x;
:\;s;
:\;T<^<s<
:\<&;
:]:z:
:];v;
:];y;
:]=k=
:^;5<
:_<z<
:`>{>
:+:6:::S:]:k:
:+:B:
:+:E:Q:o:
:<:H:h:p:x:
:<:L:X:`:
:<;\;h;
:<;J;u;.<@<b<v<
:<;x;
:-<+=
:>:W:\:
:>;K;v;
:0:@:D:\:`:d:l:p:x:
:0:@:D:T:X:\:`:h:
:0:G:c=k>u>
:0;];
:0;4;8;<;@;D;H;L;P;T;X;\;`;d;h;l;p;t;x;|;
:0;H;
:0R0d0H1
:1:=:I:U:z:
:1:s:
:1;|;
:1;E;k;u;
:1;L;V;k;
:2:<:U:\:w:
:2:7:=:
:2:L:
:2;7;<;^;p;
:2;i;~;
:3:A:
:3:Q:]:i:u:
:3;N;q;
:3;Q;V;
:4:\:
:4:`:
:4:<:D:L:T:\:d:l:x:
:4:D:P:t:|:
:4:o:
:4:W:r:
:4;>;W;a;
:5:F:a:h:
:5:Y:
:5;[;
:5;_<{<
:5;W;v;
:6:]:
:6:C:G:K:O:S:W:[:u:a=
:6:F:W:`:f:
:6:G:
:6:J:
:6:N:X:q:{:
:6:p:
:6:Q:l:
:6:s;
:6:T:e:
:6;\;f;
:6;6<G<
:7:]:
:7:r:
:7:R:m:
:7:s:
:7;f;x;
:7;K;x;};
:7;u;z;
:8:?:F:
:8:@:L:l:t:|:
:8:\:
:8:A:h:q:
:8:c:
:8:H:T:\:
:8:V:g:
:8;v;
:9:F;_;
:9:p:
:9:T:^:h:r:|:
:9;s;
:9;w;
:A,u?
:a:f:q:?;
:a:L;
:A:P:
:a;{;
:AM:am:PM:pm
:A-uG
:B:f:
:B:F:J:N:R:V:Z:^:b:f:j:n:r:v:}:
:b;o;
:c:h:
:C;b;
:c;o<
:C;u;
:D:N:n:
:D:T:`:h:
:E;`;
:e<q=g>
:F:d:
:F:Z:e<d>
:F;^;4<A<i<
:f;p;
:f;x;
:G:m:w:
:G:Q:e:o:!;/;C;
:G;P;
:H:h:
:H:Z:
:I<K=\>w>
:J;~;
:Jan:January:Feb:February:Mar:March:Apr:April:May:May:Jun:June:Jul:July:Aug:August:Sep:September:Oct:October:Nov:November:Dec:December
:K;g;~;
:K;X;y;
:L:x:
:L<k<
:m;y;
:n:u:
:N;s;
:N;u;
:O;t;
:P:`:l:
:P:r:
:P;j;
:Please, install necessary language-pack-XX and configure locales
:Q:c:s:
:S:\:f:o:y:
:S:h:
:S:u:
:S:v:
:Sun:Sunday:Mon:Monday:Tue:Tuesday:Wed:Wednesday:Thu:Thursday:Fri:Friday:Sat:Saturday
:T;^;
:U:\:l:
:U:g:z:
:U:q:
:U;`;*<J<\<a<
:V:c:
:W:\:a:
:X:]:
:Y;c;};
; ;$;(;,;0;4;<;T;X;\;`;t;x;
; ;$;(;,;0;4;<;T;X;p;t;
; ;$;(;,;0;4;8;<;@;D;H;L;P;T;X;\;`;d;h;l;p;t;x;|;
; ;$;(;,;0;4;8;<;@;D;H;S;
; ;$;(;0;4;8;@;X;\;t;
; ;$;(;0;H;L;P;T;X;l;p;t;x;|;
; ;$;,;0;4;<;T;X;p;
; ;$;<;@;D;L;d;h;
; ;$;<;@;X;\;t;x;|;
; ;$;<;@;X;h;x;
; ;$;8;<;@;D;H;L;P;T;X;\;`;d;h;l;p;x;
; ;(;\;l;x;
; ;(;0;<;\;d;l;t;
; ;(;0;<;\;h;
; ;(;0;8;@;P;t;|;
; ;(;2;6;<;F;J;P;Z;`;i;q;w;{;
; ;*;0;4;;;E;J;T;Z;d;n;t;};
; ;,;8;H;P;\;`;l;p;|;
; ;,;L;T;\;d;l;x;
; ;,;L;T;\;d;p;
; ;,;L;X;`;
; ;.;H;
; ;-;6;R;W;f;k;z;
; ;@;H;P;\;|;
; ;@;H;P;X;`;h;t;|;
; ;@;H;P;X;`;l;
; ;@;H;P;X;`;p;
; ;@;H;P;X;d;
; ;@;L;l;t;
; ;+;R;
; ;<;@;L;l;x;
; ;0;@;P;T;X;\;`;d;h;l;p;t;x;|;
; ;0;4;8;L;P;T;l;|;
; ;0;4;D;H;X;\;`;x;
; ;0;8;@;H;P;X;h;x;
; ;4;@;Q;
; ;8;H;L;\;l;|;
; ;8;H;L;P;X;p;
; ;T;d;p;
; ;T;d;p;x;
; <@<R<W<
; <X<
;!;(;=;R;Y<
;!;.;:;K;
;!;2;8;=;I;S;_;p;
;!;5;A;M;Y;~;
;!;5;A;M;Y;u;
;!;D;
;!<><q<
;!<4<i<
;!<7<M<c<
;!<A<N<e<
;!=(=A=
;";=;X;
;";4;
;";c;
;#;(;C;
;#;-;;;F;J;c;m;y;
;#;-;7;A;K;];j;v;
;#;1;V;a;x;
;#;8;O;
;#<E<P<c<
;#=?=j=
;$;(;@;P;T;d;t;x;
;$;(;8;<;@;X;\;t;x;|;
;$;*;.;`;
;$;,;0;7;A;G;K;R;\;a;k;q;{;
;$;,;4;@;`;l;t;
;$;,;4;<;D;L;T;\;d;l;t;
;$;,;4;<;D;L;T;\;d;l;t;|;
;$;,;4;<;D;L;T;\;d;p;
;$;,;4;<;D;L;T;\;h;
;$;,;4;<;D;L;T;`;
;$;,;4;<;D;L;X;|;
;$;,;4;<;D;P;t;|;
;$;,;4;L;T;\;d;l;t;|;
;$;,;8;\;d;l;t;|;
;$;,;8;X;d;l;
;$;,;D;T;\;x;
;$;,;p;
;$;@;P;\;d;
;$;<;H;h;p;x;
;$;<;N;
;$;=;i;r;
;$;0;8;l;|;
;$;0;M;`;
;$;0;T;\;d;l;t;|;
;$;4;@;H;h;
;$;D;`;p;|;
;$;D;L;T;`;
;$;D;L;X;x;
;$<,<4<<<X<x<
;$<+<C<V<u<
;$<4<@<H<l<t<
;%;,;
;%;:;I;N;X;d;u;
;%;+;4;C;M;d;{;
;%;=;V;
;%;0;C;a;m;y;
;%;1;L;V;b;};
;%;6;<;I;S;_;p;
;%;8;h;~;
;%;A;
;%<4<k<
;%<c=
;&;,;2;7;=;D;K;R;Z;`;d;j;t;z;~;
;&;-;:;B;H;L;g;o;
;&;0;:;D;N;X;b;l;v;
;&;3;y;
;&;7;
;&;8;
;&;9;V;g;
;&;F;i;
;&<:<
;&<;<
;(;,;<;@;P;`;d;h;l;t;
;(;,;D;H;`;d;|;
;(;?;
;(;0;8;@;L;l;t;|;
;(;4;E;
;(;8;H;X;h;x;
;(;A;m;
;(<8<D<L<l<t<|<
;(<b<o<v<
;(>H?
;);:;u;
;);3;=;_;v;~;
;);5;A;M;i;
;);5;Q;
;);5;Z;
;);D;U;
;)<><D<\<n<
;)<Y<
;)<z<
;*;?;V;
;*;4;N;p;z;
;*;A;,=6=K=`=w=
;*;B;h;
;*;F;_;m;
;*;M;
;*;P;|;
;*<:<R<k<w<
;*<J<z<
;,;@;L;];
;,;|;
;,;<;@;D;L;d;h;l;t;x;
;,;<;@;D;X;\;l;|;
;,;0;@;D;T;d;h;x;|;
;,;0;4;H;L;P;h;x;|;
;,;0;4;H;L;P;T;h;l;
;,;4;@;`;l;t;
;,;4;<;D;L;T;\;d;l;x;
;,;5;i;
;,;8;@;t;
;,;8;X;d;l;
;,;8;X;h;
;,;q;
;,;T;|;
;,<<<H<l<t<|<
;,<<<H<P<
;,<d<p<
;,<I<a<x<
;,<q<
;,<T<
;.;4;<;Q;];v;|;
;.;6;
;.;B;V;j;
;.;E;V;o;v;
;.;v;};
;.<^<
;.<5<J<_<
;.<f<
;.=|=
;/;D;[;v;
;/;G;l;
;/<L<j<
;:;h;
;';,;c;p;
;';,;F;L;];e;j;{;
;-;;;
;;;S;m;
;;;S;Z;s;Z<a<
;-;8;f;
;';B;];x;
;';D;N;g;~;
;-;H;c;~;
;-;P<`=p>
;';t;
;?;_;
;@;P;\;d;|;
;@;q;
;@;t;O<
;@;x;
;@<x<
;[<e<z<
;\$ r
;\$ u
;\$(t\
;\;w;
;]>g>|>
;^<r<
;_;p;
;_<z<
;|$ |
;|$ u
;|$$tB
;|$,|
;|84u
;};w=
;~ ~W
;+;k;
;+<4<e<n<
;+<J<[=v=u>
;'<:<O<a<k<
;<;M;
;<<_<
;<<E<X<e<o<
;<<F<_<p<
;<<N<
;'<2<W<
;'<A<M<s<
;-<D<q<z=
;-<H<c<~<
;-<I<
;'<J<2=
;'<q<
;-<v<
;=;\;
;=;_;
;=;B;a;-<M<W<p<
;==R=
;>;H;];r;
;>;n;
;>;q;
;><z<
;0;:;N;b;s;
;0;4;8;@;D;H;L;T;l;p;
;0;4;8;P;`;d;h;
;0;8;@;H;P;\;|;
;0;8;@;H;T;t;|;
;0;8;X;`;
;0;D;X;l;};
;0;G;
;0;P;
;0;P;b;g;
;0;T;x;
;0<g<
;0=e?l?
;0E0Y0c0
;0u*;
;0v:f
;1;\;y;
;1;=;I;U;z;
;1;L;g;
;1;T;o;
;1<]<d<x<
;1<=<I<
;1<I<
;1<I<w<G=E>
;1<o<
;1<V<h<
;1uZ9M
;2;C;_;v;
;2;C;I;N;Z;l;s;
;2;U;p;
;2u0;
;3;?;P;
;3;f;%=X=
;3;F;e;
;3;Q;];i;u;
;3;T;
;3<;<N<S<o<t<
;3<f<
;3<U<`<v<
;3<Y<s<
;3=V=
;3tqf
;3u ;
;4;;;B;
;4;?;b;l;
;4;@;H;|;
;4;}=
;4;<;D;L;T;\;d;l;t;|;
;4;<;D;L;X;x;
;4;D;P;X;
;4;X;|;
;4<;<S<f<
;4<<<l<
;4<O<H=
;4<x<
;4<z<
;5;;;];
;5;?;s;
;5;@;S;q;};
;5;P;k;
;5;s;
;5;X;s;
;5<}<
;5<<<Q<f<}<
;6;\;f;v;
;6;G;
;6<H<
;6<R<
;6<U<
;7;d;
;7<b<D=
;7<L<
;7=(>v?
;8;`;
;8;>;C;O;Y;c;u;z;
;8;A;h;q;
;8;c;
;8;p;
;8;T;d;p;x;
;8<?<T<i<
;8<f<y<
;8<I<
;9;L;j;|;
;9;M;
;9;T;o;
;9<k<x<
;9<S<a<
;9<X<
;A;`;|;
;A;O;
;a<%=B=W=p=
;a<p<
;AHr)
;AHr.
;b;h;
;B<m<
;B<O<p<v<
;B<V<d<s<
;C;e;p;
;CputV
;D$4tI
;D;\;d;l;t;|;
;D;I;N;b;x;
;D;T;`;
;D;T;`;h;
;d<n<
;E;n;
;E;W;\;
;E<H=P=
;F t:jX_
;F t+
;F t>
;F ti
;F$tK
;F(tu
;F;g;p;
;F;M<
;F<n<
;F<v=
;F<w<
;F8t%
;G;y;
;H uk
;H;O;g;z;
;H;X;d;
;H<f<x<
;H<v<{<
;J<j<|<
;J<T<
;j<v<
;K;3<U<w<
;K;p;
;k;u;
;K<f<
;L;\;h;p;
;L;Q;V;r;
;L<v<
;M;\<d>
;M;];m;t;y;
;M;};
;N;_;g;l;t;~;
;N;t;
;N@s]
;N<U<j<
;O;f;w;
;O;g;
;O;k;
;Ott3
;P;b;
;P<t<
;pLs-
;Q$sT
;Q<m<
;R;q;
;s$}(k
;S;c;x;
;S;y;
;S<^<h<
;S<m<
;s8tb
;T$ t&
;T$$u ;D$(u
;t$(|
;t$(r
;T$,r
;U;4<;<T<
;U<^<
;u<-=
;V<g<
;w sG
;W;a;
;X;a;
;X;y;
? ?$?(?,?0?4?8?<?@?D?H?L?P?T?X?\?`?d?h?l?p?t?x?|?
? ?$?(?,?0?D?H?`?d?|?
? ?$?+?5?:?F?L?V?c?g?m?r?x?~?
? ?$?<?L?P?T?X?`?d?x?|?
? ?$?4?D?H?L?d?h?
? ?(?0?<?\?d?l?t?
? ?(?0?<?\?h?
? ?(?0?8?D?d?l?t?
? ?(?8?@?P?X?`?h?p?x?
? ?*?6?Q?~?
? ?,?4?h?x?
? ?,?h?
? ?;?
? ?'?A?k?
? ?0?@?D?T?d?h?l?p?
? ?0?<?D?d?
? ?0?4?8?<?@?T?d?t?x?
? ?2?7?<?U?f?l?q?{?
? ?5?J?
? ?8?<?T?X?\?p?t?x?|?
? ?C?_?
? ?T?d?p?x?
? @ T T 3
?!?&?7?<?N?S?f?q?y?~?
?!?-?9?E?j?
?!?-?J?]?{?
?!?@?y?
?"?(?,?3?@?E?P?V?`?k?q?u?{?
?"?,?6?@?J?T?^?h?r?|?
?"?'?
?"?2?:???P?U?h?s?y?
?"?3?q?
?"_^t
?#?/?5?:?W?j?o?
?#?;?B?^?f?
?#?'?-?=?B?G?L?R?\?b?h?m?u?z?
?#?^?
?#?<?B?F?P?n?~?
?#?<?m?w?
?#?3?
?#?D?u?
?#?L?o?
?#?T?
?#?v?
?#?V?q?
?$?(?,?D?T?d?t?x?
?$?(?,?D?T?X?\?`?t?
?$?(?@?D?\?l?p?t?x?
?$?,?
?$?,?4?@?`?h?p?
?$?,?4?@?`?l?
?$?,?4?<?D?L?T?\?d?l?t?
?$?,?4?<?D?L?T?\?d?l?t?|?
?$?,?4?<?D?L?T?\?d?l?x?
?$?,?4?<?D?L?T?\?h?
?$?,?4?<?D?L?X?x?
?$?,?4?<?D?P?p?x?
?$?,?4?<?H?h?p?x?
?$?,?4?<?X?h?t?|?
?$?,?8?\?d?l?t?|?
?$?;?
?$?@?P?\?d?
?$?<?L?\?l?p?
?$?>?U?l?
?$?4?8?H?L?P?h?l?p?t?x?|?
?$?4?8?P?T?l?p?
?$?6?;?P?U?h?|?
?$?8?<?T?d?h?l?p?t?x?|?
?$?9?x?
?$?b?
?$?D?`?p?|?
?$?D?L?T?\?h?
?$?D?P?p?|?
?$?D?P?p?x?
?$?E?^?
?$?F?W?
?$?H?X?d?l?
?$?X?h?t?|?
?%?,?3?:?B?H?L?R?X?^?b?h?o?w?
?%?0?C?a?m?y?
?%?J?
?(?,?<?@?P?T?d?h?x?|?
?(?,?<?@?X?\?t?x?
?(?,?0?8?P?`?d?t?
?(?,?D?H?L?P?T?X?\?`?d?h?l?p?t?x?|?
?(?=?P?\?y?
?(?0?<?@?L?P?\?h?x?
?(?0?8?D?d?l?t?
?(?2?9?Q?a?q?
?(?2?W?n?
?(?8?@?L?P?\?`?l?x?
?(?8?H?X?h?x?
?(?H?P?\?|?
?(?H?P?X?`?h?t?
?(?L?T?\?d?l?t?|?
?(?N?
?)?.?3?O?`?
?)?=?K?_?m?
?)?7?K?
?)?9?P?`?
?)?N?`?d?h?l?p?t?x?|?
?)?Q?
?*?<?
?*?<?L?v?
?*?=?e?
?*?5?A?R?
?*?6?G?
?*?6?G?Q?[?e?r?
?*?a?h?
?*?T?~?
?,???h?m?r?
?,?\?
?,?0?@?D?T?X?h?l?p?
?,?0?4?8?@?X?h?l?|?
?,?0?H?L?P?d?h?x?|?
?,?4?<?D?L?T?\?d?l?x?
?,?4?<?H?h?p?
?,?4?P?`?l?t?
?,?c?j?
?,?J?Y?b?o?
?,?k?
?,?W?
?.?@?
?.?I?d?
?.?U?\?u?
?.?w?
?/?;?T?m?y?
?/?4?9?I?N?e?v?|?
?/?J?^?o?w?
?/?J?e?
?/?y?
?:?s?
?;F(r
???i?
???k?
?'?]?g?|?
?-?`?
?-?<?H?b?x?
?'?1?;?E?Q?b?
?'?7?@?
?'?c?j?
?'?D?
?-?D?
?-?d?k?
?-?P?
?@?^?j?o?t?
?@?d?
?[?o?
?\?r?
?\?z?
?+?@?
?+?1?6?B?L?X?i?
?+?o?y?
?+?U?m?w?
?<?^?q?
?<?D?L?T?\?d?l?t?|?
?=?B?
?=?k?
?=?p?
?=?U?
?>?n?
?>?V?g?
?0?@?L?T?
?0?`?
?0?5?:?L?W?]?b?k?z?
?0?8?@?H?T?t?
?0?8?@?H?T?t?|?
?0?D?S?^?
?0?H?\?e?
?0?K?f?
?0?v?
?0?X?
?1?=?I?U?q?
?1?H?S?
?1?s?
?2?U?x?
?2?Z?
?3?G?s?
?3?I?_?
?3?N?i?
?3?V?y?
?3?X?}?
?4?\?
?4?<?D?L?T?\?h?
?4?<?D?L?X?|?
?4?<?D?P?t?|?
?4?<?H?h?p?x?
?4?8?P?`?d?t?x?
?4?A?F?W?\?m?r?
?4?D?H?L?P?T?\?t?x?
?4?D?H?L?P?T?X?\?`?d?h?l?p?t?x?
?4?D?H?X?\?p?
?4?D?H?X?h?l?p?t?x?
?4?D?P?X?x?
?4?O?
?4?P?`?l?t?
?5?^?u?
?5?L?d?l?}?
?5?l?s?
?6???P?
?6?H?
?6?o?
?6?U?
?7?A?Z?
?7?H?
?7?N?[?
?8?A?w?
?8?D?d?p?
?8?F?
?8?V?h?
?9?C?`?
?9?S?q?}?
?A?H?a?
?A?W?m?
?b?~?
?C?a?m?y?
?C?a?u?
?C?e?p?
?C?M?S?Z?`?r?y?
?D?T?`?h?
?f?x?
?H?n?
?H?X?d?l?
?K?x?
?L?\?h?p?
?L?Q?V?g?o?t?
?M?W?c?
?N?S?
?N?S?^?
?O?p?
?P?W?
?QPSjpZjoY
?QWh`q/
?QWh0w/
?RVRPQ
?S?g?
?S?u?
?T?[?s?
?tn@P
?U?\?
?U?s?
?V?j?
?w*VP
?W?d?
?wBVW
?Windows::AI::MachineLearning::TensorBase<unsigned short,unsigned short,struct winrt::Windows::AI::MachineLearning::implementation::TensorUInt16Bit,struct winrt::Windows::AI::MachineLearning::ITensorUInt16Bit,struct winrt::Windows::AI::MachineLearning::implementation::TensorUInt16Bit_base<struct winrt::Windows::AI::MachineLearning::implementation::TensorUInt16Bit,struct ITensorNative,struct Windows::AI::MachineLearning::ILotusValueProviderPrivate> >::GetCpuResource
?X?e?
?Z?d?
@.data
@.reloc
@?QWh
@0^0|0
@0P0\0d0
@ffn@ffn@ffn@ffn@
@hX)1
@PhDB.
@t"VS
[%hs(%hs)]
[%hs]
[:^alnum:]
[:^alpha:]
[:^ascii:]
[:^blank:]
[:^cntrl:]
[:^digit:]
[:^graph:]
[:^lower:]
[:^print:]
[:^punct:]
[:^space:]
[:^upper:]
[:^word:]
[:^xdigit:]
[:alnum:]
[:alpha:]
[:ascii:]
[:blank:]
[:cntrl:]
[:digit:]
[:graph:]
[:lower:]
[:print:]
[:punct:]
[:space:]
[:upper:]
[:word:]
[:xdigit:]
[]^-\
[^\x00-\x{10ffff}]
[8GduO
[hdz.
[libprotobuf %s %s:%d] %s
[ONNXRuntimeError]
[ShapeInferenceError] 
[SPj"
[tX9]
[TypeInferenceError] 
\$$VW
\$(PQ
\$DVW
\$PVW
\$PYj@
\$T;\$X
\0c0x0
\H`l3
\hP~.
\Windows::AI::MachineLearning::TensorMemoryBufferReference<unsigned int>::Capacity
\x%02x
\x{%x}
] != number of classlabels[
] (usually, this means you 
] should not be greater than specified axis dim value [
], while 
]|pIX
]<+u8
^|*W?
^0e0z0
^9w ~
^j@X;
_,9^,|g
_\9^,
_^[Y]
___lc_codepage_func
___lc_collate_cp_func
___lc_locale_name_func
___mb_cur_max_func
__acrt_iob_func
__AdjustPointer
__current_exception
__CxxFrameHandler3
__pctype_func
__processing_throw
__RTtypeid
__std_exception_copy
__std_exception_destroy
__std_terminate
__std_type_info_compare
__std_type_info_destroy_list
__std_type_info_name
__stdio_common_vfprintf
__stdio_common_vsnprintf_s
__stdio_common_vsprintf
__stdio_common_vsprintf_s
__stdio_common_vswprintf
__strncnt
__uncaught_exception
_9~ t
_aligned_free
_aligned_malloc
_beginthreadex
_callnewh
_calloc_base
_cexit
_CIcosh
_CIfmod
_CIpow
_CIsinh
_CItanh
_close
_configure_narrow_argv
_create_locale
_crt_atexit
_CxxThrowException
_difftime64
_DmlExecutionProvider_
_dtest
_errno
_except_handler4_common
_execute_onexit_table
_fdtest
_fence_after
_fence_before
_free_base
_free_locale
_fseeki64
_fsopen
_get_errno
_get_stream_buffer_pointers
_Getdays
_Getmonths
_Gettnames
_gmtime64_s
_initialize_narrow_environment
_initialize_onexit_table
_initterm
_initterm_e
_invalid_parameter_noinfo
_invalid_parameter_noinfo_noreturn
_kernel_time
_libm_sse2_acos_precise
_libm_sse2_asin_precise
_libm_sse2_atan_precise
_libm_sse2_cos_precise
_libm_sse2_exp_precise
_libm_sse2_log_precise
_libm_sse2_pow_precise
_libm_sse2_sin_precise
_libm_sse2_sqrt_precise
_libm_sse2_tan_precise
_localtime64_s
_lock_file
_lock_locales
_malloc_base
_mktime64
_purecall
_read
_realloc_base
_register_onexit_function
_RuleBasedTransformer
_seh_filter_dll
_set_errno
_sopen_s
_Strftime
_stricmp
_strtoi64
_towlower_l
_towupper_l
_unlock_file
_unlock_locales
_Unused
_W_Getdays
_W_Getmonths
_W_Gettnames
_wcsdup
_Wcsftime
_wcsicmp
_wfsopen
_Wh|R/
_wsopen_s
`.rdata
`c` - cell gate
`f(x) = x for x >= 0`., is applied to the data tensor elementwise.
`f` - forget gate
`h` - hidden gate
`H` - Hidden state
`i` - input gate
`num_directions` - 2 if direction == bidirectional else 1
`o` - output gate
`P[iof]`  - P peephole weight vector for input, output, and forget gates
`PB[iof]`  - P peephole weight vector for backward input, output, and forget gates
`R[iofc]` - R recurrence weight matrix for input, output, forget, and cell gates
`R[zrh]` - R recurrence weight matrix for update, reset, and hidden gates
`r` - reset gate
`Rb[iofc]` - R bias vectors for input, output, forget, and cell gates
`RB[iofc]` - R recurrence weight matrix for backward input, output, forget, and cell gates
`Rb[zrh]` - R bias vectors for update, reset, and hidden gates
`RB[zrh]` - R recurrence weight matrix for backward update, reset, and hidden gates
`RBb[iofc]` - R bias vectors for backward input, output, forget, and cell gates
`RBb[zrh]` - R bias vectors for backward update, reset, and hidden gates
`RBbi` - RR bias vectors for backward input gate
`Rbi` - R parameter bias vector for input gate
`RBi` - R recurrence weight matrix for backward input gate
`Ri` - R recurrence weight matrix for input gate
`t` - time step (t-1 means previous time step)
`W[iofc]` - W parameter weight matrix for input, output, forget, and cell gates
`W[zrh]` - W parameter weight matrix for update, reset, and hidden gates
`Wb[iofc]` - W bias vectors for input, output, forget, and cell gates
`WB[iofc]` - W parameter weight matrix for backward input, output, forget, and cell gates
`Wb[zrh]` - W bias vectors for update, reset, and hidden gates
`WB[zrh]` - W parameter weight matrix for backward update, reset, and hidden gates
`WBb[iofc]` - W bias vectors for backward input, output, forget, and cell gates
`WBb[zrh]` - W bias vectors for backward update, reset, and hidden gates
`WBbi` - WR bias vectors for backward input gate
`Wbi` - W parameter bias vector for input gate
`WBi` - W parameter weight matrix for backward input gate
`Wi` - W parameter weight matrix for input gate
`X` - input tensor
`z` - update gate
{"cat" : "
{%d,%d}
{%d,}
{,+{(
{2W4R6i6
{additionalDescription}
{broadcast_doc}
{description}
{filter_desc}
{name}
{op_type}
{opName}
|$\QP
|$\uo
|$09t$
|$4;}
|$49}
|$4Pj
|$dQP
|$poVQ
|$T9t$<
|mISink must be provided.
} PSRQ
}(9] t
}, actural: 
}, Got: 
}, input shape = {
}. Actual:
}. Got: 
}[j X
}L+L$
}N+D$
}QSVW
}SSVW
~&j0Y
~,9~$t
~3a*~3a*~3a*~3a*
~B;~,r
~d;=DF:
~h_^]
~ljpX
~X_[^
+/+E+F+M+s+v+
+](VW
++<>||~~
++Q5@.
++Q5@.Q5@.Q5@.Q5@.
+>7:Z
+020K0\0v0
+494S4
+CL9SLj
+F ;F$}
+hd)1
+hp61
+K(+S
+L$4x]
+T$$;
+V +V
+v$x+v$xv$+xv+$xv$+x+$vx+$vx$v+x+$vx$+vx+v $+v $v $+v +$v $++$ v+$ v$ v++$ v$+ v+xv$+ v$v$ +v+ $v$ ++x$v+ $v$v ++ $v$ +v
< <$<(<,<0<4<8<<<@<D<H<L<P<T<X<\<`<d<h<l<p<t<x<|<
< <$<(<,<0<4<H<L<P<h<l<p<
< <$<(<,<0<4<H<X<\<l<|<
< <$<(<,<4<8<L<P<T<X<\<`<d<h<l<p<t<x<|<
< <$<(<@<P<T<X<\<p<t<
< <$<:<@<M<
< <$<<<@<D<X<\<`<t<
< <%<*<B<S<Y<^<j<|<
< <&<-<7<<<G<M<W<a<g<k<q<w<
< <(<\<l<x<
< <(<0<<<\<d<l<x<
< <(<0<<<D<x<
< <(<0<8<@<H<X<|<
< <(<4<T<\<d<p<
< <(<4<T<\<d<p<x<
< <(<8<@<P<X<h<p<
< <*<4<><H<R<\<f<p<z<
< <,<L<X<x<
< <@<
< <@<H<P<\<|<
< <<<L<X<x<
< <0<<<D<d<
< <0<4<8<<<@<D<H<L<P<T<X<\<`<d<h<l<p<x<|<
< <0<8<H<P<`<h<x<
< <3<Q<]<i<u<
< <8<<<@<D<L<P<d<h<l<
< <9<P<
< <D<L<T<\<d<l<t<|<
< <J<S<
< <T<d<p<x<
< =\=
< =0=<=\=h=
< =D=
< =N=
<!<_<
<!<-<><t<
<!<-<9<E<j<
<!<-<9<U<
<!<1<8<E<M<S<W<o<
<!<c<
<!<L<h<|<
<!=[=
<!='=,=2=<=A=P=t=
<!=9=m=v=
<!=D=T=
<!=M=
<"<)<-<3<=<C<G<M<T<\<b<f<m<u<{<
<"<~<
<"<'<:<E<K<U<e<j<y<~<
<"<5<Z<d<i<
<"<7<D<S<i<u<_=
<"<9<
<"<b<
<"=_=
<#<*<1<8<J<O<`<e<z<
<#<\<c<{<
<#<8<=<R<W<l<q<
<#<8<O<
<#<8<O<k<
<#<A<M<R<^<j<v<
<#<A<M<Y<e<
<#=)=/=5=;=A=G=M=S=Y=_=d=q=
<#=*=?=T=h=
<#=;=
<#=?=u=
<#=E=[=m=>>P>
<#=H=
<$<(<,<0<D<H<`<p<t<x<
<$<(<,<0<D<H<L<`<d<h<|<
<$<(<@<D<\<`<x<
<$<(<<<@<D<X<h<l<p<
<$<)<=<B<N<Z<k<
<$<)<3<9<C<N<S<X<^<b<h<n<x<~<
<$<,<<<D<P<\<p<
<$<,<4<@<H<`<p<
<$<,<4<<<D<L<T<\<d<l<t<|<
<$<,<4<<<D<L<T<`<
<$<,<4<<<D<L<T<`<h<
<$<,<4<<<D<L<X<`<
<$<,<4<<<D<P<p<x<
<$<,<4<<<H<l<t<|<
<$<,<4<<<H<P<p<
<$<,<D<T<\<x<
<$<+<
<$<<<@<X<h<l<p<t<x<
<$<=<
<$<0<P<X<`<h<p<|<
<$<0<P<X<`<l<
<$<4<8<<<@<T<d<t<x<|<
<$<9<N<e<
<$<A<`<j<
<$<D<L<T<\<d<p<
<$<D<L<T<`<
<$<D<L<X<x<
<$<D<P<p<x<
<$<F<W<
<$<H<
<$<j<
<$<k<}<
<$=4=@=H=|=
<$=J=
<$=X=
<$>.>C>X>
<$>P>W>k>w>
<%<*</<K<\<
<%<@<[<v<
<%<@<Q<W<\<u<z<
<%<\<c<{<
<%<1<?<Y<
<%<b<t<
<%<D=p=
<%<J<r<
<%<Y<
<%=,=7=N=[=n=
<%=+=D=X=c=
<%=c=
<%=r=
<&<;<z<
<&<8<
<&<A<K<W<r<|<
<&=8=t=
<&=C=[=b=~=
<&=E=|=
<(<,<0<4<8<L<P<`<p<t<x<|<
<(<,<0<8<<<P<T<l<p<t<
<(<,<D<T<X<p<t<
<(<^<
<(<=<u<
<(<><|<
<(<0<8<@<H<P<\<|<
<(<0<8<@<H<X<
<(<0<8<D<d<p<
<(<4<<<p<
<(<4<<<T<x<
<(<4<T<\<h<
<(<4<T<`<
<(<4<T<p<
<(<8<H<P<\<`<l<p<|<
<(<8<H<X<h<x<
<(<D<T<`<h<
<(<e<l<
<(<H<P<\<|<
<(<K<v<
<(<Q<
<(<X<
<(=_=
<(=`=
<(=-=L=Q=e=r=~=
<(=1=\=
<(=8=D=d=p=
<(=8=D=d=p=x=
<(=8=D=L=
<(=U=
<)<:<@<E<Q<[<g<x<
<)<C<
<)<I<U<d<
<)=0=F=V=
<)=f=
<*<E<`<
<*<F<x<
<*=>=L=[=
<*=U=
<,<<<@<D<L<d<h<
<,<<<H<P<p<
<,<<<L<
<,<<<L<\<l<|<
<,<><
<,<0<4<8<@<D<H<\<`<p<t<x<
<,<0<4<L<P<h<l<p<
<,<4<@<`<h<t<
<,<4<<<D<L<T<\<d<l<t<
<,<4<<<D<L<T<\<d<l<x<
<,<4<<<H<P<h<x<
<,<7<=<B<K<Z<d<y<
<,<A<
<,<F<
<,<L<
<,=6=K=`=U?f?q?w?}?
<,=t=
<.<E<
<.<N<_<{<
<.=^=
<.=e=
<.=E=V=z=
<.=I=d=
<.=Q=
<.=Z=
</<:<c<
</<\<|<
</<5<:<F<V<]<m<
</<D<f<
</<F<
</<j<
</=G=j=
</=U=_=p=
</assembly>
<:<D<Y<n<
<:<s<
<:=D=J=s=
<:t%<,t!</u%
<:u WSj;j
<:u#W
<;=V=y=
<?<p<
<?=S=o=
<?xml version='1.0' encoding='UTF-8' standalone='yes'?>
<@<P<d<
<@>]>
<[<2=p=
<]<j<
<^=8>
<_u-A;
<`<{<
<}<P=
<+<<<X<o<
<+<2<?<K<\<
<+<3<8<O<`<f<k<w<
<+<9<H<V<t<
<+<H<
<+<K<o<
<+<M<
<+=:=X=w=
<+=>=[=l=
<+=K=
<+>\>i>p>
<+>A>q>v>{>
<'<,<
<'<,<1<B<J<O<f<w<}<
<'<,<E<V<\<i<s<
<'<[<
<<<d<
<<<D<L<T<\<d<l<t<|<
<<<E<V<
<<<L<X<`<
<<=d=
<<=K=W=
<<=n=
<'<1<=<N<
<'<1<5<;<E<I<O<Y<_<g<p<v<z<
<'<2<9<W<d<o<v<
<'<2<P<s<
<-<3<K<]<
<-<B<
<-<D<h<
<'<f<
<-=[=
<-=]=v=
<-=_=F>W>
<==z=
<=>G>s>
<'=1=
<=DDD
<'=g=s=
<-=J=Z=z=
<'=M=W=w=
<-=T=p=
<-=x=
<><E<_<r<w<
<><n<
<0|Q<7
<0<:<O<d<
<0<@<D<\<`<d<l<p<
<0<4<8<@<D<L<P<d<t<x<
<0<4<8<<<D<\<l<p<t<
<0<E<\<
<0<h<
<0<t<
<0<V<
<0=7=P=a=x=c>j>
<0=I?
<0D0l0x0
<0L0v0
<1<j<q<y<
<1<r<
<1<s<
<1=B=I=O=r=y=s>
<1=K>
<1=q=
<2<@=J=_=t=
<2<B<H<P<e<q<
<2=<=U=
<2=N=i=
<3<=<R<g<~<
<3<H<_<
<3<I?z?
<3=@=Q>l>m?
<3=c=
<3=o=
<3=q=
<4<;<H<T<e<
<4<@<`<h<p<x<
<4<<<H<h<t<
<4<8<P<`<d<h<l<t<
<4<D<H<X<\<l<p<
<4<I<
<4<P<`<l<t<
<4=;=S=f=
<5<K<i<y<
<5<P<k<
<5<q<~<
<5=M={=
<6<H<
<6===R=g=~=
<6=Q=a=g=o=
<7<@<m<}<
<7<|<
<7<p<
<7<S<
<7<V<g<
<7=A=[=g=u=
<7=l=
<8<@<H<P<X<d<
<8<@<L<l<t<|<
<8<\<
<8<M<T<^<j<w<
<8<N<x<}<
<8<X<|<
<8=e=
<8=E=f=x=
<8=p=
<9<d<
<9=B=^=
<9=c=
<9=H=
<9=O=y=~=
<A<f<
<A<g<q<
<a<w<
<A<W<k<
<A=f=w=
<A=f=x=
<A=R=X=]=j=
<assembly xmlns='urn:schemas-microsoft-com:asm.v1' manifestVersion='1.0'>
<B<I<P<j<
<b=l=
<B=V=l=
<C<h<~<
<C=b=
<c=z=
<d?{?
<d<q<
<D<V<x<
<D>W>
<f?q?
<F<f<x<
<F<W<
<F<X<
<F=B>A?
<F=n=
<F=O=
<F=q=
<F=y=
<G<e<
<G<j<t<
<G<N<\<
<g<p<
<G<Q<
<G=B>[>`>
<G=Q=^=
<H<|<
<H<U<a<o<
<H<X<d<l<
<H=+>q>
<H=p=
<H=u=E>
<H=U=v=|=
<hDu/
<I=f=w=
<I=k=u=
<J<[<s<
<J<[=v=
<J<p<
<j=q=|=
<K=0?x?
<K=U=j=
<L<\<h<p<
<L<g<
<L<o<y<
<L<S<h<}<
<L=k=
<l=s={=
<l=y=O>i>
<M<`<
<M<k<p<
<M<W<z<
<m=]>
<N<t<~<
<N=W=
<O<V<k<
<P?m?
<P<`<l<t<
<P<z<
<P=f=
<Pukj
<Q<[<
<Q<b<
<Q=v=
<q=x=
<R<m<
<R=v=
<S<W<[<_<c<g<k<o<s<w<{<
<S=e=j=
<S=j=
<S=q=}=
<SVWj
<t<{<
<T=d=t=
<U<g<l<
<V<q<
<V=q=
<W<e<
<W<v<
<X<a<
<X=5>
<xt"<Xu!
<Y<b<
<Y<q<y<
<Y=c=}=
<Z<x<}<
<Z=d=j=
= =$=(=,=0=4=8=<=@=D=H=L=P=T=X=\=`=d=h=l=p=t=x=|=
= =$=(=,=0=4=8=<=C=
= =$=(=,=4=8=<=D=\=`=d=h=l=
= =$=(=@=D=\=`=x=
= =$=(=<=@=D=H=L=P=X=\=`=h=
= =$=<=L=P=h=x=|=
= =$=<=L=P=T=l=|=
= =&=,=2=6=<=@=G=O=U=[=`=f=m=w=~=
= =(=@=D=\=`=d=h=l=p=t=x=|=
= =(=\=l=x=
= =(=0=@=H=X=`=p=x=
= =(=8=@=P=X=h=p=
= =,=8=H=X=h=x=
= =,=L=T=`=
= =,=L=X=x=
= =?=
= =@=H=P=X=`=h=p=|=
= =0=@=D=H=L=P=X=\=p=t=
= =I=l=
= =n=
= >;>K>Q>Y>q>}>
= >|>
= ><>C>h>
= >0><>D>
= >O?
= >P>
= >Y>+?
=!=&=J=P=U=_=d=
=!=2=O=p=
=!=C=h=
=!=Q=|=
=!=u=|=
=!>4>>>D>f>
=!>F>X>
="=)=B=S=K>V>
="=4=9=>=Q=V=[=t=
="=5=_=t=
="=7=L=f=
=">)>>>S>
=#=(=A=R=X=e=o={=
=#=5=:=L=Q=j=
=#=6=R=^=w=|=
=#>*>C>T>v>
=#>:>c>
=#>:>E>
=#>E>P>c>
=#>X>
=$=(=,=D=H=L=T=l=p=t=|=
=$=(=@=P=`=p=t=
=$=*=B=T=
=$=,=4=@=`=h=p=|=
=$=,=4=@=H=h=
=$=,=4=<=D=L=T=\=d=l=t=|=
=$=,=4=<=D=L=T=\=h=
=$=,=4=<=D=L=X=`=
=$=,=4=<=D=L=X=x=
=$=,=4=<=H=l=t=|=
=$=,=4=D=L=T=\=h=p=
=$=,=8=\=d=l=t=|=
=$=,=8=X=`=p=
=$=,=T=\=h=
=$=.=8=B=L=V=`=j=t=~=
=$=.=C=X=o=
=$=@=P=\=d=
=$=<=L=P=`=d=t=x=|=
=$=<=L=P=h=l=
=$=0=:=F=W=
=$=0=8=|=
=$=0=8=l=|=
=$=3=s=
=$=4=<=D=L=T=\=d=l=t=|=
=$=4=8=P=`=d=t=x=|=
=$=4=D=H=X=\=`=x=|=
=$=8=E=Q=b=
=$=9=N=b=
=$=D=`=p=|=
=$>+>E>X>]>
=$>4>
=$>4>@>`>l>
=$>4>@>H>|>
=$>8>A>
=%=,=2=D=K=r=|=
=%=/=D=Y=
=%=:=
=%=;=J=
=%=0=C=a=m=y=
=%=5===M=U=a=m=
=%=m=t=
=%=X=t=
=%>/>9>
=%>[>d>
=%>n>
=&=,=6=K=X=d=u=
=&=0=4=:=D=H=N=X=_=f=m=t={=
=&=1=S=r=
=&=7=~=
=&=7=w=
=&=8=
=&=D=l=
=&=e=
=&=U=
=&>:>
=&>;>
=&>A>
=(=,=<=@=D=H=L=P=T=\=`=d=h=p=t=x=|=
=(=,=<=L=P=`=d=|=
=(=,=0=4=8=@=D=H=P=T=X=\=`=t=x=
=(=,=D=H=`=p=t=
=(=.=2=7=<=B=L=R=V=\=c=m=r=~=
=(=/=<=M=U=d=n=x=
=(=-=
=(=0=<=\=d=l=t=|=
=(=0=<=\=x=
=(=0=H=l=|=
=(=0=P=X=t=
=(=4=<=p=
=(=4=T=\=d=p=
=(=8=\=d=l=t=|=
=(=8=<=L=\=`=d=h=p=
=(=8=D=d=l=t=
=(=8=H=P=\=`=l=p=|=
=(=C=U=
=(=d=
=(=F=V=\=d=y=
=(=H=X=`=
=(>8>D>L>
=(>F>K>
=(>H>P>`>
=(>p>
=(>P>x>
=)=5=Q=
=)=5=Z=
=)=B=u=
=)=D=
=)=E=
=)=R=
=)>6>X>
=)>M>a>j>
=*=<=C=P=\=m=
=*=5=y=
=*=V=]=q=}=
=*>1>S>
=*>4>M>w>
=*>N>|>
=,=<=@=P=T=X=\=d=|=
=,=<=L=\=l=|=
=,=0=4=L=\=`=d=x=|=
=,=0=H=X=\=`=d=h=l=p=t=x=|=
=,=0=H=X=h=l=
=,=4=@=d=l=t=|=
=,=4=<=D=L=T=\=d=l=t=
=,=8=@=t=
=,=8=@=X=`=p=
=,=8=X=d=
=,=A=X=
=,=Q=X=y=
=,=T=|=
=,>@>
=,>`>
=,>d>
=.=<=A={=3>P>`>t>
=.=C=Z=
=.=I=|=
=.=l=u=
=.>v>
=/=4=n=
=/>A>~>
=/>B>Q>h>
=/>K>U>j>
=:> ?
=:>b>s>
=:>D>m>
=:>Y>V?h?
=;>}>
=;>H>r>
=@=|=
=@=G=`=q=
=@>[>
=@>[>b>{>
=@>`>
=@>i>~>
=@>x>
=[>b>{>
=\>i>
=]>f>n>
=^>y>
=+=<=X=o=
=+=8=W=a=s=
=+>4>
=+>K>W>d>|>F?
=<=2>
=<=D=L=T=\=d=l=t=|=
=<=H=h=p=x=
=<>F>[>p>
=-=[=
='=-=7=B=G=O=T=Z=d=h=n=r=y=
==> Context: 
==>G>
==>N>
='=A=M=[=}=
=-=D=
='=d=z=
='=G={=
=-=H=P=c=
='=P=n=
='>`>
=>>s>
='>E>J>
='>K>n>s>
='>v>
=0=:=W=y=
=0=?=P=
=0=@=H=d=t=
=0=@=P=T=l=|=
=0=|=
=0=<=\=d=l=x=
=0=<=N=i=
=0=8=@=H=T=t=
=0=8=D=d=l=x=
=0=H=b=x=
=0=I=V=
=0=J=
=0=L=\=h=
=0D0]0g0
=1===I=U=q=
=1=6=;=M=R=W=o=
=1=6=Q=
=1=8=E=Q=b=
=1=8=R=e=j=
=1=B=H=M=Y=c=o=
=1=N=
=1=s=
=1>W>
=2=7=t=
=2=R=
=3=:=B=I=P=V=]=o=x=
=3=<=q=
=3=8=S=
=3=C=[=
=3=g=
=3>f>
=3>Y>s>
=4=@=H=|=
=4=<=H=h=x=
=4=8=P=T=X=\=d=h=|=
=4=d=
=4=D=P=p=|=
=4=D=P=X=
=4=T=
=4>A>
=4>D>P>p>|>
=4>t>
=5=V=e=
=5=X=
=5>[>e>u>
=5><>U>_>
=5>F>S>l>
=6=@=L=g=q=}=
=6=G=
=6=G=k=@>Y>`>g>m>
=6=S=`=
=6>H>
=7>d>i>~>
=7>e>
=7>k>
=8=?=
=8=@=H=P=X=d=
=8=@=H=P=X=d=l=
=8=E=R=Y=|=
=8=h=t=
=8>J>h>
=8>p>
=9=d=w=
=9=S=q=}=
=9>@>U>j>
=9>N>
=A=b=m=
=AMDiu!
=b=~=
=C=e=p=
=C>P>
=c>s?
=C>X>
=d=|=
=D=K=c=v=
=D=l=
=D=p=
=D=q=
=D=T=`=h=
=D=Z=z=
=E=\=
=E=M=R=c=h=}=
=F>d>k>
=G=f=
=G=r=
=g=t=
=G>N>g>
=g>p>"?F?X?
=G>S?
=Genuu
=H=t=
=H=X=d=
=H>Z>_>
=I=l=
=I=N=t=y=
=I=y=
=J=O=W=C>q>
=K?f?t?
=K=c=}=
=K>^>f>m>
=k>4?
=L=`=h=p=x=
=L=t={=
=L>h>
=L>T>\>h>
=m>1?c?l?
=m>g?
=N=~=
=n=G?}?
=N=t=~=
=N>U>n>
=O=w=
=o>|>
=p=w=
=Q=|=
=Q=X=p=
=R=_=
=R>}>
=R>n>q?
=S=y=
=S>\>
=V=u=
=V>]>v>
=V>h>
=W=j=
=x>|?
=Y>z>
=Z=+>5>J>_>
> ?%?A?F?N?_?e?~?
> ?J?W?x?
> ?L?d?
> ?m?
> ?T?
> ?V?]?
> ?Y?|?
> >$>(>,>0>4><>T>X>\>`>t>x>|>
> >$>(>,>0>4>8><>@>D>H>L>P>T>\>t>x>
> >$>(>,>0>4>8><>@>D>H>L>P>T>X>\>`>d>h>l>p>t>x>|>
> >$>(>,>0>4>8><>@>H>`>d>|>
> >$>8><>@>T>X>\>`>t>x>|>
> >$>8><>@>X>\>`>t>x>|>
> >&>+>0>6>A>E>K>R>_>j>p>z>
> >&>->?>H>O>X>x>
> >(><>D>X>`>t>|>
> >(>0>@>H>l>t>
> >(>0>8>@>P>`>h>p>
> >(>4>T>`>
> >(>8>\>d>l>t>|>
> >,>4>h>x>
> >,>L>T>\>d>l>t>|>
> >,>L>X>x>
> >@>H>T>t>|>
> >0><>D>d>
> >0>4>8><>@>D>H>L>P>T>X>\>`>d>h>l>p>x>
> >0>4>8>L>P>T>l>|>
> >4>8>H>L>d>t>x>|>
> >4>9>>>R>W>\>o>t>y>
> >8><>@>D>X>\>t>
> >D>L>T>\>d>l>t>|>
> >O>h?w?
>!?`?
>!?F?s?
>!?H?
>!?P?
>!>%>+>/>8>?>J>O>\>b>h>m>t>x>~>
>!>>>U>b>
>!>->9>E>a>
>!>->9>I>P>_>g>o>z>
>!>v>
>!>y>
>"?2?X?r?
>"?f?
>">(>->9>C>O>`>
>">=>y>
>">'>9>>>C>W>\>a>v>~>
>">0>I>f>z>
>">9>
>">9>J>P>U>a>k>w>
>#?f?
>#>\>
>#>->=>G>Q>[>e>o>y>
>#>0>9>U>Z>i>q>
>#>A>M>R>^>j>v>
>#>A>M>Y>e>
>#>D>
>#>E>
>#>S>
>#>S>n>
>#>x>
>$?.?=?M?Y?e?q?
>$?-?
>$?4?@?H?|?
>$?D?L?X?|?
>$?F?W?
>$?L?t?
>$?X?
>$>(>.>2>9>E>J>U>[>e>t>z>~>
>$>)>B>S>Y>f>w>|>
>$>,><>H>h>t>|>
>$>,>4><>D>L>T>\>d>l>t>
>$>,>4><>D>L>T>\>d>l>t>|>
>$>,>4><>D>L>T>\>h>
>$>,>4><>D>L>T>`>
>$>,>4><>D>L>T>l>t>|>
>$>,>4><>D>L>X>|>
>$>,>4><>H>h>p>
>$>,>4><>T>`>h>
>$>,>8>\>d>l>t>|>
>$>,>8>X>d>
>$><>N>
>$>->3>=>C>J>Q>X>`>f>j>p>v>|>
>$>0>P>X>`>h>p>x>
>$>0>P>X>`>h>x>
>$>4>8>H>L>\>l>p>t>x>|>
>$>5>s>
>$>8>H>X>h>l>
>$>D>`>p>|>
>$>D>L>T>\>d>l>x>
>$>D>L>T>`>
>%?A?q?
>%?K?U?
>%?M?^?x?
>%?V?g?
>%>*><>A>Z>k>q>~>
>%>>>j>
>%>3>^>
>%>9>C>L>
>%>B>b>l>
>%>J>
>&?-?F?W?n?
>&?3?Q?
>&?F?W?
>&?I?d?
>&>,>B>I>^>l>r>x>~>
>&>?>
>&>[>
>&>+>:>?>N>S>b>g>v>{>
>&>+>=>B>G>[>`>{>
>&>2>C>y>
>&>7>G>w>
>&>8><>@>D>H>L>P>T>X>\>`>d>h>l>s>
>&>C>S>!?H?]?
>&>h>{>
>(?\?
>(?8?D?L?
>(?C?^?
>(?D?l?
>(?L?p?
>(?x?
>(>,><>@>D>L>d>h>
>(>,><>@>P>`>d>t>x>
>(>,>0>4>H>L>P>d>h>l>p>
>(>,>D>H>`>d>|>
>(>,>D>T>d>t>x>
>(>,>D>T>d>t>x>|>
>(>,>D>T>X>\>`>h>l>t>
>(>.>2><>Z>j>p>x>
>(>=>T>
>(>0>@>H>X>`>p>x>
>(>0><>@>L>P>\>h>x>
>(>0>8>D>d>l>t>
>(>0>d>t>
>(>2><>F>P>Z>d>n>x>
>(>8><>@>X>h>l>p>
>(>8>H>X>h>x>
>(>9>?>L>^>e>r>~>
>(>d>
>(>H>T>\>
>(>H>T>t>|>
>(>I>O>g>y>
>(>o>
>)?;?@?E?b?y?~?
>)?D?N?c?x?
>)>0>5>K>P>k>
>)>3>=>M>W>a>k>u>
>)>5>Q>
>)>E>}>
>*?1?F?[?r?
>*?h?
>*?L?
>*>/>4>P>f>w>
>*>3>`>
>*>c>
>*>E>`>
>*>f>
>*>u>
>,?^?
>,?`?
>,?<?H?P?p?x?
>,><>@>X>h>l>|>
>,><>D>L>T>\>d>|>
>,><>H>P>
>,><>L>P>T>l>p>
>,>4><>D>L>T>\>h>
>,>6><>C>I>[>b>
>,>8>@>t>
>,>e>l>
>,>h>
>.?3?t?
>.?5?K?
>.?5?N?_?v?
>.>B>S>d>u>
>.>e>
>/?>?\?|?
>/>@>F>K>W>i>v>
>:?\?
>:?A?Z?
>:?D?Y?n?
>:>A>c>
>:>D>]>
>:>V>i>
>;?H?s?
>;>M>
>;>N>[>
>;>X>d>
>-?;?d?
>-???D?
>??P?|?
>?>k>
>?>q>
>'?1?J?y?
>'?C?^?
>@>l>
>@>t>O?
>\>l>x>
>]?y?
>^>s>
>^>s>{>
>_^[]
>`>s>
>+?:???Q?X?e?q?
>+?8?
>+?F?
>+><>V>
>+>>>}>
>+>0>5>R>v>
>+>4>;>h>F?U?
>+>5>A>\>f>r>
>+>H>Y>u>
><?g?
><?p?
><>]>v>
><>`>
><>`>x>
><>a>
><>D>T>\>d>l>t>|>
><>H>h>p>|>
><>H>h>p>x>
>>?G?[?
>'>]>
>->}>
>>>{>
>>>a>
>>>n>
>'>7>A>Q>[>k>
>->B>
>'>C>a>u>
>'>I>T>
>->J>x>
>'>T>s>
>->y>
>0>@>P>t>|>
>0>{>
>0>>>
>0>4>8>@>X>\>t>x>|>
>0>5>N>_>e>r>
>0>7>\>i>
>0>8>@>H>P>`>
>0>J>k>
>0>J>z>
>0>L>\>h>
>0>L>c>W?
>0>P>X>`>l>
>0>Z>a>z>
>1?y?
>1>=>I>U>q>
>1>B>_>l>}>
>1>d>
>1>T>
>2???
>2?<?T?\?a?s?x?}?
>2?n?t?
>2?Z?
>2>`>
>2>9>
>3?=?R?g?{?
>3?f?
>3?V?q?
>3>f>
>3>Q>]>i>u>
>3B>Windows::AI::MachineLearning::TensorMemoryBufferReference<class std::basic_string<char,struct std::char_traits<char>,class std::allocator<char> > >::Capacity
>4?9?W?d?p?
>4?b?
>4>@>H>|>
>4><>l>t>
>4>>>S>h>
>4>8><>@>D>H>L>P>T>X>\>`>d>h>l>p>b?~?
>4>8>P>T>X>l>p>t>
>4>D>H>L>P>T>X>\>p>t>x>
>4>D>T>d>h>l>p>x>
>4>K>
>4>X>h>t>
>5>b>l>
>5>s>
>5>X>
>6>G>
>6>Q>t>
>7?C?
>7?Z?
>7>,?
>7>S>g>
>7>V>g>
>7>Z>Z?
>8?p?
>8>\>
>9>j>
>A?H?a?
>a?k?
>A?P?_?k?s?
>a?s?
>Anu 
>B?Q?s?
>C>'?G?U?d?
>C>s>
>D?K?`?u?
>D>_>j>
>D>K>c>v>
>D>l>
>D>N>g>
>D>t>
>DXBCO
>E?P?
>F?Z?
>F>|>
>File not found: %s
>G?b?s?
>h>q>
>H>X>d>l>
>I?`?
>I?z?
>i>r>
>I>S>
>j?t?
>J>p>z>
>K?]?b?
>K?U?j?
>K>R>t>
>L?c?
>L?R?n?s?
>l?x?
>L>\>h>
>L>\>h>p>
>L>a?
>m>+?;?
>M>V>z>
>N>~>
>P>h>
>P>n>z>
>T>[>s>
>V?d?
>Y>`>
>Z>~>
0 == center_point_box_ || 1 == center_point_box_
0 == memory_size % kMinAllocationSize
0 0 06070>0?0
0 0$0(0,0004080<0@0D0H0L0P0T0X0\0`0d0h0l0p0t0x0|0
0 0$0(0,0004080<0@0H0L0P0T0X0\0`0d0h0l0p0t0x0|0
0 0$0(0004080<0@0H0`0p0
0 0$0<0@0X0\0t0x0|0
0 0(0
0 0(0@0D0\0l0|0
0 0(040<0\0x0
0 0(0H0d0t0
0 0)0n0
0 0,040h0x0
0 0@0H0P0X0`0l0
0 0<0L0X0x0
0 000<0D0d0
0 00040D0H0`0d0h0l0p0t0x0|0
0 00040D0H0X0\0t0
0 00040L0\0`0d0h0p0
0 00070<0?0
0 00080H0P0`0h0x0
0 000T0\0d0l0t0|0
0 02070
0 04080<0@0D0H0L0P0T0X0\0`0h0
0 080<0@0T0X0\0`0h0l0p0x0
0 080<0T0d0h0l0
0 0D0L0T0\0d0l0t0|0
0 0T0d0p0x0
0 1'1j1q1
0 1D1l1
0 1X1
0!0)080:0
0!0)080;0
0!0+0g0m0
0!0<0g0
0!0=0]0g0
0!0=0s0W1
0!010A0S0
0!03080Q0]0c0h0
0!040<0A0S0X0j0o0
0!060
0!060I0U0r0
0!1D1g1q1
0!1F1X1
0!1I1
0!2I2
0"0+0K0R0Y0
0"0=0M0_0q0
0"030J0`0
0"050T0
0"080=0U0Z0s0{0
0"0E0`0j0
0"0w0
0"1E1
0"1H1R1
0"9I9o9
0#0(0-0I0]0p0
0#0A0M0Y0e0
0#0f0l0
0#0U0
0#0W0
0#1*1L1
0#1;1i1}1
0#1>1Y1
0#141N1U1\1
0#1a1
0#1A1M1R1^1j1v1
0#1h1
0$0(0,000D0T0X0\0`0h0
0$0(0@0D0\0`0d0l0
0$0(0@0D0H0L0P0T0X0\0`0d0h0l0p0t0|0
0$0(0<0L0P0`0p0t0x0|0
0$0*0.040:0@0D0J0Q0Y0b0h0r0x0
0$0*040?0E0I0O0Y0_0c0i0p0|0
0$0*0v0
0$0,040@0`0l0
0$0,040<0D0\0d0l0t0|0
0$0,040<0D0L0T0\0d0l0t0|0
0$0,040<0D0L0T0\0d0l0x0
0$0,040<0D0L0T0\0h0
0$0,040<0D0L0X0|0
0$0,040<0D0L0X0x0
0$0,040<0D0P0p0|0
0$0,040<0D0P0p0x0
0$0,040<0H0h0p0x0
0$0,040<0X0h0t0|0
0$0,080@0
0$0,080X0d0
0$0.0Z0
0$000P0X0`0h0p0x0
0$000P0X0d0l0
0$04080<0T0X0\0`0h0|0
0$04090H0M0\0a0q0v0
0$080R0h0r0
0$090>0S0X0l0q0v0
0$0D0`0p0|0
0$0D0b0
0$0D0L0T0\0d0l0t0
0$0D0P0p0
0$0E0g0
0$0F0[0
0$1.1C1X1
0$111x1
0$1E1
0$1F1X1
0$1X1
0$2'5.5G5X5,6H6
0$262
0%010=0y0
0%010=0Y0
0%0A0
0%0C0_0
0%0e0m0|0
0%0P0
0%2[2
0&0/0N0
0&0;0l0s0
0&0?1T1
0&0=0K0b0p0
0&0-020F0S0_0p0
0&020>0Z0
0&060i0
0&0Z0_0
0&1,1P1m1{1
0&141N1S1X1|1
0&171j1
0&181
0&181^1q1
0&1E1|1
0&1G1
0&1I1
0(0,0<0@0D0\0l0p0t0
0(0,0004080<0@0D0H0L0P0T0X0\0`0h0
0(0.040:0@0F0L0R0Z0b0h0l0r0x0~0
0(0@0H0Y0
0(0|0
0(0=0T0H1R1g1|1
0(0-0<0A0]0b0
0(000<0@0L0P0\0h0x0
0(000d0t0
0(040T0\0h0
0(040T0`0
0(080<0@0D0H0P0h0x0
0(080<0@0H0\0`0p0t0
0(080H0X0h0x0
0(091
0(0H0P0X0`0h0t0
0(1`1
0(121P1W1p1
0(131c1
0(1U1
0)0.0H0
0)030=0G0Q0[0e0o0y0
0)04090>0D0H0O0U0Y0_0c0j0w0
0)050Q0
0)090>0\0a0w0|0
0)0D0_0z0
0)0T0
0)1.1J1O1m1r1
0)1x1
0*0/0B0U0[0a0g0m0s0y0
0*0X0
0*161B1N1j1
0*1A1I1O1l1s1
0*1M1f1w1
0,0;0@0U0f0l0q0
0,0<0@0H0L0T0h0l0|0
0,0<0@0P0T0d0h0
0,0>0
0,00040<0@0H0`0d0h0p0t0
0,00040L0P0T0\0`0t0x0|0
0,000H0X0\0`0x0|0
0,01060S0e0}0
0,010J0[0a0n0x0
0,040
0,040<0D0L0T0\0d0l0t0|0
0,060O0
0,0c0
0,0H0h0t0
0,0O0j0
0,161N1V1[1n1s1
0,1S1
0,1W1
0,1X1]1b1t1y1~1
0.0A0I0|0
0.0c0
0.0G0n0
0.0Q0
0.1^1
0.171x1
0.1a1
0.1A1^1o1
0.1M1l1
0/0@0F0K0W0b0w0
0/0}0
0/060]0g0m0t0z0
0/0C0
0/0h0
0/0R0m0
0/161O11282Q2b2
0:0@0X0j0
0:0L0Q0
0:1D1[1g1u1
0:1U1_1
0;0q0s1
0;0x0
0;1@1E1a1
0;1F1
0?0D0
0?1R1h1w1
0?1s1z1
0@0d0
0@0h0
0@0t0
0@0w0
0@1v1
0@1x1
0[1g1z1
0^1k1
0^1v1n5
0_^[Y]
0_1f1
0_1s1
0`0y0
0}4>5E5
0+0?0H0
0+0<0H0U0[0a0k0
0+050J0_0v0
0+070P0V0Z0d0
0<0<0A0
0<0A0y0
0<0D0T0\0d0l0t0|0
0<0H0P0
0<0L0X0`0
0<0m0
0<0W0T182
0<0X0h0x0
0<1|3)5G7
0<1R1
0<1U1;2O2y2
0=0=0
0=0c0
0=0t0{0
0>0|0
0>0E0^0s0
0>0n0
0>1s1
0-0#1
0-0:0?0P0U0g0l0
00@0L0T0
0'0@0Q0v0
0'0}0
000@0D0T0X0h0x0|0
000<0\0d0l0t0|0
00000
00000=0=0
00080@0H0P0\0|0
00080@0H0P0\0d0
000B0G0
000C0O0`0
000J0s0
000L0\0h0p0
000S0v0
000X0
001e1
001h1
001K1
0-020
0-040H0T0b0
0070L0a0
0-0d0k0
0'0j0w0
0'0N0S0b0g0x0
0'0T0
0-0u0
0-0V0
0'1.131I1Q1V1i1n1
0'1.1G1~1
01@1H1X1`1p1x1
010=0I0U0q0
01050;0;0
01050;0<0A0
010A0P1
010F0U0
011>1
011T1w1
0123456789-
0123456789-+Ee
0123456789ABCDEFabcdef-+Xx
0123456789ABCDEFabcdef-+XxPp
0123456789abcdefghijklmnopqrstuvwxyz
013o3
0-1E1g1{1$2
0-1H1O1d1y1
0'1k1
0-1l1
01L1u1
020<0U0
021<1
021Q1
021V1h1
021w1
0'2K2R2k2|2
030[0~0
030m0
030Q0]0i0u0
031L1o1
031U1`1
040<0D0L0T0\0d0l0t0|0
040<0D0L0T0\0d0p0x0
040<0D0P0p0|0
04080P0T0h0x0|0
040904E4
040I0
040m0v0
040X1_1
041`1e1j1|1
041O1j1
041p1
051j1
051Q1
060F0W0`0f0
060g0
060H0
060k0
061_1
061G1Y1i1
061i1
061Q1e1
061t1
-070P0z0
070U0o0
071G1
080@0H0P0\0d0
080@0H0P0`0
080@0H0T0\0
080H0T0t0|0
080I0{0
080I0c0j0q0
080X0x0
081A1h1q1
081d1
081p1
081T1
090?0W0i0
0909AZaz
090J0S0Y0
090L0T0[0{0
091`1
091t1
0A0}0
0a0~0
0A0j0
0a0k0
0A1x1
0B0L0n0~0
0B0m0
0B0n0p2
0B0r0
0C0i0s0
0C1o1v1
0C1Z1e1
0D0j0
0D0l0
0D0N0
0D0O0s0
0D0T0`0h0
0D1K1d1
0E0k0
0E0L0d0
0E1`2e3
0F0M0T0h0t0
0F0X0
0F1M1U1^1
0F1z1
0g0<1`1
0G1]1n1
0G1R1
0-g-o-p-
0h0"1
0H0e0
0H0M0R0d0i0n0
0I0_0
0I0P0q0
0I1$2
0I1d1n1
0I1e1
0i1v1
0I2F6
0j}h(
0j}h0*-
0j}hH
0j}hX
0J0T0
0K0b1
0K0R0g0|0
0K0T0]0f0
0K0w0
0L0g0l0
0L0o0
0L0T0\0
0L0x0
0M0}0
0m2"3
0O0u0
0O1{1
0P0T0X0\0`0d0
0P1f1x1
0Q162o2
0Qh|2-
0Qh4!-
0QhLI-
0R1l1
0S0n0{1
0S0q0
0S0u0
0s1J2f2
0ShX|-
0T0o0
0U8\8q8
0V0c0
0V1g1
0W0{0&1
0W0s0
0W1h1
0X0x0
0X1o1
0z0[1
0Z0d0
0Z1y1
1 == capability->nodes.size()
1 1$1(1,1014181<1@1D1H1L1P1T1X1\1`1d1h1l1p1t1x1|1
1 1$1(1014181<1@1D1H1L1P1T1X1\1`1d1l1
1 1$1(1014181L1\1`1p1
1 1%1+11171=1D1J1P1Z1^1d1i1p1x1
1 1(1\1l1x1
1 1(101<1D1l1t1|1
1 1(101<1D1x1
1 1(10181D1d1l1t1|1
1 1(10181H1
1 1(141<1
1 1(181@1P1X1h1p1
1 1*1w1
1 1,101<1@1D1H1T1X1d1
1 1,141h1x1
1 1;1V1q1
1 1@1H1d1t1
1 1@1H1P1X1`1h1p1|1
1 1@1H1T1t1|1
1 101<1D1d1
1 10141D1H1`1d1|1
1 10141L1\1`1d1h1l1p1t1x1|1
1 181<1@1D1H1L1P1T1X1\1`1d1x1|1
1 181<1T1X1l1|1
1 1b1@4W4,5C5
1 1D1L1T1\1d1l1t1|1
1 2)2H2O2Q2_2
1 2;2^2y2
1 2@2R2W2
1 2_2
1 2'2<2Q2:3
1 282g2{2
1 for the first maximum value, and 0 for all others
1!1&1<1A1F1Z1_1z1
1!1(1/1A1X1l1p1t1x1|1
1!1-1>1
1!1-191E1a1
1!1-1I1
1!161V1>3]3g3|3
1!1c1
1!22282=2Q2^2j2{2
1!2v2
1"1)161B1S1
1"1*1?1K1d1j1n1x1
1"1?1_1j1}1
1"1`1~1
1"1<1R1\1q1
1"1>1R1h1r1
1"161B1P1
1"1K1v1
1"2E2n2
1"2F2
1#1(1-1I1]1
1#1*1?1T1k1
1#1'1+1/13171;1?1K1_1j1
1#141j1
1#161;1@1R1W1\1t1
1#1C1
1#1G1
1#1H1_1
1#1M1p1v1
1#2(2
1#2E2P2c2
1#2P2
1#2W2
1$1(1@1D1H1L1T1l1p1
1$1(181<1T1d1t1x1
1$1(1H1h1
1$1*10141:1>1E1R1]1c1m1x1~1
1$1,141@1`1h1p1x1
1$1,141@1`1l1
1$1,141<1D1L1T1\1
1$1,141<1D1L1T1\1d1l1t1
1$1,141<1D1L1T1\1d1l1t1|1
1$1,141<1D1L1T1\1d1l1x1
1$1,141<1D1L1T1\1h1
1$1,141<1D1L1T1`1
1$1,141<1D1P1p1
1$1,141<1H1P1p1
1$1,141<1L1T1\1d1p1
1$1,141<1X1h1t1|1
1$1,181\1d1l1t1|1
1$1,181X1d1
1$1@1P1\1d1
1$1<1@1X1h1x1|1
1$1=1T1
1$101P1\1|1
1$1-1:1A1[2
1$111V1h1$343
1$141@1H1|1
1$1D1L1T1t1|1
1$1D1L1X1x1
1$1V1
1$2[2
1$2P2
1%1;1,2Z2
1%1+10161=1C1G1M1S1Y1_1e1k1q1w1}1
1%101C1a1m1y1
1%141
1%2H2S2
1&1;1P1l1
1&1+1>1C1X1]1q1v1
1&1+101C1H1M1f1w1}1
1&1-1F1k1
1&181
1&1A1t1
1&1N1
1&1q1
1&1R1W1\1n1s1x1
1&2+202L2Q2V2o2
1&282
1&2u2
1&4~506R6\6r6
1(1,1@1D1\1`1x1
1(1,1<1@1X1h1x1|1
1(1,10141<1@1D1X1\1`1d1h1p1t1|1
1(10181D1d1l1x1
1(101d1t1
1(1-1=1B1N1`1e1u1
1(121;1p1l3
1(141T1\1d1l1t1|1
1(181<1@1T1X1h1l1|1
1(181<1@1X1\1t1x1
1(181<1@1X1h1l1
1(181H1L1\1`1d1|1
1(181H1X1`1l1p1|1
1(181H1X1h1x1
1(191J1[1
1(1B1L1e1v1
1(1d1
1(1H1P1\1|1
1(1H1P1X1d1
1(1L1d1l1t1|1
1(1s1
1(222G2\2
1(252V2\2t2
1(2l3
1)1:1V1k1
1)151Q1
1)1B1f1p1
1)1N1
1)1N1`1d1h1l1p1t1x1|1
1)1q2
1)1T1
1)1Y1t1
1)2@2^2t2
1*1/141H1M1h1
1*161G1
1*1E1k1
1*1M1
1*2{2
1*232W2w2
1*272N2
1*2c2
1,1<1H1h1p1x1
1,101@1D1T1d1t1x1
1,101@1D1T1X1h1l1p1t1|1
1,1014181<1@1D1H1L1P1T1X1\1`1t1x1|1
1,10141L1\1`1d1x1|1
1,10141L1P1h1x1|1
1,10141L1P1T1X1\1`1d1h1l1p1t1x1|1
1,11161O1T1Y1r1
1,121J1\1
1,141<1D1L1X1x1
1,181X1`1l1t1
1,181X1`1p1x1
1,1P1O2Z2
1,232K2n2
1,2d2
1.0.200713-1013.1.vb.07142e1
1.141C1J1S1Y1_1h1o1
1.141L1^1
1.1H1X1b1u1
1.1M1
1.2;2^2d2|2
1.2b2i2
1.2l2
1.2U2
1.2V2|2
1/1@1F1K1W1i1p1}1
1/111
1/1K1
1/262K2`2
1/282S2j2
1/2O2{2
1:1j1
1:2t2G3
1;1[1{1
1;1e1
1;1i1s1
1?1_1
1?1f1
1?1k1r1
1?1w1
1?2[2
1?2F2[2p2X5l5v5
1@1d1
1@1f102}2D3q4
1@1P1\1d1
1@2d2l2t2|2
1@2E2
1@3d5`8n8
1\1f1
1\2q2
1\2z2
1]162G2
1^1l1
1`2h2p2|2
1`9L;
1+2?2n2
1+222J2]2|2
1+2F2P2e2z2
1+2V2
1+2Z2
1<1d1
1<1D1L1T1\1d1l1t1|1
1<1D1T1\1d1l1t1|1
1<1L1X1`1
1<2C2\2w2
1<2q2
1=1j172
1=1p1
1=1t1{1
1=2Z2h2m2
1>2K2n2t2
1>2q2
101@1D1H1L1`1d1|1
101@1L1T1
101<1\1d1l1x1
1014181P1`1d1h1
1014181P1T1l1p1t1
10181@1H1P1\1|1
10181@1L1l1t1|1
10181@1X1d1
101a1h1}1
101K1
101X1
102F2X2
1091C1X1m1
10P0`0
10S0Z0b0i0p0v0}0
10X0a0
1'1~1
1-1<1G1T1[1c1q1|1
1-1<1Q1u1
111=1I1U1q1
1'1-11171;1B1O1T1_1e1o1z1
11181
111A1
111F1]1
111F1K1
111s1
111Z1
112L2
1-141M1^1u1@3J3_3t3
1-171\1l1p1t1x1|1
1'1j1
1'1o1
1-1q1
1'1R1c1x1
1'1Z1o1
121?1J1
121=1`1j1
121O1
1'242f2u2 3
1'242U2[2s2
1'2J2m2
1-2P2}2
1'2R2
1-2Y2`2t2
131`1
131=1
131j1v1
131z1
132S2S3q3}3
132X2]2|3
141;1P1e1
141@1d1l1t1|1
141<1D1L1T1\1d1l1x1
141<1D1L1T1\1h1
141>1[1{1
141D1P1X1|1
141I1`1
142;2T2^2
142_2j2
142m2
151?1T1i1~1
151@1R1D2W2
151i1
153=3o6w678?8^8d8j8p8v8|8
161G1
161G1z1
161H1
161I1h1
161y1=5
162G2
162Q2
162V2g2
171I1
171m1
172b2
172d2
181@1H1P1\1|1
181l1
182[2
191G1
191K1
192v2
1a1n1
1A1Q1c1
1B2]2s2
1B2I2f2u2
1C1Z1u1
1C2L2U2`2f2l2u2
1C2V205>5
1D input tensor
1-D input tensor
1D int64 tensor of the same length as input's dimension number, includes numbers of repeated copies along input's dimensions.
1D output tensor
1-D tensor of axes that `starts` and `ends` apply to.
1-D tensor of ending indices (exclusive) of corresponding axis in `axes`
1-D tensor of ending indices (exclusive) of corresponding axis in axes
1-D tensor of floats
1-D tensor of shape (num_rois,) with each element denoting the index of the corresponding image in the batch.
1-D tensor of slice step of corresponding axis in `axes`. Default to 1. 
1-D tensor of starting indices of corresponding axis in `axes`
1-D Tensor of the range.
1D tensor. The shape of the expected output tensor. If empty tensor is given, the output would be a scalar.
1D1T1`1
1D2h2
1E2a2
1e2o2
1E2W2i2x2
1F1X1
1F2W2
1G1L1Q1e1
1G1N1f1y1
1g2{2
1H1t1
1H1X1d1l1
1H1X1h1
1H2O2W2`2
1J1O1T1g1o1t1
1J1y1h3
1J3s3
1l2s2
1M3]3
1N2U2n2
1N3E5\5
1O2Y2n2
1P1`1l1t1
1p1|1
1P1|1
1P1U1
1P2l2
1P2V2k2!3<3A3s3
1P2W2_2f2m2s2z2
1P2W2l2
1Q1`1d1h1l1p1t1x1|1
1Q3l3
1r2!444k4<6G6
1R2T3
-1S1^1r1
1S1{1
1S2`2
1S2Y3
1S5o5
1T1d1p1
1T1d1p1x1
1T2w2
1U2u2
1V1m1
1W2#3~4
1W2a2
1W2b2j2
1W2N3
1W3f5
1X1~1
1Y1j1
1Y2c2}2
1Y2k2b3Z4
1Y2t2~2
1y2Y3~4
1Z1o1
2 2$2(2,2
2 2$2(2,2024282<2@2D2H2L2P2T2X2\2`2d2h2l2p2t2x2|2
2 2$2(2@2P2T2d2h2l2p2
2 2$2<2@2D2H2L2T2X2\2`2d2l2
2 2$2<2L2P2T2l2|2
2 2$282<2@2D2X2\2l2p2
2 2$282H2L2d2t2x2
2 2$282H2L2P2h2x2|2
2 2(2,20242<2@2D2H2P2h2x2|2
2 2(2@2d2t2
2 2(202@2H2X2`2
2 2(242T2\2d2l2t2|2
2 2(282H2P2X2h2x2
2 2,242h2x2
2 2,2L2T2\2h2
2 202@2D2T2X2p2
2 20242D2H2L2T2l2|2
2 20242L2\2l2|2
2 20282\2d2t2|2
2 212D2W2]2
2 2'2/25292?2I2O2U2Y2`2h2q2w2
2 282<2@2T2X2\2t2
2 292J2f2
2 2D2L2T2\2d2l2t2|2
2 3n4w4
2 3X3
2!2&2:2?2X2i2o2|2
2!2:2
2!2:2q2x2
2!2:2r2y2
2!2+202>2X2g2w2|2
2!2-222>2J2V2r2
2!22262<2@2F2J2R2V2\2`2f2j2p2t2
2!2-292E2a2
2!2'3;3I3Z3&4@4o4}4
2!262K2b2
2!282
2!2A2M2R2a2g2r2v2
2!2c2
2!2E2
2!2H2a2x2
2!3F3X3
2!3U3\3u3
2"2(22282B2H2R2X2b2h2r2x2
2"2.2:2V2
2"2:2K2Q2V2`2e2q2{2
2"2?2^2h2
2"2>2l2
2"2A2H2a2r2
2"3!5g5
2"3/3
2"3=3h3
2"353Q3]3
2"3x3
2"3Y3
2#2>2g2i5
2#2A2M2Y2e2
2#3:3E3
2#373U3
2#3E3P3c3
2#3q3
2$2(2,2@2D2H2\2`2d2h2p2
2$2(2,2024282<2@2D2H2P2h2l2
2$2(2,2D2H2L2T2l2p2
2$2(2/272A2G2Q2W2^2e2n2u2
2$2(2@2D2H2\2`2d2|2
2$2(2@2P2T2X2\2`2d2h2l2p2t2x2|2
2$2(2<2L2P2`2d2h2l2
2$2,242@2`2h2p2x2
2$2,242@2d2l2t2|2
2$2,242<2D2\2d2l2
2$2,242<2D2L2T2\2d2l2t2|2
2$2,242<2D2L2T2\2d2p2
2$2,242<2D2P2X2x2
2$2,242<2H2l2t2|2
2$2,282X2`2l2
2$2,2X2|2
2$2@2P2\2d2
2$2+2K2V2g2
2$202P2\2d2
2$272C2`2s2
2$2D2`2p2|2
2$2D2L2T2\2d2l2t2
2$2D2P2p2|2
2$2L2T2\2p2x2
2$2L2T2`2
2$2O2w2
2$2X2h2t2|2
2$3,383X3`3l3
2$3@3
2$3+3@3U3
2$343@3H3|3
2%2:2Q2
2%2\2c2{2
2%2>2O2U2Z2f2x2
2%212?2}2
2%242
2%2A2
2%3_3
2%3a3
2&2/282P2
2&272
2&272~2
2&282n2
2&2I2l2
2&3:3q3
2&3|3
2&383
2&3C3[3b3~3
2&3d3
2&3l3
2&3R3
2(2,2D2T2X2\2`2d2h2p2
2(2/282X2_2f2
2(2`2
2(202<2\2d2p2
2(202<2\2h2
2(20282@2D2L2`2h2l2t2
2(202P2l2|2
2(2-2K2P2\2h2y2
2(282<2@2X2h2l2|2
2(282<2T2d2h2
2(282H2L2P2T2\2t2
2(282H2P2\2`2l2p2|2
2(282H2X2h2x2
2(2a2
2(2C2a2u2
2(2H2P2\2|2
2(2H2P2X2`2h2p2|2
2(313
2(3e3
2(3f3
2(3X3|4
2)2.2I2
2)2@2W3j3
2)252Q2
2)2c2
2)2m2
2)3I3j3
2)3O3Y3
2)3U3Z3_3q3y3~3
2*292J2Q2X2t2
2*2F2
2*2G2P2P2`2
2*2j2
2*2O2c2h2m2
2*313F3[3u3
2*363B3N3j3
2*3G3
2*3r4
2,2<2@2D2\2`2d2h2l2p2t2x2|2
2,202@2D2T2X2\2d2h2|2
2,242@2`2h2p2x2
2,242@2`2h2t2
2,242<2D2L2T2\2d2l2t2|2
2,242<2D2L2T2\2d2l2x2
2,242D2L2T2\2d2l2
2,282@2t2
2,282S2
2,2F2
2,2g2
2,2T2|2
2,3h3u3
2,3T3
2.2J2a2
2.3F3P3n3
2.3P3Z3s3}3
2/2;2]2i2
2/2[2
2/2]2
2/2_2
2/2F2
2/3B3\3m3
2/3E3j4
2/4k4q4
2:2A2Z2
2:2F2R2^2z2
2:3?3D3e3
2:3g3
2:3j3
2:3w3
2:3W3^3w3
2;2\2
2;2I2
2;3^3
2;3f3
2;3j4y4
2?2k2p2u2
2@2|2
2@2d2
2@2P2\2d2
2@3T3q3x3
2\2d2t2{2
2^3x3
2`2~2`
2{2i508^8c8h8y8
2{2V3g3
2+2_2
2+2>2]2
2+2J2
2+2N2
2+2u4~4
2+343e3n364G4
2+3K3T3r3
2<2`2
2<2D2L2T2d2l2x2
2<2H2h2t2
2<2h2m2r2
2<2W2|2
2<3n3
2<3z3
2=2O2T2
2=3o3
2>3Q3
202@2L2T2
202@2P2T2X2p2t2
20242H2L2d2h2l2p2
20282@2H2P2X2d2
202A2l2
202E2c2
202R2\2y2
203h3
203S3y3
21262J2\2a2w2
21262L2Q2h2m2|2
212A2Q2a2q2~2
212L2g2
214O4b4
2'2,272=2G2R2W2_2c2j2t2x2~2
2-2:2?2P2U2f2k2p2
2'2;2K2_2o2
2-2>2v2X4s4z4
2-222>2C2Q2V2d2i2
222O2k2
2-242I2^2r2L3v3\4
2'272A2Q2[2k2
2'2L2
2-2P2s2
22X2e2
232:2B2I2P2V2]2o2x2
232G2s2
232M2
232V2
233U3
2-3A3
2'3v3.555N5U5o5
242`2
242<2D2L2T2\2d2l2t2|2
242<2D2P2p2x2
242<2D2P2t2|2
242<2H2h2p2x2
242D2P2X2
242D2P2X2|2
243;3P3e3|3
243V3g3
262`2x2
262B2_2r2
262H2
263G3
263H3
272A2Z2
272p2
272R2o2
272V2g2
282@2H2P2\2|2
282@2H2T2t2|2
282H2T2\2
282M2i2
282R2
283q3
283v3
28466M6}6
292@2G2p2w2~2
292n2
292N2T2l2~2
292s2
293_3u3z3
293_3z3
2b2T4
2B3O3
2b3r3z3
2c2~2
2C2a2
2C2e2p2
2D input tensor to copy shape, and optionally, type information from.
2D2d2o2
2D2M2a2
2D2p2
2D2p2u2z2
2D2R2
2D2T2`2h2
2D3Q3]3n3
2E2J2O2a2i2n2
2E3b3r3
2E3r3
2f2{2
2F2e2
2F2P2i2z2
2f2s2
2F3\3
2F3M3b3w3
2F3X3
2g2_3
2G2L2
2G3M3f3z3
2g3n3
2G3Y3y4
2g4$5x5
2H2X2d2
2H2X2d2l2
2H3}3
2h3q3
2h3s3
2I3U3
2J2`2
2J2v2{2
2J2V2b2n2
2J3]3>4
2k2}2
2K3"4
2K3R3g3|3
2K3U3`3k3v3~3
2L3b3
2L3k3r3
2L3x3
2M2j2z2
2M2V2
2N2~2
2N2h3N4
2n4{4
2O2{2
2O2c2
2O3k3
2O3T3
2P2`2l2
2P2`2l2t2
2P2O3E6
2P3]3n4
2Q2a2m2{2
2Q3V3[3z3
2q6~6
2S2k2
2S2m2}2
2S2u2
2S2v2
2S3s3
2S5`5&6G6
2T2w2
2T2z2
2V2c2j2
2V2e2
2V3j3
2V3r3
2VQSQ
2w335
2W3w3H4
2Z2`2u2
3 3$3(3,3034383<3@3D3H3\3`3d3h3l3p3
3 3$3(3,3034383<3@3D3H3L3P3T3X3\3`3d3h3l3p3t3x3|3
3 3$3(3,3034383<3@3D3H3L3P3T3X3\3`3h3l3p3t3|3
3 3$3(3,303D3H3L3P3T3\3`3h3l3
3 3$3<3@3D3H3\3`3p3t3
3 3$3<3@3X3h3l3t3
3 3$3<3L3P3T3l3|3
3 3$34383<3@3D3L3P3T3\3`3d3h3p3t3x3|3
3 3&3*30373C3H3S3Y3c3m3r3x3|3
3 3(303@3H3P3X3h3p3x3
3 3(343T3\3d3l3t3|3
3 3,343P3X3\3`3l3t3
3 3,343x3
3 3,3L3X3x3
3 3/3o3
3 3@3H3P3`3
3 3@3H3P3X3`3h3p3
3 3@3H3T3t3
3 303<3D3d3
3 3034383@3X3\3t3
3 3034383L3P3T3X3`3x3|3
3 30343D3T3X3h3l3p3
3 32373<3T3e3k3p3|3
3 353J3c3
3 353s3
3 383H3L3d3h3
3!3%3)3-3135393=3A3E3I3M3Q3`3
3!313A3Q3a3q3
3!32383=3M3R3b3g3t3
3!3-393E3a3
3!343c3}3
3!3c3
3!3H3Q3x3
3!3N3]3
3!4D4_4
3"3&303D3I3S3b3g3m3
3"3*3:3B3N3Z3k3
3"3,3
3"3,363@3J3b3o3{3
3"333D3U3f3w3
3"373j3q3
3"373K3}3
3"3N3U3\3p3|3
3"424:4
3"494C4Y4e4
3#:3:f:t:}:
3#3,32383F3L3P3V3`3f3j3p3|3
3#3/353:3W3j3o3
3#3;3N3m3
3#333J3
3#343
3#343o3
3#383G3Z3_3
3#3A3M3R3^3j3v3
3#3D3
3#3Z3f3r3~3
3#4*4L4
3#4?4:5P5z5
3#4|5
3#434O4
3#4D4
3#4I4V4
3#4n4
3#4P4v4
3#525E5
3$3(30343H3X3h3x3|3
3$3(383<3@3X3\3`3t3x3
3$3(383H3L3\3l3|3
3$3(383H3X3\3`3t3x3
3$3)3.333@3E3N3R3Y3_3i3o3v3
3$3,3`3p3|3
3$3,30383L3T3\3d3l3t3
3$3,343<3D3L3d3p3
3$3,343<3D3L3T3\3d3l3t3
3$3,343<3D3L3T3\3d3l3t3|3
3$3,343<3D3L3T3\3d3p3
3$3,343<3D3L3T3\3h3
3$3,343<3D3L3X3x3
3$3,343<3D3P3p3x3
3$3,343<3D3P3X3x3
3$3,343<3H3P3p3
3$3,383\3d3l3t3|3
3$3,383X3`3h3p3|3
3$3,383X3d3l3
3$3,3L3T3\3d3l3t3
3$3;3U3t3~3
3$3@3W3
3$3+323[3b3i3v3
3$3<3@3D3X3\3`3x3
3$30383l3|3
3$303P3X3d3
3$34383<3@3T3X3p3t3|3
3$34383H3L3P3h3x3|3
3$383D3U3
3$3D3`3p3|3
3$3D3P3X3
3$3F3
3$3H3M3R3z3
3$4)4.4@4E4J4b4s4y4~4
3$4+4@4U4l4
3$444@4`4h4p4x4
3$4j4
3$4J4l4
3%3*30363=3D3K3S3Y3]3c3i3o3s3y3
3%3:3d3n3
3%303C3a3m3y3
3%313=3Y3
3%323|3#4_4
3%363;3H3M3\3a3p3u3
3%393M3a3u3
3%3i3
3%4/4H4Y4p4
3%4=4`4
3%4B4
3%4E4
3%4P4
3%4Q4n4
3&3,313=3M3T3d3y3
3&3,5K5U5j5
3&3;3V3
3&3}3
3&353Q3Z3
3&3A3\3
3&3R3
3&3V3
3&484
3&4k4p4{4
3(3:3
3(30383D3d3l3t3|3
3(30383D3L3l3t3|3
3(343<3T3d3l3t3|3
3(383H3X3h3p3|3
3(383H3X3h3x3
3(3A3I3N3a3f3{3
3(3C3
3(3H3T3\3
3(3L3T3\3d3l3t3|3
3(454
3(4D4
3(4g4n4d5
3)3@3
3)3>3S3j3~3
3)333i3
3)333M3a3w3
3)353C3]3
3)353Q3
3)3c3
3)3r3
3)3R3l3
3)4^4
3)404H4[4z4
3)4L4
3)4Z4
3*313V3w3
3*363B3N3j3
3*363R3
3*373[3w3
3*414S4
3*4f4
3,3<3@3D3\3l3p3
3,3<3L3P3T3X3\3`3t3
3,3>3
3,30343H3L3P3T3\3t3x3
3,343@3`3h3x3
3,343@3H3|3
3,343<3D3L3T3\3d3l3t3|3
3,343<3D3L3T3\3h3
3,383X3`3h3p3|3
3,383X3d3
3,3O3
3,4<4H4P4
3,434K4^4}4
3,434K4k4
3.3:3F3R3n3
3.3=3P3]3i3z3
3.3O3V3o3y3
3.4V4u4
3.4W4f4
3.5:5K5
3/3=3L3
3/34393K3P3U3n3z3
3/3E3
3/494[4k4}4
3/4N4f4w4
3:3?3|3
3:3G3l3
3:3O3g3
3:4i4X6o6
3;3[3
3;4^4
3?3[3
3?3J3t3{3
3?4j4
3?4q4
3@3P3\3d3
3@4V4u4
3@4x4
3[3b3{3
3\4~4
3\4c4x4
3_3|3
3_4E5;6
3_4i4o4X5w5
3`4(5P5x5
3`4+7
3`4v4
3{5E7a7
3+353N3X3w3
3+373p3
3+3h3q3
3+3R3
3+5?5
3<3\3
3<3`3
3<3L3X3`3
3<3Y3
3=3h3
3=4a4
3=4X4{4
3>3a3
3>3C3
3>3n3
3>4r4
303@3D3H3P3h3l3
303@3L3T3
3034383L3P3T3X3l3p3
30383@3L3l3t3|3
30383@3L3l3x3
30383D3d3l3x3
303C3b3
303G3c3
303K3f3
303n3
303N3
303T3A4O5
304@4I5
30A0X0l0
30H0t0
30Q0]0i0u0
313;3
313>3"4F4s4
313L3g3
313M3
313s3
323I3
324?4
32-bit hash value.
3'3`4w4
3-3<3K3P3`3e3u3z3
3'3<3P3
3'3=3m3{3
3-3>3K3g3n3t3~3
3-323J3O3h3p3u3
33393=3G3h3x3~3
334M4b4h4n4t4z4
334U4`4v4
334U4m4
3-373L3a3x3
3'393
3-3b3i3p3
3'3C3Z3
3-3D4W4t4
3'3H3N3f3x3
3-3o3
3'3u3
3-4:4>4B4F4J4N4R4V4Z4^4b4f4j4n4r4v4
343?3Q3
343`3
343<3D3L3T3\3d3l3t3|3
343<3D3L3X3x3
343<3H3h3t3|3
343<3X3h3t3|3
34383<3@3T3X3\3t3x3
343D3H3L3P3T3X3\3`3d3h3l3p3t3x3|3
343h3
343X3h3t3
344r4
3-4r4
3-4S4]4
3'4X4
353;3S3e3
353Q3
354X4
363M3x4
364G4
373Q3
374K4a4w4
383@3d3x3
383@3H3P3\3|3
383[3~3
383=3G3S3a3
383f3z3
383p3
384=4B4^4r4
384H4T4j4
384J4h4
385[5V6e6
393^3
393T3o3
3A3]3}3
3A3c3
3A3F3K3j3
3A3h3
3A3x3
3A4H4U4
3A4k4
3c3#4
3C3~3
3C3l3s4
3C4P4q4w4
3C5a5m5y5
3D3l3
3D3L3X3x3
3D4_4z4
3D4L4T4\4d4l4t4|4
3D4Q4r4x4
3d4t5
3E3]3y3
3e3l3
3E3z3
3E4L4a4v4
3F4f4x4
3F5U5b6o6
3g4p4"5F5X5
3H3 4?4v4}4
3H3h3x3
3H3O3c3o3}3
3H3p3
3H3x3
3H4z4
3J3f3
3J3V3b3n3
3j4q4
3J4z4
3K4]4b4
3K4^4l4
3L3\3h3p3
3L3T3
3L3x3}3
3N3i3
3N3v3
3n4|4
3N4i4}4
3N4X4q4
3O3k3
3O4r4,5O5
3P3`3l3t3
3P3|3
3P3q3w3~3
3P4f4x4
3p547`7
3R3h3w3
3R4_4}4
3S5o5~5
3t4\5V7e7|7
3V3}3
3V3h3
3X4t4
3Y4c4}4
3Y4f4
3Z3d3
4 4$4(4,4044484<4@4D4H4L4P4T4X4\4`4d4h4l4p4t4x4|4
4 4$4(4,40484<4@4D4L4d4h4
4 4$4(4<4@4D4H4P4T4\4`4t4x4|4
4 4$4(404H4X4\4p4t4
4 4$4,4044484<4@4D4H4L4P4T4X4\4p4t4
4 4$4<4@4D4X4h4x4|4
4 4$44484H4L4\4`4x4|4
4 4$4s4
4 4(404@4d4l4t4|4
4 4(40484@4L4l4t4|4
4 4(4H4d4t4
4 4(4L4\4d4l4t4|4
4 4)4b4
4 4*4?4T4v4
4 4,444
4 4,444h4x4
4 4,4L4T4\4h4
4 4,4L4X4`4
4 4@4H4P4X4`4h4p4|4
4 4@4H4T4t4|4
4 4@4L4l4x4
4 404<4\4d4l4t4|4
4 404<4D4x4
4 4044484P4`4d4t4x4|4
4 40444D4H4L4P4d4h4l4p4x4|4
4 4D4L4T4\4d4l4t4|4
4 4T4d4p4x4
4 5*5?5T5k5
4 595\5
4 5K5
4 5L5
4 5U5
4 5X5
4 5X5d5l5v5
4!4\4
4!4+4=4R4i4
4!41474<4Q4a4q4{4
4!414A4Q4a4q4
4!424C4T4e4v4
4!4'41464=4A4G4M4S4W4]4g4l4w4}4
4!484Q;[;I<S<l<
4!4c4
4!4f4
4!4H4Q4x4
4!4L4f4
4!4v4
4!4W4n4
4!5]5
4!525:5m5y5
4!5'5,585B5L5^5c5s5
4!555k5
4!5F5W5
4"4&4*4.4t4
4"4.4J4
4"4.4S4
4"4]4
4"4'4B4
4"5E5h5
4"5W5
4"5W5f5w5{5
4#4)434=4B4H4L4R4\4b4f4l4s4
4#4=4Y4
4#4A4M4Y4e4
4#4K4Q4[4
4#4Z4f4r4~4
4#5[5
4#505d>
4#5E5]5s5
4#5E5P5c5
4#5S<
4$4(4,4044484<4@4D4H4L4P4T4X4`4x4|4
4$4(4,40484<4D4X4\4t4x4
4$4(4@4D4\4l4p4t4x4|4
4$4(4@4P4T4d4h4l4p4x4|4
4$4,4`4p4
4$4,444@4H4h4
4$4,444\4d4l4t4|4
4$4,444<4D4L4T4\4d4l4t4|4
4$4,444<4D4L4T4\4h4
4$4,444<4D4L4T4l4t4|4
4$4,444<4H4h4p4|4
4$4,484
4$4,484X4d4
4$4@4P4\4d4
4$44484<4T4d4h4l4t4x4|4
4$444D4H4X4\4l4p4t4x4|4
4$454k4
4$464;4K4]4b4
4$464;4V4
4$484@4T4\4`4h4p4x4|4
4$4D4L4X4x4
4$4D4P4X4
4$5`5e5
4$515N5w5
4$555f5
4$595X5
4$5d5l5t5
4$5L5t5
4%4|4
4%4+41494=4B4H4N4R4Y4a4g4k4q4w4}4
4%4+484J4W4c4t4
4%404C4a4m4y4
4%464q4
4%464Z4h4
4%4A4
4%5@596
4%5C5z5
4%5F5
4&575y5
4&585
4&585h5
4&5b5
4&5E5{5
4&5F5W5
4&5J5e5l5
4&5u5
4&5Y5
4&686
4&6X7
4&787
4(4,4<4@4D4H4P4h4x4|4
4(404<4\4h4
4(40484D4d4p4
4(40484H4X4`4h4x4
4(404T4\4l4t4|4
4(444<4\4d4l4t4
4(444<4T4d4l4t4|4
4(444M4S4W4a4
4(484@4L4X4h4x4
4(484<4L4P4`4d4h4|4
4(484<4L4P4T4h4l4p4
4(484H4P4\4`4l4p4|4
4(4D4d4
4(4e4L5S5l5
4(4J4c4
4(4L4T4\4d4l4t4|4
4(4O4X4j4o4t4
4(5/5D5Y5p5
4(5:5\5v5
4(5:5X5
4(5`5
4(585D5L5
4(5D5
4(5f6
4(5G5
4(5L5T5l5
4(5p5
4(5P5|5
4)494N4a4m4
4)4Y4f4|4
4)5@5F5K5Q5[5r5
4)5t5
4)5w5
4*4/4D4I4^4c4x4}4
4*4\4f4{4
4*4L4f4w4
4*4s4
4*575U5{5
4*5D5}5
4*5n5
4*5Q5Z5
4*5X5]5b5s5x5}5
4,4)5N6
4,4<4@4P4`4d4h4
4,4<4H4P4
4,4<4L4P4`4d4t4x4
4,404@4D4\4l4p4t4x4|4
4,404@4D4H4\4`4d4l4
4,40444L4P4T4h4l4
4,404H4X4\4t4x4
4,414E4R4^4o4
4,444<4D4L4T4\4d4l4t4|4
4,4a4
4,4d4
4,5<5H5P5
4,5a5
4,5j5
4,5N5a5
4.4?4V4C5J5_5t5l8
4.434Q4^4j4{4
4.494@4j4s4
4.5k5x5
4/;q;
4/464O4Y4
4/4g4
4/4J4o4
4/6>7K7
4:4@4]4
4:4E4z4
4:4L4
4:4s4
4:5]5
4:5D5i5q5v5
4:5D5o5
4:5N5
4;4^4
4;5d5
4?4\4v4
4?4I4Z4
4@4d4
4@4h4
4@5P5\5d5
4\5h5t5
4]5t5~5
4^5"6)616:6
4`6{6
4|6|9
4+4<4w4
4+404:4F4T4
4+5=5B5
4+555J5_5v5
4+5D5_5
4+5h5
4+5K5
4<4`4
4<4C4W4c4t4
4<4D4L4T4\4d4l4x4
4<4D4L4X4x4
4<4D4P4p4x4
4<4L4X4`4
4<4W4r4
4<4Y4
4<5p5
4>4f4x4
4>4n4
4>5@6m6
4>5g5
4044484<4@4T4X4p4t4
40444L4\4`4x4|4
40454:4S4d4j4o4{4
404J4V4
405a5
405c5
405D5M5
405F5X5
41464H4T4e4
414H4
414L4g4
414L4V4x4
415O5o5
41P1Z1o1
424{5
424<4E4
424C4a4m4y4
424O4g4
424P4\4
434\4
434b4i4p4
434H4_4s4}4
434H4O4Y4c4p4
434j4v4
434L4n4u4
435{5
435d5
435T5,7i7
435Y5s5
4'4;4p4
4'414;4E4O4a4h4u4
444\4
444<4D4L4T4\4d4l4t4|4
444<4D4L4T4\4d4l4x4
444<4D4L4X4x4
444<4H4h4p4|4
4-444[4
444h4
444O4j4
444P4`4l4t4
444R4h4
444S4
444V4
445_5j5
4-4B4Y4
4'4f4
4-4L4f4
4-4P4s4
4'4R4u4
4-4V4
4-5;5V5_5m5
454?4T4i4
455V5h5
4'595c5
4'5C5n5
4-5J5p5
464@4U4j4
464G4
464H4W4
464S4
464U4
465C5d5j5
465K5
467H7
474?4K4X4h4r4
474B4X4j4
475>5S5h5
484@4H4X4|4
484@4L4l4t4
484S4n4
485?5X5i5
494]4
494_4
494>4e4j4
494V4q4
4A4]4t4
4a4}4
4a4m4|4
4B5l5
4B5l5V6g6
4b5x5
4b7~7
4C4d4
4C4e4p4
4C4H4V4[4k4p4
4C5^5y5
4C5H5
4C5h5
4C5P5
4C5w5
4C6N6X6
4C7P7?8
4C8a8u8
4-D tensor after resizing, [N,C,H,W]
4-D tensor, [N,C,H,W]
4D4_4
4d4q4
4D4t4y4
4D5Q5
4E5L5\5f5
4E5L5e5v5
4F4M4e4x4
4F4M4T4a4
4F4X4
4F5S5_5p5
4F6d6
4G5j5
4G5t5
4H4X4d4l4
4H5o5
4hH71
4I5y5
4i7s7
4J4|4
4J4T4
4J4W4
4J5g5
4J5u5
4K4j4u4
4K4s4
4L4Y4m4
4L5W5
4M4_4j4x4
4M6f6
4o4|4
4O4T4
4O4u4
4O5`5
4O5r5
4P4`4l4t4
4Q4o4
4R5g5
4S4y4
4S4Z4o4
4S5]5r5
4SVW3
4T4t4
4T5z5
4V4h4
4V4q4~4
4W4i4|4
4W5n5
4W6{6
4X4v4
4X5i5
4Y5n5t5
5 5$5(5,5@5D5T5d5h5l5
5 5$5(5,5054585<5@5D5H5L5P5T5X5\5`5d5h5l5p5t5x5|5
5 5$5(5,50585P5T5l5|5
5 5$5)5/55595?5C5J5R5\5`5f5p5t5z5
5 5$5<5@5D5X5h5l5|5
5 5&5*50545;5C5M5S5]5c5j5q5w5
5 5(5\5l5x5
5 5(505<5\5d5l5x5
5 5(545T5\5h5
5 5(545T5`5
5 5(5L5T5d5l5t5|5
5 5,5:5T5
5 5,5L5T5\5d5p5
5 5@5H5P5X5`5l5t5
5 5@5H5P5X5d5
5 5@5L5l5x5
5 5@5L5T5
5 505@5D5H5L5T5l5p5
5 50585H5P5X5`5h5p5
5 515B5S5d5~5
5 515l5
5 54585P5T5X5l5p5
5 585<5T5X5p5
5 6*6@6
5 606<6D6x6
5 6H6
5 6h6
5 6M6p6
5 6p6
5!5)555A5
5!5>5_5}5
5!5'545F5M5Z5f5w5
5!5-595E5a5
5!5c5
5!5O5g5r5
5!5Z5a5y5
5!6@6
5!6O6l6
5!8!0-g-
5"5)5
5"5;5\5u5
5"5=5G5`5
5"5K5Q5W7i7
5"5l5
5#5(5.54585>5E5O5T5^5d5n5{5
5#5(5-5A5F5a5
5#5)5.575A5K5h5n5
5#5;5X5p5
5#5?5V5i6|6
5#5@5Z5
5#505
5#515@5
5#5-595G5
5#585O5<6F6[6p6
5#5A5M5R5^5j5v5
5#5A5M5Y5e5
5#5z5
5#656H6x6
5#6B6
5#6E6P6f6
5#6I6m6|6
5#6j6
5$5(5,50585<5D5\5`5d5x5|5
5$5)5<5A5U5Z5s5
5$5,545@5`5h5p5x5
5$5,545<5D5L5`5h5p5x5
5$5,545<5D5L5T5\5d5l5t5
5$5,545<5D5L5T5\5d5l5t5|5
5$5,545<5D5L5T5\5d5l5x5
5$5,545<5D5L5T5\5h5
5$5,545<5H5l5t5|5
5$5,545D5P5p5
5$5,585X5`5h5t5
5$5,5t5
5$5?5b5
5$5?5P5V5[5g5q5{5
5$5\5d5p5
5$5+575<5G5M5W5a5f5l5p5v5|5
5$5<5L5T5p5
5$50585|5
5$54585P5`5p5t5
5$545D5H5`5p5
5$595N5b5
5$5D5`5p5|5
5$5D5P5t5|5
5$5E5Z5
5$6?6X6
5$6|6s8
5$676P6X6]6p6u6
5$6b6
5$6C6J6c6t6
5$6W6
5%5+5C5U5
5%5-5B5N5g5m5q5{5
5%5-5K5W5p5v5
5%5E5y5
5%5Y5
5%6@6[6v6
5%6C6
5%6C6z6
5%6O7k7u7
5%6q6
5%6T6
5&5,5D5V5
5&5Q5y5+626C6d6{6
5&6\6
5&6T6d6
5(5,50585P5T5X5l5p5t5x5
5(5,5D5T5X5\5`5t5x5|5
5(50585@5H5T5t5|5
5(545<5p5
5(545<5T5d5l5t5|5
5(545T5`5h5
5(585@5L5P5\5`5l5x5
5(585\5d5l5t5|5
5(585<5D5\5`5h5p5
5(585<5L5\5l5p5
5(585<5L5P5T5X5\5d5|5
5(585H5X5h5x5
5(5H5P5X5`5h5p5x5
5(5H5P5X5`5l5
5(5H5T5\5
5(5H5T5t5|5
5(6`6
5(6h6
5)5/595`5
5)505Z5c5
5)6I6[6`6
5*5B5Y5^5u5z5
5*5u5
5*6<6A6F6
5*6H6>7G7
5*6K6a6u7
5*6M6
5*6T6)8
5*6y6
5,505@5D5T5X5h5x5|5
5,505H5L5d5h5
5,505H5X5\5l5p5
5,515I5N5[5`5e5u5}5
5,585X5d5
5,5b5}5r6`7B8^8k8
5,5C5M5f5w5
5,5T5|5
5,636K6p6
5,6m6
5,8084888<8F8U8m8V9l9
5.535H5M5b5g5~5
5.5I5d5
5.5k5
5.656e6
5/5[5
5/575=5Z5a5
5/5F5Z5d5m5
5/5q5{5
5/696J6O6T6Y6d6n6
5/6P6
5/6T6u6
5:5K5c5
5:6K6a6h6r6|6
5;5B5X5u5|5
5;5W5~5
5;5Z5e5
5;6c6
5?5~5
5?6`6u6|6
5?6x6
5@5{5
5@5d5
5@5I5q5
5@5P5\5d5
5@6i6
5@6U6
5\5c5x5
5^6e6
5_6q6
5_8f8{8
5`6$7+737<7
5+5^5y5
5+515T5Y5
5+525`5
5+5F5a5|5
5+6C6]6
5+6E6N6
5<5`5
5<5a5
5<5C5[5n5
5<5D5P5p5x5
5<5e5k6
5<5g5
5<5L5X5x5
5<5p5
5<6g6
5<6p6
5=5Q5
5=5u5
5>5R5\5e5
5>5T5
5>5V5]5
505@5D5H5`5p5t5
505@5L5l5t5|5
505@5P5T5l5p5t5x5|5
5054585<5@5D5H5L5P5T5X5\5`5d5h5p5
50545L5P5h5l5
505v5
505x6$7
506@6L6T6
506F6W6
50H0W0\0
515=5I5U5q5
51585?5L5
516G6
516S6Z6b6i6p6v6}6
525K5d5}5
526D6I6N6
535a5
535F5R5o5
535j5v5
535N5
535t5
535W5m5
536:6O6d6
536[6g6~6
536v6
545@5`5l5t5
545<5D5L5h5x5
545<5D5L5T5\5d5l5t5|5
545C5V5c5o5
545D5H5X5\5`5h5
545D5H5X5\5t5x5
545D5P5X5
545D5T5X5\5d5|5
545P5`5l5t5
546l6
546X6g6
5'5;5C5I5W5c5
5'535D5
5'5-525>5[5`5r5y5
555F5b5y5
555Z5
556}6
556<6Q6f6
5'585
5'5C5i5s5
5-5D5
5-5h5
5'5R5
5-5R5m5
5'6.6G6X6o6
5'606T6c6
565~5
565H5M5R5}5
565U5_5t5
566=6R6g6
566M6b6
566P6
5'6H6
5'6h6
5'6H6]6d6n6
5-6v6
575<5R5W5g5o5t5
575>5W5h5
575R5m5
585@5H5P5\5|5
585@5H5T5t5|5
585@5L5l5t5
585D5
585D5d5p5
585L5T5\5h5
585t5
586[6v6
586e6
586g6
586p6
586r6
588G8Z8Z<{<
595g5
597/8
5A5H5O5
5A7]7
5C; ?
5C5e5p5
5C5J5_5t5
5C5s5
5C9a9
5D5P5p5|5
5D5T5`5h5
5D6j6
5E5x5
5E6J6O6k6
5F566G6
5f5m5
5F5W5
5F5Z5f5r5~5
5F6W6
5g5s5y5
5G5w5
5H6p6
5I6`6
5I6~6
5I6X6i6
5ineI
5j5,6G6
5J5o5
5j5y5
5J6g6x6
5J6j6|6
5K6}6
5L5\5h5p5
5L5k5
5L5S5k5
5L5U5~5
5L6r6
5N5e5z5$6`6m6i7
5N6^6j6x6
5ntel
5O5`5
5O6l6
5P5~5
5P6^6
5P6b6
5p7]9K;w<
5R7y7
5S6#7
5S63738
5T5%7
5t5`6
5T5t5
5T6a6
5U6_6x6
5u697
5V5e5
5V6b6
5V6c6
5V6g6
5w5~5
5W6^6s6
5W6s6
5X5j5
5Y5t5
5Y6c6}6
5Z627C7
6 6$6(6,6064686<6@6D6H6L6`6d6h6l6p6t6x6|6
6 6$6(6,6064686<6@6D6H6L6P6T6X6\6`6d6h6l6p6t6x6|6
6 6$6(6,6064686<6@6D6H6S6q6}6
6 6$6(6,6064686<6@6D6L6P6T6X6\6`6d6h6l6p6t6x6|6
6 6$6(6,6064686L6P6`6d6h6p6t6x6|6
6 6$6(606H6L6P6T6X6l6p6
6 6$6<6@6X6h6l6p6t6
6 6$6<6L6P6T6X6\6d6h6l6t6x6|6
6 6(6@6D6H6\6`6p6t6
6 6(6@6P6`6d6t6x6
6 6(606@6H6P6X6h6p6x6
6 6(646<6p6
6 6(646T6\6d6l6t6
6 6(6H6P6l6|6
6 6@6H6P6X6`6h6p6|6
6 6@6H6P6X6d6
6 6@6L6l6x6
6 6@6P6t6|6
6 606@6D6H6L6T6l6|6
6 606<6D6d6
6 606T6\6d6l6t6|6
6 64686H6L6d6h6
6 7(787G7
6 707<7D7x7
6 7c7
6 7D7h7
6 7h7
6 7r7
6 7V7p7
6 7X7
6!6&6+6C6O6U6Z6w6
6!656
6!6'6,62686?6G6L6V6\6`6f6l6r6v6|6
6!6-696E6a6
6!6-696E6j6
6!7&767;7G7W7\7|7
6!7G7l7
6"6(62686B6H6R6X6b6h6r6x6
6"646<6I6S6[6e6x6
6"6'6|6
6"6E6c6
6"7>7l7
6"7D7U7t7}7
6#6(6?6P6V6[6g6w6
6#6)6/63696=6D6L6V6Z6`6j6n6t6{6
6#6*676}6
6#6>6E6^6o6
6#666=6e6m6z6
6#686M6d6
6#686M6f6
6#6O6
6#7(7-7?7D7I7a7r7x7}7
6#7;7
6#7E7P7c7
6#7J7V7b7n7
6$6(6,6@6P6`6d6h6|6
6$6(6,6D6H6L6`6d6h6|6
6$6(6@6P6T6h6l6
6$6,6`6p6|6
6$6,6<6D6L6T6\6d6t6
6$6,646<6D6\6h6p6
6$6,646<6D6L6T6\6d6l6t6|6
6$6,646<6D6L6T6\6d6l6x6
6$6,646<6D6L6T6`6
6$6,646<6D6L6X6x6
6$6,646<6D6P6p6|6
6$6,646<6H6h6p6|6
6$6,646<6H6h6p6x6
6$6,646<6H6l6t6|6
6$6,686X6`6h6p6|6
6$6,686X6`6h6p6x6
6$6,686X6`6h6t6
6$6<6L6T6p6
6$6<6p6
6$60686l6|6
6$606A6z6
6$606P6X6d6l6
6$64686<6@6D6H6L6P6T6X6\6`6d6h6l6p6
6$64686<6P6T6d6h6l6p6
6$64696Y6^6v6
6$676T6e6
6$686@6H6P6d6l6t6|6
6$686V6[6
6$696>6R6W6q6v6
6$6F6P6e6z6
6$747@7H7|7
6%6/646>6D6N6X6^6g6m6r6w6}6
6%6;6X6
6%606C6a6m6y6
6%666
6%6A6
6%7,7A7V7p7
6%7^7
6%717
6%7H7c7
6%7J7
6%7K7Z7
6%7m7
6&6;6O6
6&6+6=6J6V6g6
6&6<6
6&626N6
6&676~6h7
6&686w6
6&6G6e6
6&6H6S6b6l6x6>7
6&6I6|6
6&6m8
6&6Q6
6&787
6&7r7
6&7T7
6(6,6D6T6X6p6t6x6
6(6]6h6r6
6(6<6
6(606<6h6p6
6(606L6\6h6p6
6(646<6p6
6(646T6`6
6(6-676C6Q6
6(686H6P6\6`6l6p6|6
6(686H6X6h6x6
6(6C6
6(6D6T6`6
6(6F6W6
6(6H6O6V6
6(6H6P6X6`6h6t6
6(6u6
6(717h7
6(787D7L7
6(7P7
6(7W7
6(7x7@8l8
6)6.636F6K6P6i6z6
6)606E6Z6n6
6)6B7)8
6)7>7D7\7n7
6)70868x8
6)797E7S7m7
6*6?6u6
6*6\6~6
6*6c6
6*717:7V7c7
6*737
6,6|6
6,6<6L6P6h6l6
6,60646<6T6X6\6d6h6|6
6,6064686L6P6T6X6\6d6|6
6,60646L6P6T6h6x6|6
6,606D6H6`6p6t6x6
6,606H6L6d6h6l6t6x6
6,61666Q6
6,686@6t6
6,6C6Z7m7
6,6D6a6y6
6,6D6L6X6
6,6I6
6,6w6
6,7I7
6,7T7f7w7
6,7x7
6.676X6
6.686l6
6.6P7c7p7
6.6V6h6
6.7?7l7
6.7a7|7
6.7A7T7
6.7T7^7n7~7
6.7V7u7
6.7Z7a7u7
6/64696Q6b6h6m6y6
6/666;6P6U6b6
6/6O6
6/6Z6v6
6:6]6
6:7U7
6;6@6E6Y6^6c6w6|6
6;798
6?6_6
6?6J6t6{6
6?7S7h7n7
6?7v7
6@6P6\6|6
6@6x6
6@7m8
6@7V7o7{7
6@7x7
6\6p6
6]6<7
6]8g8
6^8z8
6_6l6
6_6o6|6
6`6m6
6`7f7m7
6+61666B6L6X6i6
6+6F6k6
6+7<7
6+7C7
6+7C7]7
6+7V7x7
6<6[6`6e6
6<6D6L6T6\6d6l6t6|6
6<6D6P6p6x6
6<7L7X7x7
6<7R7
6=6j6~6
6=7S7
606@6D6\6l6p6
60646L6P6h6x6|6
60656
60676S6
60686D6d6l6t6|6
60686D6d6p6
606F6W6
606K6f6
606l6
607t7
60J0U0o0
616;6E6Q6a6q6}6
616@6Q6a6
616[6
616<6B6
616=6I6U6z6
61696>6P6U6i6n6
616l6
617L7/8Z8
617W7
626?6F6m6
626I6W6y6
626U6p6
62797p7
627M7F8X8
636@6Z6w6
636=6N6
636S6
637^7r7|7
637>7H7c7u7
637I7R:_:0;?<Z<O=
637N7U7
646:6h6
646@6`6l6
646@6d6l6t6|6
646<6D6L6T6`6
646D6T6X6\6`6h6
646P6`6l6t6
64787<7@7D7H7L7P7T7X7t7Y9j9
647P7
656?6
656@6S6z6
656G:
656M6c6
656n6u6
656S6
657%8
657S7
6'6.6>6E6U6\6l6s6
6'6.63686E6M6]6d6q6~6
6'6>6J6`6u6{6
6'62676?6C6H6N6T6Z6^6e6o6t6~6
666_6s6|6
666c6{9
666H6
666h697Y7`7u7
666x:
6'676=6E6Z6f6
667d7
667H7
667k7
6-6A6K6T6
6-6A6r6
6'6C6
6-6G6
6-7^7&878
676[6
676>6W6?7Z7a7z7
676d6
677D7U8p8q9
677f7x7
6-7h7
6'7m7
6-7Y7^7c7u7}7
686@6L6l6x6
686A6
686A6X6a6
686H6T6\6
687?7X7i7
687?7Y7
687H7T7t7
696N6T6l6~6
696S6q6}6
697\7
697F7R7c7
697J7j7(8
6A6c6
6A6d6
6B6I6P6j6
6B7o7t7
6C6e6p6
6C6f6
6c6j6
6C6j6v6
6c7i7p7
6d6B9%<
6D6t6
6D6T6`6h6
6D7f7w7
6D7K7p7}7
6D7X7
6E6]6j6q6
6e6l6
6E6L6
6E6q6v6{6
6E7}7
6E7i7
6E7L7W7n7{7
6E7r7
6F6i8
6F7`7v7
6f7f8
6f8[;
6G7e7
6H6p6
6H6X6d6
6H7n7x7
6I6o6y6
6i6y6
6I7f7w7
6j:q;9<
6JCy7JCy7JCy7JCy7
6K6P6^6c6h6z6
6l6 777r7{7
6L6\6h6p6
6L6S6k6~6
6L6t6
6L7{7&8=8q8
6L7h7
6L7o7
6L7Z7r7
6M7u7
6N6y6F7
6N7^7
6N8m8
6O7l7
6P6`6p6
6P7a7
6P7U7
6r6y6
6R7_7
6s7~7
6S7x7
6T6^6
6U6_6
6U6s6
6U6t6~6
6V6h6
6V8g8
6W6y6
6w7&888
6W7^7
6w768l9
6X6_6x6
6X6i6
6X6s6
6X7o7
6Z8=:
7 7$7
7 7$7(7,7074787<7@7D7H7L7P7T7X7\7`7d7h7l7p7t7x7
7 7$7(7,7074787<7@7D7H7L7P7T7X7\7`7d7h7l7p7t7x7|7
7 7$7(707H7X7\7l7|7
7 7$7<7L7\7`7d7|7
7 7$74787P7T7l7p7
7 7$787H7L7d7t7x7|7
7 7$787H7L7P7h7l7
7 7$787H7L7P7T7\7t7x7
7 7$7s7
7 7%7<7A7N7S7b7g7v7{7
7 7&707=7B7H7L7R7X7^7b7h7l7s7
7 7(7,74787@7D7L7T7X7\7`7d7l7p7x7
7 7(7@7P7X7t7
7 7(707<7\7d7l7t7
7 7(707<7\7d7l7x7
7 7(707<7\7h7
7 7(70787@7H7T7t7|7
7 7(70787H7l7t7|7
7 7(7L7T7d7l7t7|7
7 7,707<7@7L7X7h7x7
7 7,747T7p7
7 7,787H7X7h7p7|7
7 7,7L7T7`7
7 7;7V7q7
7 7@7H7T7t7|7
7 707@7D7\7`7x7|7
7 707@7D7T7d7h7l7p7x7
7 707@7H7P7`7p7x7
7 707<7\7d7p7
7 70747D7H7L7d7h7l7p7t7x7
7 74787H7L7d7h7|7
7 787<7T7d7h7x7|7
7 787H7L7P7T7X7\7`7d7h7l7p7t7x7|7
7 797J7a7
7 7A7G7_7q7
7 7A7Q7W7_7t7
7 7D7L7T7\7d7l7t7|7
7 7T7d7p7x7
7 8*8?8T8
7 8;8U8_8q8x8`:
7 8T8x8
7!7&7;7@7S7g7s7
7!7(7
7!7:7^7e7~7
7!717A7M7a7j7
7!7H7d7
7!7M7a7x7
7!8*8
7!8*8]8u8
7!8>8U8
7!8r8
7"7&7*7.72767:7>7B7F7J7N7R7V7Z7^7b7f7j7n7r7v7z7~7
7"7(72787B7H7R7X7b7h7r7x7
7"7S7^7r7
7"8|8
7"8=8B8
7"878G8N8[8b8i8r8
7"8r8y8
7#7)7-73777>7F7P7T7Z7d7h7n7u7|7
7#7*71787?7D7I7N7U7[7e7j7q7y7
7#7?7
7#72777A7M7[7
7#787g7
7#7A7M7R7^7j7v7
7#7A7M7Y7e7
7#7y7
7#8,8
7#8-8R8X8b8h8r8x8
7#8E8[8j8c9
7#8E8P8c8
7#8g8
7$7(787<7@7X7h7l7|7
7$7)7>7C7X7]7r7w7
7$7,747<7D7L7T7\7d7l7t7|7
7$7,747<7D7L7T7\7d7l7x7
7$7,747<7D7L7T7\7h7
7$7,747<7H7l7t7
7$7,747<7P7X7l7t7|7
7$7,747<7T7`7h7
7$7,787X7`7h7p7x7
7$7,787X7`7h7t7
7$7,787X7d7
7$7@7P7\7|7
7$7@7P7\7d7
7$7<7D7h7x7
7$7<7L7T7p7
7$70787l7|7
7$717C7P7\7m7
7$727C7T7a7
7$74787H7L7d7h7l7p7t7x7|7
7$797U7s7
7$7c7t7|7
7$7D7L7T7\7d7l7t7
7$7D7P7t7|7
7$8`8
7$838U8\8
7$8D8Z8
7%7\7c7{7
7%7^7x7
7%7+7/757<7H7M7X7^7h7s7y7}7
7%7<7K;
7%7=7S7q7}7
7%747a7
7%7A7
7%7G7i7
7%828
7%878T8a8
7%8g8p8
7&7;7Y7n7
7&7_7d9
7&8,8T8Z8
7&878i8
7&888i8
7&8-8F8
7&8E8|8
7&8F8U8|8
7&8i8
7(7,707D7T7X7p7
7(7`7
7(707<7D7d7
7(70787D7d7l7t7
7(707d7t7
7(717X7a7x7
7(727;7
7(747<7\7x7
7(757A7R7
7(787\7d7l7t7|7
7(787<7L7P7`7d7t7x7
7(787<7L7P7h7x7|7
7(7D7T7`7
7(7H7P7\7|7
7(7H7P7`7
7(7H7T7t7|7
7(7H7X7@8
7(7L7T7\7d7l7t7|7
7(8:8\8v8
7(8`8
7(828~>
7(878=8Y8b8n8z8
7(888D8L8l8
7(8M8c8y8
7(8p8
7)7=7Q7]7i7u7
7)757F7
7)757Q7
7)8T8w8
7*71787Y7
7*757y7
7*7I7
7*7T7[7b7
7*8^8
7*8F8
7*8I8b8g8
7*8w8
7*8x8
7,7^7o7
7,7=7C7P7b7i7v7
7,7>7
7,7074787@7X7h7l7|7
7,70747H7L7d7t7x7|7
7,717J7Y7q7
7,747@7`7h7p7x7
7,747<7D7\7d7
7,747<7D7L7T7\7d7l7t7|7
7,747<7X7h7t7|7
7,7H7X7d7
7,8@8
7,8<8H8P8
7,848\8d8
7,8c8w8
7,8G8b8
7,8x8
7,9<9
7.7?7P7f7
7.7E7J7a7f7u7z7
7.7L7
7.8Q8
7/757=7R7^7r7
7/7R7u7
7/8G8j8
7/8L8
7/8Z8u8
7/ER}
7:7F7R7^7z7+9?9I9R9
7:7l7v7
7:8G8h8n8
7;7O7~7
7;7uO
7;7ur
7;8O8d8j8
7;8y8
7;FXuS
7?7[7
7?7D9`9j9
7?8\8s8
7?8R8s85:V:
7?8u9
7?8W8|8
7?fff?
7@7[7
7@7G7f7w7
7@7P7\7d7
7@8G8\8q8
7@PVW
7\7n7
7^7e7~7
7_8s8|8
7}-WV
7+777H7
7+787E7k7
7+7F7a7|7
7+7F7i7
7+8?8^8
7+818
7+858R8
7+8h8z8
7<7C7[7{7
7<7D7P7p7|7
7<7h7
7<7H7P7
7<7p7
7<8J9
7<8t8
7=8`8
7>8P8{8
707@7D7H7L7`7d7h7l7
707@7D7H7L7P7X7p7t7
707@7D7T7d7h7p7
707<7Y7l7
707G7
708:8O8d8{8
708@8L8T8t8
708}8
708C8g8
70D0e0k0
717\7
717p7
717T7
717W7d7
71888D8z8"9
718g8
727@7
727M7h7
727z8
728g8
728U8p8
737d7
737N7i7
737Q7]7i7u7
737s7
737S7o7
738^8
738B8S8
738x8
739J9
747_7
747<7D7L7T7\7d7l7t7|7
747<7D7L7X7x7
74787<7P7T7X7\7d7h7l7p7t7|7
747D7H7L7d7h7l7
-747I7^79:
747S7
748H8`8h8
748k8
757b7
757F7L7Q7]7g7q7{7
757l7s7
757S7
758R8c8
767D7o7
767Q7l7
7-7@7w7
7'717u7
7'757
7'767
777J7_7q7{7
777K7
777R7
7'787`7r7
778K8
7-7h7
78|As
787@7H7P7X7`7l7
787@7H7P7X7d7
787@7L7l7t7|7
787\7
787|7
787D7d7l7t7|7
787H7T7\7
787S7
788H8T8t8
788p8
7-8K8P8
78l3fC
7'8M8r8
7'8T8Y8i8q8v8
7A7N7\7a7s7x7}7
7A9]9
7B8O8
7B8Q:^:/;+<'=8>S>
7C7e7p7
7C7O7`7
7C8Y8j8{8
7D7d7q7
7D7g7
7D7y7
7E7O7o7
7F7c7
7F7q7
7F7W7
7F7y7
7F8X879o9
7f9l:Y=
7g7~7
7G7f7
7G7Q7j7{7
7G8m8
7G8N8
7G8N8g8
7G9Q9f9{9
7h$a/
7H7Q7x7
7H8`8g8
7hTT-
7I7O7Y7m7
7I8c8
7i9|9
7J7h7q7
7J7m7
'7JCy7
7K7|7
7K7f7x7
7k7r7
7K8]8b8
7l7|7O8c8
7L8r8|8
7L9v9
7m9$:1:E:s:
7n9{9`:
7O7k7
7O8g8n8
7P7\7
7P7n7
7p7w7
7P8%9A9
7P8k9q:e;
7Q7J9
'7QVh
'7QVhX
7R7u7
7S7g7p7
7T8d839?:
7u.9T7
7U8\8u8
7V7e7
7V7H8`8j8
7V8g8
7V9 ;c=x=
7V93:Q:e:y:
7W8`8
7X8e8
7x8U9
7Z8z8
8 :y:
8 8$8(8,8084888<8@8D8H8L8P8T8X8\8`8d8h8l8p8t8x8|8
8 8$8(8,848L8\8l8p8
8 8$8(8@8D8\8`8d8l8
8 8$8(8@8D8\8l8|8
8 8$8<8@8X8h8l8p8
8 8$8<8@8X8h8l8p8t8x8|8
8 8$8<8@8X8h8x8|8
8 8%818;8G8X8
8 8(8\8l8x8
8 8(80888@8L8l8x8
8 8(80888D8d8l8x8
8 8(80888D8d8p8
8 8)808<8q8
8 8*848>8H8R8\8f8p8
8 8,848h8x8
8 8,848x8
8 8,8L8X8x8
8 8@8H8P8X8`8h8t8
8 8@8L8l8t8
8 8@8L8l8x8
8 8<8L8X8`8
8 8=8^8z8
8 808@8P8T8l8p8t8
8 808<8D8d8
8 80888@8P8X8`8h8p8x8
8 818M8d8w9
8 84888H8L8P8d8h8x8|8
8 84888P8T8l8p8
8 848D8H8`8d8h8l8
8 848D8H8L8P8T8X8\8`8d8h8l8p8t8x8
8 888<8T8d8h8l8p8t8x8|8
8 9*9O9c9n:
8 909<9D9x9
8 9'9?9R9q9
8 9H9h9
8 9I9N9W9i9q9v9
8 9l9
8!8%8+858;8?8E8L8X8]8h8n8x8
8!858I8U8a8m8
8!8'8+8F8N8^8e8r8z8
8!8-898E8a8
8!8c8
8!8G8h8
8!9(9/9
8!9'9X9n9y9
8!9r9
8"8&8*8.82868:8>8B8F8J8N8R8V8Z8^8b8f8j8n8r8v8z8~8
8"8;8@8Y8a8f8x8}8
8"8|8
8"9E9k9
8"9g9
8"9j9
8#8,83898F8M8d8
8#8=8
8#828Y8
8#83888J8R8W8h8m8r8
8#848q8
8#888O8
8#8E8M8d8o8
8#8i8
8#8O8
8#939
8#9F9
8#9U9s9
8$;.;S;j;
8$;;;R;l;
8$8(8,8D8T8X8p8t8
8$8(8.858=8G8K8Q8[8_8e8l8s8z8
8$8(8@8D8\8`8d8x8|8
8$8,848@8`8h8p8
8$8,848<8D8L8T8\8d8l8t8|8
8$8,848<8D8L8T8\8d8p8
8$8,848<8D8L8T8\8h8
8$8,848<8D8L8T8`8
8$8,848<8D8P8p8|8
8$8,848<8D8P8p8x8
8$8,848<8H8h8p8x8
8$8,848D8L8T8\8d8l8t8|8
8$8.888M8^8d8i8u8
8$8;8
8$8@8P8\8d8
8$8+83898=8C8M8S8W8\8c8k8u8{8
8$8<8L8P8T8X8l8p8
8$80888l8|8
8$808P8\8d8
8$848@8d8l8t8|8
8$858h8
8$8D8`8p8|8
8$8D8L8X8x8
8$8G8j8
8$9*979B9[9f9o9x9~9
8$9<9C9\9|9
8$949@9`9l9
8$949@9H9|9
8$9D9
8%8,8G8Q8j8{8
8%8/8:8O8b8n8
8%8:8Q8m8
8%8{8
8%8<8n8
8%808C8a8m8y8
8%8-828E8J8_8d8y8~8
8%8P8~8
8%9,9\9t9
8%9.9W:
8%9a9f9
8%9m9 ;=;
8&;-;U;
8&8,808:8[8k8q8y8
8&828>8Z8
8&828J8
8&888
8&8A8\8
8&8T8^8
8&9.939D9I9Z9_9d9z9
8&9:9
8&969
8&9P:
8&9T9
8&9V9g9
8(8,8<8@8P8`8d8t8x8|8
8(8,8084888<8@8D8H8L8P8T8X8\8`8d8x8|8
8(8.888C8G8M8W8]8a8g8m8t8
8(8:8I8Y8
8(808<8\8d8l8t8|8
8(808<8\8h8
8(808<8H8X8h8p8|8
8(80888@8H8T8t8|8
8(808d8t8
8(848<8p8
8(888@8L8P8\8`8l8x8
8(888<8@8X8\8t8x8
8(888<8T8d8t8x8|8
8(8F8g8y8
8(8L8T8\8d8l8t8|8
8(9:9X9v9
8(9B9p9
8(9T9
8)8:8Q8
8)8:8V8m8
8)8=8F8n8
8)868D8
8)8D8_8
8)8E8
8)8K8
8)8N8`8d8h8l8p8t8x8|8
8)8V8]8d8~8
8)999@9M9T9[9b9k9z9
8)9l9
8)9q9
8*:E:J:
8*8<8C8P8\8m8
8*818J8
8*868B8N8j8
8*868S8f8
8*91969<9B9\9k9{9
8,8%9
8,8<8M8V8\8
8,808H8L8d8h8
8,808H8X8\8t8
8,828?8Q8^8j8{8
8,848<8X8h8t8|8
8,848H8P8X8`8t8|8
8,888X8`8l8t8
8,9d9
8,9K9
8,9P9
8,9U9\9a9x9}9
8,9X9
8,9X9]9b9t9y9~9
8.8b8~8
8.8I8
8.8l859
8.9^9
8/8@8F8S8i8n8
8/8D8-<
8/8J8e8
8/9<9]9c9{9
8/9<9Y9s9
8/9J9
8:8A8
8:8A8F8[8`8e8
8:9\9
8:9G9O:j:_;
8;7u ;
8?8T8f8
8?8Z8u8
8@8Q8l8
8@8Y8a8f8x8}8
8\u"j
8^93:Q:]:i:u:
8^u(@
8_^[]
8_8z8
8_9h9
8_9v9
8`8g8
8`9$:V:_:u:
8{un@
8+8>8]8
8+83888K8P8d8i8
8+8F8j8
8<8`8
8<8D8L8T8\8d8l8x8
8<8D8L8T8\8d8p8x8
8<8D8L8X8x8
8<8L8X8`8
8<8x8
8<9E9e9
8<9W9r9
8=8y8
8=9w9
8>9d9m9
8>9o9
80?0X0
808@8D8\8`8d8x8|8
808@8L8T8t8
808<8\8h8
808>8H8Y8d8j8
8084888@8X8\8t8
808H8T8t8
808O8
809@9L9T9t9
809P9x9
809x9
81:M:`:
818=8I8U8q8
818>8o8
81868O8`8f8s8
818L8g8
818s8
82898
828F8
828M8h8
829~9
829i9
838:8Y8c8|8
83888=8O8T8Y8q8
838i8s8
838j8v8
839#:
839a9
848:8R8d8
848;8B8
848\8h8
848<8D8L8h8x8
848<8d8l8t8
848<8D8L8T8\8d8|8
848<8D8L8T8\8d8l8t8|8
848<8D8L8T8\8d8p8
848<8D8L8T8\8h8
84888<8P8`8d8h8
84888P8T8l8|8
848A8b8g8
848H8Q8e8w8
849D9P9p9
85:X:
858?8T8i8
858>8
858l8s8
858W8|8
859A9[9v9
859B9o9
859v9
868G8z8
868U8
868X8
869_9
869~9
869H9
878C8H8M8i8
878d8
878s8
878W8
878z8
879g:
879K9`9f9
8'818A8N8[8{8
8-828G8V8b8z8
888@8L8l8t8|8
888c8
888H8T8\8
8-898E8Q8m8
889A9h9s9
889l9
889N9
8-8C8a8m8y8
8'8s9
8'8w8
8'9/949c9
8'9;9P9{9
89}4w
8'929
8-949>9H9[9b9o9v9
8-959c9
898>8H8T8e8
899C9\9
899C9X9m9
8'9C9Z9
8A8a8r8
8A8g8
8A8H8
8A8Q8q8
8B8}8
8B8I8P8
8C:v:
8C8`8:9
8C8e8p8
8C8t8
8D;U;[;k;
8D9g9
8D9T9
8D9y9
8E8c8
8E8u8
8E8z8
8E9S9k9q9
8F8W8
8F9#:
8F9w9
8G8c8
8G9c9
8G9Q9f9{9
8G9V9
8giP9giP9giP9giP9
8h|j-
8H8Y8
8h9E:
8h9p9
8I8[8`8
8i869G9
8I9D;x;
8I9o9~9
8J8V8
8K8p8
8L8\8h8p8
8L8~9
8M8f8w8
8M8W8
8N8}8
8N9]9u9V:l:
8N9U9n9
8O9l9
8O9n9x9
8P8`8l8t8
8Q:q:~:
8Q:r;
8Q8h8
8Q9j9~9
8Q9s9z9
8QWh4Y/
8R9f9
8r9w9
8S8}8
8U9v9
8-uJ@
8V8u8
8V9h9
8W$ta!
8X t5
8Z8|8
8Z9q9I:j:
8Z9z9
9 :%:;:@:P:X:]:n:s:
9 :>:J:O:T:p:
9 :C:p:
9 :p:
9 9$9(9,9094989<9@9D9H9L9P9d9h9l9
9 9$9(9,9094989<9@9D9H9L9P9T9X9\9`9d9h9l9p9t9x9|9
9 9$9(9,9094989<9@9D9L9P9X9p9t9x9|9
9 9$9(9,9094989<9@9T9X9\9p9
9 9$9(9,90989<9@9D9H9L9P9T9X9\9p9t9
9 9$9(9,949L9\9`9d9h9p9x9
9 9$9<9L9P9T9l9|9
9 9$989<9@9D9H9P9h9x9|9
9 9%9*9=9B9G9`9q9w9|9
9 9&9,92969;9B9J9T9Z9d9h9n9x9
9 9&9,92989>9D9J9P9V9\9b9h9o9s9w9{9
9 9(909@9d9l9t9|9
9 9(90989@9H9T9t9|9
9 9(949T9\9d9l9x9
9 9(949T9\9h9
9 9(989@9H9X9`9p9
9 9(9L9T9d9l9t9|9
9 9,9
9 9,9L9T9`9
9 9?9
9 9@9H9P9X9`9h9p9|9
9 9@9H9T9t9|9
9 9@9L9l9t9|9
9 9@9P9t9|9
9 9<9L9X9x9
9 909<9D9d9
9 9094989L9P9h9x9|9
9 909T9\9d9l9t9|9
9 969G9
9 989@9d9t9
9 9D9L9T9\9d9l9t9|9
9 9T9d9p9x9
9!:/:
9!:;:
9!:1:=:K:e:
9!:g:
9!:J:Q:V:l:q:
9!919A9Q9q9
9!959A9M9Y9u9
9!9d9
9!9H9X9
9!9X9a9
9":,:
9":/:P:V:n:
9":=:9;
9":Q:
9"9(92989B9H9R9X9b9h9r9x9
9"9(9-999C9O9`9
9"9)919;9?9E9O9S9Y9`9g9q9w9}9
9"9.9J9
9"9:9L9
9"90<
9#:`:e:
9#:>:Y:t:
9#:A:M:Y:e:
9#:A:U:a:m:y:
9#:E:P:c:
9#:E:U:[:c:{:
9#9)9.9:9L9S9`9l9}9
9#9:9?9D9^9c9h9|9
9#9<9M9S9`9r9
9#959M9
9#979D9P9^9
9#989R9
9#9-93979=9D9P9U9`9f9p9{9
9#9-9H9R9k9u9
9#9A9M9Y9e9
9#9R9d9
9$:4:@:`:h:t:
9$:4:@:H:|:
9$:T:
9$<d<
9$9(9@9D9\9`9x9|9
9$9(9@9P9T9X9\9`9t9
9$9,92969Q9Y9i9p9}9
9$9,949@9d9l9t9|9
9$9,949<9D9L9T9\9d9l9t9|9
9$9,949<9D9L9T9`9
9$9,949<9D9L9X9x9
9$9,949<9D9P9t9|9
9$9<9L9P9`9d9h9
9$90959@9F9P9Z9_9e9i9o9y9
9$90989\9l9t9|9
9$909P9`9
9$909P9X9`9l9
9$939
9$9D9L9T9\9h9
9$9D9L9X9x9
9$9G9r9
9$9X9h9t9|9
9%:2:>:O:
9%:H:
9%9%:8:o:
9%9*969F9M9]9r9
9%9@9[9v9
9%909C9a9m9y9
9%9A9
9&:<:Q:
9&:2:C:W:
9&:3:T:Z:r:
9&:6:a:}:
9&9*9C9M9[9f9j9
9&9|9
9&979i9
9&9B9Y9p:
9&9e9
9&9E9|9
9&9F9z9
9&9k9
9(:`:
9(:8:D:L:
9(:j:
9(;`;
9(;w;
9(9,9<9@9P9`9d9h9
9(9,909H9L9d9h9l9t9
9(9,9D9H9`9d9|9
9(9,9D9H9`9p9t9x9|9
9(9?9Z9v9
9(9|9
9(909<9H9X9`9l9p9|9
9(90949<9@9H9L9T9X9\9`9d9l9p9x9|9
9(90989@9H9\9d9
9(90989@9L9T9l9t9
9(909d9l9t9|9
9(909H9P9t9
9(909P9X9x9
9(949<9p9
9(989<9L9P9`9p9
9(989<9L9P9`9p9t9x9
9(989<9T9X9\9`9d9h9l9p9t9x9|9
9(989H9P9\9`9l9p9|9
9(9e9
9(9H9P9`9
9(9H9P9X9`9h9p9x9
9):2:H:
9)9>9S9q9}9
9)959Q9
9*939`9
9*9c9
9,:<:H:P:
9,:<:H:T:p:
9,:c:
9,:C:a:w:
9,9\9
9,909@9P9`9d9h9l9t9
9,9094989<9@9D9H9L9P9T9X9\9`9d9h9p9
9,90949H9X9h9l9p9
9,909H9X9h9l9p9t9
9,949<9D9L9T9\9d9l9t9|9
9,949<9D9L9T9\9d9p9
9,949<9D9L9X9x9
9,949<9X9h9t9|9
9,989@9t9
9,989X9d9
9,9a9
9,9P9p9
9.:5:<:N:W:
9.:t:
9.9k9
9.9K9q9
9/:L:
9/:Z:u:
9/9[9s9
9/989
9/989?9F9S9d9
9/9O9
9::~:
9::A:Z:
9:9E9
9:9N9\9l9
9:9s9
9':S:X:]:o:t:y:
9-:y:
9;9E9Z9o9
9;9H9[9
9?:x:
9?;k;r;
9@;D;H;L;P;T;X;\;`;d;h;l;s;
9@9d9
9@9M9j9o9t9
9@9P9\9d9|9
9\;x;
9\9r9
9^(v)
9^(v`
9^,|0
9^9k9
9_(s3Sj
9_,~6
9_LuEQ
9_Pv.
9`9p9|9
9{:6;H;
9{Tt;
9|$4t?
9}(u29}Pu
9~$~8
9~LtQ
9+:=:D:N:W:c:s:}:
9+:C:]:
9+9<9z9
9+90959F9K9P9b9j9o9
9+909C9N9T9^9s9
9+919~9
9+9V9
9<;s;
9<9\9
9<9b9
9<9C9{9
9>:h;
9>:R:h:
9>:Y:t:
9>:Z:z:
9>9q9
9>9R9[9
90:@:L:l:x:
90:@:L:T:t:
90:\:
90:^:r:
909?9`9z9
909[9
909^9y9
909}9
909<9\9h9
9094989P9`9d9|9
90949L9P9h9l9p9
90949L9P9X9\9`9d9h9|9
90989D9L9
909M:T:
909W9^9w9
909Z9j9o9
90T0^0s0
91:V:g:
91;x;E<)=P=T=X=\=`=d=h=l=p=t=x=|=
91969B9T9Y9m9r9
91999>9P9U9Z9o9t9
919C9
92:[:b:g:}:
92:]:x:
92:9:@:\:g:u:
92:N:
92:Q:
929f:
93:e:
93:f:x:
93:Q:]:i:u:
93:U:`:s:
939=9R9g9~9
939Q9]9i9u9
939Q9V9
94:;:q:
94:;:S:f:
94:b:l:
94:h:t:
94:L:S:v:
949<9D9L9T9\9h9
949=:;;W<r<
949D9P9X9
949G9Q9n9
949j9
949N9_9
949P9`9l9t9
949X9
959J9d9
959L9<:i:~:
959P9k9
96:=:R:g:
96:E:
96:H:
969H9
969k9
969V9g9
979[9{9
979s9
979Z9}9
98:?:X:
98:D:v:
98:l:
98:t:
989A9h9q9
989H9T9\9
989S9n9
98tKV
98uC;
98uR;
98uT;
9-9:9
99:l:
99;L;
9'9@9F9J9T9u9
9'9^9e9}9
9'909m9w9
9-969
9-999E9Q9m9
999a9
9'9D9
9'9e9c;
9-9H9c9~9
9-9i9
9'9k9
9'9K9
9-9O9Y9~9
9-9r9
99vHh
9A:H:]:r:
9A:R:
9a9}9
9A9~9
9A9F9_9d9}9
9A9H9_9k9y9
9A9K9
9B;U;
9B9^9
9B9g9s9
9C(v?
9C,|F
9C:c:z:
9c9~9
9C9e9p9
9C9H9M9_9d9i9
9D$ ~
9D$Du3
9D9e9
9D9l9
9E,}J
9E8}J
9ED}d
9EH}d
9F$t@
9F:U:l:
9f;w;
9F9W9
9G\uZ
9G9r9
9GLvd
9H:d:
9H9X9d9
9H9X9d9l9
9I;P;i;
9I9|9
9I9m9|9
9J:e:o:
9J:f:p:
9J9u9O:U:\:t:{:
9K9j9u9
9L$@u*
9L:l:
9L9S9k9
9M:R:
9M9a9
9M9V9
9N<s<
9n9{9
9p u 9p
9p u!
9p$uN
9p0t*
9P9`9l9t9
9P9n9z9
9p9w9
9Q u!9A$u
9Q:[:
9R9{9
9s:~:
9S:o:
9S<f<y<
9S9g9
9S9p9
9S9q9}9
9S9u9
9SHv%
9t$$t]
9t$0u
9T:z:
9T9|9
9T9w9,;
9U:e:q:
9U:p:
9u4wn
9u4wt
9U9f9
9U9p9
9V uj9V
9V:h:
9W:s:];g;
9w0tM
9wPvi
9wT|p
9X,u"hxB-
9X<\<`<d<h<l<p<
9X9{9
9X9h9t9
9x9S:N;T;];f;o;x;
9y:5<Q<
9Y:f:y:
9Z:c:
9Z;t;
9z9+:
a != nullptr && b != nullptr
A ;J@
A + (M * lda - (lda - K)) <= A_end
A' = transpose(A) if transA else A
A 1-D input tensor that is to be processed.
A 1-D INT64 tensor containing the the count of each element of 'uniques' in the input 'x'
A 1-D INT64 tensor of the same size as 'x' containing the indices for each value in 'x' in the output 'uniques'
A 1-D tensor containing a single positive value corresponding to the number of top elements to retrieve
A 1-D tensor holding values from the input dictionary.
A 1-D tensor indicates the shape you want to expand to, following the broadcast rule
A 1-D tensor of the same type as 'x' containing all the unique values in 'x' sorted in the same order that they occur in the input 'x'
A 1-D values of (height, width).
A 1-D values of (leftBorder, topBorder, rightBorder, bottomBorder).
A 2D tensor with the contents of the input tensor, with input dimensions up to axis flattened to the outer dimension of the output and remaining input dimensions flattened into the inner dimension of the output.
A boolean termination condition. Optional. Pass empty string to skip.
A collection of intercepts.
A collection of weights of the model(s).
A dictionary.
A dimension cannot be less than -1.
A dso with name 
a filter
A float.
A list of 2 (or 4 if bidirectional) activation functions for update, reset, and hidden gates. The activation functions must be one of the activation functions specified above. Optional: See the equations for default if not specified.
A list of 3 (or 6 if bidirectional) activation functions for input, output, forget, cell, and hidden. The activation functions must be one of the activation functions specified above. Optional: See the equations for default if not specified.
A list of floats.
A list of integers, along which to reduce. The default is to caculate along axes [0,2,3] for calculating mean and variance along each channel. Two variables with the same C-coordinate are associated with the same mean and variance.
A list of integers, along which to reduce. The default is to reduce over all the dimensions of the input tensor.
A list of integers. By default, reverse the dimensions, otherwise permute the axes according to the values given.
A list of ints.
A list of labels.
A list of strings. One and only one of 'keys_*'s should be set.
A list of strings. One and only one of 'value_*'s should be set.
A maximum trip-count for the loop specified at runtime. Optional. Pass empty string to skip.
A protocol message was rejected because it was too big (more than 
A shape tensor must be a vector tensor.
A string indicating the desired element type of the output tensor, one of 'TO_FLOAT', 'TO_STRING', 'TO_INT64'.
A string to use when an input integer value is not found in the map.<br>One and only one of the 'default_*' attributes must be defined.
A string vocabulary array.<br>One and only one of the vocabularies must be defined.
A string.
A tensor of rank >= axis.
A tensor representing the same data as the input map, ordered by their keys
A tensor that concats all the intermediate output values of the hidden. It has shape `[seq_length, num_directions, batch_size, hidden_size]`
A tensor that concats all the intermediate output values of the hidden. It has shape `[seq_length, num_directions, batch_size, hidden_size]`. 
A tensor that concats all the intermediate output values of the hidden. It has shape `[seq_length, num_directions, batch_size, hidden_size]`. It is optional if `output_sequence` is 0.
A value that needs replacing.
A$+A 
A,+A(
A,+A(j
a_scale
a_zero_point
a_zero_point->Shape().NumDimensions() == 0 || (a_zero_point->Shape().NumDimensions() == 1 && a_zero_point->Shape().GetDims().size() == 1)
A`+A\j
A<+A8
A<+A8j
A0\0Y1
A0+A,
A09A,t++A,
A0T0q0
A0V;A4t
A8+A4
A8+A4P
abort
Acosh
acoshf
AcquireSRWLockExclusive
AcquireSRWLockShared
across_channels
activatibleClassId
activation
Activation functions:
activation_alpha
activation_beta
activation_func_names.size() == static_cast<size_t>(num_directions_) * 2
activation_func_names.size() == static_cast<size_t>(num_directions_) * 3
ActivationDescCount
ActivationDescs
activations
activations_.size() == static_cast<size_t>(num_directions)
AD;AH
adapterLuidHighPart
adapterLuidLowPart
add the enum type to the switch statement
AddFoldedRange recurses too much.
Adding default CPU execution provider.
addition
address family not supported
address in use
address not available
Adlam
Af98u
affine
Affine
aggregate_function
AH;A@
ai.onnx
ai.onnx.ml
AL;AD|
All implicit inputs should have OrtValue instances by now. 
All inputs and outputs must have the same data type.
All inputs must have the same shape
All inputs to Concat must have same rank
All Tensor types
Allocated memory at 
allocation failure
Allocation of tensor types requires a shape.
allocator != nullptr
allocator_ptr_ != nullptr
Allowed values are 1 and 2. Current level is set to 
allowed_activations.find(activations_[direction]) != allowed_activations.end()
allowed_directions.find(direction_) != allowed_directions.end()
alpha
Alpha
alpha_ > 0.0f
already connected
An attribute specifying the number of scan_inputs M. 
An axis tensor must be a scalar tensor.
An input tensor to hash.
An input tensor with shape [num_batches, num_classes, spatial_dimension]
An input tensor with shape [num_batches, spatial_dimension, 4]. The single box data format is indicated by center_point_box.
An input tensor.
An integer to use when an input string value is not found in the map.<br>One and only one of the 'default_*' attributes must be defined.
An integer vocabulary array.<br>One and only one of the vocabularies must be defined.
An integer.
An optional list of K flags, one for each scan_output. The i-th element of the list specifies whether the i-th scan_output should be constructed by appending or prepending a new value in each iteration: 0 indicates appending and 1 indicates prepending. If omitted, all scan_output tensors will be produced by appending a value in each iteration.
An optional list of K flags. The i-th element of the list specifies the axis for the i-th scan_output. The scan outputs are accumulated along the specified axis. If omitted, 0 will be used as the scan axis for every scan_output.
An optional list of M flags. The i-th element of the list specifies the axis to be scanned (the sequence axis) for the i-th scan_input. If omitted, 0 will be used as the scan axis for every scan_input.
An optional list of M flags. The i-th element of the list specifies the direction to be scanned for the i-th scan_input tensor: 0 indicates forward direction and 1 indicates reverse direction. If omitted, all scan_input tensors will be scanned in the forward direction.
an optional list of strings attribute that contains a list of separators - regular expressions to match separators Two consecutive segments in X connected by a separator would be divided into two tokens. For example, if the input is "Hello World!" and this attribute contains only one space character, the corresponding output would be ["Hello", "World!"]. To achieve character-level tokenization, one should set the 'separators' to [""], which contains an empty string.
An optional string. Token's regular expression in basic POSIX format (http://pubs.opengroup.org/onlinepubs/9699919799/basedefs/V1_chap09.html#tag_09_03). If set, tokenizer may produce tokens matching the specified pattern. Note that one and only of 'tokenexp' and 'separators' should be set.
An ordered collection of tensors, all with the same element type.
Anatolian_Hieroglyphs
and computes the output.
and contains the {name} values of the corresponding input.
and output tensor Y has shape (M, N). A will be transposed before doing the
Ap+Al
AP+AL
Ap+AlY
api-ms-win-core-com-l1-1-0.dll
api-ms-win-core-com-l1-1-1.dll
api-ms-win-core-debug-l1-1-0.dll
api-ms-win-core-errorhandling-l1-1-0.dll
api-ms-win-core-file-l1-1-0.dll
api-ms-win-core-handle-l1-1-0.dll
api-ms-win-core-heap-l1-1-0.dll
api-ms-win-core-interlocked-l1-1-0.dll
api-ms-win-core-libraryloader-l1-2-0.dll
api-ms-win-core-libraryloader-l1-2-1.dll
api-ms-win-core-localization-l1-2-0.dll
api-ms-win-core-memory-l1-1-0.dll
api-ms-win-core-processthreads-l1-1-0.dll
api-ms-win-core-processthreads-l1-1-1.dll
api-ms-win-core-profile-l1-1-0.dll
api-ms-win-core-psapi-l1-1-0.dll
api-ms-win-core-string-l1-1-0.dll
api-ms-win-core-synch-l1-1-0.dll
api-ms-win-core-synch-l1-2-0.dll
api-ms-win-core-sysinfo-l1-1-0.dll
api-ms-win-core-sysinfo-l1-2-0.dll
api-ms-win-core-threadpool-l1-2-0.dll
api-ms-win-core-util-l1-1-0.dll
api-ms-win-core-winrt-error-l1-1-0.dll
api-ms-win-core-winrt-error-l1-1-1.dll
api-ms-win-core-winrt-l1-1-0.dll
api-ms-win-core-winrt-string-l1-1-0.dll
api-ms-win-crt-convert-l1-1-0.dll
api-ms-win-crt-filesystem-l1-1-0.dll
api-ms-win-crt-heap-l1-1-0.dll
api-ms-win-crt-locale-l1-1-0.dll
api-ms-win-crt-math-l1-1-0.dll
api-ms-win-crt-private-l1-1-0.dll
api-ms-win-crt-runtime-l1-1-0.dll
api-ms-win-crt-stdio-l1-1-0.dll
api-ms-win-crt-string-l1-1-0.dll
api-ms-win-crt-time-l1-1-0.dll
api-ms-win-eventing-provider-l1-1-0.dll
AQQQh 
AQQQWh
AQQVWh
Arabic
Arbitrary input
Arbitrary output
Arbitrated channel order
Arbitrated channel order reason
arg_num < arg_counts.size()
ArgMax
ArgMin
argument list too long
Argument mismatch when removing edge.
argument out of domain
Argument size (%d) exceeds the tensor size (%d).
Argument size (%u) exceeds the tensor size (%u).
Argument type mismatch when adding edge.
Armenian
Array of sequence lengths.  len(seq_lengths) should equal batch size N.
ArrayFeatureExtractor
as possible.
Asinh
asinhf
At least one output should be requested.
At most one dimension can be -1.
At+Ap
AT+AP
At+Ap
Atanh
atanhf
ATensor
Attempt to retrieve final output before it was set.
Attempt to use DefaultLogger but none has been registered.
Attempting to broadcast an axis by a dimension other than 1. 
Attempting to get an input that does not exist.
Attempting to get an output that does not exist.
Attention layer weight shape error! Expected: {
Attention mechanism memory sequence lengths must have shape {
Attention mechanism memory sequence lengths value must in (0, 
Attention mechanism memory shape error! Expected: {
Attention memory layer weight shape error! Expected:{
Attention query layer weight shape error! Expected:{
Attention v weight shape error! Expected:{
Attibute name and type don't match
AttnLSTM
Attribute 
Attribute '
Attribute (name: 
Attribute `broadcast=1` needs to be passed to enable broadcasting.
Attribute axes has incorrect length
Attribute axes is not set.
Attribute blocksize is not set.
Attribute border needs to be specified with four border elements, got 
attribute case_change_action has invalid value
attribute case_change_action is not set
Attribute dilations has incorrect size
Attribute expected to have a one-dim tensor
Attribute expected to have tensor type
attribute is_case_sensitive is not set
Attribute kernel_shape has incorrect size
Attribute kernel_shape has incorrect size.
Attribute kernel_shape must be specified
Attribute kernel_shape must be specified.
attribute mark is not set
attribute mincharnum is not set
attribute mincharnum must have a positive value
attribute pad_value is not set
Attribute pads has incorrect length
Attribute pads has incorrect size
Attribute pads has incorrect size.
Attribute perm of Transpose has an invalid value. Value 
Attribute pooled_shape has incorrect length
Attribute pooled_shape must be specified
Attribute shape is not set.
Attribute specification type mismatch.
Attribute strides has incorrect size
Attribute strides has incorrect size.
Attribute to is not set.
Attribute value for pads is required
Attribute 'value' of Constant node must exist with 'Tensor' data.
attributeCount
author
auto_pad
auto_pad must be either NOTSET, SAME_UPPER, SAME_LOWER or VALID. Where default value is NOTSET, which means explicit padding is used. SAME_UPPER or SAME_LOWER mean pad the input so that the output size match the input.In case of odd number add the extra padding at the end for SAME_UPPER and at the beginning for SAME_LOWER. VALID mean no padding.
auto_pad must be either NOTSET, SAME_UPPER, SAME_LOWER or VALID. Where default value is NOTSET, which means explicit padding is used. SAME_UPPER or SAME_LOWER mean pad the input so that the output size match the input.In case of odd number add the extra padding at the end for SAME_UPPER and at the beginning for SAME_LOWER. VALID mean no padding. DEPRECATION NOTE: auto_pad is only intended to support legacy uses, and for framework authors, one is explicitly encouraged to use explicit padding specified in the pads attribute.
average
AVERAGE
AveragePool
Avestan
avgCpuUsage
avgPageFaultCount
avgTime
avgWorkingSetMemory
'axes' has a duplicate axis
'axes' has an axis outside of the tensor dimension count
'axes' has an out of range axis
'axes' has duplicates
Axes that `starts` and `ends` apply to. It's optional. If not present, will be treated as [0, 1, ..., len(`starts`) - 1].
axes_right_stride >= 0 && static_cast<uint64_t>(axes_right_stride) < std::numeric_limits<size_t>::max()
axis 
axis <= X_NumDims && axis >= -X_NumDims
axis == 1 || axis == largest
axis >= -tensor_rank && axis <= tensor_rank - 1
Axis along which to repeat.
'axis' attribute must have a value in the range [
axis greater than input data dimension!
Axis has less than the requested k elements.
axis must be in [-r, r-1]
'axis' must be in [-rank(indices)-1, rank(indices)]
Axis must be within range [
axis_ < static_cast<int64_t>(rank)
axis_tensor->Shape().IsScalar()
AxisCount
B + (N * ldb - (ldb - K)) <= B_end
B' = transpose(B) if transB else B
B,+B(
b;:'Windows::AI::MachineLearning::DmlOrtSessionBuilder::Initialize
b_scale
b_zero_point
b_zero_point->Shape().NumDimensions() == 0 || (b_zero_point->Shape().NumDimensions() == 1 && b_zero_point->Shape().GetDims().size() == 1)
B|+Bx
B0?1S2
B0+J$@+J
B0+J8+B,
b2 4(4=4
B2^2^3]5T7l7
BackUp() can only be called after a successful Next().
bad address
bad allocation
Bad arg in kInstAltMatch: 
Bad arg in kInstCapture: 
Bad args: nsubmatch=
bad array new length
Bad call to ParseState::ParsePerlFlags
bad cast
bad conversion
bad exception
bad file descriptor
Bad final char: 
bad function call
Bad hex digit 
bad locale name
bad message
Bad node spec: 
Bad optional access
Bad reference count 
bad repetition operator
bad variant access
bad_weak_ptr
Balinese
Bamum
Base values for classification, added to final class score; the size must be the same as the classes or can be left unassigned (assumed 0)
base_values
base_values_.empty() || base_values_.size() == static_cast<size_t>(class_count_) || base_values_.size() == weights_classes_.size()
base_values_.empty() || base_values_.size() == static_cast<size_t>(n_targets_)
Bassa_Vah
Batak
batch_axis
batch_axis != time_axis
batch_axis < 2
batch_indices
batch_indices shape input tensor has wrong dimension
batch_size is < 1
BatchNormalization
BatchNormalization kernel for CPU provider does not support non-spatial cases
BatchNormalizationAddFusion
BatchNormalizationMulFusion
Begin execution
Bengali
beta_ > 0.0f
Bf9T$
bfloat16
Bgra8
Bhaiksuki
Bias applied to each channel, same size as C.
Bias size (
Bias tensor of shape (C).
BiasTensor
bidirectional
bilinear
BILINEAR
Binarized output data
Binarizer
Binding
BinForSize(bin_size * 2 - 1) == BinFromIndex(b)
BinForSize(bin_size * 2) != BinFromIndex(b)
BinForSize(bin_size + 255) == BinFromIndex(b)
BinForSize(bin_size) == BinFromIndex(b)
BinFromIndex(c->bin_num)->free_chunks.erase(h) > 0
BitmapBounds
BitmapBounds must reference a property value with type UInt32Array with 4 elements.
bitmappixelformat
BitmapPixelFormat
BitmapPixelFormat must be either Rgba8, Bgra8, or Gray8
Blocks of [blocksize, blocksize] are moved.
BlockSize
blocksize
Blocksize must be positive
Bool to determine if hidden state is zeroes or passed along for timesteps past the given sequence_length.
Boolean
boolean
Boolean whether to mark the beginning/end character with start of text character (0x02)/end of text character (0x03).
Boolean. Whether the identification of stop words in X is case-sensitive. Default is false
Bopomofo
border
both data and indices tensor need to have rank larger than zero.
boxes
boxes and scores should have same num_batches.
boxes and scores should have same spatial_dimention.
boxes must be a 3D tensor.
BP+BL
Bp+Bl
Brahmi
Braille
BRANCH_EQ
BRANCH_GT
BRANCH_GTE
BRANCH_LEQ
BRANCH_LT
broadcast
broken pipe
broken promise
Bt+Bp
BTensor
buffer
buffers_.find(mem_patterns_->locations[i]) == buffers_.end()
Buginese
Buhid
bumped the operator version but 
Byte size calculation and serialization were inconsistent.  This may indicate a bug in protocol buffers or it may be caused by concurrent modification of 
bytemap range 
C + (M * ldc - (ldc - N)) <= C_end
C$^_[]
C$+C j
C(Q9C,t
C)#3r
C,;0t
C,G+C(
C:\apilot\agent\_work\2\s\dml/Common/ApiHelpers.h
C:\apilot\agent\_work\2\s\dml/Common/GeneratedSchemaHelpers.h
C:\apilot\agent\_work\2\s\engine/OperatorAuthorHelper/MLOperatorAuthorHelper.h
C:\apilot\agent\_work\2\s\engine/OperatorAuthorHelper/OperatorHelper.h
C:\apilot\agent\_work\2\s\engine/OperatorAuthorHelper/SchemaInferenceOverrider.h
C:\apilot\agent\_work\2\s\engine\DmlExecutionProvider\src\BucketizedBufferAllocator.cpp
C:\apilot\agent\_work\2\s\engine\DmlExecutionProvider\src\CommandAllocatorRing.h
C:\apilot\agent\_work\2\s\engine\DmlExecutionProvider\src\CommandQueue.cpp
C:\apilot\agent\_work\2\s\engine\DmlExecutionProvider\src\DescriptorPool.cpp
C:\apilot\agent\_work\2\s\engine\DmlExecutionProvider\src\DmlCommandRecorder.cpp
C:\apilot\agent\_work\2\s\engine\DmlExecutionProvider\src\DmlCommon.cpp
C:\apilot\agent\_work\2\s\engine\DmlExecutionProvider\src\ExecutionContext.cpp
C:\apilot\agent\_work\2\s\engine\DmlExecutionProvider\src\ExecutionPlanBuilder.cpp
C:\apilot\agent\_work\2\s\engine\DmlExecutionProvider\src\ExecutionProvider.cpp
C:\apilot\agent\_work\2\s\engine\DmlExecutionProvider\src\FusedGraphKernel.cpp
C:\apilot\agent\_work\2\s\engine\DmlExecutionProvider\src\GpuEvent.h
C:\apilot\agent\_work\2\s\engine\DmlExecutionProvider\src\GraphTransformer.cpp
C:\apilot\agent\_work\2\s\engine\DmlExecutionProvider\src\Operators\DmlOperator.cpp
C:\apilot\agent\_work\2\s\engine\DmlExecutionProvider\src\Operators\DmlOperatorActivation.cpp
C:\apilot\agent\_work\2\s\engine\DmlExecutionProvider\src\Operators\DmlOperatorAffine.cpp
C:\apilot\agent\_work\2\s\engine\DmlExecutionProvider\src\Operators\DmlOperatorBatchNormalization.cpp
C:\apilot\agent\_work\2\s\engine\DmlExecutionProvider\src\Operators\DmlOperatorCast.cpp
C:\apilot\agent\_work\2\s\engine\DmlExecutionProvider\src\Operators\DmlOperatorConcat.cpp
C:\apilot\agent\_work\2\s\engine\DmlExecutionProvider\src\Operators\DmlOperatorConstantOfShape.cpp
C:\apilot\agent\_work\2\s\engine\DmlExecutionProvider\src\Operators\DmlOperatorConvolution.cpp
C:\apilot\agent\_work\2\s\engine\DmlExecutionProvider\src\Operators\DmlOperatorCopy.cpp
C:\apilot\agent\_work\2\s\engine\DmlExecutionProvider\src\Operators\DmlOperatorCrop.cpp
C:\apilot\agent\_work\2\s\engine\DmlExecutionProvider\src\Operators\DmlOperatorDepthToSpace.cpp
C:\apilot\agent\_work\2\s\engine\DmlExecutionProvider\src\Operators\DmlOperatorElementWise.cpp
C:\apilot\agent\_work\2\s\engine\DmlExecutionProvider\src\Operators\DmlOperatorExpand.cpp
C:\apilot\agent\_work\2\s\engine\DmlExecutionProvider\src\Operators\DmlOperatorEyeLike.cpp
C:\apilot\agent\_work\2\s\engine\DmlExecutionProvider\src\Operators\DmlOperatorGather.cpp
C:\apilot\agent\_work\2\s\engine\DmlExecutionProvider\src\Operators\DmlOperatorGemm.cpp
C:\apilot\agent\_work\2\s\engine\DmlExecutionProvider\src\Operators\DmlOperatorInstanceNormalization.cpp
C:\apilot\agent\_work\2\s\engine\DmlExecutionProvider\src\Operators\DmlOperatorLocalResponseNormalization.cpp
C:\apilot\agent\_work\2\s\engine\DmlExecutionProvider\src\Operators\DmlOperatorLpNormalization.cpp
C:\apilot\agent\_work\2\s\engine\DmlExecutionProvider\src\Operators\DmlOperatorMatMul.cpp
C:\apilot\agent\_work\2\s\engine\DmlExecutionProvider\src\Operators\DmlOperatorMaxUnpool.cpp
C:\apilot\agent\_work\2\s\engine\DmlExecutionProvider\src\Operators\DmlOperatorMeanVarianceNormalization.cpp
C:\apilot\agent\_work\2\s\engine\DmlExecutionProvider\src\Operators\DmlOperatorMemcpy.cpp
C:\apilot\agent\_work\2\s\engine\DmlExecutionProvider\src\Operators\DmlOperatorNeg.cpp
C:\apilot\agent\_work\2\s\engine\DmlExecutionProvider\src\Operators\DmlOperatorOneHot.cpp
C:\apilot\agent\_work\2\s\engine\DmlExecutionProvider\src\Operators\DmlOperatorPadding.cpp
C:\apilot\agent\_work\2\s\engine\DmlExecutionProvider\src\Operators\DmlOperatorPooling.cpp
C:\apilot\agent\_work\2\s\engine\DmlExecutionProvider\src\Operators\DmlOperatorRecurrentNeuralNetwork.cpp
C:\apilot\agent\_work\2\s\engine\DmlExecutionProvider\src\Operators\DmlOperatorReduce.cpp
C:\apilot\agent\_work\2\s\engine\DmlExecutionProvider\src\Operators\DmlOperatorResize.cpp
C:\apilot\agent\_work\2\s\engine\DmlExecutionProvider\src\Operators\DmlOperatorRoiPooling.cpp
C:\apilot\agent\_work\2\s\engine\DmlExecutionProvider\src\Operators\DmlOperatorScatter.cpp
C:\apilot\agent\_work\2\s\engine\DmlExecutionProvider\src\Operators\DmlOperatorSlice.cpp
C:\apilot\agent\_work\2\s\engine\DmlExecutionProvider\src\Operators\DmlOperatorSpaceToDepth.cpp
C:\apilot\agent\_work\2\s\engine\DmlExecutionProvider\src\Operators\DmlOperatorSplit.cpp
C:\apilot\agent\_work\2\s\engine\DmlExecutionProvider\src\Operators\DmlOperatorTile.cpp
C:\apilot\agent\_work\2\s\engine\DmlExecutionProvider\src\Operators\DmlOperatorTopk.cpp
C:\apilot\agent\_work\2\s\engine\DmlExecutionProvider\src\Operators\DmlOperatorTranspose.cpp
C:\apilot\agent\_work\2\s\engine\DmlExecutionProvider\src\Operators\DmlOperatorValueScale2D.cpp
C:\apilot\agent\_work\2\s\engine\DmlExecutionProvider\src\Operators\OperatorRegistration.cpp
C:\apilot\agent\_work\2\s\engine\DmlExecutionProvider\src\Operators\OperatorUtility.cpp
C:\apilot\agent\_work\2\s\engine\DmlExecutionProvider\src\PooledUploadHeap.cpp
C:\apilot\agent\_work\2\s\engine\DmlExecutionProvider\src\ReadbackHeap.cpp
C:\apilot\agent\_work\2\s\engine\DmlExecutionProvider\src\TensorDesc.cpp
C:\apilot\agent\_work\2\s\engine\lotus\cmake\external\onnx\onnx\defs\controlflow\defs.cc
C:\apilot\agent\_work\2\s\engine\lotus\cmake\external\onnx\onnx\defs\controlflow\old.cc
C:\apilot\agent\_work\2\s\engine\lotus\cmake\external\onnx\onnx\defs\generator\defs.cc
C:\apilot\agent\_work\2\s\engine\lotus\cmake\external\onnx\onnx\defs\generator\old.cc
C:\apilot\agent\_work\2\s\engine\lotus\cmake\external\onnx\onnx\defs\logical\defs.cc
C:\apilot\agent\_work\2\s\engine\lotus\cmake\external\onnx\onnx\defs\logical\old.cc
C:\apilot\agent\_work\2\s\engine\lotus\cmake\external\onnx\onnx\defs\math\defs.cc
C:\apilot\agent\_work\2\s\engine\lotus\cmake\external\onnx\onnx\defs\math\old.cc
C:\apilot\agent\_work\2\s\engine\lotus\cmake\external\onnx\onnx\defs\nn\defs.cc
C:\apilot\agent\_work\2\s\engine\lotus\cmake\external\onnx\onnx\defs\nn\old.cc
C:\apilot\agent\_work\2\s\engine\lotus\cmake\external\onnx\onnx\defs\object_detection\defs.cc
C:\apilot\agent\_work\2\s\engine\lotus\cmake\external\onnx\onnx\defs\quantization\defs.cc
C:\apilot\agent\_work\2\s\engine\lotus\cmake\external\onnx\onnx\defs\reduction\defs.cc
C:\apilot\agent\_work\2\s\engine\lotus\cmake\external\onnx\onnx\defs\rnn\defs.cc
C:\apilot\agent\_work\2\s\engine\lotus\cmake\external\onnx\onnx\defs\rnn\old.cc
C:\apilot\agent\_work\2\s\engine\lotus\cmake\external\onnx\onnx\defs\tensor\defs.cc
C:\apilot\agent\_work\2\s\engine\lotus\cmake\external\onnx\onnx\defs\tensor\old.cc
C:\apilot\agent\_work\2\s\engine\lotus\cmake\external\onnx\onnx\defs\traditionalml\defs.cc
C:\apilot\agent\_work\2\s\engine\lotus\cmake\external\onnx\onnx\defs\traditionalml\old.cc
C:\apilot\agent\_work\2\s\engine\lotus\cmake\external\protobuf\src\google\protobuf\arena.cc
C:\apilot\agent\_work\2\s\engine\lotus\cmake\external\protobuf\src\google\protobuf\generated_message_util.cc
C:\apilot\agent\_work\2\s\engine\lotus\cmake\external\protobuf\src\google\protobuf\io\coded_stream.cc
C:\apilot\agent\_work\2\s\engine\lotus\cmake\external\protobuf\src\google\protobuf\io\zero_copy_stream.cc
C:\apilot\agent\_work\2\s\engine\lotus\cmake\external\protobuf\src\google\protobuf\io\zero_copy_stream_impl_lite.cc
C:\apilot\agent\_work\2\s\engine\lotus\cmake\external\protobuf\src\google\protobuf\message_lite.cc
C:\apilot\agent\_work\2\s\engine\lotus\cmake\external\protobuf\src\google\protobuf\repeated_field.cc
C:\apilot\agent\_work\2\s\engine\lotus\cmake\external\protobuf\src\google\protobuf\wire_format_lite.cc
C:\apilot\agent\_work\2\s\engine\lotus\cmake\external\re2\re2/walker-inl.h
C:\apilot\agent\_work\2\s\engine\lotus\cmake\external\re2\re2\bitstate.cc
C:\apilot\agent\_work\2\s\engine\lotus\cmake\external\re2\re2\compile.cc
C:\apilot\agent\_work\2\s\engine\lotus\cmake\external\re2\re2\dfa.cc
C:\apilot\agent\_work\2\s\engine\lotus\cmake\external\re2\re2\nfa.cc
C:\apilot\agent\_work\2\s\engine\lotus\cmake\external\re2\re2\onepass.cc
C:\apilot\agent\_work\2\s\engine\lotus\cmake\external\re2\re2\parse.cc
C:\apilot\agent\_work\2\s\engine\lotus\cmake\external\re2\re2\prog.cc
C:\apilot\agent\_work\2\s\engine\lotus\cmake\external\re2\re2\re2.cc
C:\apilot\agent\_work\2\s\engine\lotus\cmake\external\re2\re2\regexp.cc
C:\apilot\agent\_work\2\s\engine\lotus\cmake\external\re2\re2\simplify.cc
C:\apilot\agent\_work\2\s\engine\lotus\cmake\external\re2\re2\tostring.cc
C:\apilot\agent\_work\2\s\engine\lotus\include\onnxruntime\core/common/const_pointer_container.h
C:\apilot\agent\_work\2\s\engine\lotus\include\onnxruntime\core/framework/data_types.h
C:\apilot\agent\_work\2\s\engine\lotus\include\onnxruntime\core/framework/ml_value.h
C:\apilot\agent\_work\2\s\engine\lotus\include\onnxruntime\core/framework/op_kernel.h
C:\apilot\agent\_work\2\s\engine\lotus\include\onnxruntime\core/framework/tensor.h
C:\apilot\agent\_work\2\s\engine\lotus\include\onnxruntime\core/graph/graph.h
C:\apilot\agent\_work\2\s\engine\lotus\onnxruntime\contrib_ops\cpu\attnlstm\bahdanau_attention.cc
C:\apilot\agent\_work\2\s\engine\lotus\onnxruntime\contrib_ops\cpu\attnlstm\deep_cpu_attn_lstm.cc
C:\apilot\agent\_work\2\s\engine\lotus\onnxruntime\contrib_ops\cpu\attnlstm\deep_cpu_attn_lstm.h
C:\apilot\agent\_work\2\s\engine\lotus\onnxruntime\contrib_ops\cpu\element_wise_exp_ops.h
C:\apilot\agent\_work\2\s\engine\lotus\onnxruntime\contrib_ops\cpu\expand_dims.h
C:\apilot\agent\_work\2\s\engine\lotus\onnxruntime\contrib_ops\cpu\gather_nd.cc
C:\apilot\agent\_work\2\s\engine\lotus\onnxruntime\contrib_ops\cpu\image_scaler.h
C:\apilot\agent\_work\2\s\engine\lotus\onnxruntime\contrib_ops\cpu\maxpool_with_mask.h
C:\apilot\agent\_work\2\s\engine\lotus\onnxruntime\contrib_ops\cpu\murmur_hash3.cc
C:\apilot\agent\_work\2\s\engine\lotus\onnxruntime\contrib_ops\cpu\pad.cc
C:\apilot\agent\_work\2\s\engine\lotus\onnxruntime\contrib_ops\cpu\tokenizer.cc
C:\apilot\agent\_work\2\s\engine\lotus\onnxruntime\core/framework/bfc_arena.h
C:\apilot\agent\_work\2\s\engine\lotus\onnxruntime\core/framework/execution_frame.h
C:\apilot\agent\_work\2\s\engine\lotus\onnxruntime\core/framework/execution_providers.h
C:\apilot\agent\_work\2\s\engine\lotus\onnxruntime\core/framework/func_kernel.h
C:\apilot\agent\_work\2\s\engine\lotus\onnxruntime\core/framework/node_index_info.h
C:\apilot\agent\_work\2\s\engine\lotus\onnxruntime\core/framework/ort_value_tensor_slicer.h
C:\apilot\agent\_work\2\s\engine\lotus\onnxruntime\core/optimizer/initializer.h
C:\apilot\agent\_work\2\s\engine\lotus\onnxruntime\core/providers/common.h
C:\apilot\agent\_work\2\s\engine\lotus\onnxruntime\core/providers/cpu/controlflow/if.h
C:\apilot\agent\_work\2\s\engine\lotus\onnxruntime\core/providers/cpu/controlflow/loop.h
C:\apilot\agent\_work\2\s\engine\lotus\onnxruntime\core/providers/cpu/controlflow/scan_utils.h
C:\apilot\agent\_work\2\s\engine\lotus\onnxruntime\core/providers/cpu/generator/random.h
C:\apilot\agent\_work\2\s\engine\lotus\onnxruntime\core/providers/cpu/math/clip.h
C:\apilot\agent\_work\2\s\engine\lotus\onnxruntime\core/providers/cpu/math/element_wise_ops.h
C:\apilot\agent\_work\2\s\engine\lotus\onnxruntime\core/providers/cpu/math/gemm.h
C:\apilot\agent\_work\2\s\engine\lotus\onnxruntime\core/providers/cpu/math/matmul_helper.h
C:\apilot\agent\_work\2\s\engine\lotus\onnxruntime\core/providers/cpu/ml/cast_map.h
C:\apilot\agent\_work\2\s\engine\lotus\onnxruntime\core/providers/cpu/ml/category_mapper.h
C:\apilot\agent\_work\2\s\engine\lotus\onnxruntime\core/providers/cpu/ml/dictvectorizer.h
C:\apilot\agent\_work\2\s\engine\lotus\onnxruntime\core/providers/cpu/ml/feature_vectorizer.h
C:\apilot\agent\_work\2\s\engine\lotus\onnxruntime\core/providers/cpu/ml/label_encoder.h
C:\apilot\agent\_work\2\s\engine\lotus\onnxruntime\core/providers/cpu/ml/ml_common.h
C:\apilot\agent\_work\2\s\engine\lotus\onnxruntime\core/providers/cpu/ml/normalizer.h
C:\apilot\agent\_work\2\s\engine\lotus\onnxruntime\core/providers/cpu/ml/svmclassifier.h
C:\apilot\agent\_work\2\s\engine\lotus\onnxruntime\core/providers/cpu/nn/autopad_type.h
C:\apilot\agent\_work\2\s\engine\lotus\onnxruntime\core/providers/cpu/nn/batch_norm.h
C:\apilot\agent\_work\2\s\engine\lotus\onnxruntime\core/providers/cpu/nn/conv_base.h
C:\apilot\agent\_work\2\s\engine\lotus\onnxruntime\core/providers/cpu/nn/flatten.h
C:\apilot\agent\_work\2\s\engine\lotus\onnxruntime\core/providers/cpu/nn/instance_norm.h
C:\apilot\agent\_work\2\s\engine\lotus\onnxruntime\core/providers/cpu/nn/lp_norm.h
C:\apilot\agent\_work\2\s\engine\lotus\onnxruntime\core/providers/cpu/nn/lrn.h
C:\apilot\agent\_work\2\s\engine\lotus\onnxruntime\core/providers/cpu/nn/pool_base.h
C:\apilot\agent\_work\2\s\engine\lotus\onnxruntime\core/providers/cpu/nn/roi_pool.h
C:\apilot\agent\_work\2\s\engine\lotus\onnxruntime\core/providers/cpu/nn/shrink.h
C:\apilot\agent\_work\2\s\engine\lotus\onnxruntime\core/providers/cpu/nn/unpool.h
C:\apilot\agent\_work\2\s\engine\lotus\onnxruntime\core/providers/cpu/reduction/reduction_ops.h
C:\apilot\agent\_work\2\s\engine\lotus\onnxruntime\core/providers/cpu/rnn/deep_cpu_gru.h
C:\apilot\agent\_work\2\s\engine\lotus\onnxruntime\core/providers/cpu/rnn/deep_cpu_lstm.h
C:\apilot\agent\_work\2\s\engine\lotus\onnxruntime\core/providers/cpu/rnn/rnn.h
C:\apilot\agent\_work\2\s\engine\lotus\onnxruntime\core/providers/cpu/rnn/rnn_helpers.h
C:\apilot\agent\_work\2\s\engine\lotus\onnxruntime\core/providers/cpu/tensor/concat.h
C:\apilot\agent\_work\2\s\engine\lotus\onnxruntime\core/providers/cpu/tensor/gather.h
C:\apilot\agent\_work\2\s\engine\lotus\onnxruntime\core/providers/cpu/tensor/identity_op.h
C:\apilot\agent\_work\2\s\engine\lotus\onnxruntime\core/providers/cpu/tensor/mean_variance_normalization.h
C:\apilot\agent\_work\2\s\engine\lotus\onnxruntime\core/providers/cpu/tensor/pad.h
C:\apilot\agent\_work\2\s\engine\lotus\onnxruntime\core/providers/cpu/tensor/reshape.h
C:\apilot\agent\_work\2\s\engine\lotus\onnxruntime\core/providers/cpu/tensor/slice.h
C:\apilot\agent\_work\2\s\engine\lotus\onnxruntime\core/providers/cpu/tensor/space_depth_ops.h
C:\apilot\agent\_work\2\s\engine\lotus\onnxruntime\core/providers/cpu/tensor/split.h
C:\apilot\agent\_work\2\s\engine\lotus\onnxruntime\core/providers/cpu/tensor/squeeze.h
C:\apilot\agent\_work\2\s\engine\lotus\onnxruntime\core/providers/cpu/tensor/transpose.h
C:\apilot\agent\_work\2\s\engine\lotus\onnxruntime\core/providers/cpu/tensor/unsqueeze.h
C:\apilot\agent\_work\2\s\engine\lotus\onnxruntime\core/providers/cpu/tensor/upsample.h
C:\apilot\agent\_work\2\s\engine\lotus\onnxruntime\core/providers/cpu/tensor/utils.h
C:\apilot\agent\_work\2\s\engine\lotus\onnxruntime\core/util/math.h
C:\apilot\agent\_work\2\s\engine\lotus\onnxruntime\core\common\profiler.cc
C:\apilot\agent\_work\2\s\engine\lotus\onnxruntime\core\common\status.cc
C:\apilot\agent\_work\2\s\engine\lotus\onnxruntime\core\common\task_thread_pool.h
C:\apilot\agent\_work\2\s\engine\lotus\onnxruntime\core\framework\allocation_planner.cc
C:\apilot\agent\_work\2\s\engine\lotus\onnxruntime\core\framework\bfc_arena.cc
C:\apilot\agent\_work\2\s\engine\lotus\onnxruntime\core\framework\data_transfer.cc
C:\apilot\agent\_work\2\s\engine\lotus\onnxruntime\core\framework\data_types.cc
C:\apilot\agent\_work\2\s\engine\lotus\onnxruntime\core\framework\environment.cc
C:\apilot\agent\_work\2\s\engine\lotus\onnxruntime\core\framework\ex_lib_loader.cc
C:\apilot\agent\_work\2\s\engine\lotus\onnxruntime\core\framework\execution_frame.cc
C:\apilot\agent\_work\2\s\engine\lotus\onnxruntime\core\framework\execution_provider.cc
C:\apilot\agent\_work\2\s\engine\lotus\onnxruntime\core\framework\feeds_fetches_manager.cc
C:\apilot\agent\_work\2\s\engine\lotus\onnxruntime\core\framework\graph_partitioner.cc
C:\apilot\agent\_work\2\s\engine\lotus\onnxruntime\core\framework\kernel_registry.cc
C:\apilot\agent\_work\2\s\engine\lotus\onnxruntime\core\framework\mldata_type_utils.cc
C:\apilot\agent\_work\2\s\engine\lotus\onnxruntime\core\framework\mlvalue_tensor_slicer.cc
C:\apilot\agent\_work\2\s\engine\lotus\onnxruntime\core\framework\node_index_info.cc
C:\apilot\agent\_work\2\s\engine\lotus\onnxruntime\core\framework\op_kernel.cc
C:\apilot\agent\_work\2\s\engine\lotus\onnxruntime\core\framework\op_kernel_info.cc
C:\apilot\agent\_work\2\s\engine\lotus\onnxruntime\core\framework\op_node_proto_helper.cc
C:\apilot\agent\_work\2\s\engine\lotus\onnxruntime\core\framework\parallel_executor.cc
C:\apilot\agent\_work\2\s\engine\lotus\onnxruntime\core\framework\sequential_executor.cc
C:\apilot\agent\_work\2\s\engine\lotus\onnxruntime\core\framework\session_state.cc
C:\apilot\agent\_work\2\s\engine\lotus\onnxruntime\core\framework\session_state_initializer.cc
C:\apilot\agent\_work\2\s\engine\lotus\onnxruntime\core\framework\tensor.cc
C:\apilot\agent\_work\2\s\engine\lotus\onnxruntime\core\framework\tensor_shape.cc
C:\apilot\agent\_work\2\s\engine\lotus\onnxruntime\core\framework\utils.cc
C:\apilot\agent\_work\2\s\engine\lotus\onnxruntime\core\graph\contrib_ops\contrib_defs.cc
C:\apilot\agent\_work\2\s\engine\lotus\onnxruntime\core\graph\function.cc
C:\apilot\agent\_work\2\s\engine\lotus\onnxruntime\core\graph\graph.cc
C:\apilot\agent\_work\2\s\engine\lotus\onnxruntime\core\graph\graph_utils.cc
C:\apilot\agent\_work\2\s\engine\lotus\onnxruntime\core\optimizer\constant_folding.cc
C:\apilot\agent\_work\2\s\engine\lotus\onnxruntime\core\optimizer\graph_transformer_utils.cc
C:\apilot\agent\_work\2\s\engine\lotus\onnxruntime\core\optimizer\optimizer_execution_frame.cc
C:\apilot\agent\_work\2\s\engine\lotus\onnxruntime\core\optimizer\transformer_memcpy.cc
C:\apilot\agent\_work\2\s\engine\lotus\onnxruntime\core\platform\windows\env.cc
C:\apilot\agent\_work\2\s\engine\lotus\onnxruntime\core\providers\cpu\controlflow\if.cc
C:\apilot\agent\_work\2\s\engine\lotus\onnxruntime\core\providers\cpu\controlflow\loop.cc
C:\apilot\agent\_work\2\s\engine\lotus\onnxruntime\core\providers\cpu\controlflow\scan_8.cc
C:\apilot\agent\_work\2\s\engine\lotus\onnxruntime\core\providers\cpu\controlflow\scan_9.cc
C:\apilot\agent\_work\2\s\engine\lotus\onnxruntime\core\providers\cpu\controlflow\scan_utils.cc
C:\apilot\agent\_work\2\s\engine\lotus\onnxruntime\core\providers\cpu\generator\constant_of_shape.cc
C:\apilot\agent\_work\2\s\engine\lotus\onnxruntime\core\providers\cpu\generator\random.cc
C:\apilot\agent\_work\2\s\engine\lotus\onnxruntime\core\providers\cpu\math\element_wise_ops.cc
C:\apilot\agent\_work\2\s\engine\lotus\onnxruntime\core\providers\cpu\math\gemm_helper.h
C:\apilot\agent\_work\2\s\engine\lotus\onnxruntime\core\providers\cpu\math\matmul_integer.cc
C:\apilot\agent\_work\2\s\engine\lotus\onnxruntime\core\providers\cpu\math\quantize_linear_matmul.cc
C:\apilot\agent\_work\2\s\engine\lotus\onnxruntime\core\providers\cpu\math\top_k.cc
C:\apilot\agent\_work\2\s\engine\lotus\onnxruntime\core\providers\cpu\ml\cast_map.cc
C:\apilot\agent\_work\2\s\engine\lotus\onnxruntime\core\providers\cpu\ml\feature_vectorizer.cc
C:\apilot\agent\_work\2\s\engine\lotus\onnxruntime\core\providers\cpu\ml\imputer.cc
C:\apilot\agent\_work\2\s\engine\lotus\onnxruntime\core\providers\cpu\ml\linearclassifier.cc
C:\apilot\agent\_work\2\s\engine\lotus\onnxruntime\core\providers\cpu\ml\linearregressor.cc
C:\apilot\agent\_work\2\s\engine\lotus\onnxruntime\core\providers\cpu\ml\ml_common.h
C:\apilot\agent\_work\2\s\engine\lotus\onnxruntime\core\providers\cpu\ml\normalizer.cc
C:\apilot\agent\_work\2\s\engine\lotus\onnxruntime\core\providers\cpu\ml\onehotencoder.cc
C:\apilot\agent\_work\2\s\engine\lotus\onnxruntime\core\providers\cpu\ml\scaler.cc
C:\apilot\agent\_work\2\s\engine\lotus\onnxruntime\core\providers\cpu\ml\svmclassifier.cc
C:\apilot\agent\_work\2\s\engine\lotus\onnxruntime\core\providers\cpu\ml\svmclassifier.h
C:\apilot\agent\_work\2\s\engine\lotus\onnxruntime\core\providers\cpu\ml\svmregressor.cc
C:\apilot\agent\_work\2\s\engine\lotus\onnxruntime\core\providers\cpu\ml\tree_ensemble_classifier.cc
C:\apilot\agent\_work\2\s\engine\lotus\onnxruntime\core\providers\cpu\ml\treeregressor.cc
C:\apilot\agent\_work\2\s\engine\lotus\onnxruntime\core\providers\cpu\ml\zipmap.cc
C:\apilot\agent\_work\2\s\engine\lotus\onnxruntime\core\providers\cpu\nn\conv_transpose.cc
C:\apilot\agent\_work\2\s\engine\lotus\onnxruntime\core\providers\cpu\nn\lrn.cc
C:\apilot\agent\_work\2\s\engine\lotus\onnxruntime\core\providers\cpu\nn\pool.cc
C:\apilot\agent\_work\2\s\engine\lotus\onnxruntime\core\providers\cpu\nn\qlinearconv.cc
C:\apilot\agent\_work\2\s\engine\lotus\onnxruntime\core\providers\cpu\nn\roi_pool.cc
C:\apilot\agent\_work\2\s\engine\lotus\onnxruntime\core\providers\cpu\nn\shrink.cc
C:\apilot\agent\_work\2\s\engine\lotus\onnxruntime\core\providers\cpu\nn\string_normalizer.cc
C:\apilot\agent\_work\2\s\engine\lotus\onnxruntime\core\providers\cpu\nn\tfidfvectorizer.cc
C:\apilot\agent\_work\2\s\engine\lotus\onnxruntime\core\providers\cpu\nn\Unpool.cc
C:\apilot\agent\_work\2\s\engine\lotus\onnxruntime\core\providers\cpu\object_detection\non_max_suppression.cc
C:\apilot\agent\_work\2\s\engine\lotus\onnxruntime\core\providers\cpu\object_detection\non_max_suppression.h
C:\apilot\agent\_work\2\s\engine\lotus\onnxruntime\core\providers\cpu\object_detection\roialign.h
C:\apilot\agent\_work\2\s\engine\lotus\onnxruntime\core\providers\cpu\reduction\reduction_ops.cc
C:\apilot\agent\_work\2\s\engine\lotus\onnxruntime\core\providers\cpu\rnn\deep_cpu_gru.cc
C:\apilot\agent\_work\2\s\engine\lotus\onnxruntime\core\providers\cpu\rnn\deep_cpu_lstm.cc
C:\apilot\agent\_work\2\s\engine\lotus\onnxruntime\core\providers\cpu\rnn\rnn_helpers.cc
C:\apilot\agent\_work\2\s\engine\lotus\onnxruntime\core\providers\cpu\tensor\cast_op.cc
C:\apilot\agent\_work\2\s\engine\lotus\onnxruntime\core\providers\cpu\tensor\compress.cc
C:\apilot\agent\_work\2\s\engine\lotus\onnxruntime\core\providers\cpu\tensor\concat.cc
C:\apilot\agent\_work\2\s\engine\lotus\onnxruntime\core\providers\cpu\tensor\eye_like.cc
C:\apilot\agent\_work\2\s\engine\lotus\onnxruntime\core\providers\cpu\tensor\isinf.cc
C:\apilot\agent\_work\2\s\engine\lotus\onnxruntime\core\providers\cpu\tensor\nonzero_op.cc
C:\apilot\agent\_work\2\s\engine\lotus\onnxruntime\core\providers\cpu\tensor\pad.cc
C:\apilot\agent\_work\2\s\engine\lotus\onnxruntime\core\providers\cpu\tensor\quantize_linear.cc
C:\apilot\agent\_work\2\s\engine\lotus\onnxruntime\core\providers\cpu\tensor\reshape_helper.h
C:\apilot\agent\_work\2\s\engine\lotus\onnxruntime\core\providers\cpu\tensor\reverse_sequence.cc
C:\apilot\agent\_work\2\s\engine\lotus\onnxruntime\core\providers\cpu\tensor\reverse_sequence.h
C:\apilot\agent\_work\2\s\engine\lotus\onnxruntime\core\providers\cpu\tensor\scatter.cc
C:\apilot\agent\_work\2\s\engine\lotus\onnxruntime\core\providers\cpu\tensor\slice.cc
C:\apilot\agent\_work\2\s\engine\lotus\onnxruntime\core\providers\cpu\tensor\space_depth_ops.cc
C:\apilot\agent\_work\2\s\engine\lotus\onnxruntime\core\providers\cpu\tensor\split.cc
C:\apilot\agent\_work\2\s\engine\lotus\onnxruntime\core\providers\cpu\tensor\tile.cc
C:\apilot\agent\_work\2\s\engine\lotus\onnxruntime\core\providers\cpu\tensor\transpose.cc
C:\apilot\agent\_work\2\s\engine\lotus\onnxruntime\core\providers\cpu\tensor\unsqueeze.cc
C:\apilot\agent\_work\2\s\engine\lotus\onnxruntime\core\providers\cpu\tensor\upsample.cc
C:\apilot\agent\_work\2\s\engine\lotus\onnxruntime\core\providers\cpu\tensor\where_op.cc
C:\apilot\agent\_work\2\s\engine\lotus\onnxruntime\core\session\inference_session.cc
C:\apilot\agent\_work\2\s\engine\lotus\onnxruntime\core\util\protobuf_parsing_utils.cc
C:\apilot\agent\_work\2\s\engine\OperatorAuthorHelper\MLOperatorAuthorHelper.h
C:\apilot\agent\_work\2\s\engine\OperatorAuthorHelper\OperatorHelper.cpp
C:\apilot\agent\_work\2\s\engine\OperatorAuthorHelper\OperatorHelper.h
C:\apilot\agent\_work\2\s\graph\DML\GraphCompiler.cpp
C:\apilot\agent\_work\2\s\graph\DML\OpaqueOperationDesc.cpp
C:\apilot\agent\_work\2\s\packages\Microsoft.Windows.Wil.Internal.0.2.46\inc\wil\opensource/wil/wrl.h
C:\apilot\agent\_work\2\s\packages\Microsoft.Windows.Wil.Internal.0.2.46\inc\wil\opensource\wil\resource.h
C:\apilot\agent\_work\2\s\winml\common\DeviceHelpers.cpp
C:\apilot\agent\_work\2\s\winml\dll\D3DDeviceCache.cpp
C:\apilot\agent\_work\2\s\winml\dll\FeatureCompatibility.h
C:\apilot\agent\_work\2\s\winml\dll\ImageConversionHelpers.cpp
C:\apilot\agent\_work\2\s\winml\dll\ImageConverter.cpp
C:\apilot\agent\_work\2\s\winml\dll\ImageFeatureValue.cpp
C:\apilot\agent\_work\2\s\winml\dll\LearningModel.cpp
C:\apilot\agent\_work\2\s\winml\dll\LearningModelBinding.cpp
C:\apilot\agent\_work\2\s\winml\dll\LearningModelDevice.cpp
C:\apilot\agent\_work\2\s\winml\dll\LearningModelSession.cpp
C:\apilot\agent\_work\2\s\winml\dll\MapBase.h
C:\apilot\agent\_work\2\s\winml\dll\MLOperatorAuthorImpl.cpp
C:\apilot\agent\_work\2\s\winml\dll\MLOperatorAuthorImpl.h
C:\apilot\agent\_work\2\s\winml\dll\module.cpp
C:\apilot\agent\_work\2\s\winml\dll\SequenceBase.h
C:\apilot\agent\_work\2\s\winml\dll\TelemetryEvent.cpp
C:\apilot\agent\_work\2\s\winml\dll\TensorBase.h
C:\apilot\agent\_work\2\s\winml\dll\TensorBaseHelpers.h
C:\apilot\agent\_work\2\s\winml\dll\TensorBuffer.h
C:\apilot\agent\_work\2\s\winml\dll\TensorToVideoFrameConverter.cpp
C:\apilot\agent\_work\2\s\winml\dll\VideoFrameToTensorConverter.cpp
C:\apilot\agent\_work\2\s\winml\lib\Core\CpuOrtSessionBuilder.cpp
C:\apilot\agent\_work\2\s\winml\lib\Core\DmlOrtSessionBuilder.cpp
C:\apilot\agent\_work\2\s\winml\lib\Core\FeatureDescriptorFactory.cpp
C:\apilot\agent\_work\2\s\winml\lib\Core\ModelInfo.cpp
C:\apilot\agent\_work\2\s\winml\lib\Core\ZeroCopyInputStreamWrapper.cpp
C;_,|
C\+CX
C\+CXQ
C++/WinRT version:2.0.190605.7
c->in_use() && (c->bin_num == kInvalidBinNum)
C0a0m0r0~0
C0f0#1F1
C0PRj
c0v1S3
C0VWP
c2->prev == h1
C4+C0
C8;C<tF
C8;C<tN
C89SL|,
CalculateNodeIndexInfo must be called prior to GetExecutionInfo.
callContext
CallContext:[%hs] 
calloc
cAMDt
Can not digest separators: 
Can not digest tokenexp: 
Can not find the execution provider 
Can not find the node 
Can not get shape initializer data!
Canadian_Aboriginal
Cannot allocate buffer larger than kint32max for 
Cannot concatenate scalars
Cannot creat GPU tensor on CPU device
cannot find allocator
Cannot slice scalars
Cannot split using values in 'split' attribute. Axis=
Cannot use SearchOnePass for unanchored matches.
Can't 
Can't merge shape info. Both source and target dimension have values but they differ. Source=
Can't slice a non-tensor OrtValue. Type was 
Can't use func with null ptr
Carian
Carries out batch normalization as described in the paper
Case not handled in ComputeSimple: 
case where axis=1, this means the input tensor will be coerced into a 2D tensor
case_change_action
cast node to cast from float16 to float32 on cpu
Cast op must have 'to' argument of type DataType
cast_to
CastDef_%d
CastFloat16Transformer
Casting to and from strings is not supported yet.
CastMap
Category
CategoryMapper
cats_int64s
cats_strings
Caucasian_Albanian
Caught exception while destructing CustomOpsLoader with message: 
Caught exception while loading custom ops with message: 
CD+C@
CD+K4+C@
ceil_mode
Cell clip threshold. Clipping bounds the elements of a tensor in the range of [-threshold, +threshold] and is applied to the input of activations. No clip if not specified.
CellMemInitTensor
CellMemoryMinusOneTensor
CellMemoryTensor
center_point_box
center_point_box only support 0 or 1
Ch+Cd
Ch+Cdj
CH0X,
Chakma
Channel order changed for fused conversion
ChannelCount
Char embedding size does not match char_embedding_size attribute.
Char embedding size does not match conv kernal size 2.
char_embedding_size
CHECK failed: !coded_out.HadError(): 
CHECK failed: !is_closed_: 
CHECK failed: (backup_bytes_) == (0): 
CHECK failed: (buffer_size) >= (0): 
CHECK failed: (byte_size_before_serialization) == (byte_size_after_serialization): 
CHECK failed: (bytes_produced_by_serialization) == (byte_size_before_serialization): 
CHECK failed: (count) <= (buffer_used_): 
CHECK failed: (count) <= (last_returned_size_): 
CHECK failed: (count) <= (target_->size()): 
CHECK failed: (count) >= (0): 
CHECK failed: (last_returned_size_) > (0): 
CHECK failed: (min_bytes) <= (std::numeric_limits<size_t>::max() - kBlockHeaderSize): 
CHECK failed: (new_size) <= ((std::numeric_limits<size_t>::max() - kRepHeaderSize) / sizeof(old_rep->elements[0])): 
CHECK failed: (scc->visit_status.load(std::memory_order_relaxed)) == (SCCInfoBase::kRunning): 
CHECK failed: (value.size()) <= (kint32max): 
CHECK failed: backup_bytes_ == 0 && buffer_.get() != NULL: 
CHECK failed: target_ != NULL: 
checks.input_copy_needed != DeviceCopyCheck::Unknown && checks.output_copy_needed != DeviceCopyCheck::Unknown
checksum
Cherokee
Child node if expression is false
Child node if expression is false.
Child node if expression is true
Child node if expression is true.
Chosen support vectors
CL+CH
Class labels if using integer labels.<br>One and only one of the 'classlabels_*' attributes must be defined.
Class labels if using string labels.<br>One and only one of the 'classlabels_*' attributes must be defined.
Class labels when using integer labels. One and only one 'classlabels' attribute must be defined.
Class labels when using string labels. One and only one 'classlabels' attribute must be defined.
Class scores (one per class per example), if prob_a and prob_b are provided they are probabilities for each class, otherwise they are raw scores.
class_ids
class_nodeids
class_nodeids_.size() == class_ids_.size()
class_nodeids_.size() == class_weights_.size()
class_treeids
class_weights
classes_strings
Classification outputs (one class per example).
Classification scores ([N,E] - one score for each class and example
classlabels_int64s
classlabels_ints
classlabels_strings
classlabels_strings_.empty() ^ classlabels_int64s_.empty()
classlabels_strings_.size() > 0 || classlabels_ints_.size() > 0
clip_ > 0.f
ClipThreshold
close() failed: 
CloseHandle
CloseThreadpoolWork
CoalesceWalker::ShortVisit called
CoCreateFreeThreadedMarshaler
CoCreateGuid
code != static_cast<int>(MLStatus::OK)
Coefficient of ELU default to 1.0.
Coefficient of ELU.
Coefficient of leakage default to 0.01.
Coefficient of leakage.
Coefficient of SELU default to 1.0507.
Coefficient of SELU default to 1.05070102214813232421875 (i.e., float32 approximation of 1.0507009873554804934193349852946).
Coefficient of SELU default to 1.6732.
Coefficient of SELU default to 1.67326319217681884765625 (i.e., float32 approximation of 1.6732632423543772848170429916717).
coefficients
coefficients_.size() > 0
coerced into one. For an arbitrary n-dimensional tensor
CoIncrementMTAUsage
colorspacegamma
com.microsoft
Common
CompanyName
CompareStringEx
Compatible layouts
Compiler::Copy called!
Complex128
complex128
Complex64
complex64
Compress
computation if attribute transA is non-zero, same for B and transB.
Compute failed for node: 
Compute Y = alpha * A' * B' + beta * C, where input tensor A has shape (M, K) or (K, M),
Compute_
Computes an one-layer GRU. This operator is usually supported via some custom
Computes an one-layer LSTM. This operator is usually supported via some
Computes an one-layer simple RNN. This operator is usually supported
Computes the {name} of the input tensor's element along the provided axes. The resulted
Computes the indices of the {name} elements of the input tensor's element along the 
computes the output.
Concat
Concat of 
concat_result
Concatenated tensor
condition
condition && X && Y
Condition for the if
condition, X, and Y inputs are required!
ConditionTensor
connection aborted
connection already in progress
connection refused
connection reset
constant
Constant
ConstantFill
ConstantFolding
ConstantOfShape
Constrain bias type to 32-bit integer tensor.
Constrain filter type to 8-bit integer tensor.
Constrain index tensor to int64
Constrain indice type to int32 or int64
Constrain indices to integer types
Constrain input a and its zero point data type to 8-bit integer tensor.
Constrain input A data type to 8-bit integer tensor.
Constrain input and output  types to float tensors.
Constrain input and output to all tensor types.
Constrain input and output types to all numeric tensors.
Constrain input and output types to all tensor types.
Constrain input and output types to all tensors.
Constrain input and output types to any tensor type.
Constrain input and output types to float tensors
Constrain input and output types to float tensors.
Constrain input and output types to float/int tensors.
Constrain input and output types to high-precision numeric tensors.
Constrain input and output types to signed numeric tensors.
Constrain input and output types.
Constrain input b and its zero point data type to 8-bit integer tensor.
Constrain input B data type to 8-bit integer tensor.
Constrain input type to 8-bit integer tensor.
Constrain input type to unsigned or signed 32-bit integer tensor, or string tensor. It should be utf-8 encoded if using unicode.
Constrain input types to float tensors.
Constrain input types.
Constrain input types. Casting from complex is not supported.
Constrain input types. Casting from strings and complex are not supported.
Constrain input types. Strings and complex are not supported.
Constrain input w and its zero point data type to 8-bit integer tensor.
Constrain input x and its zero point data type to 8-bit integer tensor.
Constrain input 'X' and output 'Y' to all tensor types.
Constrain input0 and output types to float tensors
Constrain output data type to 32-bit integer tensor.T2 must be tensor(uint32) when T1 is tensor(uint8),or must be tensor(int32) when T1 is tensor(int8).
Constrain output mask types to boolean tensors.
Constrain output to int64 tensor, which should be a scalar though.
Constrain output to int64 tensor.
Constrain output type to 8-bit integer tensor.
Constrain output type to unsigned and signed 32-bit integer tensor.
Constrain output types to any tensor type.
Constrain output types to be numerics.
Constrain output types to bool, int32, int64, float16, float, double tensors.
Constrain output types to boolean tensors.
Constrain output types to float tensors.
Constrain output types to integral tensors.
Constrain output types. Casting to complex is not supported.
Constrain output types. Casting to strings and complex are not supported.
Constrain output types. Strings and complex are not supported.
Constrain output y and its zero point data type to 8-bit integer tensor.
Constrain output Y data type as 32-bit integer tensor.
Constrain output y data type to 32-bit integer tensor.
Constrain repeat's type to int64 tensors.
Constrain seq_lens to integer tensor.
Constrain seq_lens to integral tensors.
Constrain tiles and axis's type to int64 tensors.
Constrain to all tensor types.
Constrain to any tensor type.
Constrain to any tensor type. If the dtype attribute is not provided this must be a valid output type.
Constrain to boolean tensors.
Constrain to tensor(float).
Constrain to tensor(int32).
Constrain types to float tensors.
Constrain types to int tensors.
Constrain 'x' to float or int32 tensor.
Constrain 'x', 'y_scale' to float tensors.
Constrain 'x_zero_point' and 'x' to 8-bit integer tensors.
Constrain 'x_zero_point' and 'x' to 8-bit/32-bit integer tensor.
Constrain 'y', 'x_scale' to float tensors.
Constrain 'y_zero_point' and 'y' to 8-bit integer tensor.
Constrain 'y_zero_point' and 'y' to 8-bit integer tensors.
Constrains input to boolean tensor.
Constrains input to float tensors.
Constrains input to integral tensors.
Constrains input to only numeric types.
Constrains input types to all numeric tensors.
Constrains input/output to boolean tensors.
Constrains output to boolean tensor.
Constrains to boolean tensors.
consumed_inputs
context does not contain text
context.GetTempSpaceAllocator(&allocator_).IsOK()
Conv filter size does not match embedding_size attribute.
Conv kernal size 1 does not match conv_window_size attribute .
conv_window_size
ConvActivationFusion
ConvAddFusion
ConvBNFusion
Conversion Error
Convert
ConvertCPUTensorToVideoFrameWithSoftwareBitmap
ConvertVideoFrameWithSoftwareBitmapToCPUTensor
ConvInteger
ConvMulFusion
ConvTranspose
Coptic
Copy from/to host memory
copy of the input. Note that our implementation of Dropout does scaling in
copy_info.size() == num_feeds
copy_to_new_fetches_cached_values.size() == num_outputs
corrupted protobuf data: tensor shape size(
CoTaskMemAlloc
CoTaskMemFree
Could not create kernel for node: 
Could not find an implementation for the node 
Could not find chunk in bin
Could not find OrtValue with name '
Could not find Region for 
Could not infer data type from input tensor with data type 
Could not write a profile because no model was loaded.
count
count_include_pad
counts
Couple the input and forget gates if 1, default 0.
Couple the input and forget gates if 1.
CoupleInputAndForget
CoupleInputForget
Cp;Ct
Cp_^[
CP+CL
Cphh}-
CPQVQ
CPUExecutionProvider
create_func(&context, &func_state_) == 0
Create_State_
CreateDirect3D11DeviceFromDXGIDevice
CreateDirect3D11SurfaceFromDXGISurface
CreateDXGIFactory1
CreateEventW
CreateFileW
CreateMutexExW
CreateSemaphoreExW
CreateSubgraphSessionState should have created an entry earlier.
CreateThreadpoolWork
Creating bin of max chunk size 
cross device link
CrossChannel
Ct+Cp
CTensor
CUDAExecutionProvider
Cuneiform
cur + size <= end
cur_input == end_input || cur_input->first >= 0
cur_iteration_ < num_iterations_
currentContextId
currentContextMessage
currentContextName
Currently only scalar zero_point is supported. TODO: add per channel zero point support.
custom implementation such as CuDNN.
custom_logger != nullptr
Cypriot
Cyrillic
D D R R z | 
D$ ;D$$
D$ ;t$(u
D$ @;D$(
D$ +|$X
D$ 0X,
D$ 9|$
D$ 9D$$
D$ 9D$(u
D$ j@P
D$ PQ
D$ PSW
D$ VW
D$ VWP
D$$!T$L
D$$;|$(
D$$;D$
D$$;L$
D$$+D$ @
D$$98u
D$$9D$
D$$9D$,t7
D$$9D$,t9
D$$j@P
D$$PR
D$$PW
D$$SV
D$$VW
D$(|b
D$(|h
D$(|i
D$(|l
D$(+D$
D$(9|$
D$(SVW
D$,;Wtu
D$@;D$D
D$@9u
D$@SVW
D$\;D$`
D$\WVP
D$`+M@
D$`VP
D$<kt$
D$<Pj
D$0|b
D$09|$ u
D$09t$X
D$09u
D$0Pf
D$0Pj
D$0QQ
D$0SV
D$0SVW
D$4;D$ 
D$4+|$(
D$49D9
D$4kt$
D$4QPR
D$4VP
D$8;D$<
D$8;t$(u
D$89|$ u
D$89D$
D$8PQ
D$8PQQ
D$d;D$(
D$DPQQ
D$dRQWV
D$DWSP
D$H;D$,
D$H;s
D$L;D$
D$L;D$,
D$L;D$4
D$LWRP
D$P;D$
D$p9},
D$p9T$,
D$p9U
D$p9u
D$pPQQ
D$pRQWV
D$pSSQRP
D$TWSP
D$x9t$4
D$x9u
D$XSVWj03
d%w{f
d%w{f[
d_iter[d_i] < d_max
D0f0x0
d0h0x0|0
d3d11.dll
D3D11On12CreateDevice
d3d12.dll
D3D12SerializeRootSignature
D3D12SerializeVersionedRootSignature
D5 B:
Data of TensorProto ( tensor name: 
data overflow
data tensor must have rank >= 1
Data to be binarized
Data to be classified.
Data to be encoded, a tensor of shape [N,C] or [C]
Data to be encoded.
Data to be processed.
Data to be regressed.
Data to be scaled.
Data to be selected
Data type for starts and ends inputs' need to be int32_t or int64_t, but instead got 
data type is different from updates type
data type is not supported
Data type X must be float or double, but instead got 
data_0
data_1.Shape() == shape
DATA_BATCH
data_n.Shape() == shape
data_transfer registered is nullptr.
data_type
DataTypeImpl::GetType<T>() == dtype_
DeadState in RunStateOnByte
DebugBreak
DecodePointer
DEEPCPU_ATTN_LSTM
DEEPCPU_LSTM
Default
default 1; Pooled output Y's height.
default 1; Pooled output Y's width.
Default logger already set. 
default_float
default_int64
default_logger_id must be provided if instance_type is InstanceType::Default
default_string
defaultAttributeCount
Defines how to aggregate leaf values within a target. <br>One of 'AVERAGE,' 'SUM,' 'MIN,' 'MAX.'
DeleteCriticalSection
delta
delta in Range operator can not be zero!
delta in Range operator should be scalar like tensor, yet got shape:
DENSE
depth
Depth is negative.
DepthToSpace
DequantizeLinear
deque<T> too long
Describes the axis of the inputs when coerced to 2D; defaults to one because the 0th axis most likely describes the batch_size
description
Deseret
Deserialize tensor 
destination address required
detailed description of the broadcasting rules.
detect_negative
detect_positive
Detensorization for this format is unsupported on the current device.
Detensorize Descriptor Heap
Detensorize Rootsignature
Devanagari
device or resource busy
Device: [
device_copy_checks.status == DeviceCopyCheck::Unknown
DFA out of memory: size 
DictVectorizer
dilation == 1
Dilation not supported for AutoPadType::SAME_UPPER or AutoPadType::SAME_LOWER.
Dilation value along each axis of filter.
dilation value along each axis of the filter.
dilation value along each axis of the filter. If not present, the dilation defaults to 1 along each axis.
Dilations
dilations
Dilations dimensions should match kernel shape
dilations_.size() == kernel_shape_.size()
dim0_offset < dim0_size
dimension <= num_dims
Dimension could not be inferred: incompatible shapes
Dimension of input 
Dimension on which to do the sort.
Dimension value inferred (
dimension_count * 2 == pads.size()
dimension_count > 0
DimensionCount
dimensions [a_0 * ... * a_{k-1}, a_k * ... * a_{n-1}]. For the default
dimstart <= dimend && dimend <= size()
Direction
direction
directions
DirectML.dll
directory not empty
DisableThreadLibraryCalls
Dividend tensor
division
Divisor tensor
DllCanUnloadNow
DllGetActivationFactory
DML allocator
DML CPU
DML_OPERATOR_ACTIVATION_ELU
DML_OPERATOR_ACTIVATION_HARD_SIGMOID
DML_OPERATOR_ACTIVATION_HARDMAX
DML_OPERATOR_ACTIVATION_IDENTITY
DML_OPERATOR_ACTIVATION_LEAKY_RELU
DML_OPERATOR_ACTIVATION_LINEAR
DML_OPERATOR_ACTIVATION_LOG_SOFTMAX
DML_OPERATOR_ACTIVATION_PARAMETERIZED_RELU
DML_OPERATOR_ACTIVATION_PARAMETRIC_SOFTPLUS
DML_OPERATOR_ACTIVATION_RELU
DML_OPERATOR_ACTIVATION_SCALED_ELU
DML_OPERATOR_ACTIVATION_SCALED_TANH
DML_OPERATOR_ACTIVATION_SHRINK
DML_OPERATOR_ACTIVATION_SIGMOID
DML_OPERATOR_ACTIVATION_SOFTMAX
DML_OPERATOR_ACTIVATION_SOFTPLUS
DML_OPERATOR_ACTIVATION_SOFTSIGN
DML_OPERATOR_ACTIVATION_TANH
DML_OPERATOR_ACTIVATION_THRESHOLDED_RELU
DML_OPERATOR_AVERAGE_POOLING
DML_OPERATOR_BATCH_NORMALIZATION
DML_OPERATOR_CAST
DML_OPERATOR_CONVOLUTION
DML_OPERATOR_DEPTH_TO_SPACE
DML_OPERATOR_DIAGONAL_MATRIX
DML_OPERATOR_ELEMENT_WISE_ABS
DML_OPERATOR_ELEMENT_WISE_ACOS
DML_OPERATOR_ELEMENT_WISE_ACOSH
DML_OPERATOR_ELEMENT_WISE_ADD
DML_OPERATOR_ELEMENT_WISE_ADD1
DML_OPERATOR_ELEMENT_WISE_ASIN
DML_OPERATOR_ELEMENT_WISE_ASINH
DML_OPERATOR_ELEMENT_WISE_ATAN
DML_OPERATOR_ELEMENT_WISE_ATANH
DML_OPERATOR_ELEMENT_WISE_CEIL
DML_OPERATOR_ELEMENT_WISE_CLIP
DML_OPERATOR_ELEMENT_WISE_CONSTANT_POW
DML_OPERATOR_ELEMENT_WISE_COS
DML_OPERATOR_ELEMENT_WISE_COSH
DML_OPERATOR_ELEMENT_WISE_DEQUANTIZE_LINEAR
DML_OPERATOR_ELEMENT_WISE_DIVIDE
DML_OPERATOR_ELEMENT_WISE_ERF
DML_OPERATOR_ELEMENT_WISE_EXP
DML_OPERATOR_ELEMENT_WISE_FLOOR
DML_OPERATOR_ELEMENT_WISE_IDENTITY
DML_OPERATOR_ELEMENT_WISE_IF
DML_OPERATOR_ELEMENT_WISE_IS_NAN
DML_OPERATOR_ELEMENT_WISE_LOG
DML_OPERATOR_ELEMENT_WISE_LOGICAL_AND
DML_OPERATOR_ELEMENT_WISE_LOGICAL_EQUALS
DML_OPERATOR_ELEMENT_WISE_LOGICAL_GREATER_THAN
DML_OPERATOR_ELEMENT_WISE_LOGICAL_LESS_THAN
DML_OPERATOR_ELEMENT_WISE_LOGICAL_NOT
DML_OPERATOR_ELEMENT_WISE_LOGICAL_OR
DML_OPERATOR_ELEMENT_WISE_LOGICAL_XOR
DML_OPERATOR_ELEMENT_WISE_MAX
DML_OPERATOR_ELEMENT_WISE_MEAN
DML_OPERATOR_ELEMENT_WISE_MIN
DML_OPERATOR_ELEMENT_WISE_MULTIPLY
DML_OPERATOR_ELEMENT_WISE_POW
DML_OPERATOR_ELEMENT_WISE_QUANTIZE_LINEAR
DML_OPERATOR_ELEMENT_WISE_RECIP
DML_OPERATOR_ELEMENT_WISE_SIGN
DML_OPERATOR_ELEMENT_WISE_SIN
DML_OPERATOR_ELEMENT_WISE_SINH
DML_OPERATOR_ELEMENT_WISE_SQRT
DML_OPERATOR_ELEMENT_WISE_SUBTRACT
DML_OPERATOR_ELEMENT_WISE_TAN
DML_OPERATOR_ELEMENT_WISE_TANH
DML_OPERATOR_ELEMENT_WISE_THRESHOLD
DML_OPERATOR_GATHER
DML_OPERATOR_GEMM
DML_OPERATOR_GRU
DML_OPERATOR_GRU_ELEMENT_WISE
DML_OPERATOR_JOIN
DML_OPERATOR_LOCAL_RESPONSE_NORMALIZATION
DML_OPERATOR_LP_NORMALIZATION
DML_OPERATOR_LP_POOLING
DML_OPERATOR_LSTM
DML_OPERATOR_LSTM_FUSED_ACTIVATION
DML_OPERATOR_MAX_POOLING
DML_OPERATOR_MAX_POOLING1
DML_OPERATOR_MAX_UNPOOLING
DML_OPERATOR_MEAN_VARIANCE_NORMALIZATION
DML_OPERATOR_ONE_HOT
DML_OPERATOR_PADDING
DML_OPERATOR_REDUCE
DML_OPERATOR_RESAMPLE
DML_OPERATOR_RNN
DML_OPERATOR_RNN_FUSED_ACTIVATION
DML_OPERATOR_RNN_GATHER
DML_OPERATOR_RNN_OVERWRITE
DML_OPERATOR_RNN_ZERO
DML_OPERATOR_ROI_POOLING
DML_OPERATOR_SCATTER
DML_OPERATOR_SLICE
DML_OPERATOR_SPACE_TO_DEPTH
DML_OPERATOR_SPLIT
DML_OPERATOR_TILE
DML_OPERATOR_TOP_K
DML_OPERATOR_UPSAMPLE_2D
DML_OPERATOR_VALUE_SCALE_2D
DMLCreateDevice1
DmlExecutionProvider
DmlFusedNode_
DmlFusedNodeDomain
DoCoalesce failed: r1->op() is 
DoCoalesce failed: r2->op() is 
does not have a kernel registry.
Dogra
domain
Domain already set in registry
Done saving initialized tensors
Done saving kernels.
Done saving OrtValue mappings.
Double
double
double_data
drop_states
Dropout
Dropout takes one input data (Tensor<float>) and produces two Tensor outputs,
Dropout takes one input floating tensor and produces two tensor outputs,
DSVWj
DtEVW
dtype
dup_replacements.find(&arg) == dup_replacements.end()
Duplicate name in feeds: 
Duplicate stopwords not allowed
Duplicate type constraint name
duplicated allocator
duplicated location
duplicated ort_value index:
Duployan
Duration (us)
dword
DX12TextureToGPUTensor
DXBC#
DXBC.
DXBC\8
DXBC_9
DXBC1w
DXBC7
DXBC70
DXBCd
DXBCd=
DXBCF
DXBCN
DXBCT0
DXCoreCreateAdapterFactory
dxgi.dll
DynamicSlice
E$j,Y
E(QQPQPQ
E,9E0|pV
E,PQS
E,PQW
E,VW3
E_Xsquared
E0O0h0
e0x0k1
E1g1q1
E4Y4c4l4
Each of these dimensions must be matched correctly, or else the operator
EdgeConsistency
Egyptian_Hieroglyphs
Either both scale and offset can be of feature size (
Either one of the separators OR tokenexp attributes required but none is set
Elbasan
elem_proto != nullptr
elem_type
Element type of input 
Element type of input was unknown
elements, but feeds has 
Element-wise {name} of each of the input tensors (with Numpy-style broadcasting support).
elementwise on the input tensors `A` and `B` (with Numpy-style broadcasting support).
elementwise on the input tensors `A` and `B`.
EliminateDropout
EliminateIdentity
EliminateSlice
else_branch
embedding_size
Empty dimensions for input tensor
Empty input dimensions.
Empty scale in attributes
Empty stopwords not allowed
Empty value of imputed values.
Enable broadcasting
EnableDebugOutput
Encoded output data
Encoded output data, having one more dimension than X.
EncodePointer
Encountered unknown exception in Initialize()
Encountered unknown exception in Load()
Encountered unknown exception in Run()
end_idx >= start_idx && end_idx <= total_items
Ending indices (exclusive) of corresponding axis in axes`
EndPadding
endpos: 
Ends must be a 1-D array
ENGINE_ERROR
EnterCriticalSection
entiu
Entry exists in node 
entry.second
en-US
Environment dependent string that denotes the locale according to which output strings needs to be upper/lowercased.Default en_US or platform specific equivalent as decided by the implementation.
Environment must be initialized before creating an InferenceSession.
Environment::IsInitialized()
Epsilon
epsilon
Equal
equal
Equations (Default: f=Sigmoid, g=Tanh):
Equations (Default: f=Sigmoid, g=Tanh, h=Tanh):
Equations (Default: f=Tanh):
ERROR
Error compiling '
Error during EndProfiling(): 
Error mapping feeds: 
Error mapping output names: 
Error parsing '
Error reverse compiling '
Error: Duplicate definition-site for (
errormessage
Ethiopic
evalModelCounters
Evaluation
Evaluation produced unexpected output variables.
event
Event Name
eventId
EventRegister
EventSetInformation
EventUnregister
EventWriteTransfer
EX_squared
Exceeded maximum protobuf size of 2GB: 
Exception
Exception caught: 
Exception during initialization: 
Exception during loading: 
Exception joining threads in TaskThreadPool: 
exec_plan_ptr
executable format error
Execution frame was null
Execution plan was not found in SessionState. CreatePlan must be called first.
Execution Provider
Execution provider 
Execution type '
execution_frame_->GetOrCreateNodeOutputMLValue(output_arg_index, nullptr, p_value).IsOK()
executionType
EXECUTOR
existing_entries.find(attribute_name) == existing_entries.cend()
Exiting due to terminate flag being set to true.
Expand
ExpandDims
expanded
Expected AllocateFinalOutput to have been called to before we increment the iterator
Expected AllocateFinalOutput to have been called to before we read the OrtValue from the iterator.
Expected 'replace_value_int64' attribute since 'imputed_values_int64' is specified
Expected 'replaced_value_float' attribute since 'imputed_value_floats' is specified
Expecting a non-empty tokenexp
Expecting activation to be one of Affine, Relu, LeakyRelu, ThresholdedRelu, Tanh, ScaledTanh, Sigmoid, HardSigmoid, Elu, Softsign, Softplus. Got 
Expecting indices to be either int32_t or int64_t
Exponent
ExponentTensor
Extending allocation by 
ext-ms-win-dxcore-l1-1-0.dll
extra_shape
EyeLike
EyeLike : Input tensor dimension is not 2
F _^[
F F ~ ~ 
F$+F 
F$+F P
F$9F 
F(;F,
F(;F,tDh
F,;F0
F,+F(
f;A.uO
F;D$$r
F;u$|
F;w |
F\+FX
F<+F8j
F08VHt8
F09F8
f0E1L1z1q2
F0f0w0
F78|As
Factor used in computing the running mean and variance.e.g., running_mean = running_mean * momentum + mean * (1 - momentum), default is 0.9f.
Factor used in computing the running mean and variance.e.g., running_mean = running_mean * momentum + mean * (1 - momentum).
Failed
Failed to acquire buffer from model stream.
Failed to add kernel for 
Failed to analyze start state.
Failed to center crop the provided input image. The calculated bounds exceed the dimensions of the image, or do not match the model inputs dimensions.
Failed to construct locale with name:
Failed to copy tensor to execution provider: 
Failed to create kernel for op: 
Failed to create LearningModel. Ivalid argument model_path_size.
Failed to create LearningModel. Ivalid argument p_model_path.
Failed to create LearningModel. Ivalid argument pp_model_unk.
Failed to create LearningModelDevice. Ivalid argument device.
Failed to create LearningModelDevice. Ivalid argument queue.
Failed to create operator registry.
Failed to create output tensor for 
Failed to create output tensor for If output 
Failed to create output tensor for output #
Failed to find input name in the mapping: 
Failed to find kernel for 
Failed to find symbol in library
Failed to get allocator for initializer '
Failed to get allocator for location: 
Failed to get allocator for optimizer
failed to get first output!
Failed to get initialized tensor 
Failed to load model with error: 
Failed to obtain detect_negative
Failed to obtain detect_positive
Failed to return bound object for model variable output %s
Failed to unload DSO: 
Failed to unload library
Failed to update bound object for model variable output %s
FailFast
failureCount
failureId
failureType
FallbackError
false
False instead of True.
FATAL
Fatal error: 
Fatal error: 0 count processors from GetLogicalProcessorInformation
Fatal error: 0 count processors from GetSystemInfo
fclose
Feature id for each node.
FeatureVectorizer
feed_mlvalue
feed_names.size() == num_feeds
feeds.size() == feed_mlvalue_idxs.size()
fesetround
Fetches vector passed to GetOutputs contains 
fetches.empty() || fetches.size() == fetch_mlvalue_idxs.size()
fetches.size() == node->OutputDefs().size()
fff?Qj
fff?QVh
fff?QVhH
fflush
fgetc
fgetpos
Fh+Fd
FH+FD
Fh+Fd
FH9FDu
FhhN,
FHN&C
Field '
file exists
file too large
FileDescription
fileName
filename too long
FileVersion
filter number not equal to input channel number.
FilterTensor
Final N loop carried dependency values then K scan_outputs
Final values of the loop's N state variables followed by K scan_outputs
final_output_mlvalue_
final_state_and_scan_outputs
First dimension (num_rois) of batch_indices and rois don't match
First input does not have rank 2
First input operand for the logical operator.
first input tensor has wrong dimension
First input tensor must have rank 3
First operand, base of the exponent.
First operand, should share the type with the second operand.
First operand.
First set of probability coefficients.
First, offset by this.<br>Can be length of features in an [N,F] tensor or length 1, in which case it applies to all features, regardless of dimension count.
FixedLayout
FixedLayoutAndOperatorPreference
Fl0X,
Flag indicating whether the regression is a one-class SVM or not.
Flatten
Flist<T> too long
float
Float
float
Float representing the threshold for deciding when to remove boxes based on score. It is a scalar
Float representing the threshold for deciding whether boxes overlap too much with respect to IOU. It is scalar. Value range [0, 1].
float_data
Float16
float16
FLOAT16 is not supported
floor
Floor
FLPWj:
fmaxf
fmod attribute must be true for float, float16 and double types
fmod must have value either 0 or 1
fmod_
For each node, define what to do in the presence of a missing value: if a value is missing (NaN), use the 'true' or 'false' branch based on the value in this array.<br>This attribute may be left undefined, and the defalt value is false (0) for all nodes.
For each node, define what to do in the presence of a NaN: use the 'true' (if the attribute value is 1) or 'false' (if the attribute value is 0) branch based on the value in this array.<br>This attribute may be left undefined and the defalt value is false (0) for all nodes.
For example, the following tensor shapes are supported (with broadcast=1):
For ort_value with index: 
For previous (depreciated) non-spatial cases, implementors are suggested
forgot to update the version range in DomainToVersionRange 
Format was input image %d. Input image format must Bgra8, Rgba8 or Gray8.
Format was output image %d. Output image format must be Bgra8, Rgba8 or Gray8.
FormatMessageW
forward
found
found duplicated provider 
foward
FP+FL
fputc
frame != nullptr
fread
FreeLibrary
frexp
fromStream
fsetpos
Ft+Fp
func info for node: 
FuncKernel call failed with error code: 
Function
function
function not supported
Fused
fused 
fused Conv 
fused Gemm 
fused Matmul and Add 
fused op (
fused_
fused_activation
fused_activation_domain
fused_activation_since_version
fused_alpha
fused_beta
fused_function_subgraph
fused_gamma
fused_ratio
FusedActivation
FusedAdd
FusedBatchNormalization
FusedConv
FusedConvTranspose
FusedGemm
FusedInstanceNormalization
FusedMatMul
FusedMeanVarianceNormalization
FusedSum
future
future already retrieved
FVhdI-
FVVVWh
fwrite
FYY;u
G(;G,}
G,+G(
G,+G(3
G,+G(j
G,9_(u
G,C+G(
G;{ |
G;{$|
G;~$|
G@+G<j
G\9w`~
G_^[]
G`+G\
G0N0c0x0
g0p0"1F1X1
G0PQQ
G0QVP
G0Z0o0
G4;G8t-
G8PRQ
G9{ ~ j
gamma
Gamma
gates
Gather
GatherND
GatherND requires two tensor inputs.
GEMM: Dimension mismatch, W: 
Gemm: Invalid bias shape for broadcast
GemmActivationFusion
gemmlowp error: %s
GENERAL ERROR
General Matrix multiplication:
generic
Georgian
Get preallocated buffer for initializer '
GetCPInfo
GetCurrentProcess
GetCurrentProcessId
GetCurrentThreadId
GetExitCodeThread
GetFileSizeEx
GetFileSizeEx 
GetLastError
GetLocaleInfoEx
GetLogicalProcessorInformation
GetModuleFileNameA
GetModuleHandleExW
GetModuleHandleW
GetNativeSystemInfo
GetOrCreateOutputMLValue(index, p_ml_value).IsOK()
GetProcAddress
GetProcessHeap
GetProcessTimes
GetRestrictedErrorInfo
GetStringTypeW
GetSystemInfo
GetSystemTimeAsFileTime
GetSystemTimePreciseAsFileTime
GetTickCount64
GH;0|
Gh+Gd
GhhN,
GivenTensorFill
GL+GH
Glagolitic
GlobalAveragePool
GlobalLpPool
GlobalMaxPool
Got nullptr from GetKernel for node: 
Got weights of size: 
Gothic
GP4[,
GPhN,
GPUTensorToDX12Texture
GQWhx
-grams
-grams detected
Grantha
graph
Graph attribute inferencing failed: 
Graph attribute inferencing returned type information for 
Graph ctor should have created NodeArg for initializer.
Graph has 
Graph in 'body' attribute of Loop should have 
Graph input #
Graph input with name 
Graph must be in single static assignment (SSA) form, however '
Graph to run if condition is false. Has N outputs: values you wish to be live-out to the enclosing scope. The number of outputs must match the number of outputs in the then_branch.
Graph to run if condition is true. Has N outputs: values you wish to be live-out to the enclosing scope. The number of outputs must match the number of outputs in the else_branch.
Graph::InferAndVerifySubgraphTypes should have already validated that num_variadic_inputs matched the subgraph inputs or required inputs.
graph_optimization_level < TransformerLevel::MaxTransformerLevel
graph_proto != nullptr
graph_proto cannot be null
graph_viewer_
GraphProto attribute inferencing is not enabled in this InferenceContextImpl instance.
Gray8
greater
Greater
Greek
group
group count is <= 0
GroupCount
GrowStack() failed: 
GRU operator does not support double yet
GRUUnit
GSL: Postcondition failure at C:\apilot\agent\_work\2\s\engine\lotus\cmake\external\gsl\include\gsl/pointers: 91
GSL: Precondition failure at C:\apilot\agent\_work\2\s\engine\lotus\cmake\external\gsl\include\gsl/gsl_algorithm: 53
GSL: Precondition failure at C:\apilot\agent\_work\2\s\engine\lotus\cmake\external\gsl\include\gsl/pointers: 77
GSL: Precondition failure at C:\apilot\agent\_work\2\s\engine\lotus\cmake\external\gsl\include\gsl/span: 150
GSL: Precondition failure at C:\apilot\agent\_work\2\s\engine\lotus\cmake\external\gsl\include\gsl/span: 162
GSL: Precondition failure at C:\apilot\agent\_work\2\s\engine\lotus\cmake\external\gsl\include\gsl/span: 176
GSL: Precondition failure at C:\apilot\agent\_work\2\s\engine\lotus\cmake\external\gsl\include\gsl/span: 196
GSL: Precondition failure at C:\apilot\agent\_work\2\s\engine\lotus\cmake\external\gsl\include\gsl/span: 211
GSL: Precondition failure at C:\apilot\agent\_work\2\s\engine\lotus\cmake\external\gsl\include\gsl/span: 475
GSL: Precondition failure at C:\apilot\agent\_work\2\s\engine\lotus\cmake\external\gsl\include\gsl/span: 516
GSL: Precondition failure at C:\apilot\agent\_work\2\s\engine\lotus\cmake\external\gsl\include\gsl/span: 523
GSL: Precondition failure at C:\apilot\agent\_work\2\s\engine\lotus\cmake\external\gsl\include\gsl/span: 524
GSL: Precondition failure at C:\apilot\agent\_work\2\s\engine\lotus\cmake\external\gsl\include\gsl/span: 555
GSL: Precondition failure at C:\apilot\agent\_work\2\s\engine\lotus\cmake\external\gsl\include\gsl/span: 561
gsl::narrow_cast<int64_t>(input_axes_.size()) == num_scan_inputs_
gsl::narrow_cast<int64_t>(input_shape.Size()) == size
gsl::narrow_cast<int64_t>(output_axes_.size()) == num_scan_outputs
gsl::narrow_cast<int64_t>(tensor_shape.NumDimensions()) >= slice_dimension
gsl::narrow_cast<int64_t>(X_shape.NumDimensions()) >= axis_
GT;GX
Gt+Gp
GtF+Gp
Gujarati
Gunjala_Gondi
Gurmukhi
GX+GT
GX9G\t
h != kInvalidChunkHandle
h < chunks_.size()
H$+H 
H,+H(
h9l9p9t9x9|9
Hangul
Hanifi_Rohingya
Hanunoo
Hardmax
hardmax
Hardmax inputs N, D and N * D must be < 
hardsigmoid
HardSigmoid
has output size 
has_starts && has_ends && attr_starts_.size() == attr_ends_.size()
Hatran
Hb$EfkJ
HeapAlloc
HeapFree
Hebrew
Height
height
Height
height
Height
height
height_scale
hh(-1
hidden
hidden_prev
hidden_size
HiddenInitTensor
HiddenTensor
Hiragana
HL$(+
host unreachable
HRESULT
hResult
HRESULT
hresult
HRESULT
hresult
Ht+Hp
https://arxiv.org/abs/1502.03167. Depending on the mode it is being run,
https://en.wikipedia.org/wiki/Basic_Linear_Algebra_Subprograms#Level_3
Hx+Ht
i < input_shape.NumDimensions()
id >= 0 && static_cast<size_t>(id) < ml_value_info_.size()
identifier removed
Identity
If 0, normalize the mean only.  Default is 1.
If 1, mean and variance are computed across channels. Default is 0.
If broadcasting is enabled, the right-hand-side argument will be broadcasted
If keepdims equal 0, then the resulted tensor have the reduced dimension pruned. 
If necessary the right-hand-side argument will be broadcasted to match the
If node has 
'If' node has 
If set to nonzero, run spatial batch normalization in test mode, default is 0.
If set, defines the broadcast dimensions.
If set, defines the broadcast dimensions. See doc for details.
If shape was concrete we shouldn't be using a custom allocator
If spatial is true, the dimension of bias is (C). If spatial is false, the dimensions of bias are (C x D1 x ... x Dn)
If spatial is true, the dimension of scale is (C). If spatial is false, the dimensions of scale are (C x D1 x ... x Dn)
If spatial is true, the dimension of the running mean (training) or the estimated mean (testing) is (C). If spatial is false, the dimensions of the running mean (training) or the estimated mean (testing) are (C x D1 x ... x Dn).
If spatial is true, the dimension of the running variance(training) or the estimated variance (testing) is (C). If spatial is false, the dimensions of the running variance(training) or the estimated variance (testing) are (C x D1 x ... x Dn).
If the pads parameter is provided the shape of the output is calculated via the following equation:
If the value of map_form is 'SPARSE,' this attribute indicates the total length of the output tensor.
If true and category is not present, will return all zeros; if false and a category if not found, the operator will fail.
If true, compute the mean and variance across all spatial elements If false, compute the mean and variance across per feature.Default is 1.
If true, compute the mean and variance across per activation. If false, compute the mean and variance across per feature over each mini-batch.
If value is 1, output type is uint32_t, else int32_t. Default value is 1.
iFormat
iHeight
illegal byte sequence
illegal input path:
iLuid
IMAGE
Image.BitmapPixelFormat
Image.ColorSpaceGamma
Image.NominalPixelRange
Image[
ImageScaler
Imperial_Aramaic
impl_->max_gram_length_ >= impl_->min_gram_length_
impl_->max_skip_count_ >= 0
impl_->min_gram_length_ > 0
impl_->weighting_criteria_ != kNone
impl_->weights_.size() == impl_->ngram_indexes_.size()
implementation such as CuDNN.
Imputed output data
imputed_value_floats
imputed_value_int64s
imputed_values_float_.empty() ^ imputed_values_int64_.empty()
Imputer
in onnx/defs/schema.h).
in test mode or not, the output Y will either be a random dropout, or a simple
in the inclusive range [
In this situation, we must have a_0 = N and a_1 * ... * a_{n-1} = D.
inappropriate io control operation
IncludePadding
Incompatible dimensions
Incompatible dimensions for matrix multiplication
Inconsistent shape in loop output for output 
Incorrect or missing attribute value for starts and ends
Incorrect or missing input value for starts and ends
Incorrect output shape
index < data_.size()
index >= 0 && static_cast<size_t>(index) < inputs.size()
index >= 0 && static_cast<size_t>(index) < outputs.size()
index out of range
Index tensor shape should be same as that of the input data tensor to unpool.
IndexDimensions
Indicate up to which input dimensions (exclusive) should be flattened to the outer dimension of the output. The value for axis must be in the range [0, R], where R is the rank of the input tensor. When axis = 0, the shape of the output tensor is (1, (d_0 X d_1 ... d_n), where the shape of the input tensor is (d_0, d_1, ... d_n). 
Indicates the transform to apply to the regression output vector.<br>One of 'NONE,' 'SOFTMAX,' 'LOGISTIC,' 'SOFTMAX_ZERO,' or 'PROBIT'
Indicates the transform to apply to the score. <br> One of 'NONE,' 'SOFTMAX,' 'LOGISTIC,' 'SOFTMAX_ZERO,' or 'PROBIT.'
Indicates the transform to apply to the score. <br>One of 'NONE,' 'SOFTMAX,' 'LOGISTIC,' 'SOFTMAX_ZERO,' or 'PROBIT'
Indicates the transform to apply to the score. <br>One of 'NONE,' 'SOFTMAX,' 'LOGISTIC,' 'SOFTMAX_ZERO,' or 'PROBIT.'
Indicates the transform to apply to the scores vector.<br>One of 'NONE,' 'SOFTMAX,' 'LOGISTIC,' 'SOFTMAX_ZERO,' or 'PROBIT'
Indicates whether to do OvR or multinomial (0=OvR is the default).
Indicates whether to only output as many values as are in the input (dense), or position the input based on using the key of the map as the index of the output (sparse).<br>One of 'DENSE', 'SPARSE'.
indice_tensor != nullptr
indices
Indices
Indices and updates must have the same rank
Indices dim=
indices element out of data bounds, idx=
Indices must have the same rank as Input. Indices rank=
Indices tensor from max pooling across the input tensor. The dimensions of indices are the same as output tensor. The values in indices of are the indices of the selected values during pooling. The indices are computed as flatten 1-D tensor, and the indices do not consider padding. So the values in indices are in [0, N x C x D1 x ... x Dn).
indices tensor must has rank larger than 0
Indices tensor must have rank >= 1
Indices vs updates dimensions differs at position=
IndicesTensor
ineIu
Inferred elem type differs from existing elem type: (
Inferred shape and existing shape differ in dimension 
Inferred shape and existing shape differ in rank: (
info.GetAttr("alpha", &alpha_).IsOK()
info.GetAttr("beta", &beta_).IsOK()
info.GetAttr("blocksize", &blocksize_).IsOK()
info.GetAttr("direction", &direction).IsOK()
info.GetAttr("direction", &direction_).IsOK()
info.GetAttr("hidden_size", &hidden_size_).IsOK()
info.GetAttr("hidden_size", &int64_value).IsOK() && int64_value > 0
info.GetAttr("keepdims", &keepdims).IsOK()
info.GetAttr("linear_before_reset", &int64_value).IsOK()
info.GetAttr("scale", &scale_).IsOK()
info.GetAttr<float>("alpha", &alpha_).IsOK()
info.GetAttr<float>("beta", &beta_).IsOK()
info.GetAttr<float>("high", &high_).IsOK()
info.GetAttr<float>("low", &low_).IsOK()
info.GetAttr<float>("mean", &mean_).IsOK()
info.GetAttr<float>("scale", &scale_).IsOK()
info.GetAttr<float>("spatial_scale", &spatial_scale_).IsOK()
info.GetAttr<int64_t>("across_channels", &across_channels_).IsOK()
info.GetAttr<int64_t>("axis", &axis_).IsOK()
info.GetAttr<int64_t>("batch_axis", &batch_axis).IsOK()
info.GetAttr<int64_t>("count_include_pad", &temp).IsOK()
info.GetAttr<int64_t>("default_int64", &default_int_).IsOK()
info.GetAttr<int64_t>("dtype", &dtype).IsOK()
info.GetAttr<int64_t>("max_map", &max_map_).IsOK()
info.GetAttr<int64_t>("n_targets", &n_targets_).IsOK()
info.GetAttr<int64_t>("normalize_variance", &normalize_variance_).IsOK()
info.GetAttr<int64_t>("num_scan_inputs", &num_scan_inputs_).IsOK()
info.GetAttr<int64_t>("p", &p_).IsOK()
info.GetAttr<int64_t>("sample_size", &num_samples_).IsOK()
info.GetAttr<int64_t>("size", &size).IsOK()
info.GetAttr<int64_t>("targets", &targets_).IsOK()
info.GetAttr<int64_t>("time_axis", &time_axis).IsOK()
info.GetAttr<int64_t>("transA", &temp).IsOK()
info.GetAttr<int64_t>("transB", &temp).IsOK()
info.GetAttr<ONNX_NAMESPACE::GraphProto>("body", &proto).IsOK()
info.GetAttr<ONNX_NAMESPACE::GraphProto>("else_branch", &proto).IsOK()
info.GetAttr<ONNX_NAMESPACE::GraphProto>("then_branch", &proto).IsOK()
info.GetAttr<std::string>("auto_pad", &auto_padding).IsOK()
info.GetAttr<std::string>("cast_to", &attr).IsOK()
info.GetAttr<std::string>("default_string", &default_string_).IsOK()
info.GetAttr<std::string>("map_form", &attr).IsOK()
info.GetAttr<std::string>("mode", &mode).IsOK()
info.GetAttr<std::string>("norm", &norm).IsOK()
info.GetAttr<T>("max", &max_).IsOK()
info.GetAttr<T>("min", &min_).IsOK()
info.GetAttrs("activations", activations_).IsOK()
info.GetAttrs("axes", axes_).IsOK()
info.GetAttrs(std::is_same<AttrType, std::string>::value ? "string_vocabulary" : "int64_vocabulary", vocabulary_).IsOK()
info.GetAttrs<float>("bias", bias_).IsOK()
info.GetAttrs<float>("coefficients", coefficients_).IsOK()
info.GetAttrs<float>("kernel_params", kernel_params).IsOK()
info.GetAttrs<float>("rho", rho_).IsOK()
info.GetAttrs<float>("scales", scales_).IsOK()
info.GetAttrs<int64_t>("cats_int64s", int_categories).IsOK()
info.GetAttrs<int64_t>("kernel_shape", kernel_shape_).IsOK()
info.GetAttrs<int64_t>("pooled_shape", pooled_shape).IsOK()
info.GetAttrs<int64_t>("shape", shape).IsOK()
info.GetAttrs<std::string>("cats_strings", string_categories).IsOK()
info.GetAttrs<std::string>("classes_strings", string_classes).IsOK()
info.GetAttrs<std::string>("classlabels_strings", classlabels_strings_).IsOK() || info.GetAttrs<int64_t>("classlabels_ints", classlabels_ints_).IsOK()
Inherited
Initial values of the loop's N state variables followed by M scan_inputs
initial_c
initial_h
initial_state_and_scan_inputs
initialize preallocated buffer failed
InitializeConditionVariable
InitializeCriticalSection
InitializeCriticalSectionAndSpinCount
InitializeCriticalSectionEx
Initialized tensor with unexpected type: 
InitializeSListHead
InitializeSRWLock
Initializing session.
InitOnceBeginInitialize
InitOnceComplete
InitOnceExecuteOnce
input
input 
Input 
input \in [a_0, a_1, ..., a_{k-1}, a_k, ..., a_{n-1}] and k is
Input and output types can be of any tensor type.
input and zero_point pair is expected to have be same type.
input and zero_point pair is expected to have same type.
Input axes has incorrect length
Input axes has invalid data
Input axis is invalid: 
Input B must have shape {
Input can be of any tensor type.
Input cannot be split evenly on selected axis. Input shape=
Input channels C is not equal to kernel channels * group.
Input channels is not divisible by group.
Input contains invalid utf8 chars at: 
input count mismatch
input count mismatch, expected 1 input - the tensor to be processed
input count mismatch, expected 2 inputs - the tensor to be processed and a tensor containing k value
Input count of Tile OP mismatch, the first one is empty
Input count of Tile OP mismatch, the second one is empty
Input data
Input data tensor containing the indices corresponding to elements in the first input tensor X.This tensor is typically the second output of the MaxPool op.Dimensions must be the same as input tensor X. The indices are linear, i.e. computed considering the tensor as flattened 1-D tensor, assuming row-major storage. Also, the linear indices should not consider padding. So the values in indices are in the range [0, N x C x D1 x ... x Dn).
Input data tensor from previous layer; has size (N x C x H x W), where N is the batch size, C is the number of channels, and H and W are the height and width. Note that this is for the 2D image. Otherwise the size is (N x C x D1 x D2 ... x Dn)
Input data tensor from previous layer; has size (N x C x H x W), where N is the batch size, C is the number of channels, and H and W are the height and width. Note that this is for the 2D image. Otherwise the size is (N x C x D1 x D2 ... x Dn). Optionally, if dimension denotation is in effect, the operation expects input data tensor to arrive with the dimension denotation of [DATA_BATCH, DATA_CHANNEL, DATA_FEATURE, DATA_FEATURE ...].
Input data tensor from the previous operator; 4-D feature map of shape (N, C, H, W), where N is the batch size, C is the number of channels, and H and W are the height and the width of the data.
Input data tensor from the previous operator; dimensions are in the form of (N x C x D1 x D2 ... Dn), where N is the batch size, C is the number of channels. Statistics are computed for every channel of C over N and D1 to Dn dimensions. For image data, input dimensions become (N x C x H x W). The op also accepts single dimension input of size N in which case C is assumed to be 1
Input data tensor from the previous operator; dimensions for image case are (N x C x H x W), where N is the batch size, C is the number of channels, and H and W are the height and the width of the data.
Input data tensor from the previous operator; dimensions for image case are (N x C x H x W), where N is the batch size, C is the number of channels, and H and W are the height and the width of the data. For non image case, the dimension are in the form of (N x C x D1 x D2 ... Dn), where N is the batch size.
Input data tensor from the previous operator; dimensions for image case are (N x C x H x W), where N is the batch size, C is the number of channels, and H and W are the height and the width of the data. For non image case, the dimensions are in the form of (N x C x D1 x D2 ... Dn), where N is the batch size.
Input data tensor from the previous operator; dimensions for image case are (N x C x H x W), where N is the batch size, C is the number of channels, and H and W are the height and the width of the data. For non image case, the dimensions are in the form of (N x C x D1 x D2 ... Dn), where N is the batch size. Optionally, if dimension denotation is in effect, the operation expects the input data tensor to arrive with the dimension denotation of [DATA_BATCH, DATA_CHANNEL, DATA_FEATURE, DATA_FEATURE ...].
Input data tensor that has to be unpooled. This tensor is typically the first output of the MaxPool op.Dimensions for image case are (N x C x H x W), where N is the batch size, C is the number of channels, and H and W are the height and the width of the data. For non-image case, the dimensions are in the form of (N x C x D1 x D2 ... Dn), where N is the batch size. Optionally, if dimension denotation is in effect, the operation expects the input data tensor to arrive with the dimension denotation of [DATA_BATCH, DATA_CHANNEL, DATA_FEATURE, DATA_FEATURE ...].
Input data to be scaled
Input data with index: 
Input data.
Input data. It can be either tensor or scalar.
Input 'depth' must be rank 1 tensor.
Input 'depth' must have exactly one element.
Input dimension cannot be less than 3.
Input dimensions are either [C] or [N][C] allowed
Input dimensions are either[C > 0] or [1][C > 0] allowed
Input does not need to explicitly be a 2D vector; rather, it will be
Input element type of 
Input features_per_batch[
Input for n-gram extraction
Input initial_c must have shape {
Input initial_h must have shape {
Input is ether string UTF-8 or int32/int64
Input is expected to have four dimensions corresponding to [N,C,H,W]
Input is expected to have four dimensions corresponding to [N,C,H,W], got 
Input is missing. The operator Cast expects one and only one input
Input matrix
'input' must have rank >= 2
Input of int64 must have output of string 
Input of shape [N,F]
Input of string must have output of int64
Input of tensor(int64) must have output of tensor(string)
Input of tensor(string) must have output of tensor(int64)
Input P must have shape {
Input R must have shape {
Input scales's element type must be float.
Input sequence_lens must have shape {
Input shape must have either [C] or [1,C] dimensions where C > 0
Input shape must have either [C] or [B,C] dimensions with B > 0.
Input shape needs to be at least a single dimension.
Input steps has incorrect length
Input string contains invalid utf8 chars: 
Input tensor
Input tensor A
Input tensor A. The shape of A should be (M, K) if transA is 0, or (K, M) if transA is non-zero.
Input tensor B
input tensor B has shape (K, N) or (N, K), input tensor C is broadcastable to shape (M, N),
Input tensor B. The shape of B should be (K, N) if transB is 0, or (N, K) if transB is non-zero.
Input tensor C
Input tensor C, can be inplace.
Input tensor C. The shape of C should be unidirectional broadcastable to (M, N).
Input tensor can be of arbitrary type.
Input tensor containing indices. The values must be non-negative integers. Any entries in the 'indices' input tensor with values outside the range [0, depth) will result in one-hot representation with all 'off_value' values in the output tensor.In case 'indices' is of non-integer type, the values will be casted to int64 before use.
Input tensor expected to contain int64 data
Input tensor has no dimensions
Input tensor must be 2-dimensional
Input tensor must be 4-dimensional
Input tensor must have at least 2 dimensions
Input tensor must have atleast 2 dimensions
Input tensor must have rank 1 or 2
Input tensor must have rank 2
Input tensor of [N,C,H,W], where N is the batch axis, C is the channel or depth, H is the height and W is the width.
Input tensor of any shape broadcastable to X shape, the exponent component.
Input tensor of any shape, base of the exponent.
Input tensor of any shape.
Input tensor of shape [N,C,H,W]
Input tensor to be cast.
Input tensor to copy shape and optionally type information from.
Input tensor to Unique op should be 1D
Input tensor whose elements to be clipped
Input tensor with shape [batch_size, class_size], where class_size is the number of all possible outcomes. Each value along the axis zero represents the unnormalized log-probability of each corresponding outcome in a batch.
input tensor X
Input tensor X must have atleast 2 dimensions.
Input tensor.
Input tensors of wrong rank (0).
Input type is not float tensor but keys_floats is set
Input type is not int64 tensor but keys_int64s is set
Input type is not string tensor but key_strings is set
Input type was null
Input types for the Shrink operator are constrained to all numeric types only. Got bool type here.
Input types for the Shrink operator are constrained to all numeric types only. Got std::string type here.
Input 'values' must be rank 1 tensor.
Input 'values' must have exactly two elements.
Input W must have shape {
Input was expected to have tensor type. Got 
Input X must be 4-dimensional.
Input X must have 3 dimensions only. Actual:
input.Shape().NumDimensions() == 4
Input/Output is a string tensor
input_as_shape
input_count >= 0 && static_cast<size_t>(input_count) == input_dimensions_.size()
input_count >= 1
input_depth % (blocksize_ * blocksize_) == 0
input_dims.size() >= 2
input_forget
input_height % this->blocksize_ == 0
input_shape.NumDimensions() <= 2
input_shape.Size() > 0
input_shape[i] == 1
input_tensor != nullptr
input_tensor_ptr != nullptr
input_width % this->blocksize_ == 0
InputCount
inputCount
inputCount >= 1
inputdimensions
inputdimensions attribute must be provided
Inputs
inputs
inputs are expected to have tensor type and output type should not be null.
inputs are expected to have tensor type.
Input's height (
Input's width (
inputs_n_rank == inputs_0_rank
InputTensor
InputTensors
InputVideoFrame
Inscriptional_Pahlavi
Inscriptional_Parthian
InstanceNormalization
Insufficient dimensions to slice on 
int16
Int16
Int32
int32
int32_data
Int64
int64
Int64 tensor
int64_data
int64_vocabulary
Integer indicate the format of the box data. The default is 0.0 - the box data is supplied as [y1, x1, y2, x2] where (y1, x1) and (y2, x2) are the coordinates of any diagonal pair of box cornersand the coordinates can be provided as normalized (i.e., lying in the interval [0, 1]) or absolute. Mostly used for TF models.1 - the box data is supplied as [x_center, y_center, width, height]. Mostly used for Pytoch models.
Integer representing the embedding vector size for each char.If not provide, use the char embedding size of embedding vector.
Integer representing the embedding vector size for each word.If not provide, use the fileter size of conv weight
Integer representing the maximum number of boxes to be selected per batch per class. It is a scalar.
intercepts
InterlockedPushEntrySList
Internal error in BatchNormalizationMulFusion. BatchNormalization_B_tensor_proto is NULL
Internal error in ConvMulFusion. conv_B_tensor_proto is NULL
Internal error.
Internal error. The preallocated buffer is too small. Requires 
InternalName
InterpolationMode
interrupted
Invalid activation function of 
Invalid allocation info. Provider name = 
Invalid allocation kind: 
invalid allocator
Invalid arg_num of 
invalid argument
Invalid argument for depth; it's not a scalar.
Invalid argument for values; either it's rank is more than 1 or it has more than 2 elements
Invalid argument: input has empty dimensions.
Invalid argument: X input has empty dimensions.
Invalid attribute perm {
Invalid axes attribute, axes attribute (if present) should have the same size as starts/ends attributes
Invalid batch_axis of 
Invalid CAST_TO value of 
invalid character class
invalid character class range
Invalid data type for GRU operator of 
Invalid data type for LSTM operator of 
Invalid data type of 
Invalid destination node arg slot specified when adding edge.
Invalid destination node arg slot specified when removing edge.
Invalid dim0_offset of 
Invalid dimension of 
Invalid dimension value: 
Invalid 'direction' argument of '
Invalid dtype of 
Invalid entries in sequence_lens. Max sequence length was 
invalid escape sequence
Invalid Feed Input Name:
Invalid GRU hidden gate activation function: 
Invalid GRU reset gate activation function: 
invalid hash bucket count
invalid index 
invalid indice found, indice = 
Invalid input B: 0th dimension != 
Invalid input B: number of dimensions is not 1: 
Invalid input B: NumDimensions() != 
Invalid input data: number of dimensions is less than 3: 
Invalid input image height provided. Height is set to zero.
Invalid input image height provided. Width is set to zero.
Invalid input image width provided. Height is set to zero.
Invalid input mean: 0th dimension != 
Invalid input mean: NumDimensions() != 
Invalid input scale: 0th dimension != 
Invalid input scale: number of dimensions is not 1: 
Invalid input scale: NumDimensions() != 
Invalid input shape: 
Invalid input type of 
Invalid input type of value: 
Invalid input type:
Invalid input var: 0th dimension != 
Invalid input var: NumDimensions() != 
Invalid input X: Empty dimensions
Invalid LSTM merge activation function of 
Invalid 'mode' attribute value
Invalid mode of value 
Invalid mode of value: 
invalid named capture group
Invalid node indexes specified when adding edge.
Invalid node indexes specified when removing edge.
Invalid normalize value of 
invalid ort_value_index:
Invalid Output Name:
Invalid PACK_MAP value of 
Invalid 'pads' attribute value
invalid perl operator
Invalid position of 0
Invalid RE2: 
invalid repetition size
Invalid scan input:
invalid seek
Invalid shape value: 
Invalid source node arg slot specified when adding edge.
Invalid source node arg slot specified when removing edge.
invalid stod argument
invalid stof argument
invalid stoi argument
invalid stol argument
invalid stoll argument
invalid stoul argument
invalid stoull argument
invalid string position
Invalid Target shape product of 0
Invalid tensor shape slice argument.
Invalid TensorProto
Invalid time_axis of 
Invalid type
Invalid type of the input argument
invalid unordered_map<K, T> key
invalid UTF-8
Invalid value for attribute axis
Invalid value for attribute k
Invalid value in scan_input_axes for input 
Invalid value in scan_output_axes for output 
Invalid value in 'split' attribute. All values must be > 0
Invalid value of attribute 'axis'
Invalid value(
Invalid value/s in sequence_lens. All values must be > 0 and < seq_length. seq_length=
Invalid values in '
invalid vector<T> subscript
Invalid Y argument: index is out of range: Y[
Invalid Y argument: num_indices = 0
INVALID_ARGUMENT
INVALID_GRAPH
INVALID_PROTOBUF
io error
ios_base::badbit set
ios_base::eofbit set
ios_base::failbit set
iostream
iostream stream error
iou_threshold
iou_threshold must be in range [0, 1].
is a directory
is applied to the data tensor elementwise.
'is defined.
is_case_sensitive
is_concrete_shape_
is_test
isalpha
isCpu
IsDebuggerPresent
isdigit
IsInf
islower
IsNaN
IsNan
IsProcessorFeaturePresent
IsScalarOr1ElementVector(&x_scale)
IsScalarOr1ElementVector(&x_zero_point)
IsScalarOr1ElementVector(&y_scale)
IsScalarOr1ElementVector(&y_zero_point)
isspace
isupper
iswspace
it != indices.end()
it != parents.end()
iteration_num_ < sequence_len_
iWidth
j h(@.
j h,5.
j h0a1
j h851
j hx[.
j Z_[
j!h0*1
j"h0a1
j#h851
j$h@n1
j$h0*1
j$Z_[
j$Z_^
j&hhs0
J&WTh
j(h`x8
j(h0a1
j(htl0
j(Z_[
j(Z_^
j)h8p.
j,Z_[
j/hX<.
j/hx60
j;h 90
j;hx60
j@X9E
j}h0*1
j<h@i/
j<h0a1
J0W0x0~0
j4hx[.
j4Z_^
j8hpj.
j8Z_[
j9hpk0
jahh|-
Javanese
jBh0*1
jBh851
jCh0*1
jCh851
jDh0*1
jDh851
jEh0*1
jFh0*1
jfhhs0
jfhx[.
jGh0*1
jghpe0
j'h851
jHh0*1
jHhxo1
jIh0*1
jJhl"0
jjhx[.
jMhpX.
jmhx[.
jnh("0
jNhp;.
jNhpX.
job_.size() = 
joZjpY
joZRY
jp[h,Y/
jpZjoY
Jt+Jp
jth("0
jVhh|-
jwhP,-
k <= dims.size()
k argment [
K input must be a one-dimensional tensor of size 1.
K input must be of type int64.
k tensor should be a 1D tensor of size 1
K,+CD
K@9KDt
k_temp > 0
K`+K\
K0QVWQ
K0R0k0
K32GetProcessMemoryInfo
Kaithi
Kannada
Katakana
Kayah_Li
Keep the reduced dimension or not, default 1 mean keep reduced dimension.
keepdims
kernel != nullptr
Kernel creation failed for node: 
kernel_create_info != nullptr && kernel_create_info->kernel_def != nullptr
kernel_params
kernel_shape
kernel_shape is not compatible with W shape.
kernel_shape num_dims is not compatible with W num_dims.
kernel_shape num_dims is not compatible with X num_dims.
kernel_shape_[dim] > 0
kernel_type
KERNEL32.DLL
kernel32.dll
kernelbase.dll
key_type
keys_floats
keys_int64s
keys_strings
Kharoshthi
Khmer
Khojki
Khudawadi
KLhD,.
known by the checker.
Kp+Cdj
kRegexpCapture cap() == 0
KX9K\t
L$ ;L$0|
L$ ;M
L$ ;t$$
L$ VP
L$$;]
L$$;M
L$$_^3
L$$QP
L$$RQ
L$$Sf
L$(9M
L$(PV
L$(Sj
L$,_^[3
L$,_^3
L$,QP
L$@Pj
L$`u"
L$`VP
L$`WR
L$|SQQP
L$<_^[3
L$<QP
L$<RQ
L$<WQ
L$0;L$D
L$0SV
L$0xP
L$4;L$<
L$4_^[3
L$4RQ
L$d;M
L$DRQ
L$HPV
L$Hu{
L$L;M$
L$L;P
L$L_^[3
L$L_^3
L$LQP
L$lu"
L$P;T$ 
L$pPu
L$T;}
L$X;P
l?4?~?
l?4?~?4?~?4?~?4?~?
L>2?~>2?~>2?~>2?~>
L1 norm
L2 norm
Label encoder has only one input.
Label encoder has only one output.
LabelEncoder
lambd
last dimension of indices must not be larger and rank of data tensor
last dimension of indices must not be larger than rank of input tensor
Latin
Layout conversion
LCMapStringEx
lda >= K && ldb >= K && ldc >= N
ldexp
leaky_relu_
leaky_relu_alpha
LeakyRelu
leakyrelu
LeaveCriticalSection
Left input tensor for the logical operator.
left operand cannot broadcast on dim 
left.NumDimensions() == 2 || left.NumDimensions() == 1
legacy optimization attribute.
LegalCopyright
len <= op_schema.inputs().size()
len > 0
length
length of each output
length overflow
Lepcha
Level
Limbu
limit
limit in Range operator should be scalar like tensor, yet got shape:
LINEAR
Linear
linear
Linear_A
Linear_B
linear_before_reset
LinearBeforeReset
LinearClassifier
LinearRegressor
lineNumber
list count 
List of 3 elements containing gamma, coef0, and degree, in that order. Zero if unused for the kernel.
List of categories, ints.<br>One and only one of the 'cats_*' attributes must be defined.
List of categories, strings.<br>One and only one of the 'cats_*' attributes must be defined.
list of floats. This attribute stores the weight of each n-gram in pool. The i-th element in weights is the weight of the i-th n-gram in pool. Its length equals to the size of ngram_indexes. By default, weights is an all-one tensor.This attribute is used when mode is "IDF" or "TFIDF" to scale the associated word counts.
List of int64 n-grams learned from the training set. Either this or pool_strings attributes must be present but not both. It's an 1-D tensor starting with the collections of all 1-grams and ending with the collections of n-grams. The i-th element in pool stores the n-gram that should be mapped to coordinate ngram_indexes[i] in the output vector.
list of int64s (type: AttributeProto::INTS). This list is parallel to the specified 'pool_*' attribute. The i-th element in ngram_indexes indicate the coordinate of the i-th n-gram in the output tensor.
List of integers indicate the padding element count at the beginning and end of each axis, for 2D it is the number of pixel. `paddings` rank should be double of the input's rank. `paddings` format should be as follow [x1_begin, x2_begin...x1_end, x2_end,...], where xi_begin the number of pixels added at the beginning of axis `i` and xi_end, the number of pixels added at the end of axis `i`.
List of integers indicating the number of padding elements to add or remove (if negative) at the beginning and end of each axis. For 2D it is the number of pixels. `pads` rank should be double of the input's rank. `pads` format should be as follow [x1_begin, x2_begin...x1_end, x2_end,...], where xi_begin the number of pixels added at the beginning of axis `i` and xi_end, the number of pixels added at the end of axis `i`.
List of non-negative integers, indicate the dimensions to be inserted
List of non-negative integers, indicate the dimensions to squeeze.
List of stop words. If not set, no word would be removed from X.
List of strings n-grams learned from the training set. Either this or pool_int64s attributes must be present but not both. It's an 1-D tensor starting with the collections of all 1-grams and ending with the collections of n-grams. The i-th element in pool stores the n-gram that should be mapped to coordinate ngram_indexes[i] in the output vector.
List of tensors for 
List of tensors for concatenation
List of tensors for Max.
List of tensors for Mean.
List of tensors for Min
List of tensors for Sum.
LoadLibraryA
LoadLibraryExA
LoadLibraryW
loadModelCounters
Local\SM0:%d:%d:%hs
locale
localeconv
LocalSize
localtime_s(&local_tm, &in_time_t) == 0
location
log of softmax
log sum
log sum exponent
log_stream.str().c_str()
log2f
LogHr
LOGISTIC
LogSoftmax
logsoftmax
Loop 'body' subgraph outputs should all be tensors but output 
'Loop' node has 
LOWER
Lower boundary of the output values.
lp pool
LPh\I-
LpNormalization
LpPool
lstd::exception: %hs
LSTM operator does not support double yet
Lycian
Lydian
M QVj
M$@Pj
M_ >= 0 && K_ > 0 && N_ >= 0
m_runtimeSessionId
M0+M(
Mahajani
Main Graph instance should have populated all subgraphs when being resolved.
Makasar
Malayalam
Malformed onnx file.
Malformed repeat 
malloc
Mandaic
Manichaean
Map with key type: 
map(int64, double)
map(int64, float)
map(int64, string)
map(string, double)
map(string, float)
map(string, int64)
map/set<T> too long
map_form
map_form_ != PACK_MAP::SPARSE || max_map_ > 0
Marchen
Masaram_Gondi
Match contains invalid utf8 chars: 
MatMul
MatMul dimension mismatch
MatMulAddFusion
MatMulInteger
Matrix after normalization
Matrix multiply results from A * B
max_gram_length
max_gram_length must be inbounds of ngram_counts: 
max_map
max_map must be > 0 if map_form is SPARSE
max_output_boxes_per_class
max_skip_count
max_skip_count is required
max_skip_count must be non-negative: 
maxCpuUsage
Maximum n-gram length. If this value is 3, 3-grams will be used to generate the output.
Maximum number of events reached, could not record profile event.
Maximum number of items (integers/strings) to be skipped when constructing an n-gram from X. If max_skip_count=1, min_gram_length=2, max_gram_length=3, this operator may generate 2-grams with skip_count=0 and skip_count=1, and 3-grams with skip_count=0 and skip_count=1
Maximum value, above which element is replaced by max
maxPageFaultCount
MaxPool
MaxpoolWithMask
MaxRoiPool
maxTime
MaxUnpool
MaxUnpool op must have either two or three inputs.
maxWorkingSetMemory
MC:\apilot\agent\_work\2\s\winml\dll\TensorMemoryBufferReference.h
MeanTensor
MeanVarianceNormalization
Medefaidrin
Meetei_Mayek
Mem pattern for initializer 
mem_steps <= max_memory_steps_ && mem_steps > 0
memchr
memcmp
memcpy
Memcpy
MemcpyFromHost
MemcpyToHost
MemcpyTransformer
memmove
Memory pattern planner is not enabled on this execution framework.
memory_seq_lens
memset
Mende_Kikakui
Meroitic_Cursive
Meroitic_Hieroglyphs
message
message size
message.Category()
message.Location().ToString(onnxruntime::CodeLocation::kFilenameAndPath).c_str()
message.Message().c_str()
metaDataCount
metaDataKeys
metaDataValues
mh ,1
Mhdz.
Microsoft
Microsoft (R) HLSL Shader Compiler 10.1
Microsoft Corporation
Microsoft.Windows.AI.MachineLearning
min_gram_length
min_gram_length >= max_gram_length required: 
min_gram_length is required
min_gram_length must be inbounds of ngram_counts: 
minATL$__a
minATL$__m
minATL$__z
mincharnum
mincharnum is too big for char level tokenezation
mincharnum_ > 0
minCpuUsage
Minimum n-gram length. If this value is 2 and max_gram_length is 3, output may contain counts of 2-grams and 3-grams.
Minimum number of characters allowed in the output. For example, if mincharnum is 2, tokens such as "A" and "B" would be ignored
Minimum value, under which element is replaced by min
minPageFaultCount
minTime
minWorkingSetMemory
Mismatch between expected shape and shape from first output
Mismatch between input data and B: size of B != input channel count 
Mismatch between input data and scale: size of scale != input channel count 
Mismatch between number of source and target dimensions. Source=
Mismatched attribute type in '
Mismatched data types between input and output Tensors. 
Mismatched tensor element type for output 
Mismatched type for output 
missing )
missing ]
Missing case in Compiler: 
Missing input tensor to be processed
Missing Input: 
Missing opset in the model. All ModelProtos MUST have at least one entry that specifies which version of the ONNX OperatorSet is being imported.
Missing or invalid starts and ends attribute
Missing/Invalid 'axes' attribute value
Missing/Invalid 'axis' attribute value
Misuse of LoopStateVariable. Attempt to move beyond end of sequence
MKLDNNExecutionProvider
ML9uH
MLCreateOperatorRegistry
mode attribute is 
mode is required
mode: 
model format error!
model format error! Missing 'location'
model format error! Need a key for the external data info
model format error! Need a value for the external data info
Model image inputs must have tensor type of Float or Float16.
Model load
Model stream is invalid.
Model variable %s, expects %s, but binding was attempted with an incompatible type %s.
Model was not loaded
Model was not loaded.
MODEL_LOADED
model_loading_proto
model_run
ModelCreation
modelname
ModelProto does not have a graph.
ModelProto was null.
module
momentum
Mongolian
Msg:[%ws] 
Multani
multi_class
MultiByteToWideChar
Multinomial
multiplication
Multiplicative spatial scale factor to translate ROI coordinates from their input scale to the scale used when pooling.
Multiplicative spatial scale factor to translate ROI coordinates from their input spatial scale to the scale used when pooling, i.e., spatial scale of the input feature map X relative to the input image. E.g.; default is 1.0f. 
MurmurHash3
Must have 1 or more inputs
Must have a single dimension
Must have a single dimension of 1
Must have valid 'axis' attribute
Must provide classlabels_strings or classlabels_int64s but not both.
Must provide imputed_values_float_ or imputed_values_int64_ but not both.
mutually equal shape is specified by the argument "axis", and if it is not set,
Myanmar
N ;N$
n >= 0 && static_cast<size_t>(n) < ml_value_info_.size()
n >= 0 && static_cast<size_t>(n) < plan_.allocation_plan.size()
N 99t
N 9H 
N classes
N$+N 
N$9H 
N, Top class for each point
n_supports
n_targets
N0+N,
Nabataean
N-D full precision Input tensor to be quantized.
N-D full precision output tensor. It has same shape as input 'x'.
N-D quantized input tensor to be de-quantized.
N-D quantized Input tensor to be de-quantized.
N-D quantized output tensor. It has same shape as input 'x'.
N-D tensor
N-D tensor after resizing
ND99t
NDHCW
NDHWC
N-dimensional matrix A
N-dimensional matrix B
N-dimensional quantized matrix a
N-dimensional quantized matrix b
nearbyintf
NEAREST
nearest
Negative index values are not permitted. First entry in map has index value of 
Negative ngram_indexes values are not allowed
Negative values are not allowed in a shape specification
network down
network reset
network unreachable
New shape
new_fetches.empty()
New_Tai_Lue
n-gram counts out of bounds for 
Ngram results
ngram_counts
ngram_indexes
ngram_indexes must be non-empty with no negative values
NGRAPHExecutionProvider
NH;VD
NH99t
nhh\0
njob_ = 
NL99t
no argument for repetition operator
No attribute with name:'
No attribute with this name is defined.
no buffer space
no child process
no error
No Graph instance was found for attribute 
No graph was found in the protobuf.
No hardware adapters available
No kernel shape is set.
no link
no lock available
no message
no message available
no name
No Op registered for 
No opset import for domain '
no protocol option
No provider specified.
No ranges in char class
no space on device
no state
no stream resources
no such device
no such device or address
no such file or directory
no such process
No suitable kernel definition found for op 
No support vectors.
NO_MODEL
NO_SUCHFILE
Node (
Node id for each node. Ids may restart at zero for each tree, but it not required to.
Node id for each node. Node ids must restart at zero for each tree and increase sequentially.
node id that this weight is for.
Node:
node_arg
node_compute_funcs.size() == nodes_need_compile.size()
node_index < nodes_.size()
node_index_info_
node_offsets_index < node_offsets_.size()
NodeProto (name: 
Nodes in a graph must be topologically sorted, however input '
nodes_.size() < std::numeric_limits<int>::max()
nodes_falsenodeids
nodes_featureids
nodes_hitrates
nodes_id_size == nodes_falsenodeids_.size()
nodes_id_size == nodes_featureids_.size()
nodes_id_size == nodes_modes_.size()
nodes_id_size == nodes_truenodeids_.size()
nodes_id_size == nodes_values_.size()
nodes_missing_value_tracks_true
nodes_modes
nodes_nodeids
nodes_nodeids_.size() == nodes_falsenodeids_.size()
nodes_nodeids_.size() == nodes_featureids_.size()
nodes_nodeids_.size() == nodes_modes_names_.size()
nodes_nodeids_.size() == nodes_truenodeids_.size()
nodes_nodeids_.size() == nodes_values_.size()
nodes_treeids
nodes_truenodeids
nodes_values
nominalpixelrange
NominalRange_0_255
NominalRange_16_235
Non concat axis dimensions must match: Axis 
Non per-tensor quantization is not supported now.
Non-empty ngram_counts is required
Non-empty ngram_indexes is required
non-empty pool_int64s is required if pool_strings not provided
NonMaxSuppression
NonZero
Non-zero status code returned while running Node: 
normalize_variance
normalized exponential
Normalized_0_1
Normalized_1_1
Normalizer
NormalizeVariance
not a directory
not a socket
not a stream
not connected
not enough memory
Not implemented
Not implemented field number 
Not implemented fused activation: 
Not satsified: (iou_threshold >= 0 && iou_threshold <= 1)
Not satsified: boxes_dims[0] == scores_dims[0]
Not satsified: boxes_dims[1] == scores_dims[2]
Not satsified: boxes_dims[2] == 4
Not satsified: boxes_shape.NumDimensions() == 3
Not satsified: data_n.DataType() == concat_result.DataType()
Not satsified: I_shape == X_shape
Not satsified: inferredOutputShape[dim] <= shape[dim]
Not satsified: inferredPad <= kernel_shape_[dim - 2]
Not satsified: input_count >= 1
Not satsified: input_dims >= 3
Not satsified: inputs_0_rank > 0
Not satsified: inputs_n_dims[axis_index] == inputs_0_dims[axis_index]
Not satsified: K_ == right_shape[0]
Not satsified: K_ == right_shape[right_num_dims - 2]
Not satsified: left_num_dims >= 1 && right_num_dims >= 1
Not satsified: left_padded_dims_[idx_dim] == 1
Not satsified: M_ == 1 && N_ == 1
Not satsified: num_dims_with_pad - 1 == num_output_dims
Not satsified: num_dims_with_pad - 2 == num_output_dims
Not satsified: num_dims_with_pad == num_output_dims
Not satsified: pooling_dims == kernel_shape_.size()
Not satsified: ret.IsOK()
Not satsified: right_padded_dims_[idx_dim] == 1
Not satsified: scores_shape.NumDimensions() == 3
Not satsified: tensor_shape->Shape().GetDims().size() == 1
Not satsified: X_shape.NumDimensions() >= 3
Not satsified: x_shape.NumDimensions() >= 3
not support normalize yet.
not supported
NOT_IMPLEMENTED
Notations:
NOTSET
Nt99t
NT99t
ntdll.dll
nteltF=Authu
Null input ptr
Null input X ptr
Null rois_ptr
NULL state in RunStateOnByte
nullptr != ends_tensor && ends_tensor->Shape().NumDimensions() == 1
nullptr != graph_viewer
nullptr != start_tensor && start_tensor->Shape().NumDimensions() == 1
nullptr != sub_graph && nullptr != sub_graph->GetMetaDef()
nullptr != tensor_type_base
nullptr != type_proto
nullptr == axes_tensor || start_tensor->Shape() == axes_tensor->Shape()
nullptr == steps_tensor || start_tensor->Shape() == steps_tensor->Shape()
num_categories_ > 0
num_classes is < 1
num_entries < 0 || gsl::narrow_cast<int64_t>(directions.size()) == num_entries
num_entries == int_categories.size()
num_outputs == copy_info.size()
num_samples is < 1
num_scan_inputs
Number of dimensions for batch indices should be exactly 1
Number of dimensions for rois should be exactly 
Number of elements of input 'scales' must be same as rank of input 'X' and element type must be float.
Number of elements of input 'scales' must be same as rank of input 'X'.
Number of entries in '
Number of entries in 'scan_input_axes' was 
Number of entries in 'scan_output_axes' was 
number of groups input channels and output channels are divided into.
number of groups input channels and output channels are divided into. default is 1.
Number of inputs (
Number of items must compose whole 
Number of neurons in the hidden layer
Number of neurons in the hidden layer.
Number of repeated copies to make of the input tensor.
Number of sampling points in the interpolation grid used to compute the output value of each pooled output bin. If > 0, then exactly sampling_ratio x sampling_ratio grid points are used. If == 0, then an adaptive number of grid points are used (computed as ceil(roi_width / output_width), and likewise for height). Default is 0.
Number of scan input axes specified (
Number of scan output axes specified (
Number of times to sample.
Number of top elements to retrieve
NumCapturesWalker::ShortVisit called
NupharExecutionProvider
Nushu
O$_^[
O(;O,tV
O,;G(
O,;G(uv9N,uqW
O\91t
O\YYf
O`91t
O0_^]
O4^_[
OD91t
Od91t
of dimensions [a_0, a_1 * ... * a_{n-1}], where a_0 is often the batch size.
offset
Offset
offset + size <= size_t(span.size())
offset >= 0 && static_cast<size_t>(offset) < node_values_.size()
Offsets
Ogham
OGLY0
OGLY0Q
OH91t
oHeight
Ol_Chiki
OL9_T|5
OL91t
Old_Hungarian
Old_Italic
Old_North_Arabian
Old_Permic
Old_Persian
Old_Sogdian
Old_South_Arabian
Old_Turkic
OLEAUT32.dll
oLuid
One (or two if bidirectional) activation function for input gate. The activation function must be one of the activation functions specified above. Optional: Default `Tanh` if not specified.
One float, indicates the value to be filled, default is 0
One float, indicates the value to be filled.
One of 'MAX,' 'L1,' 'L2'
One or more missing required inputs. 
One or more outputs forming list of tensors after splitting
one_class
OneHot
OneHot node must have three inputs.
OneHotEncoder
Only bool
Only one instance of LoggingManager created with InstanceType::Default can exist at any point in time.
Only one of keys_*'s can be set in label encoder.
Only one of values_*'s can be set in label encoder.
Only ONNX MLDataType can be registered
Only supports `int32_t` or `int64_t` inputs for starts/ends/axes/steps
ONNX Schema 
onnx.AttributeProto
onnx.FunctionProto
onnx.GraphProto
onnx.ModelProto
onnx.NodeProto
onnx.OperatorSetIdProto
onnx.StringStringEntryProto
onnx.TensorAnnotation
onnx.TensorProto
onnx.TensorProto.Segment
onnx.TensorShapeProto
onnx.TensorShapeProto.Dimension
onnx.TypeProto
onnx.TypeProto.Map
onnx.TypeProto.Opaque
onnx.TypeProto.Sequence
onnx.TypeProto.SparseTensor
onnx.TypeProto.Tensor
onnx.ValueInfoProto
ONNX_NAMESPACE::TensorProto::DataType_IsValid(dtype_) && dtype_ != ONNX_NAMESPACE::TensorProto::UNDEFINED
ONNX_NAMESPACE::TensorProto::DataType_IsValid(output_dtype_) && output_dtype_ != ONNX_NAMESPACE::TensorProto::UNDEFINED
onnxruntime
onnxruntime::`anonymous-namespace'::GetCurrentTimeString
onnxruntime::`anonymous-namespace'::TraverseFormalParametersWithTypeProto
onnxruntime::`anonymous-namespace'::WindowsEnv::FormatLibraryFileName
onnxruntime::`anonymous-namespace'::WindowsEnv::GetNumCpuCores
onnxruntime::BatchNorm<float>::BatchNorm
onnxruntime::BFCArena::AllocateRawInternal
onnxruntime::BFCArena::AllocationRegion::AllocationRegion
onnxruntime::BFCArena::AllocationRegion::IndexFor
onnxruntime::BFCArena::BFCArena
onnxruntime::BFCArena::ChunkFromHandle
onnxruntime::BFCArena::DeallocateRawInternal
onnxruntime::BFCArena::Extend
onnxruntime::BFCArena::FindChunkPtr
onnxruntime::BFCArena::FreeAndMaybeCoalesce
onnxruntime::BFCArena::InsertFreeChunkIntoBin
onnxruntime::BFCArena::Merge
onnxruntime::BFCArena::RegionManager::RegionFor
onnxruntime::BFCArena::RemoveFreeChunkFromBin
onnxruntime::BFCArena::RemoveFreeChunkIterFromBin
onnxruntime::BFCArena::Reserve
onnxruntime::BFCArena::SplitChunk
onnxruntime::BroadcastIterator::Append
onnxruntime::BroadcastIterator::Init
onnxruntime::BroadcastVariadic
onnxruntime::Cast<__int64>::Cast
onnxruntime::Cast<__int64>::Compute
onnxruntime::Cast<bool>::Cast
onnxruntime::Cast<bool>::Compute
onnxruntime::Cast<class std::basic_string<char,struct std::char_traits<char>,class std::allocator<char> > >::Cast
onnxruntime::Cast<class std::basic_string<char,struct std::char_traits<char>,class std::allocator<char> > >::Compute
onnxruntime::Cast<double>::Cast
onnxruntime::Cast<double>::Compute
onnxruntime::Cast<float>::Cast
onnxruntime::Cast<float>::Compute
onnxruntime::Cast<int>::Cast
onnxruntime::Cast<int>::Compute
onnxruntime::Cast<short>::Cast
onnxruntime::Cast<short>::Compute
onnxruntime::Cast<signed char>::Cast
onnxruntime::Cast<signed char>::Compute
onnxruntime::Cast<union onnxruntime::MLFloat16>::Cast
onnxruntime::Cast<union onnxruntime::MLFloat16>::Compute
onnxruntime::Cast<unsigned __int64>::Cast
onnxruntime::Cast<unsigned __int64>::Compute
onnxruntime::Cast<unsigned char>::Cast
onnxruntime::Cast<unsigned char>::Compute
onnxruntime::Cast<unsigned int>::Cast
onnxruntime::Cast<unsigned int>::Compute
onnxruntime::Cast<unsigned short>::Cast
onnxruntime::Cast<unsigned short>::Compute
onnxruntime::CastFloat16Data
onnxruntime::CastFromStringData
onnxruntime::CastToStringData
onnxruntime::Clip<float>::Clip
onnxruntime::common::Status::Status
onnxruntime::Compress::Compute
onnxruntime::ComputePadAndOutputShape
onnxruntime::ComputeTransposePadAndOutputShape
onnxruntime::ConcatBase::ConcatBase
onnxruntime::ConcatBase::PrepareForCompute
onnxruntime::ConstantFolding::ApplyImpl
onnxruntime::ConstantFolding::BuildTensorProtoForInitializer
onnxruntime::ConstantOfShape::ConstantOfShape
onnxruntime::ConstantOfShape::DispatchTypeAndFillOutput
onnxruntime::ConstantOfShape::SetValue
onnxruntime::ConstPointerContainer<class std::vector<class onnxruntime::NodeArg *,class std::allocator<class onnxruntime::NodeArg *> > >::at
onnxruntime::contrib::Affine<float>::Affine
onnxruntime::contrib::BahdanauAttention<float>::BahdanauAttention
onnxruntime::contrib::BahdanauAttention<float>::PrepareMemory
onnxruntime::contrib::DeepCpuAttnLstmOp::Compute
onnxruntime::contrib::DeepCpuAttnLstmOp::DeepCpuAttnLstmOp
onnxruntime::contrib::ExpandDims::Compute
onnxruntime::contrib::GatherNDBase::PrepareForCompute
onnxruntime::contrib::ImageScaler<float>::ImageScaler
onnxruntime::contrib::MaxpoolWithMask::Compute
onnxruntime::contrib::MurmurHash3::Compute
onnxruntime::contrib::Pad<float>::Compute
onnxruntime::contrib::Scale<float>::Scale
onnxruntime::contrib::Tokenizer::Tokenizer
onnxruntime::ConvTransposeBase::ComputePadsAndOutputShape
onnxruntime::CPUDataTransfer::CopyTensor
onnxruntime::data_types_internal::DataTypeRegistry::RegisterDataType
onnxruntime::data_types_internal::IsCompatible
onnxruntime::data_types_internal::SetMapTypes<__int64,__int64>::Set
onnxruntime::data_types_internal::SetMapTypes<__int64,class std::basic_string<char,struct std::char_traits<char>,class std::allocator<char> > >::Set
onnxruntime::data_types_internal::SetMapTypes<__int64,double>::Set
onnxruntime::data_types_internal::SetMapTypes<__int64,float>::Set
onnxruntime::data_types_internal::SetMapTypes<class std::basic_string<char,struct std::char_traits<char>,class std::allocator<char> >,__int64>::Set
onnxruntime::data_types_internal::SetMapTypes<class std::basic_string<char,struct std::char_traits<char>,class std::allocator<char> >,class std::basic_string<char,struct std::char_traits<char>,class std::allocator<char> > >::Set
onnxruntime::data_types_internal::SetMapTypes<class std::basic_string<char,struct std::char_traits<char>,class std::allocator<char> >,double>::Set
onnxruntime::data_types_internal::SetMapTypes<class std::basic_string<char,struct std::char_traits<char>,class std::allocator<char> >,float>::Set
onnxruntime::data_types_internal::SetSequenceType<__int64>::Set
onnxruntime::data_types_internal::SetSequenceType<class std::basic_string<char,struct std::char_traits<char>,class std::allocator<char> > >::Set
onnxruntime::data_types_internal::SetSequenceType<class std::map<__int64,float,struct std::less<__int64>,class std::allocator<struct std::pair<__int64 const ,float> > > >::Set
onnxruntime::data_types_internal::SetSequenceType<class std::map<class std::basic_string<char,struct std::char_traits<char>,class std::allocator<char> >,float,struct std::less<class std::basic_string<char,struct std::char_traits<char>,class std::allocator<char> > >,class std::allocator<struct std::pair<class std::basic_string<char,struct std::char_traits<char>,class std::allocator<char> > const ,float> > > >::Set
onnxruntime::data_types_internal::SetSequenceType<double>::Set
onnxruntime::data_types_internal::SetSequenceType<float>::Set
onnxruntime::DataTypeImpl::GetType<T>() == type_
onnxruntime::DataTypeImpl::TypeFromProto
onnxruntime::DeepCpuGruOp::Compute
onnxruntime::DeepCpuGruOp::DeepCpuGruOp
onnxruntime::DeepCpuLstmOp::Compute
onnxruntime::DeepCpuLstmOp::DeepCpuLstmOp
onnxruntime::DepthToSpace<float>::Compute
onnxruntime::DequantizeLinear<signed char>::Compute
onnxruntime::DequantizeLinear<unsigned char>::Compute
onnxruntime::DummyArena::Max
onnxruntime::DummyArena::Used
onnxruntime::Erf<float>::Compute
onnxruntime::ExecutionFrame::AllocateAsPerAllocationPlan
onnxruntime::ExecutionFrame::AllocateMLValueTensorSelfOwnBufferHelper
onnxruntime::ExecutionFrame::ExecutionFrame
onnxruntime::ExecutionFrame::GetAllocationPlan
onnxruntime::ExecutionFrame::TraceAllocate
onnxruntime::ExecutionFrame::TraceFree
onnxruntime::ExecutionProviders::Add
onnxruntime::ExLibLoader::~ExLibLoader
onnxruntime::Expand_8<__int64>::Compute
onnxruntime::Expand_8<bool>::Compute
onnxruntime::Expand_8<double>::Compute
onnxruntime::Expand_8<float>::Compute
onnxruntime::Expand_8<int>::Compute
onnxruntime::Expand_8<short>::Compute
onnxruntime::Expand_8<signed char>::Compute
onnxruntime::Expand_8<union onnxruntime::MLFloat16>::Compute
onnxruntime::Expand_8<unsigned __int64>::Compute
onnxruntime::Expand_8<unsigned char>::Compute
onnxruntime::Expand_8<unsigned int>::Compute
onnxruntime::Expand_8<unsigned short>::Compute
onnxruntime::EyeLike::Compute
onnxruntime::FeedsFetchesManager::SetDeviceCopyChecks
onnxruntime::Flatten::Compute
onnxruntime::Flatten::Flatten
onnxruntime::FunctionImpl::FunctionImpl
onnxruntime::FunctionKernel::FunctionKernel
onnxruntime::GatherBase::GatherBase
onnxruntime::Gemm<float,float,float,float>::Gemm
onnxruntime::GemmHelper::GemmHelper
onnxruntime::Graph::AddEdge
onnxruntime::Graph::AllocateNode
onnxruntime::Graph::CleanUnusedInitializers
onnxruntime::Graph::FuseSubGraph
onnxruntime::Graph::Graph
onnxruntime::Graph::NodeAtIndexImpl
onnxruntime::Graph::RemoveEdge
onnxruntime::Graph::Resolve
onnxruntime::Graph::SetGraphInputsOutputs
onnxruntime::Graph::SetInputs
onnxruntime::Graph::SetOutputs
onnxruntime::graph_utils::CanUpdateImplicitInputNameInSubgraphs
onnxruntime::graph_utils::GetNodeInputName
onnxruntime::graph_utils::GetNodeOutputName
onnxruntime::graph_utils::RemoveNodeWithSingleInitializerIn
onnxruntime::graph_utils::UpdateImplicitInputNameInSubgraph
onnxruntime::GraphPartitioner::Partition
onnxruntime::HandleNegativeAxis
onnxruntime::IdentityOp<0>::Compute
onnxruntime::IdentityOp<1>::Compute
onnxruntime::IExecutionFrame::GetMLValue
onnxruntime::IExecutionFrame::GetNodeIdxToMLValueIdx
onnxruntime::IExecutionFrame::GetOrCreateNodeOutputMLValue
onnxruntime::IExecutionFrame::IExecutionFrame
onnxruntime::IExecutionProvider::InsertAllocator
onnxruntime::If::Compute
onnxruntime::If::If
onnxruntime::IfImpl::Execute
onnxruntime::InferenceSession::~InferenceSession
onnxruntime::InferenceSession::AddPredefinedTransformers
onnxruntime::InferenceSession::CreateSubgraphSessionState
onnxruntime::InferenceSession::EndProfiling
onnxruntime::InferenceSession::InferenceSession
onnxruntime::InferenceSession::Initialize
onnxruntime::InferenceSession::InitializeSubgraphSessions
onnxruntime::InferenceSession::Load
onnxruntime::InferenceSession::NewIOBinding
onnxruntime::InferenceSession::Run
onnxruntime::Initializer::Initializer
onnxruntime::Initializer::ToProto
onnxruntime::InstanceNorm<float>::InstanceNorm
onnxruntime::IsInf::Compute
onnxruntime::IsInf::IsInf
onnxruntime::KernelRegistry::TryFindKernel
onnxruntime::Loop::Compute
onnxruntime::Loop::Loop
onnxruntime::LoopImpl::CreateInitialFeeds
onnxruntime::LpNorm<float>::LpNorm
onnxruntime::LRN<float>::Compute
onnxruntime::LRN<float>::LRN
onnxruntime::math::Im2colNd<float,class onnxruntime::CPUMathUtil,2>::operator ()
onnxruntime::math::Im2colNd<unsigned char,class onnxruntime::CPUMathUtil,2>::operator ()
onnxruntime::MatMulComputeHelper::Compute
onnxruntime::MatMulInteger<unsigned char,unsigned char,int>::Compute
onnxruntime::Max_6<float>::Compute
onnxruntime::MaxUnpool::Compute
onnxruntime::MaxUnpool::MaxUnpool
onnxruntime::Mean_6<float>::Compute
onnxruntime::MeanVarianceNormalization_0<float>::MeanVarianceNormalization_0
onnxruntime::Min_6<float>::Compute
onnxruntime::ml::CastMap::CastMap
onnxruntime::ml::CastMap::ComputeImpl
onnxruntime::ml::CategoryMapper::CategoryMapper
onnxruntime::ml::DictVectorizerOp<__int64,class std::basic_string<char,struct std::char_traits<char>,class std::allocator<char> > >::DictVectorizerOp
onnxruntime::ml::DictVectorizerOp<__int64,double>::DictVectorizerOp
onnxruntime::ml::DictVectorizerOp<__int64,float>::DictVectorizerOp
onnxruntime::ml::DictVectorizerOp<class std::basic_string<char,struct std::char_traits<char>,class std::allocator<char> >,__int64>::DictVectorizerOp
onnxruntime::ml::DictVectorizerOp<class std::basic_string<char,struct std::char_traits<char>,class std::allocator<char> >,double>::DictVectorizerOp
onnxruntime::ml::DictVectorizerOp<class std::basic_string<char,struct std::char_traits<char>,class std::allocator<char> >,float>::DictVectorizerOp
onnxruntime::ml::FeatureVectorizer::Compute
onnxruntime::ml::FeatureVectorizer::FeatureVectorizer
onnxruntime::ml::ImputerOp::Compute
onnxruntime::ml::ImputerOp::ImputerOp
onnxruntime::ml::LabelEncoder::LabelEncoder
onnxruntime::ml::LinearClassifier<__int64>::LinearClassifier
onnxruntime::ml::LinearClassifier<double>::LinearClassifier
onnxruntime::ml::LinearClassifier<float>::LinearClassifier
onnxruntime::ml::LinearClassifier<int>::LinearClassifier
onnxruntime::ml::LinearRegressor<float>::LinearRegressor
onnxruntime::ml::MakeCast
onnxruntime::ml::MakeNormalize
onnxruntime::ml::MakePack
onnxruntime::ml::Normalizer::Compute
onnxruntime::ml::Normalizer::Normalize
onnxruntime::ml::Normalizer::Normalizer
onnxruntime::ml::OneHotEncoderOp<__int64>::Compute
onnxruntime::ml::OneHotEncoderOp<__int64>::OneHotEncoderOp
onnxruntime::ml::OneHotEncoderOp<class std::basic_string<char,struct std::char_traits<char>,class std::allocator<char> > >::Compute
onnxruntime::ml::OneHotEncoderOp<class std::basic_string<char,struct std::char_traits<char>,class std::allocator<char> > >::OneHotEncoderOp
onnxruntime::ml::OneHotEncoderOp<double>::Compute
onnxruntime::ml::OneHotEncoderOp<double>::OneHotEncoderOp
onnxruntime::ml::OneHotEncoderOp<float>::Compute
onnxruntime::ml::OneHotEncoderOp<float>::OneHotEncoderOp
onnxruntime::ml::ScalerOp<__int64>::ScalerOp
onnxruntime::ml::ScalerOp<double>::ScalerOp
onnxruntime::ml::ScalerOp<float>::ScalerOp
onnxruntime::ml::ScalerOp<int>::ScalerOp
onnxruntime::ml::SVMClassifier<__int64>::SVMClassifier
onnxruntime::ml::SVMClassifier<double>::SVMClassifier
onnxruntime::ml::SVMClassifier<float>::SVMClassifier
onnxruntime::ml::SVMClassifier<int>::SVMClassifier
onnxruntime::ml::SVMCommon<__int64>::SVMCommon
onnxruntime::ml::SVMCommon<double>::SVMCommon
onnxruntime::ml::SVMCommon<float>::SVMCommon
onnxruntime::ml::SVMCommon<int>::SVMCommon
onnxruntime::ml::SVMRegressor<float>::SVMRegressor
onnxruntime::ml::TreeEnsembleClassifier<__int64>::Initialize
onnxruntime::ml::TreeEnsembleClassifier<__int64>::ProcessTreeNode
onnxruntime::ml::TreeEnsembleClassifier<__int64>::TreeEnsembleClassifier
onnxruntime::ml::TreeEnsembleClassifier<double>::Initialize
onnxruntime::ml::TreeEnsembleClassifier<double>::ProcessTreeNode
onnxruntime::ml::TreeEnsembleClassifier<double>::TreeEnsembleClassifier
onnxruntime::ml::TreeEnsembleClassifier<float>::Initialize
onnxruntime::ml::TreeEnsembleClassifier<float>::ProcessTreeNode
onnxruntime::ml::TreeEnsembleClassifier<float>::TreeEnsembleClassifier
onnxruntime::ml::TreeEnsembleClassifier<int>::Initialize
onnxruntime::ml::TreeEnsembleClassifier<int>::ProcessTreeNode
onnxruntime::ml::TreeEnsembleClassifier<int>::TreeEnsembleClassifier
onnxruntime::ml::TreeEnsembleRegressor<float>::TreeEnsembleRegressor
onnxruntime::ml::write_scores
onnxruntime::ml::ZipMapOp::ZipMapOp
onnxruntime::MLValueTensorSlicer<struct OrtValue const >::Create
onnxruntime::MLValueTensorSlicer<struct OrtValue const >::Iterator::operator *
onnxruntime::MLValueTensorSlicer<struct OrtValue>::Create
onnxruntime::MLValueTensorSlicer<struct OrtValue>::Iterator::operator *
onnxruntime::Mod::Compute
onnxruntime::Mod::Mod
onnxruntime::mod_internal::BroadCastFMod
onnxruntime::mod_internal::BroadCastMFloat16FMod
onnxruntime::mod_internal::BroadCastMod
onnxruntime::Multinomial::Multinomial
onnxruntime::Node::ForEachWithIndex(node.InputDefs(), [this, &kci](const onnxruntime::NodeArg& arg, size_t index) { if (kci && kci->kernel_def->IsInputOnCpu(index)) non_provider_input_defs_.insert(&arg); else provider_input_defs_.insert(&arg); return Status::OK(); }).IsOK()
onnxruntime::NodeIndexInfo::GetMLValueIndex
onnxruntime::NodeIndexInfo::GetNodeOffset
onnxruntime::NodeIndexInfo::Init::<lambda_6b96036581b66cdf82b5f39e2bc23e66>::operator ()
onnxruntime::NodeIndexInfo::Init::<lambda_961060303c5a5a6cf5cad068e6081a1d>::operator ()
onnxruntime::NonMaxSuppression::Compute
onnxruntime::NonMaxSuppression::NonMaxSuppression
onnxruntime::NonMaxSuppression::ParepareCompute
onnxruntime::NonTensorTypeBase::IsMapCompatible
onnxruntime::NonTensorTypeBase::IsSequenceCompatible
onnxruntime::NonZero<__int64>::Compute
onnxruntime::NonZero<bool>::Compute
onnxruntime::NonZero<float>::Compute
onnxruntime::NonZero<int>::Compute
onnxruntime::OpKernel::ComputeAsync
onnxruntime::OpKernelContext::GetOrCreateOutputMLValue
onnxruntime::OpKernelContext::Input
onnxruntime::OpKernelContext::NumVariadicInputs
onnxruntime::OpKernelContext::OpKernelContext
onnxruntime::OpKernelContext::Output
onnxruntime::OpKernelContext::OutputMLValue
onnxruntime::OpKernelInfo::GetAllocatorInfo
onnxruntime::OpNodeProtoHelper<class onnxruntime::ProtoHelperNodeContext>::GetAttrs
onnxruntime::OpNodeProtoHelper<struct onnx::InferenceContext>::GetAttrs
onnxruntime::OptimizerExecutionFrame::Info::Info
onnxruntime::PadBase::PadBase
onnxruntime::PadCpuImpl
onnxruntime::ParallelExecutor::RunNodeAsyncInternal
onnxruntime::PlaceNode
onnxruntime::PlannerImpl::AllocPlan
onnxruntime::PlannerImpl::Buffer
onnxruntime::PlannerImpl::GetElementSize
onnxruntime::PlannerImpl::GetLocationForNodeInput
onnxruntime::PlannerImpl::Index
onnxruntime::PlannerImpl::ProcessDef
onnxruntime::PlannerImpl::Reuse
onnxruntime::PlannerImpl::UseCount
onnxruntime::Pool<float,class onnxruntime::LpPool>::Compute
onnxruntime::Pool<float,class onnxruntime::MaxPool<8> >::Compute
onnxruntime::PoolBase::Compute
onnxruntime::PoolBase::ComputeSizePadDilations
onnxruntime::PoolBase::InferOutputSize
onnxruntime::PoolBase::PoolBase
onnxruntime::PoolBase::SetOutputSize
onnxruntime::PoolProcessContext::init
onnxruntime::PrepareForReduce
onnxruntime::profiling::Profiler::EndTimeAndRecordEvent
onnxruntime::profiling::Profiler::Initialize
onnxruntime::profiling::Profiler::StartProfiling
onnxruntime::QLinearConv::ScaleAndZeropointPairValidationHelper
onnxruntime::QLinearMatMul<unsigned char,unsigned char,unsigned char>::Compute
onnxruntime::QuantizeLinear<signed char>::Compute
onnxruntime::QuantizeLinear<unsigned char>::Compute
onnxruntime::RandomNormal::RandomNormal
onnxruntime::RandomNormalCompute
onnxruntime::RandomNormalLike::RandomNormalLike
onnxruntime::RandomUniform::RandomUniform
onnxruntime::RandomUniformCompute
onnxruntime::RandomUniformLike::RandomUniformLike
onnxruntime::ReduceKernelBase<0>::ReduceKernelBase
onnxruntime::ReduceKernelBase<1>::ReduceKernelBase
onnxruntime::Reshape::Compute
onnxruntime::Reshape_1::Reshape_1
onnxruntime::ReshapeHelper::ReshapeHelper
onnxruntime::ReverseSequenceOp::Compute
onnxruntime::ReverseSequenceOp::ReverseSequenceOp
onnxruntime::rnn::detail::ComputeGemm
onnxruntime::rnn::detail::deepcpu::ActivationFuncByName
onnxruntime::rnn::detail::deepcpu::GruOutputGateFuncByName
onnxruntime::rnn::detail::deepcpu::GruResetGateFuncByName
onnxruntime::rnn::detail::deepcpu::LstmMergeGatesFuncByName
onnxruntime::rnn::detail::MakeDirection
onnxruntime::rnn::detail::NormalizeActivationArgumentAndGetAlphaBetaCount
onnxruntime::rnn::detail::SafeRawConstPointer
onnxruntime::rnn::detail::SafeRawPointer
onnxruntime::RNN<float>::RNN
onnxruntime::RoiAlign<double>::RoiAlign
onnxruntime::RoiAlign<float>::RoiAlign
onnxruntime::RoiPool<float>::Compute
onnxruntime::RoiPool<float>::RoiPool
onnxruntime::SaveInitializedTensors
onnxruntime::SaveInputOutputNamesToNodeMapping
onnxruntime::SaveKernels
onnxruntime::SaveMLValueNameIndexMapping
onnxruntime::ScaleAndZeropointPairValidationHelper
onnxruntime::scan::detail::CreateFeedsFetchesManager
onnxruntime::scan::detail::IterateSequence
onnxruntime::scan::detail::LoopStateVariable::Next
onnxruntime::scan::detail::OutputIterator::AllocateFinalOutput
onnxruntime::scan::detail::OutputIterator::GetOutput
onnxruntime::scan::detail::OutputIterator::operator *
onnxruntime::scan::detail::OutputIterator::operator ++
onnxruntime::scan::detail::ReadDirections
onnxruntime::Scan<8>::Compute
onnxruntime::Scan<8>::Scan
onnxruntime::Scan<9>::Compute
onnxruntime::Scan<9>::Scan
onnxruntime::Scan8Impl::CreateLoopStateVariables
onnxruntime::ScanImpl::CreateLoopStateVariables
onnxruntime::ScanImpl::TransposeOutput
onnxruntime::Scatter::Compute
onnxruntime::Scatter::Scatter
onnxruntime::SequentialExecutor::Execute
onnxruntime::SessionState::AddInitializedTensor
onnxruntime::SessionState::AddSubgraphSessionState
onnxruntime::SessionState::CalculateNodeIndexInfo
onnxruntime::SessionState::GetNodeIndexInfo
onnxruntime::SessionState::SetGraphViewer
onnxruntime::SessionStateInitializer::InitializeAndSave
onnxruntime::Shrink::Compute
onnxruntime::Shrink::Shrink
onnxruntime::SizeFromDim
onnxruntime::SizeToDim
onnxruntime::Slice<__int64,0>::Compute
onnxruntime::Slice<__int64,1>::Compute
onnxruntime::Slice<bool,0>::Compute
onnxruntime::Slice<bool,1>::Compute
onnxruntime::Slice<class std::basic_string<char,struct std::char_traits<char>,class std::allocator<char> >,0>::Compute
onnxruntime::Slice<class std::basic_string<char,struct std::char_traits<char>,class std::allocator<char> >,1>::Compute
onnxruntime::Slice<double,0>::Compute
onnxruntime::Slice<double,1>::Compute
onnxruntime::Slice<float,0>::Compute
onnxruntime::Slice<float,1>::Compute
onnxruntime::Slice<int,0>::Compute
onnxruntime::Slice<int,1>::Compute
onnxruntime::Slice<short,0>::Compute
onnxruntime::Slice<short,1>::Compute
onnxruntime::Slice<signed char,0>::Compute
onnxruntime::Slice<signed char,1>::Compute
onnxruntime::Slice<union onnxruntime::MLFloat16,0>::Compute
onnxruntime::Slice<union onnxruntime::MLFloat16,1>::Compute
onnxruntime::Slice<unsigned __int64,0>::Compute
onnxruntime::Slice<unsigned __int64,1>::Compute
onnxruntime::Slice<unsigned char,0>::Compute
onnxruntime::Slice<unsigned char,1>::Compute
onnxruntime::Slice<unsigned int,0>::Compute
onnxruntime::Slice<unsigned int,1>::Compute
onnxruntime::Slice<unsigned short,0>::Compute
onnxruntime::Slice<unsigned short,1>::Compute
onnxruntime::SliceBase::FillVectorsFromInput
onnxruntime::SliceBase::SliceBase
onnxruntime::SliceIterator<__int64>::Init
onnxruntime::SliceIterator<bool>::Init
onnxruntime::SliceIterator<class std::basic_string<char,struct std::char_traits<char>,class std::allocator<char> > >::Init
onnxruntime::SliceIterator<double>::Init
onnxruntime::SliceIterator<float>::Init
onnxruntime::SliceIterator<int>::Init
onnxruntime::SliceIterator<short>::Init
onnxruntime::SliceIterator<signed char>::Init
onnxruntime::SliceIterator<union onnxruntime::MLFloat16>::Init
onnxruntime::SliceIterator<unsigned __int64>::Init
onnxruntime::SliceIterator<unsigned char>::Init
onnxruntime::SliceIterator<unsigned int>::Init
onnxruntime::SliceIterator<unsigned short>::Init
onnxruntime::SliceSkips::SliceSkips
onnxruntime::SpaceDepthBase::SpaceDepthBase
onnxruntime::SpaceToDepth<float>::Compute
onnxruntime::Split::Compute
onnxruntime::SplitBase::SplitBase
onnxruntime::SqueezeBase::ComputeOutputShape
onnxruntime::SqueezeBase::SqueezeBase
onnxruntime::string_normalizer::Locale::Locale
onnxruntime::StringNormalizer::StringNormalizer
onnxruntime::StringToAutoPadType
onnxruntime::Sum_6<float>::Compute
onnxruntime::TaskThreadPool::~TaskThreadPool
onnxruntime::Tensor::Data
onnxruntime::Tensor::DataAsSpan
onnxruntime::Tensor::DataRaw
onnxruntime::Tensor::Init
onnxruntime::Tensor::MutableData
onnxruntime::Tensor::MutableDataAsSpan
onnxruntime::Tensor::MutableDataRaw
onnxruntime::Tensor::Size
onnxruntime::Tensor::Tensor
onnxruntime::TensorAllocator<class std::basic_string<char,struct std::char_traits<char>,class std::allocator<char> > >::TensorAllocator
onnxruntime::TensorAllocator<float>::TensorAllocator
onnxruntime::TensorAllocator<int>::TensorAllocator
onnxruntime::TensorShape::SizeFromDimension
onnxruntime::TensorShape::SizeToDimension
onnxruntime::TensorShape::Slice
onnxruntime::TensorTypeBase::GetElementType
onnxruntime::TensorTypeBase::IsCompatible
onnxruntime::TfIdfVectorizer::TfIdfVectorizer
onnxruntime::Tile::Compute
onnxruntime::TopK<10,float>::TopK
onnxruntime::TopK<9,float>::TopK
onnxruntime::transformer_utils::GenerateRewriteRules
onnxruntime::transformer_utils::GenerateTransformers
onnxruntime::TransformerMemcpyImpl::ProcessDefs
onnxruntime::TransformerMemcpyImpl::ProcessInitializers
onnxruntime::TransformerMemcpyImpl::ProcessInitializers::<lambda_96d3b593d5201521d990452d7883196b>::operator ()
onnxruntime::Transpose::Compute
onnxruntime::TransposeBase::TransposeBase
onnxruntime::UnsqueezeBase::PrepareCompute
onnxruntime::UnsqueezeBase::UnsqueezeBase
onnxruntime::Upsample<float>::BaseCompute
onnxruntime::Upsample<float>::Compute
onnxruntime::Upsample<int>::BaseCompute
onnxruntime::Upsample<int>::Compute
onnxruntime::Upsample<unsigned char>::BaseCompute
onnxruntime::Upsample<unsigned char>::Compute
onnxruntime::UpsampleBase::ParseScalesData
onnxruntime::UpsampleBase::ScalesValidation
onnxruntime::UpsampleBase::StringToUpsampleMode
onnxruntime::UpsampleBase::UpsampleBase
onnxruntime::utils::CachedCopyInputsAcrossDevices
onnxruntime::utils::CachedCopyOutputsAcrossDevices
onnxruntime::utils::CachedSetupFetchesForExecute
onnxruntime::utils::CopyInputsAcrossDevices
onnxruntime::utils::CopyOneInputAcrossDevices
onnxruntime::utils::ExecuteGraph
onnxruntime::utils::GetMLDataType
onnxruntime::utils::SetupFetchesForExecute
onnxruntime::Where<class std::basic_string<char,struct std::char_traits<char>,class std::allocator<char> > >::Compute
onnxruntime::Where<float>::Compute
onnxruntime::Where<int>::Compute
onnxruntime_profile_
OnnxRuntimeProfiling
Op registered for 
Op;Otu
op_kernel_info.GetAttr<float>("bias", &bias_temp).IsOK()
op_kernel_info.GetAttr<float>("epsilon", &epsilon_).IsOK()
op_kernel_info.GetAttr<float>("lambd", &lambd_temp).IsOK()
op_kernel_info.GetAttr<int64_t>("axis", &axis_).IsOK()
op_kernel_info.GetAttr<int64_t>("axis", &axis_temp).IsOK()
op_kernel_info.GetAttr<int64_t>("k", &k_temp).IsOK()
op_kernel_info.GetAttr<int64_t>("p", &p_).IsOK()
op_name
op_type
OP+OL
opaque
opaque(
open file 
OpenProcess
OpenSemaphoreW
operation canceled
operation in progress
operation not permitted
operation not supported
operation would block
Operator '
Operator Name
OperatorPreference
OpKernel was null
Optional 1D bias to be added to the convolution, has size of M.
Optional initial value of the cell. If not specified - assumed to be 0. It has shape `[num_directions, batch_size, hidden_size]`.
Optional initial value of the hidden. If not specified - assumed to be 0. It has shape `[num_directions, batch_size, hidden_size]`.
Optional list of output lengths (see also arg 'split')
Optional scaling values used by some activation functions. The values are consumed in the order of activation functions, for example (f, g, h) in LSTM.
Optional scaling values used by some activation functions. The values are consumed in the order of activation functions, for example (f, g, h) in LSTM. Default values are the same as of corresponding ONNX operators.
Optional scaling values used by some activation functions. The values are consumed in the order of activation functions, for example (f, g, h) in LSTM. Default values are the same as of corresponding ONNX operators.For example with LeakyRelu, the default alpha is 0.01.
Optional tensor specifying lengths of the sequences in a batch. If not specified - assumed all sequences in the batch to have length `seq_length`. It has shape `[batch_size]` 
Optional tensor specifying lengths of the sequences in a batch. If not specified - assumed all sequences in the batch to have length `seq_length`. It has shape `[batch_size]`.
Optional tensor specifying lengths of the sequences in a batch. If this input is not specified, all sequences are assumed to be of the maximum sequence length (the dimension of the sequence axis of the scan_input tensors).
Original tensor
OriginalFilename
originatingContextId
originatingContextMessage
originatingContextName
Oriya
ort_value.Fence() == nullptr
ort_value.IsAllocated()
ort_value.IsTensor()
ort_value_idx == NodeIndexInfo::kInvalidEntry || (ort_value_idx >= 0 && static_cast<size_t>(ort_value_idx) < all_values_.size())
ort_value_idx >= 0 && static_cast<size_t>(ort_value_idx) < alloc_plan.size()
ort_value_index >= 0 && ort_value_index <= ort_value_name_idx_map_.MaxIdx()
ort_value_index >= 0 && static_cast<size_t>(ort_value_index) < all_values_.size()
ort_value_index >= 0 && static_cast<size_t>(ort_value_index) < alloc_plan.size()
ort_value_name_idx_map.MaxIdx() > 0
OrtAllocatorInfo: [
OrtValue has not been allocated so can't be sliced.
OrtValue indexes should have been populated.
OrtValue shape verification failed. Current shape:
OrtValue::Get
OrtValue::GetMutable
Osage
Osmanya
Out of bound access to array
outer_scope_node_args_consumed.empty()
Outgoing node could not be found.
output
Output 
output 
output (always 2D tensor)
output (floating tensor) and mask (`Tensor<bool>`). Depending on whether it is
output (Tensor<float>) and mask (Tensor<bool>). Depending on whether it is in
Output case #1: Y, mean, var, saved_mean, saved_var (training mode)
Output case #2: Y (test mode)
Output channels M is not divisible by group.
output data (Tensor<T>) where the function `f(x) = slope * x for x < 0`,
Output data after scaling
Output data tensor from average or max pooling across the input tensor. Dimensions will vary based on various kernel, stride, and pad sizes. Floor value of the dimension is used
Output data tensor from Lp pooling across the input tensor. Dimensions will vary based on various kernel, stride, and pad sizes.
Output data tensor from pooling across the input tensor. Dimensions will be N x C x 1 x 1
Output data tensor that contains the result of the convolution. The output dimensions are functions of the kernel size, stride size, and pad lengths.
Output data tensor that contains the result of the convolution. The output dimensions are functions of the kernel size, stride size, pad lengths and group count. The number of channels in the output should be equal to W.shape[1] * group (assuming zero based indices of the shape array)
Output data tensor that contains the result of the unpooling.
Output data.
Output data. If strings are input, the output values are integers, and vice versa.
Output height cannot be smaller than input height.
Output input image height provided. Height is set to zero.
Output input image width provided. Width is set to zero.
Output OrtValue has not been created for loop state variable output 
Output tensor
Output tensor (same size as X)
Output tensor containing the same value of the provided tensor.
Output tensor of [N, C * blocksize * blocksize, H/blocksize, W/blocksize].
Output tensor of [N, C/(blocksize * blocksize), H * blocksize, W * blocksize].
Output tensor of random values drawn from normal distribution
Output tensor of random values drawn from uniform distribution
Output tensor of same shape and type as input.
Output tensor of shape (M, N).
Output tensor of shape specified by 'input'.If attribute 'value' is specified, the value and datatype of the output tensor is taken from 'value'.If attribute 'value' is not specified, the value in the output defaults to 0, and the datatype defaults to float32.
Output tensor of the same dimension and type as tensor input. output_dim[i] = input_dim[i] * repeats[i]
Output tensor with clipped input elements
Output tensor with shape [batch_size, sample_size], where sample_size is the number of times to sample. Each value along the axis zero represents the outcome of the corresponding sample in a batch.
Output tensor with the same shape as input with type specified by the 'to' argument
Output tensor, same shape as input tensor T1.
Output tensor, which has the shape and type as input tensor
Output tensor.
Output tensor. Same dimension as inputs.
Output type is determined by the specified 'values_*' attribute.
Output type must be int32 or int64
Output vector incorrectly sized: output_names.size(): 
Output vector pointer is NULL
Output was expected to have tensor type. Got 
Output width cannot be smaller than input width.
Output:
output_height
output_height >= H
output_mlvalue
output_node
output_padding
output_sequence
output_shape
output_shape can also be explicitly specified in which case pads values are auto generated using these equations:
'output_shape' must be rank 1 tensor.
'output_shape' must have same number of elements as the shape of input tensor X.
output_width
output_width >= W
OutputCellSingleTensor
outputCount
OutputCount
OutputDebugStringA
OutputDebugStringW
OutputGateTensor
OutputIndexTensor
OutputIndicesTensor
OutputPadding
outputs
Outputs
Outputs from Scan are not optional and should never be null.
outputs...
OutputSequenceTensor
OutputSingleTensor
OutputTensor
OutputTensors
OutputValueTensor
oWidth
owner dead
OX91t
p p t y 
p value of the Lp norm used to pool over the input data, default is 2.0.
p value of the Lp norm used to pool over the input data.
p.second
P;W,u&
p_ == 1 || p_ == 2
p_fetches->size(): 
p_graph
p_input_provider
p_int < base_int + memory_size_
p_int >= base_int
p_ml_value
p_mlvalue
p_provider
p_type != nullptr
P=333
p063G3
p7M}6p7M
Pad should be smaller than kernel.
pad type not supported
pad type not supported.
pad_value
Padding for the beginning and ending along each axis, it can take any value greater than or equal to 0. The value represent the number of pixels added to the beginning and end part of the corresponding axis. `pads` format should be as follow [x1_begin, x2_begin...x1_end, x2_end,...], where xi_begin the number of pixels added at the beginning of axis `i` and xi_end, the number of pixels added at the end of axis `i`. This attribute cannot be used simultaneously with auto_pad attribute.
Padding for the beginning and ending along each axis, it can take any value greater than or equal to 0. The value represent the number of pixels added to the beginning and end part of the corresponding axis. `pads` format should be as follow [x1_begin, x2_begin...x1_end, x2_end,...], where xi_begin the number of pixels added at the beginning of axis `i` and xi_end, the number of pixels added at the end of axis `i`. This attribute cannot be used simultaneously with auto_pad attribute. If not present, the padding defaults to 0 along start and end of each axis.
Padding for the beginning and ending along each axis, it can take any value greater than or equal to 0.The value represent the number of pixels added to the beginning and end part of the corresponding axis.`pads` format should be as follow [x1_begin, x2_begin...x1_end, x2_end,...], where xi_begin the number ofpixels added at the beginning of axis `i` and xi_end, the number of pixels added at the end of axis `i`.This attribute cannot be used simultaneously with auto_pad attribute. If not present, the padding defaultsto 0 along start and end of each axis.
PaddingMode
paddings
PaddingValue
'pads' has wrong number of values
'pads' input must be a 1D (shape: [input_rank]) or 2D tensor (shape: [1, input_rank]) of type int64
Pads tensor should be a 1D tensor of shape [2 * input_rank] or a 2D tensor of shape [1, 2 * input_rank]
Pads tensor should be an INT64 tensor
Pads tensor size should be equal to twice the input dimension count 
pads_[dim] < kernel_shape_[dim] && pads_[dim + kernel_shape_.size()] < kernel_shape_[dim]
pads_size == 2 * dimension_count
pads_tensor.DataType() == DataTypeImpl::GetType<int64_t>()
pads_tensor_dims.size() == 1 || (pads_tensor_dims.size() == 2 && pads_tensor_dims[0] == 1)
Pahawh_Hmong
Palmyrene
Parallel execution is currently not supported for the registered CUDA Execution Provider.
ParallelExecutor::Execute
ParametricSoftplus
parse
parsing 
PartA_PrivTags
Pass 1 to enable broadcasting
pattern too large - compile failed
pattern too large - reverse compile failed
Pau_Cin_Hau
PCM>a
PeepholeTensor
Performs element-wise binary {name} (with limited broadcast support).
Performs element-wise binary {name} (with Numpy-style broadcasting support).
perm: 
permission denied
Ph ~-
Ph >1
Ph d.
Ph o.
Ph p0
Ph$B.
Ph$u.
Ph(|.
Ph(X.
Ph,l1
Ph,R.
Ph@^.
Ph@~-
Ph@=1
Ph@K1
Ph@l.
Ph@Q.
Ph\#1
Ph\&1
Ph\a.
Ph`~-
Ph`J1
Ph|@1
Ph|2-
Ph|a1
Ph|F1
Ph|q.
Ph<i-
Ph<r.
Ph<t.
Ph0(-
Ph0~-
Ph0<1
Ph001
Ph0h.
Ph0s0
Ph0t0
Ph4#1
Ph4G1
Ph4U.
Ph8k0
Ph8o0
Ph8W1
Phags_Pa
Phd!0
Phd:.
PhD31
PhD7.
Phd71
Phd91
Phdw.
Phdw0
PhdX1
Phh,.
Phh\0
PhH\1
Phh{0
Phh0-
PhhD.
PhhI1
PhhK-
PhHL.
PhhS.
Phl90
PhLe.
PhLO1
Phlx0
Phly0
Phoenician
PhP.1
Php~-
PhP>.
Php01
PhPg.
PhPI.
PhpP.
PhPs.
Phpv.
PhPV1
PhpW1
PhpY1
Pht!0
Pht..
Pht_.
PhT21
PhTA1
PhTE.
PhTE1
PhTT-
PhX-1
PhxC.
PhxG.
PhXh-
PhxJ.
PhxK-
PhXZ.
Pj!SSRQ
Pj,Zj(X
PjoZRY
Please fetch output tensor with specified shape.
poll_strings duplicate 
pool_int64s
pool_int64s duplicate 
pool_strings
pool_strings must not be empty if specified
pooled_height_ > 0
pooled_shape
pooled_shape.size() == 2
pooled_width_ > 0
PooledSize
Popularity of each node, used for performance and may be omitted.
position_ >= 0 && position_ < sequence_length_
positive
post_transform
Pow takes input data (Tensor<T>) and exponent Tensor, and
PPPP9G<u9
PPPPPPP
PPWQPh
PQhp*/
PQj\Z
PQjsZ
PQPVQ
PQPVW
PQQSVW
PQQWR
PQQWS
PQQWV
PQSQV
PQSVW
PQVQS
Preferred Layout
PRelu
PRelu takes input data (Tensor<T>) and slope tensor as input, and produces one
PreviousTensor
prob_a
prob_b
proba_.size() == probb_.size()
Process ID
Processed_STD
ProcessInfo
Processing batch
producer_of_
produces one output data (Tensor<T>) where the function `f(x) = x^exponent`,
product
ProductName
ProductVersion
promise already satisfied
PropagatedOperatorPreference
proto != nullptr
protocol error
protocol not supported
provided axis. The resulted tensor has the same rank as the input if keepdims equal 1.
provider
Provider 
Provider doesn't return correct number of compiled functions
PRQVPW
PRQWV
Psalter_Pahlavi
PSj@Z
PSj=Z
Pt+Pp
pt+pp
PWj"Z
Q0+Q,
Q9CPt
Q9G@t
Qh8?:
QhdT-
QhpP.
QLinearConv
QLinearMatMul
QQQQSPQQ
QQQVh
QQRh`Q8
QQSPQQ
QQSVIW
QQSVW
QQSVW3
QQSVWj 
QQSVWj`
QQVWQ
qR;/(
QRh0S0
QRPh\
QRPh|
QSShpP.
QSVPP
QSVWh
QSVWj
qt+qp
Quantized matrix multiply results from a * b
QuantizeLinear
QueryPerformanceCounter
QueryPerformanceFrequency
QVhtP.
QVhTX/
QVQSP
QVVWh
QWh@R/
QWh0R/
QWhTX/
QWWhpP.
r&;N,
R->Shape()[1] == 5
R1^1~1
R9CDt
raB3G
RaiseException
RaiseFailFastException
RandomNormal
RandomNormalLike
RandomUniform
RandomUniformLike
Range
Rank 1 tensor containing exactly two elements, in the format [off_value, on_value], where 'on_value' is the value used for filling locations specified in 'indices' input tensor, and 'off_value' is the value used for filling locations other than those specified in 'indices' input tensor. 
Rank 1 tensor of booleans to indicate which slices or data elements to be selected. Its length can be less than the input length alone the axis or the flattened input size if axis is not specified. In such cases data slices or elements exceeding the condition length are discarded.
rank must be greater than axis
Ranks of input data are different, cannot concatenate them, expected rank: 
ratio
raw_data
RD11<
RDEF|
RE2: invalid startpos, endpos pair. [
RE2: unexpected op: 
read only file system
ReadFile
ReadFile 
ReadFileAsString: File is too large
ReadFileAsString: 'fname' cannot be NULL
ReadFileAsString: please specify length to read
Real memory steps 
Received nullptr for custom registry
Received nullptr for exec provider
Received nullptr for graph transformer
Reciprocal
RecurrenceTensor
reduced
Reduced output tensor with integer data type.
Reduced output tensor.
ReduceL1
ReduceL2
ReduceLogSum
ReduceLogSumExp
ReduceMax
ReduceMean
ReduceMin
ReduceProd
ReduceSum
ReduceSumInteger
ReduceSumSquare
reference(Lhs: %d cells %dx%d %s, Rhs: %d cells %dx%d %s)
reflect
Regexp not destroyed.
RegisterCustomRegistry
RegisterOperatorKernel
RegisterOperatorSetSchema
Regression outputs (one per target, per example).
Regression outputs (one score per target per example).
Rejang
reject this operator. Please update your model as soon 
Release_State_
ReleaseMutex
ReleaseSemaphore
ReleaseSRWLockExclusive
ReleaseSRWLockShared
Remainder tensor
RemoveDuplicateCastTransformer
'repeat' input tensor must be 1 dimensional
'repeat' input tensor must have the same length as the 'input' tensor
Repeats
repeats
RepeatsCount
RepetitionWalker::ShortVisit called
replaced_value_float
replaced_value_int64
Requested size is too large to fit into size_t.
requested_shape[i] >= -1
Required attribute '
Required attribute axis is missing
Required inputs: 
Required min_gram_length must be positive: 
required_provider
REQUIREMENT_NOT_REGISTERED
reserved_chunks_.find(ptr) == reserved_chunks_.end()
ResetEvent
Reshape
Reshape_1
reshaped
Reshaped data.
Reshaped tensor with same data as input.
Resize
Resolve subgraph failed:
resource deadlock would occur
resource unavailable try again
result out of range
Result tensor.
Result, has same dimensions and type as A
Result, has same element type as two inputs
Result, has same shape and type as input
Result, has same type as input, with H and W dimensions reduced.
ReturnHr
Returns the tensor resulted from performing the `{name}` logical operation
reused != reused_for
reverse
ReverseSequence
Rgba8
Rh L0
Rh$}.
Rh(M0
Rh\`0
Rh\g/
Rh`@/
Rh`H0
RhDF/
Rhdp/
Rhdw.
RhhE0
RhhL0
RhL>/
RhpU/
RhTu/
RhXK0
RichUT
Right input tensor for the logical operator.
right operand cannot broadcast on dim 
right.NumDimensions() == 2
RoGetActivationFactory
RoGetAgileReference
ROI pool output shape (height, width).
RoI pooled output 4-D tensor of shape (num_rois, channels, pooled_shape[0], pooled_shape[1]).
RoI pooled output, 4-D tensor of shape (num_rois, C, output_height, output_width). The r-th batch element Y[r-1] is a pooled feature map corresponding to the r-th RoI X[r-1].
roi_batch_id < batch_size
roi_batch_id >= 0
RoiAlign
RoIs (Regions of Interest) to pool over. Should be a 2-D tensor of shape (num_rois, 5) given as [[batch_id, x1, y1, x2, y2], ...].
RoIs (Regions of Interest) to pool over; rois is 2-D input of shape (num_rois, 4) given as [[x1, y1, x2, y2], ...]. The RoIs' coordinates are in the coordinate system of the input image. Each coordinate set has a 1:1 correspondence with the 'batch_indices' input.
rois input tensor has wrong dimension
RoIs tensor must have 2 dimensions
ROITensor
RoOriginateError
RoOriginateErrorW
RoOriginateLanguageException
RoTransformError
roundf
rt (.) (Ht-1 * (Rh^T) + Rbh)
rt (.) Ht-1
rt+rp
RtlDllShutdownInProgress
Runic
running (training) or estimated (testing) mean tensor of shape (C).
running (training) or estimated (testing) variance tensor of shape (C).
Running with tag: 
RunStateOnByteUnlocked failed after Reset
RunStateOnByteUnlocked failed after ResetCache
RUNTIME_EXCEPTION
RuntimeError
RuntimePerf
runtimeSessionId
s QQQ
s,9s0
s49w,t0
Samaritan
SAME_LOWER
SAME_UPPER
sample_size
SampleOp
Sampling ratio should be >=0, but it was 
sampling_ratio
sampling_ratio_ >= 0
Saurashtra
Saved mean used during training to speed up gradient computation.
Saved mean used during training to speed up gradient computation. Should not be used for testing.
Saved variance used during training to speed up gradient computation.
Saved variance used during training to speed up gradient computation. Should not be used for testing.
saved_mean
saved_var
SaveMLValueNameIndexMapping
Saving initialized tensors.
Saving kernels.
sbetu
Scalar multiplier for input tensor C, the default value is 1.0.
Scalar multiplier for input tensor C.
Scalar multiplier for the product of input tensors A * B, the default value is 1.0.
Scalar multiplier for the product of input tensors A * B.
Scalar specifying the number of classes in one-hot tensor. This is also the size of the one-hot dimension (specified by 'axis' attribute) added on in the output tensor and the values in the 'indices' input tensor are expected to be in the range [0, depth). TheIn case 'depth' is of non-integer type, it will be casted to int64 before use.
Scale
scale
scale > 0
scale >= 1
Scale for doing quantization to get 'y'. It could be a scalar or a 1-D tensor,which means a per-tensor or per-axis quantization. If it's a 1-D tensor, its number of elements should be equal to the dimension value of 'axis' dimension of input 'x'.
Scale for doing quantization to get 'y'. It's a scalar, which means a per-tensor/layer quantization.
Scale for input 'x'. It could be a scalar or a 1-D tensor, which means a per-tensor or per-axis quantization.If it's a 1-D tensor, its number of elements should be equal to the dimension value of 'axis' dimension of input 'x'.
Scale for input 'x'. It's a scalar, which means a per-tensor/layer quantization.
scale must be a scalar
scale of quantized input a
scale of quantized input b
scale of quantized output y
Scale size: (
Scale tensor for input 'B'. It's optional and default value is 0.  It could be a scalar or a 1-D tensor, which means a per-tensor or per-column quantization. If it's a 1-D tensor, its number of elements should be equal to the number of columns of input 'B'.
Scale tensor for input 'w'. It could be a scalar or a 1-D tensor, which means a per-tensor/layer or per output channel quantization. If it's a 1-D tensor, its number of elements should be equal to the number of output channels (M).
Scale tensor for input 'w'. It's optional and default value is 0.  It could be a scalar or a 1-D tensor, which means a per-tensor/layer or per output channel quantization. If it's a 1-D tensor, its number of elements should be equal to the number of output channels (M)
Scale tensor for input 'x'. It's a scalar, which means a per-tensor/layer quantization.
Scale tensor for output 'y'. It's a scalar, which means a per-tensor/layer quantization.
Scale tensor of shape (C).
Scale value should be greater than 0.
Scale value should be greater than or equal to 1.
scale_.size() == offset_.size()
scale->Shape().NumDimensions() == 0 || (scale->Shape().NumDimensions() == 1 && scale->Shape().GetDims().size() == 1)
ScaleBias
ScaleCount
Scaled output data.
ScaledTanh
scaledtanh
Scaler
scales
Scales
scales != nullptr
scales size should be greater than 0.
scales.size() == 4
scales_size > 0
ScaleSize
ScaleTensor
Scaling parameter.
Scaling value
Scan 'body' subgraph outputs should all be tensors but output 
Scan input 
Scan inputs have inconsistent batch size. Previous value was 
Scan inputs have inconsistent sequence lengths. Previous value was 
scan_input_axes
scan_input_directions
scan_output_axes
scan_output_directions
Scatter
Schema error: 
schemaVersion
score_threshold
scores
scores must be a 3D tensor.
SearchBitState inconsistency
SearchDFA inconsistency
SearchNFA inconsistency
SearchOnePass inconsistency
Second dimension for rois should be exactly 
Second input does not have rank 2
Second input operand for the logical operator.
Second input tensor has wrong dimension
Second operand, power of the exponent.
Second operand.
Second operand. With broadcasting can be of smaller size than A. If broadcasting is disabled it should be of the same size.
Second set of probability coefficients. This array must be same size as prob_a.<br>If these are provided then output Z are probability estimates, otherwise they are raw scores.
Second, multiply by this.<br>Can be length of features in an [N,F] tensor or length 1, in which case it applies to all features, regardless of dimension count.<br>Must be same length as 'offset'
Seed for the hashing algorithm, unsigned 32-bit integer, default to 0.
sEh|c1
selected indices from the boxes tensor. [num_selected_indices, 3], the selected index format is [batch_index, class_index, box_index].
Selected output data as an array
selected_indices
separators
separators must not be empty
seq(map(int64, float))
seq(map(string, float))
seq_lengths
Sequence
sequence_lens
sequence_lens length of 
'sequence_lens' must have rank of 1
sequence_lens shape must be {batch_size}. Got:
Sequence<
SequenceIndex
SequenceLengthsTensor
SequentialExecutor::Execute
SESSION
Session
Session creation
Session has already been initialized.
Session not initialized.
Session successfully initialized.
Session was not initialized
session_initialization
session_logger != nullptr
session_state
SessionCreation
SetEvent
SetFilePointerEx
SetFilePointerEx 
SetLastError
setlocale
SetRestrictedErrorInfo
setting data_type field (tensor name: 
SetUnhandledExceptionFilter
setvbuf
Sh$e0
sH+Ch
shape
Shape
shape && tensor.Shape() == *shape
shape as a contiguous subset of the first tensor's shape. The starting of the
Shape input must be a one-dimensional tensor.
Shape must be 1 dimensional as it's tensor data is a shape
shape of left-hand-side argument. When broadcasting is specified, the second
Shape of the input tensor
shape.Size() must >=0
SHAPE_INFERENCE_NOT_REGISTERED
shapeTensor->Shape().NumDimensions() == 1
Sharada
Shavian
SHEX@
SHEX\
SHEX`
SHEX4
SHEXH
SHEXt
SHEXX
should never happen
Shouldn't be possible to have NodeArgs that haven't been handled already.
ShPj/
Shrink
Siddham
sigmoid
Sigmoid
SignWriting
Simplify case not handled: 
SimplifyWalker::ShortVisit called
Single dimension value must be greater than 0
Sinhala
size is different
Size mismatch validating subgraph inputs. Got 
Size mismatch: feed_names has 
size overflow
size_ % 2 == 1
size_ == size
size_ > 0
size_t(impl_->max_gram_length_) <= impl_->ngram_counts_.size()
size_t(impl_->min_gram_length_) <= impl_->ngram_counts_.size()
Sizes
Sleep
SleepConditionVariableCS
SleepConditionVariableSRW
Slice
Slice op must have either three, four or five inputs.
Sliced data tensor.
slope
Slope tensor. If `Slope` is of size 1, the value is sharedacross different channels
Slope tensor. The shape of slope can be smaller then first input X; if so, its shape must be unidirectional broadcastable to X
SlopeTensor
Softmax
softmax
SOFTMAX
SOFTMAX_ZERO
SoftmaxCPU inputs N, D and N * D must be < 
softplus
Softplus
Softsign
softsign
Sogdian
Sora_Sompeng
Soyombo
SpaceToDepth
SPARSE
sparse_tensor
sparse_tensor(
SparseTensor element type mismatch. 
spatial
Spatial
spatial == 1
spatial_scale
spatial_scale_ > 0
SpatialScale
Specified axis to insert a dimension
Specified shape for output.
Specify batchs of sequence words to embedding
Specify bias of conv
Specify embedding vector of char
Specify if the RNN is forward, reverse, or bidirectional. Must be one of forward (default), reverse, or bidirectional.
Specify weights of conv
Split
split
Split operator does not support 
Squeeze
squeezed
src.Size() == dst.Size()
SSSS9_<u9
SSSVh
SSSVhH4/
SSSVhp
SSSWh0
st.IsOK()
Stack not empty.
Stacktrace:
start
start in Range operator should be scalar like tensor, yet got shape:
start_tensor->Shape() == ends_tensor->Shape()
started event
Starting indices of corresponding axis in `axes`
StartPadding
startpos: 
starts
Starts and axes shape mismatch
Starts and ends shape mismatch
Starts and steps shape mismatch
Starts must be a 1-D array
StartStopEvent::EventCategoryToString
state not recoverable
StateSaver failed to restore state.
static_cast<int>(activation_func_names.size()) == num_directions_ * 3
static_cast<ptrdiff_t>(dims.size()) == extents.size() && static_cast<ptrdiff_t>(dims.size()) >= steps.size()
static_cast<ptrdiff_t>(dims.size()) == starts.size() && static_cast<ptrdiff_t>(dims.size()) == extents_.size() && static_cast<ptrdiff_t>(dims.size()) >= steps.size()
static_cast<size_t>(num_variadic_inputs) == graph_inputs->size()
status.IsOK()
status.IsOK() && !impl_->ngram_counts_.empty()
status.IsOK() && !impl_->ngram_indexes_.empty()
status.IsOK() && !input_dimensions_.empty()
status.IsOK() && !pool_int64s.empty()
std::all_of( std::begin(missing_tracks_true_), std::end(missing_tracks_true_), [](int64_t elem) { return elem >= 0; })
std::all_of(impl_->ngram_indexes_.cbegin(), impl_->ngram_indexes_.cend(), [](int64_t i) { return i >= 0; })
std::all_of(split_sizes_.cbegin(), split_sizes_.cend(), [](int64_t value) { return value > 0; })
std::count_if(subgraph_node.InputEdgesBegin(), subgraph_node.InputEdgesEnd(), [input_slot_index](const Node::EdgeEnd& entry) { return entry.GetDstArgIndex() == input_slot_index; }) == 0
Steepness
'step' cannot be 0
'step' value cannot be 0
steps
stod argument out of range
stof argument out of range
stoi argument out of range
stol argument out of range
stoll argument out of range
stopped event
Stopword contains invalid utf8 chars
stopwords
storage_order
stoul argument out of range
stoull argument out of range
strchr
strcmp
strcspn
stream timeout
strerror_s
Stride along each axis.
Stride along each axis. If not present, the stride defaults to 1 along each axis.
Strides
strides
strides_.size() == kernel_shape_.size()
String
string
STRING data (tensor name: 
string enum that cases output to be lowercased/uppercases/unchanged. Valid values are "LOWER", "UPPER", "NONE". Default is "NONE"
string tensor can not have raw data
string tensor is not supported for copying between allocators
string too long
string_data
string_vocabulary
StringFileInfo
StringNormalizer
StringOutputStream.
Strings to tokenize
strstr
strtod
strtof
strtol
strtoll
strtoul
strtoull
sub_graph.Resolve().IsOK()
subgraph
Subgraph in 'body' produces 
Subgraph input missing type.
Subgraph must have the shape set for all outputs but 
Subgraph SessionState was not found for '
Subgraph SessionState was not found for 'body' attribute.
subgraph_session_state
SubmitThreadpoolWork
subtraction
SUCCESS
suffix matching is assumed. 1-dim expansion doesn't work yet.
sum square
Sundanese
Support vector coefficients.
support_vectors
SVMClassifier
SVMRegressor
SVWj 
SVWj Y
SVWj@3
SVWj0
SVWQQ3
SVWtT
SWVRQ
SWVRQP
Syloti_Nagri
Syriac
system
SystemError
t j%X
t#j.X
t#j+X
T$ ;T
T$ 9\$
t$ QR
T$ u8
t$ Vj
T$$@;
T$$GA
t$$PQ
t$$Sh
t$(9T$
t$(WV
T$(x9
t$,PV
t$,RP
t$@;t$l
T$\;U
t$\joZRY
t$\RP
t$<RP
t$<VWQ
t$<WP
t$4+t$
T$4F;
t$4RP
T$8;U,
t$8Pj
t$8WQP
t$9K|t
T$d;U
T$d+T$\
t$DRWV
t$DSQP
T$H;P
t$HPR
T$HRQ
t$HWQV
t$j#Y
t$PjoY
t$PjoZ
t$PQP
t$pRP
t$PRP
t$pVQ
T$T;P
t$tQP
T$X9}$
t$XQP
t$XWQP
t%;A0t 
t%j$Z
t&j8X
t(hH#/
t)QPQ
t*h8n0
t,;:u
t,j-Y
t.;:u
t.;2u
t.;9u
t;VQWQ
t^j8[
t_proto.dims()[0] == 1
t_proto.dims_size() == 1
t_proto.has_data_type()
t+;>t.
t>9t$
t>x>|>
T1 != nullptr
T1p1z1
t2=fff
t4j4h
t6j(X
t79^h
t8VV9u
Tagalog
Tagbanwa
Tai_Le
Tai_Tham
Tai_Viet
Takri
Tamil
Tangut
Target shape may not have multiple -1 dimensions
Target tensor description expects IMG_TENSOR_CHANNEL_TYPE_BGR_8, but has %d channels specified instead of 3.
Target tensor description expects IMG_TENSOR_CHANNEL_TYPE_GRAY_8, but has %d channels specified instead of 1.
Target tensor description expects IMG_TENSOR_CHANNEL_TYPE_GRAY_8, IMG_TENSOR_CHANNEL_TYPE_BGR_8, or IMG_TENSOR_CHANNEL_TYPE_RGB_8 but has %d was specified.
Target tensor description expects IMG_TENSOR_CHANNEL_TYPE_RGB_8, but has %d channels specified instead of 3.
Target tensor description must either be IMG_TENSOR_DATA_TYPE_FLOAT32, or IMG_TENSOR_DATA_TYPE_FLOAT16. %d was supplied.
Target tensor height (%d) does not match input height (%d).
Target tensor width (%d) does not match input width (%d).
target_ids
target_nodeids
target_nodeids_.size() == target_ids_.size()
target_nodeids_.size() == target_weights_.size()
target_treeids
target_weights
targets
tCVWQ
td92v
tE;S\t@
tEj,X
TelemetryNameFromEnum
Telugu
TempSpace allocator not found
tensor
tensor A * B
Tensor after padding.
tensor C
tensor can either be of element size 1 (including a scalar tensor and any
tensor can't contain negative dims
Tensor element type mismatch. 
tensor has the same rank as the input if keepdims equal 1. If keepdims equal 0, then
tensor of bool, which should be a scalar.
Tensor of data to extract slices from.
Tensor of int32/int64 indices, of any rank q.
Tensor of int32/int64 indices, of r >= 1 (same rank as input).
tensor of int64, which should be a scalar.
Tensor of integers indicating the number of padding elements to add or remove (if negative) at the beginning and end of each axis. For 2D input tensor, it is the number of pixels. `pads` should be a 1D tensor of shape [2 * input_rank] or a 2D tensor of shape [1, 2 * input_rank]. `pads` format (1D example) should be as follow [x1_begin, x2_begin,...,x1_end, x2_end,...], where xi_begin is the number of pixels added at the beginning of axis `i` and xi_end, the number of pixels added at the end of axis `i`.
Tensor of rank one greater than input tensor 'indices', i.e. rank(output) = rank(indices) + 1. The data type for the elements of the output tensor is the same as the type of input 'values' is used.
Tensor of rank q + (r - 1).
Tensor of rank q >= 1.
Tensor of rank q-1+r-indices[-1].
Tensor of rank r >= 1 (same rank as input).
Tensor of rank r >= 1.
Tensor of rank r >= 2.
Tensor of rank r >=1 (same rank and shape as indices)
Tensor of rank r if axis is specified. Otherwise output is a Tensor of rank 1.
Tensor of shape [a_1, a_2, ..., a_{axis-1}, k, a_{axis+1}, ... a_n] containing the corresponding input tensor indices for the top K values.
Tensor of shape [a_1, a_2, ..., a_{axis-1}, k, a_{axis+1}, ... a_n] containing top K values from the input tensor
Tensor of shape [a_1, a_2, ..., a_n, r]
Tensor of shape equal to the broadcasted shape of condition, X, and Y.
Tensor shape cannot contain any negative value
Tensor size mismatch
tensor size overflow
tensor slope
Tensor specifying lengths of the sequences in a batch. It has shape `[batch_size]`.
Tensor to copy input into.
tensor type 
Tensor type mismatch.
Tensor type mismatch. 
tensor with rank equal to or smaller than the first tensor), or having its
Tensor with same shape of input.
tensor(
tensor(bool)
tensor(complex128)
tensor(complex64)
tensor(complext128)
tensor(complext64)
tensor(double)
tensor(float)
tensor(float16)
tensor(int16)
tensor(int32)
tensor(int64)
tensor(int8)
Tensor(scalar, or dims=[1]). First entry in the range.
Tensor(scalar, or dims=[1]). Number that increments start. Defaults to 1.
Tensor(scalar, or dims=[1]). Upper limit of sequence, exclusive.
tensor(string)
tensor(string) expected as input
tensor(uint16)
tensor(uint32)
tensor(uint64)
tensor(uint8)
tensor_shape.Shape().GetDims().size() == 1
tensor_type.has_elem_type()
Tensorization conversion is only supported to IMG_TENSOR_DATA_TYPE_FLOAT32, or IMG_TENSOR_DATA_TYPE_FLOAT16.
Tensorize Descriptor Heap
Tensorize Rootsignature
TensorProto ( tensor name: 
TensorProto (tensor name: 
TensorProto::DataType_IsValid(t_proto.data_type())
TensorrtExecutionProvider
Tensors with at least max(dims) dimensions.
TensorString objects cannot be created from a ID3D12Resource!
ter!u
terminate
TerminateProcess
test mode or not, the output Y will either be a random dropout, or a simple
text file busy
text size: 
TFIDF
TfIdfVectorizer
th$}.
Thaana
than the operator set version 
thd{.
The above behavior is similar to numpy, with the exception that numpy default keepdims to
The arccosine of the input tensor computed element-wise
The arcsine of the input tensor computed element-wise
The arctangent of the input tensor computed element-wise
The attention_v tensor in the attention mechanism. Should be of shape `[num_directions, am_attn_size]` 
The axis along which same quantization parameters are applied. It's optional.If it's not specified, it means per-tensor quantization and input 'x_scale' and 'x_zero_point' must be scalars.If it's specified, it means per 'axis' quantization and input 'x_scale' and 'x_zero_point' must be 1-D tensors.
The axis in which to compute the arg indices.
The axis on which to apply normalization, -1 mean last axis.
the axis provided, then input will be coerced into a 2-dimensional tensor with
The bias as a 1-dimensional tensor of size C to be applied to the output.
The bias tensor for input gate. Concatenation of `[Wb[iofc], Rb[iofc]]`, and `[WBb[iofc], RBb[iofc]]` (if bidirectional) along dimension 0. This tensor has shape `[num_directions, 8*hidden_size]`. Optional: If not specified - assumed to be 0.
The bias tensor for input gate. Concatenation of `[Wbi, Rbi]` and `[WBbi, RBbi]` (if bidirectional). The tensor has shape `[num_directions, 2*hidden_size]`. Optional: If not specified - assumed to be 0.
The bias tensor for the gates. Concatenation of `[Wb[zrh], Rb[zrh]]` and `[WBb[zrh], RBb[zrh]]` (if bidirectional) along dimension 0. This tensor has shape `[num_directions, 6*hidden_size]`. Optional: If not specified - assumed to be 0
The bias value added to output. Default is 0.
The binding collection does not contain a variable with name %s.
The buffer planner is not consistent with tensor buffer size, expected 
The class score for each class, for each point, a tensor of shape [N,E].
The convolution operator consumes an input tensor and {filter_desc}, and
The convolution transpose operator consumes an input tensor and {filter_desc},
The cosine of the input tensor computed element-wise
The data type for the elements of the output tensor. Default is TensorProto::FLOAT.
The data type for the elements of the output tensor. If not specified, default is TensorProto::FLOAT.
The data type to which the elements of the input tensor are cast. Strictly must be one of the types from DataType enum in TensorProto
The dimension with value zero exceeds the dimension size of the input tensor.
The engine produced an unexpected evaluation output %s, that is not a model variable output.
The engine produced an unexpected evaluation output %s, that is not a model variable.
The engine produced an unexpected evaluation output for unbound output variable %s.
The epsilon value to use to avoid division by zero, default is 1e-5f.
The epsilon value to use to avoid division by zero.
The error function of the input tensor computed element-wise. It has the same shape and type of the input.
The exponent.
The exponential of the input tensor computed element-wise
The filled tensor
The graph run each iteration. It has 2+N inputs: (iteration_num, condition, loop carried dependencies...). It has 1+N+K outputs: (condition, loop carried dependencies..., scan_outputs...). Each scan_output is created by concatenating the value of the specified output value at the end of each iteration of the loop. It is an error if the dimensions or data type of these scan_outputs change across loop iterations.
The graph run each iteration. It has N+M inputs: (loop state variables..., scan_input_elts...). It has N+K outputs: (loop state variables..., scan_output_elts...). Each scan_output is created by concatenating the value of the specified scan_output_elt value at the end of each iteration of the loop. It is an error if the dimensions of these values change across loop iterations.
The hyperbolic arccosine values of the input tensor computed element-wise
The hyperbolic arcsine values of the input tensor computed element-wise
The hyperbolic arctangent values of the input tensor computed element-wise
The hyperbolic cosine values of the input tensor computed element-wise
The hyperbolic sine values of the input tensor computed element-wise
The hyperbolic tangent values of the input tensor computed element-wise
The id of the tree that each node is in.
The id of the tree that this node is in.
The index of the class list that each weight is for.
The index of the target that each weight is for
The indices, based on 0 as the first index of any dimension.
The initial values of any loop-carried dependencies (values that change across loop iterations)
The input 1-dimensional bias tensor of size C.
The input 1-dimensional scale tensor of size C.
The input 4-dimensional tensor of shape NCHW.
The input data as Tensor.
The input map that is to be cast to a tensor
The input must be a map from strings or integers to either strings or a numeric type. The key and value types cannot be the same.
The input must be a tensor of a numeric type or string. The output will be of the same tensor type.
The input must be a tensor of a numeric type, and of of shape [N,C] or [C]. In the latter case, it will be treated as [1,C]
The input must be a tensor of a numeric type, either [C] or [N,C].
The input must be a tensor of a numeric type.
The input must be a tensor of a numeric type. The output will be of the same tensor type.
The input must be a tensor of strings or integers, either [N,C] or [C].
The input must be an integer map to either string or float.
The input sequences packed (and potentially padded) into one 3-D tensor with the shape of `[seq_length, batch_size, input_size]`
The input sequences packed (and potentially padded) into one 3-D tensor with the shape of `[seq_length, batch_size, input_size]`.
The input tensor cannot be reshaped to the requested shape. Input shape:
The input tensor that's coerced into a 2D matrix of size (NxD) as described above.
The input type is a tensor of any shape.
The input type must be a tensor of a numeric type, either [C] or [N,C].
The input type must be a tensor of a numeric type, either [N,C] or [C]. The output type will be of the same tensor type and shape.
The input type must be a tensor of a numeric type.
The input type must be a tensor of integers or strings, of any shape.
The input values
The integers of the map. This sequence must be the same length as the 'cats_strings' sequence.
The kernel type, one of 'LINEAR,' 'POLY,' 'RBF,' 'SIGMOID'.
The keys when using int keys.<br>One and only one of the 'classlabels_*' attributes must be defined.
The keys when using string keys.<br>One and only one of the 'classlabels_*' attributes must be defined.
The lambd value for the Shrink formulation. Default is 0.5.
The last output value of the cell. It has shape `[num_directions, batch_size, hidden_size]`.
The last output value of the hidden. It has shape `[num_directions, batch_size, hidden_size]`.
The last output value of the hidden. It has shape `[num_directions, batch_size, hidden_size]`. 
The mean of the normal distribution.
The model contains a 16-bit float Cast Op (%s), but the current device does not support 16-bit float.
The model contains a 16-bit float initializer (%s), but the current device does not support 16-bit float.
The model contains a 16-bit input (%ls), but the current device does not support 16-bit float.
The model contains a 16-bit output (%ls), but the current device does not support 16-bit float.
The model has been disposed.
The model has input %s with a fixed batch dimenions of size %lld not equal %d specified by the batch_size_override.
The model has no variable with name %s.
The model proto is null.
The model variable %s cannot be bound with the provided type.
The model variable %s failed tensorization.
The model variable %s is an input, but has no associated resources to bind.
The most inner dimension in boxes must have 4 data.
The natural log of the input tensor computed element-wise
The new GRU hidden state calculated by this op.
The node id of each weight
The node is not placed on any Execution Provider
The node is not placed on any Execution Provider, therefore, can't find a suitable kernel for it
The node kind, that is, the comparison to make at the node. There is no comparison to make at a leaf node.<br>One of 'BRANCH_LEQ', 'BRANCH_LT', 'BRANCH_GTE', 'BRANCH_GT', 'BRANCH_EQ', 'BRANCH_NEQ', 'LEAF'
The number of channels to sum over
The number of support vectors.
The operator computes the {name} ({description}) values for each layer in the batch
The order of the normalization, only 1 or 2 are supported.
The output 4-dimensional tensor of the same shape as input.
The output 4-dimensional tensor of the same shape as X.
The output array, elements ordered as the inputs.
The output is a 1-D tensor of string, float, or integer.
The output is a tensor of strings or integers. Its shape will be the same as the input shape.
The output map
The output mask.
The output mask. If is_test is nonzero, this output is not filled.
The output of each pooling window is divided by the number of elements (exclude pad when attribute count_include_pad is zero).
The output of each pooling window is divided by the number of elements exclude pad.
The output of each pooling window is maximum number of elements exclude pad.
The output tensor of the same shape as input.
The output tensor of the same shape as X
The output tensor of the same shape as X.
The output type will be a tensor of strings or integers, and will have the same shape as the input.
The output type will be a tensor of strings or integers, depending on which of the the classlabels_* attributes is used.
The output type will be a tensor of strings or integers, depending on which of the the classlabels_* attributes is used. Its size will match the bactch size of the input.
The output values with the same shape as input tensor (the original size without coercion).
The output will be a sequence of string or integer maps to float.
The output will be a tensor of strings or integers.
The output will be a tensor of the value type of the input map. It's shape will be [1,C], where C is the length of the input dictionary.
The output.
The pooling method. Two modes are supported: 'avg' and 'max'. Default is 'avg'.
The previous GRU hidden state.
The rank of input tensor must be >= axis
The ratio of random dropout
The recurrence weight tensor. Concatenation of `R[iofc]` and `RB[iofc]` (if bidirectional) along dimension 0. This tensor has shape `[num_directions, 4*hidden_size, hidden_size]`.
The recurrence weight tensor. Concatenation of `R[zrh]` and `RB[zrh]` (if bidirectional) along dimension 0. This tensor has shape `[num_directions, 3*hidden_size, hidden_size]`.
The recurrence weight tensor. Concatenation of `Ri` and `RBi` (if bidirectional). The tensor has shape `[num_directions, hidden_size, hidden_size]`.
the resulted tensor have the reduced dimension pruned.
The running mean (training) or the estimated mean (testing) as a 1-dimensional tensor of size C.
The running mean after the BatchNormalization operator.
The running mean after the BatchNormalization operator. Must be in-place with the input mean. Should not be used for testing.
The running variance (training) or the estimated variance (testing) as a 1-dimensional tensor of size C.
The running variance after the BatchNormalization operator.
The running variance after the BatchNormalization operator. Must be in-place with the input var. Should not be used for testing.
The scale along height dimension. It takes value greater than or equal to 1.
The scale along width dimension. It takes value greater than or equal to 1.
The scale array along each dimension. It takes value greater than 0. If it's less than 1, it's sampling down, otherwise, it's upsampling. The number of elements of 'scales' should be the same as the rank of input 'X'.
The scale array along each dimension. It takes value greater than or equal to 1. The number of elements of 'scales' should be the same as the rank of input 'X'.
The scale as a 1-dimensional tensor of size C to be applied to the output.
The scale to apply.
The scaled hyperbolic tangent values of the input tensor computed element-wise
The sequence length of the input memory for the attention mechanism. Should be of `[batch_size]` 
The sequence of the memory (input) for attention mechanism. Should be of `[batch_size, max_memory_step, memory_depth]` 
The sequence output for the hidden is optional if 0. Default 0.
The shape of filled tensor
The shape of the convolution kernel. If not present, should be inferred from input W.
The shape of the convolution kernel. If not present, should be inferred from input 'w'.
The shape of the output can be explicitly set which will cause pads values to be auto generated. If output_shape is specified pads values are ignored. See doc for details for equations to generate pads
The shape of the output can be explicitly set which will cause pads values to be auto generated. If 'output_shape' is specified, 'pads' values are ignored.
The shape of the output tensor.
The sign of the input tensor computed element-wise. It has the same shape and type of the input.
The sine of the input tensor computed element-wise
The size of each input in the input list
The size of the kernel along each axis.
The softsign (x/(1+|x|)) values of the input tensor computed element-wise
The standard deviation of the normal distribution.
The starting indexes of 1-grams, 2-grams, and so on in pool. It is useful when determining the boundary between two consecutive collections of n-grams. For example, if ngram_counts is [0, 17, 36], the first index (zero-based) of 1-gram/2-gram/3-gram in pool are 0/17/36. This format is essentially identical to CSR (or CSC) sparse matrix format, and we choose to use this due to its popularity.
The storage order of the tensor. 0 is row major, and 1 is column major.
The stream failed to parse.
The string used to pad output tensors when the tokens extracted doesn't match the maximum number of tokens found. If start/end markers are needed, padding will appear outside the markers.
The strings of the map. This sequence must be the same length as the 'cats_int64s' sequence
The subgraph in 'body' expects 
The subgraph in 'body' requires 
The tangent of the input tensor computed element-wise
The tensor has been closed and its resources are detached!
The tensor has been closed and its resources have been detached during evaluation!
The tensor has been closed and its resources have been detached!
The tensor has outstanding memory buffer references that must be closed prior to evaluation!
the tensor to be tiled using Tile OP must be atleast 1 dimensional
The tensor to split
The timestep for this operation.
The total number of regression targets, 1 if not defined.
The total number of targets.
the training phase, so during testing nothing needs to be done.
The type of the output tensor is integer.
The value for the elements of the output tensor.
The weight for each target
The weight for the class in class_id.
The weight tensor for input gate. Concatenation of `Wi` and `WBi` (if bidirectional). The tensor has shape `[num_directions, hidden_size, input_size]`.
The weight tensor for peepholes. Concatenation of `P[iof]` and `PB[iof]` (if bidirectional) along dimension 0. It has shape `[num_directions, 3*hidde_size]`. Optional: If not specified - assumed to be 0.
The weight tensor for the gates. Concatenation of `W[iofc]` and `WB[iofc]` (if bidirectional) along dimension 0. The tensor has shape `[num_directions, 4*hidden_size, input_size]`.
The weight tensor for the gates. Concatenation of `W[zrh]` and `WB[zrh]` (if bidirectional) along dimension 0. This tensor has shape `[num_directions, 3*hidden_size, input_size]`.
The weight tensor of the memory layer in the attention mechanism. Should be of shape `[num_directions, memory_depth, am_attn_size]` 
The weight tensor of the query layer in the attention mechanism. Should be of shape `[num_directions, am_query_depth(hidden_size of lstm), am_attn_size]` 
The weight tensor that will be used in the convolutions; has size (C x M/group x kH x kW), where C is the number of channels, and kH and kW are the height and width of the kernel, and M is the number of feature maps. For more than 2 dimensions, the weight shape will be (C x M/group x k1 x k2 x ... x kn), where (k1 x k2 x ... x kn) is the dimension of the kernel. The number of channels in the output should be equal to W.shape[1] * group (assuming zero based indices of the shape array)
The weight tensor that will be used in the convolutions; has size (M x C/group x kH x kW), where C is the number of channels, and kH and kW are the height and width of the kernel, and M is the number of feature maps. For more than 2 dimensions, the kernel shape will be (M x C/group x k1 x k2 x ... x kn), where (k1 x k2 x ... kn) is the dimension of the kernel. Optionally, if dimension denotation is in effect, the operation expects the weight tensor to arrive with the dimension denotation of [FILTER_OUT_CHANNEL, FILTER_IN_CHANNEL, FILTER_SPATIAL, FILTER_SPATIAL ...]. X.shape[1] == (W.shape[1] * group) == C (assuming zero based indices for the shape array). Or in other words FILTER_IN_CHANNEL should be equal to DATA_CHANNEL. 
The weighting criteria. It can be one of "TF" (term frequency), "IDF" (inverse document frequency), and "TFIDF" (the combination of TF and IDF)
The weights of attention layer in the attention wrapper. If exists, should be of shape `[num_directions, memory_depth+hidden_size, aw_attn_size]. Please note that attention mechanism context depth is also memory_depth in the attention mechanism.` 
The zero-padding added to one side of the output. This is also called adjs/adjustment in some frameworks.
then_branch
then_branch and else_branch produce different number of outputs. 
there are multiple cases for the number of outputs, which we list below:
There's no data transfer registered for copying tensors from 
t-hh_1
This API is not supported when model is loaded from proto file right now.
This is an invalid model. At top level graph without matching NodeArg that subgraph consumes. Name=
This is an invalid model. Error in Node:
This is an invalid model. Error: Duplicate definition of name (
This is an invalid model. Error: the graph is not acyclic.
This is an invalid model. Error: two nodes with same node name (
This is an invalid model. Failed to find NodeArg in all parent graphs. Name=
This is an invalid model. Graph output (
This is an invalid model. Model input (
This is an invalid model. Node (
This is an invalid model. The sum of input arg count is not equal to size of input defs in node (
This is an invalid model. Type Error: Type '
This operator applies convolution to word from left to right with window equal to conv_window_size and stride to 1.Take word 'example' for example, with conv_window_size equal to 2, conv is applied to [ex],[xa], [am], [mp]...If not provide, use the first dimension of conv kernal shape.
This operator has **optional** inputs/outputs. See [the doc](IR.md) for more details about the representation of optional arguments. An empty string may be used in the place of an actual argument's name to indicate a missing argument. Trailing optional arguments (those not followed by an argument that is present) may also be simply omitted.
This operator supports **multidirectional (i.e., Numpy-style) broadcasting**; for more details please check [the doc](Broadcasting.md).
This operator supports **unidirectional broadcasting** (
This session already contains a loaded model.
This shouldn't be called if all the sizes are equal.
This transformer is already registered 
This ZeroCopyOutputStream doesn't support aliasing. Reaching here usually means a ZeroCopyOutputStream implementation bug.
thisProto->map_type().has_key_type()
thisProto->map_type().has_value_type()
thisProto->sequence_type().has_elem_type()
thisProto->tensor_type().has_elem_type()
thisProto->value_case() == TypeProto::ValueCase::kMapType
thisProto->value_case() == TypeProto::ValueCase::kSequenceType
thisProto->value_case() == TypeProto::ValueCase::kTensorType
Thread ID
threadId
Three modes: `constant`(default) - pads with a given constant value, `reflect` - pads with the reflection of the vector mirrored on the first and last values of the vector along each axis, `edge` - pads with the edge values of array
Three modes: constant(default), reflect, edge
Threshold
threshold
Threshold value
thresholdedrelu
ThresholdedRelu
Thresholds to do the splitting on for each node.
Tibetan
Tifinagh
Tile doesn't have an implementation yet for the type: 
tiles
Time Stamp (us)
time_axis
time_axis < 2
time_axis and batch_axis must have different values but both are 
timed out
Tirhuta
tJjpSV
tM;>tM;
tmp_cats_int64s.empty() || tmp_cats_strings.empty()
to flatten the input shape to (N x C*D1*D2 ..*Dn) before a BatchNormalization Op.
to match the shape of left-hand-side argument. See the doc of `Add` for a
TO_FLOAT
TO_INT64
TO_STRING
tokenexp
Tokenized strings
Tokenizer
tolower
too many files open
too many files open in system
too many links
too many symbolic link levels
Total allocated bytes: 
Total number of elements of the input tensor
totalEvalCalls
tQVVVWS
TraceAllocation for ort_value_idx=
TraceFree for ort_value_idx=
trailing \
TransA
transA
transB
TransB
Translation
Transpose
transposed
Transposed output.
Tree id for each node.
TreeEnsembleClassifier
TreeEnsembleRegressor
treeindex >= 0
treeindex evaluated to a negative value, which should not happen.
tried to allocate 0 bytes
Tried to allocate without valid type information, ort_value index=
TryAcquireSRWLockExclusive
Trying to allocate memory for unused optional inputs/outputs
Trying to register schema with name 
TrySubmitThreadpoolCallback
tSVRWS
tV=333
tV=UUU
tVhh,1
tVShxp1
Two interpolation modes: nearest (default), and linear (including bilinear, trilinear, etc)
Two interpolation modes: nearest(default), bilinear
type != nullptr
type == dtype_
Type Error: Shape of initializer 
Type Error: Type (
Type Error: Type parameter (
Type Error: Value of initializer 
type field and data field mismatch in attribute 
Type for Tind not supported yet in Gather.
Type mismatch. Current=
type mismatch. existing=
Type not supported.
type: 
typeConstraintCount
tZh`U/
u$hxB-
u$SWVRQ
u$VRQ
u$WPQ
u%PPW
u)VVWSV
u,9s$u'
u<+]8
U<+E8
u<8D$
u>9r ~
u>9r0~
u>9rP~
u>hX)1
u9j(j
uD9}@
uehD,.
Ugaritic
Uhdz.
uint16
UInt16
UInt32
uint32
uint64
UInt64
uint64_data
uint8
UInt8
UjAX;
ulhht0
uLjih0
Unactivated gate outputs from forget, update, and output gates, pre-activation.
undefined
Undefined
Unexpected CAST_TO value of 
Unexpected descriptor LearningModelFeatureKind.
unexpected error
unexpected failure
Unexpected input data type. Actual: (
Unexpected NORMALIZE value of 
Unexpected op in Regexp::Equal: 
Unexpected opcode in IsMatch: 
Unexpected opcode in short circuit: 
Unexpected opcode: 
Unexpected special state in RunStateOnByte
Unexpected TensorKind Complex128.
Unexpected TensorKind Complex64.
Unexpected TensorKind Undefined.
Unexpected 'to' argument value: 
ungetc
Unhandled 
unhandled 
unhandled opcode: 
UnhandledExceptionFilter
Unique
unknown
Unknown AutoPadType String
Unknown Category and zeros = 0.
Unknown encoding 
unknown error
Unknown error during EndProfiling()
Unknown exception
Unknown exception in Load()
Unknown model file format version.
unknown round: 
Unknown tensor type of 
unknown_dim == -1
Unloading DSO 
unpack_status.IsOK()
UnpackTensor: the pre-allocate size does not match the size in proto
UnpackTensor: the pre-allocated size does not match the raw data size, expected 
Unrecognized attribute: 
Unrecognized data_type (tensor name: 
Unrecognized type value case (value_info name: 
Unsqueeze
UnsqueezeElimination
Unsupported 
Unsupported AutoPad Type.
Unsupported data type
Unsupported 'dtype' value: 
Unsupported image with 
Unsupported input datatype
Unsupported level
Unsupported level 
Unsupported non-raw-data data type!
Unsupported pooling size : 
Unsupported pooling size.
Unsupported type:
Unsupported value attribute datatype: 
Unsupportted tensor data type:
uOPPV
UpdateGateTensor
updates
UpdatesTensor
uPf9_
UPPER
Upper boundary of the output values.
Upsample
Upsample: Input dims != attribute 'scales' dims
Upsample: input tensor's dimension does not match the scales.
Upsample: input/output value is nullptr
Upsample: input/output value's dimension mismatch
Upsample: linear mode upsample only support 4-D tensor with NCHW layout
Upsample: linear mode upsample only support bilinear with 4 dimension.
Upsample: linear mode upsample only support bilinear, the first 2 scales should be 1.
Upsample: unexpected mode
UseCellMemoryMinusOneTensor
UseClipThreshold
usefp16
UseRecurrenceTensor
Using an input in multiple nodes on different devices is not supported currently. Input:
UTCReplace_AppSessionGuid
UTF-8 Normalized strings
UTF-8 strings to normalize
uWindows.Foundation.Collections.PropertySet
uX9t$
v >= 0 && static_cast<uint64_t>(v) <= std::numeric_limits<size_t>::max()
v QjoY
v;F(r
v_final_and_scan_outputs
v_initial
v+QWQ
V<WjdY
vAj/h
VALID
valid
Validating no unexpected access using an invalid node_index.
Value
value
Value attribute unpacking failed:
Value of alpha
Value of alpha default to 0.2
Value of alpha.
Value of attribute 
Value of beta
Value of beta default to 0.5
Value of beta.
value of k must not be negative
Value tensor should be a 1D tensor of size 1 with the same type as that of the input tensor
value too large
Value(s) to change to
Value(s) to change to.
value_info
value_proto != nullptr
value_tensor->DataType() == DataTypeImpl::GetType<float>() && value_tensor->Shape().Size() == 1
value_type
values
Values
Values greater than this are mapped to 1, others to 0.
values of data_type '
values selected at indices where condition is False
values selected at indices where condition is True
Values that are live-out to the enclosing scope. The return values in the `then_branch` and `else_branch` must be of the same shape and same data type.
values.size() == attr->floats_size()
values.size() == attr->ints_size()
values_floats
values_int64s
values_strings
ValuesTensor
VarFileInfo
Variance
VarianceTensor
vector<bool> too long
vectors_per_class
version
Vh$_.
Vh(_0
Vh(9/
Vh(D.
Vh(t/
Vh(U0
Vh,}0
Vh,L.
Vh@)1
Vh@-/
Vh@>.
Vh@g/
Vh@Q/
Vh@S/
Vh@T.
Vh\'1
Vh\x0
Vh`:1
Vh`A/
Vh`h.
Vh`U0
Vh|*.
Vh|h0
Vh|s.
Vh|S1
Vh<c.
Vh<T1
Vh0k/
Vh4S/
Vh8/0
Vh8;/
Vh8[0
Vh8].
Vh8J/
Vh8y0
vhd:0
Vhd^.
VhD_1
Vhd7/
VhdC.
VhdD1
VhdP/
VhDp0
VhDQ.
VhdS/
Vhh,1
Vhh=/
VhH8/
VhHD/
VhhE-
VhHf.
VhHo1
VhHp1
Vhhr.
VhHu.
VhL,.
VhL:.
VhLo.
Vhp:/
Vhp].
Vhp41
VhPC/
VhPg.
VhpP.
Vhpt.
Vhpx.
VhPy/
VhPZ0
Vht@.
VhT}/
Vht9.
VhtA.
VhtP.
VhtW.
VhX#0
Vhx|/
VhX8/
VhXC.
VhXd.
Vhxe.
VhXo0
VhXR.
VhXS0
vi;T$
via some custom implementation such as CuDNN.
VirtualAlloc
VirtualFree
VirtualProtect
VirtualQuery
VPh0(-
VPhh0-
vpjX_
VQSQW
VRVQ!
VS_VERSION_INFO
VSWSh
VVRh`Q8
VVSh`Q8
VVVVV
VWh@g/
VWhL^0
VWj Y
VWjoZRY
VWjX+
VWQjX
VWu'hxB-
w_^[]
w_scale
w_zero_point
W9^,u'h
WaitForSingleObject
WaitForSingleObjectEx
WaitForThreadpoolWorkCallbacks
WakeAllConditionVariable
WakeConditionVariable
Walk NULL
Warang_Citi
WARNING
Warning: 
wcsftime
wcsnlen
We do not expect duplicate registration of types for: 
We don't expect custom allocators for non-tensor types, so a shape is mandatory here.
weight and zero_point pair is expected to have same type.
Weight buffer for initializer '
weights
Weights of the intercepts, if used.
Weights of the model(s).
WeightTensor
Wether to use ceil or floor (default) to compute the output shape.
Wh($/
Wh(x/
Wh@g/
Wh@Q.
Wh@S/
Wh@w/
Wh`8.
Wh0T0
Wh4S/
WhDQ.
Whdw.
When computing the output of the hidden gate, apply the linear transformation before multiplying by the output of the reset gate.
When True (nonzero), yield X, otherwise yield Y
Where
Whether A should be transposed
Whether B should be transposed
Whether C should be broadcasted
Whether include pad pixels when calculating values for the edges. Default is 0, doesn't count include pad.
Whether the operator should behave like fmod (default=0 meaning it will do integer mods); Set this to 1 to force fmod treatment
Which axis to concat on
Which axis to concat on.  Default value is 1.
Which axis to gather on. Negative value means counting dimensions from the back. Accepted range in [-r, r-1]
Which axis to scatter on. Negative value means counting dimensions from the back. Accepted range in [-r, r-1]
Which axis to split on
Which axis to split on.
whP/1
WhpP.
Wht}/
WhtP.
Whxw/
WideCharToMultiByte
width
Width
width_scale
WidthMajor
WilError_02
will throw errors.
wilResult
Windows Machine Learning Runtime
windows.ai.machinelearning.dll
Windows.AI.MachineLearning.ILearningModelFeatureValue
Windows.AI.MachineLearning.ImageFeatureDescriptor
Windows.AI.MachineLearning.ImageFeatureValue
Windows.AI.MachineLearning.LearningModel
Windows.AI.MachineLearning.LearningModelBinding
Windows.AI.MachineLearning.LearningModelDevice
Windows.AI.MachineLearning.LearningModelEvaluationResult
Windows.AI.MachineLearning.LearningModelSession
Windows.AI.MachineLearning.LearningModelSessionOptions
Windows.AI.MachineLearning.MapFeatureDescriptor
windows.ai.machinelearning.pdb
Windows.AI.MachineLearning.Runtime
Windows.AI.MachineLearning.SequenceFeatureDescriptor
Windows.AI.MachineLearning.TensorBoolean
Windows.AI.MachineLearning.TensorDouble
Windows.AI.MachineLearning.TensorFeatureDescriptor
Windows.AI.MachineLearning.TensorFloat
Windows.AI.MachineLearning.TensorFloat16Bit
Windows.AI.MachineLearning.TensorInt16Bit
Windows.AI.MachineLearning.TensorInt32Bit
Windows.AI.MachineLearning.TensorInt64Bit
Windows.AI.MachineLearning.TensorInt8Bit
Windows.AI.MachineLearning.TensorString
Windows.AI.MachineLearning.TensorUInt16Bit
Windows.AI.MachineLearning.TensorUInt32Bit
Windows.AI.MachineLearning.TensorUInt64Bit
Windows.AI.MachineLearning.TensorUInt8Bit
Windows.AI.MachineLearning: Debug Output Enabled 
Windows.ApplicationModel.Core.CoreApplication
Windows.Foundation.Collections.IIterator`1<Boolean>
Windows.Foundation.Collections.IIterator`1<Double>
Windows.Foundation.Collections.IIterator`1<Int16>
Windows.Foundation.Collections.IIterator`1<Int32>
Windows.Foundation.Collections.IIterator`1<Int64>
Windows.Foundation.Collections.IIterator`1<Single>
Windows.Foundation.Collections.IIterator`1<String>
Windows.Foundation.Collections.IIterator`1<UInt16>
Windows.Foundation.Collections.IIterator`1<UInt32>
Windows.Foundation.Collections.IIterator`1<UInt64>
Windows.Foundation.Collections.IIterator`1<UInt8>
Windows.Foundation.Collections.IIterator`1<Windows.AI.MachineLearning.ILearningModelFeatureDescriptor>
Windows.Foundation.Collections.IIterator`1<Windows.Foundation.Collections.IKeyValuePair`2<Int64, Double>>
Windows.Foundation.Collections.IIterator`1<Windows.Foundation.Collections.IKeyValuePair`2<Int64, Int64>>
Windows.Foundation.Collections.IIterator`1<Windows.Foundation.Collections.IKeyValuePair`2<Int64, Single>>
Windows.Foundation.Collections.IIterator`1<Windows.Foundation.Collections.IKeyValuePair`2<Int64, String>>
Windows.Foundation.Collections.IIterator`1<Windows.Foundation.Collections.IKeyValuePair`2<String, Double>>
Windows.Foundation.Collections.IIterator`1<Windows.Foundation.Collections.IKeyValuePair`2<String, Int64>>
Windows.Foundation.Collections.IIterator`1<Windows.Foundation.Collections.IKeyValuePair`2<String, Object>>
Windows.Foundation.Collections.IIterator`1<Windows.Foundation.Collections.IKeyValuePair`2<String, Single>>
Windows.Foundation.Collections.IIterator`1<Windows.Foundation.Collections.IKeyValuePair`2<String, String>>
Windows.Foundation.Collections.IIterator`1<Windows.Foundation.Collections.IMap`2<Int64, Single>>
Windows.Foundation.Collections.IIterator`1<Windows.Foundation.Collections.IMap`2<String, Single>>
Windows.Foundation.Collections.IIterator`1<Windows.Media.VideoFrame>
Windows.Foundation.Collections.IKeyValuePair`2<Int64, Double>
Windows.Foundation.Collections.IKeyValuePair`2<Int64, Int64>
Windows.Foundation.Collections.IKeyValuePair`2<Int64, Single>
Windows.Foundation.Collections.IKeyValuePair`2<Int64, String>
Windows.Foundation.Collections.IKeyValuePair`2<String, Double>
Windows.Foundation.Collections.IKeyValuePair`2<String, Int64>
Windows.Foundation.Collections.IKeyValuePair`2<String, Object>
Windows.Foundation.Collections.IKeyValuePair`2<String, Single>
Windows.Foundation.Collections.IKeyValuePair`2<String, String>
Windows.Foundation.Collections.IMap`2<Int64, Double>
Windows.Foundation.Collections.IMap`2<Int64, Int64>
Windows.Foundation.Collections.IMap`2<Int64, Single>
Windows.Foundation.Collections.IMap`2<Int64, String>
Windows.Foundation.Collections.IMap`2<String, Double>
Windows.Foundation.Collections.IMap`2<String, Int64>
Windows.Foundation.Collections.IMap`2<String, Object>
Windows.Foundation.Collections.IMap`2<String, Single>
Windows.Foundation.Collections.IMap`2<String, String>
Windows.Foundation.Collections.IVector`1<Boolean>
Windows.Foundation.Collections.IVector`1<Double>
Windows.Foundation.Collections.IVector`1<Int16>
Windows.Foundation.Collections.IVector`1<Int32>
Windows.Foundation.Collections.IVector`1<Int64>
Windows.Foundation.Collections.IVector`1<Single>
Windows.Foundation.Collections.IVector`1<String>
Windows.Foundation.Collections.IVector`1<UInt16>
Windows.Foundation.Collections.IVector`1<UInt32>
Windows.Foundation.Collections.IVector`1<UInt64>
Windows.Foundation.Collections.IVector`1<UInt8>
Windows.Foundation.Collections.IVector`1<Windows.AI.MachineLearning.ILearningModelFeatureDescriptor>
Windows.Foundation.Collections.IVector`1<Windows.Foundation.Collections.IMap`2<Int64, Single>>
Windows.Foundation.Collections.IVector`1<Windows.Foundation.Collections.IMap`2<String, Single>>
Windows.Foundation.Collections.IVector`1<Windows.Media.VideoFrame>
Windows.Foundation.IAsyncOperation`1<Windows.AI.MachineLearning.LearningModel>
Windows.Foundation.IAsyncOperation`1<Windows.AI.MachineLearning.LearningModelEvaluationResult>
Windows.Foundation.IMemoryBufferReference
Windows.Foundation.IReference`1<Windows.Graphics.Imaging.BitmapBounds>
Windows.Graphics.Imaging.SoftwareBitmap
Windows.Media.VideoFrame
Windows.Storage.Streams.Buffer
Windows.Storage.Streams.IBuffer
Windows::AI::MachineLearning::compatibility_details::not_compatible_hr
Windows::AI::MachineLearning::CpuOrtSessionBuilder::CreateSession
Windows::AI::MachineLearning::CpuOrtSessionBuilder::Initialize
Windows::AI::MachineLearning::CreateModelProto
Windows::AI::MachineLearning::DmlOrtSessionBuilder::CreateSession
Windows::AI::MachineLearning::DmlOrtSessionBuilder::RegisterTransformers
Windows::AI::MachineLearning::GetTensorType
Windows::AI::MachineLearning::Internal::ImageConversionHelpers::GetBitmapPixelFormatFromChannelType
Windows::AI::MachineLearning::Internal::ImageConversionHelpers::GetChannelTypeFromSoftwareBitmap
Windows::AI::MachineLearning::Internal::ImageConversionHelpers::GetDeviceFromDirect3DSurface
Windows::AI::MachineLearning::Internal::ImageConversionHelpers::GetDirectXPixelFormatFromChannelType
Windows::AI::MachineLearning::Internal::ImageConversionHelpers::GetDXGIFormatFromDirectXPixelFormat
Windows::AI::MachineLearning::Internal::ImageConverter::CreateTextureFromUnsupportedColorFormat
Windows::AI::MachineLearning::Internal::ImageConverter::FetchOrCreateFenceOnDevice
Windows::AI::MachineLearning::Internal::ImageConverter::ResetAllocator
Windows::AI::MachineLearning::Internal::ImageConverter::ResetCommandList
Windows::AI::MachineLearning::Internal::TensorToVideoFrameConverter::ConvertCPUTensorToSoftwareBitmap
Windows::AI::MachineLearning::Internal::TensorToVideoFrameConverter::ConvertDX12TensorToUnsupportedVideoFrameFormat
Windows::AI::MachineLearning::Internal::TensorToVideoFrameConverter::ConvertGPUTensorToDX12Texture
Windows::AI::MachineLearning::Internal::TensorToVideoFrameConverter::ConvertGPUTensorToSoftwareBitmap
Windows::AI::MachineLearning::Internal::TensorToVideoFrameConverter::CreateShareableD3D12Texture
Windows::AI::MachineLearning::Internal::TensorToVideoFrameConverter::CreateSRVDescriptor
Windows::AI::MachineLearning::Internal::TensorToVideoFrameConverter::DX12TensorToVideoFrame
Windows::AI::MachineLearning::Internal::TensorToVideoFrameConverter::ShareD3D12Texture
Windows::AI::MachineLearning::Internal::TensorToVideoFrameConverter::SoftwareTensorToVideoFrame
Windows::AI::MachineLearning::Internal::VideoFrameToTensorConverter::ConvertDX12TextureToGPUTensor
Windows::AI::MachineLearning::Internal::VideoFrameToTensorConverter::ConvertSoftwareBitmapToCPUTensor
Windows::AI::MachineLearning::Internal::VideoFrameToTensorConverter::ConvertSoftwareBitmapToGPUTensor
Windows::AI::MachineLearning::Internal::VideoFrameToTensorConverter::CreateUAVDescription
Windows::AI::MachineLearning::Internal::VideoFrameToTensorConverter::ShareD3D11Texture
Windows::AI::MachineLearning::Internal::VideoFrameToTensorConverter::VideoFrameToDX12Tensor
Windows::AI::MachineLearning::Internal::VideoFrameToTensorConverter::VideoFrameToSoftwareTensor
Windows::AI::MachineLearning::TensorBase<__int64,__int64,struct winrt::Windows::AI::MachineLearning::implementation::TensorInt64Bit,struct winrt::Windows::AI::MachineLearning::ITensorInt64Bit,struct winrt::Windows::AI::MachineLearning::implementation::TensorInt64Bit_base<struct winrt::Windows::AI::MachineLearning::implementation::TensorInt64Bit,struct ITensorNative,struct Windows::AI::MachineLearning::ILotusValueProviderPrivate> >::CPUTensorize
Windows::AI::MachineLearning::TensorBase<__int64,__int64,struct winrt::Windows::AI::MachineLearning::implementation::TensorInt64Bit,struct winrt::Windows::AI::MachineLearning::ITensorInt64Bit,struct winrt::Windows::AI::MachineLearning::implementation::TensorInt64Bit_base<struct winrt::Windows::AI::MachineLearning::implementation::TensorInt64Bit,struct ITensorNative,struct Windows::AI::MachineLearning::ILotusValueProviderPrivate> >::EnsureBufferNotInUse
Windows::AI::MachineLearning::TensorBase<__int64,__int64,struct winrt::Windows::AI::MachineLearning::implementation::TensorInt64Bit,struct winrt::Windows::AI::MachineLearning::ITensorInt64Bit,struct winrt::Windows::AI::MachineLearning::implementation::TensorInt64Bit_base<struct winrt::Windows::AI::MachineLearning::implementation::TensorInt64Bit,struct ITensorNative,struct Windows::AI::MachineLearning::ILotusValueProviderPrivate> >::GetCpuResource
Windows::AI::MachineLearning::TensorBase<__int64,__int64,struct winrt::Windows::AI::MachineLearning::implementation::TensorInt64Bit,struct winrt::Windows::AI::MachineLearning::ITensorInt64Bit,struct winrt::Windows::AI::MachineLearning::implementation::TensorInt64Bit_base<struct winrt::Windows::AI::MachineLearning::implementation::TensorInt64Bit,struct ITensorNative,struct Windows::AI::MachineLearning::ILotusValueProviderPrivate> >::GetGpuResource
Windows::AI::MachineLearning::TensorBase<bool,bool,struct winrt::Windows::AI::MachineLearning::implementation::TensorBoolean,struct winrt::Windows::AI::MachineLearning::ITensorBoolean,struct winrt::Windows::AI::MachineLearning::implementation::TensorBoolean_base<struct winrt::Windows::AI::MachineLearning::implementation::TensorBoolean,struct ITensorNative,struct Windows::AI::MachineLearning::ILotusValueProviderPrivate> >::CPUTensorize
Windows::AI::MachineLearning::TensorBase<bool,bool,struct winrt::Windows::AI::MachineLearning::implementation::TensorBoolean,struct winrt::Windows::AI::MachineLearning::ITensorBoolean,struct winrt::Windows::AI::MachineLearning::implementation::TensorBoolean_base<struct winrt::Windows::AI::MachineLearning::implementation::TensorBoolean,struct ITensorNative,struct Windows::AI::MachineLearning::ILotusValueProviderPrivate> >::EnsureBufferNotInUse
Windows::AI::MachineLearning::TensorBase<bool,bool,struct winrt::Windows::AI::MachineLearning::implementation::TensorBoolean,struct winrt::Windows::AI::MachineLearning::ITensorBoolean,struct winrt::Windows::AI::MachineLearning::implementation::TensorBoolean_base<struct winrt::Windows::AI::MachineLearning::implementation::TensorBoolean,struct ITensorNative,struct Windows::AI::MachineLearning::ILotusValueProviderPrivate> >::GetCpuResource
Windows::AI::MachineLearning::TensorBase<bool,bool,struct winrt::Windows::AI::MachineLearning::implementation::TensorBoolean,struct winrt::Windows::AI::MachineLearning::ITensorBoolean,struct winrt::Windows::AI::MachineLearning::implementation::TensorBoolean_base<struct winrt::Windows::AI::MachineLearning::implementation::TensorBoolean,struct ITensorNative,struct Windows::AI::MachineLearning::ILotusValueProviderPrivate> >::GetGpuResource
Windows::AI::MachineLearning::TensorBase<class std::basic_string<char,struct std::char_traits<char>,class std::allocator<char> >,struct winrt::hstring,struct winrt::Windows::AI::MachineLearning::implementation::TensorString,struct winrt::Windows::AI::MachineLearning::ITensorString,struct winrt::Windows::AI::MachineLearning::implementation::TensorString_base<struct winrt::Windows::AI::MachineLearning::implementation::TensorString,struct ITensorNative,struct Windows::AI::MachineLearning::ILotusValueProviderPrivate> >::CPUTensorize
Windows::AI::MachineLearning::TensorBase<class std::basic_string<char,struct std::char_traits<char>,class std::allocator<char> >,struct winrt::hstring,struct winrt::Windows::AI::MachineLearning::implementation::TensorString,struct winrt::Windows::AI::MachineLearning::ITensorString,struct winrt::Windows::AI::MachineLearning::implementation::TensorString_base<struct winrt::Windows::AI::MachineLearning::implementation::TensorString,struct ITensorNative,struct Windows::AI::MachineLearning::ILotusValueProviderPrivate> >::EnsureBufferNotInUse
Windows::AI::MachineLearning::TensorBase<class std::basic_string<char,struct std::char_traits<char>,class std::allocator<char> >,struct winrt::hstring,struct winrt::Windows::AI::MachineLearning::implementation::TensorString,struct winrt::Windows::AI::MachineLearning::ITensorString,struct winrt::Windows::AI::MachineLearning::implementation::TensorString_base<struct winrt::Windows::AI::MachineLearning::implementation::TensorString,struct ITensorNative,struct Windows::AI::MachineLearning::ILotusValueProviderPrivate> >::GetCpuResource
Windows::AI::MachineLearning::TensorBase<class std::basic_string<char,struct std::char_traits<char>,class std::allocator<char> >,struct winrt::hstring,struct winrt::Windows::AI::MachineLearning::implementation::TensorString,struct winrt::Windows::AI::MachineLearning::ITensorString,struct winrt::Windows::AI::MachineLearning::implementation::TensorString_base<struct winrt::Windows::AI::MachineLearning::implementation::TensorString,struct ITensorNative,struct Windows::AI::MachineLearning::ILotusValueProviderPrivate> >::GetGpuResource
Windows::AI::MachineLearning::TensorBase<class std::basic_string<char,struct std::char_traits<char>,class std::allocator<char> >,struct winrt::hstring,struct winrt::Windows::AI::MachineLearning::implementation::TensorString,struct winrt::Windows::AI::MachineLearning::ITensorString,struct winrt::Windows::AI::MachineLearning::implementation::TensorString_base<struct winrt::Windows::AI::MachineLearning::implementation::TensorString,struct ITensorNative,struct Windows::AI::MachineLearning::ILotusValueProviderPrivate> >::TensorBase
Windows::AI::MachineLearning::TensorBase<double,double,struct winrt::Windows::AI::MachineLearning::implementation::TensorDouble,struct winrt::Windows::AI::MachineLearning::ITensorDouble,struct winrt::Windows::AI::MachineLearning::implementation::TensorDouble_base<struct winrt::Windows::AI::MachineLearning::implementation::TensorDouble,struct ITensorNative,struct Windows::AI::MachineLearning::ILotusValueProviderPrivate> >::CPUTensorize
Windows::AI::MachineLearning::TensorBase<double,double,struct winrt::Windows::AI::MachineLearning::implementation::TensorDouble,struct winrt::Windows::AI::MachineLearning::ITensorDouble,struct winrt::Windows::AI::MachineLearning::implementation::TensorDouble_base<struct winrt::Windows::AI::MachineLearning::implementation::TensorDouble,struct ITensorNative,struct Windows::AI::MachineLearning::ILotusValueProviderPrivate> >::EnsureBufferNotInUse
Windows::AI::MachineLearning::TensorBase<double,double,struct winrt::Windows::AI::MachineLearning::implementation::TensorDouble,struct winrt::Windows::AI::MachineLearning::ITensorDouble,struct winrt::Windows::AI::MachineLearning::implementation::TensorDouble_base<struct winrt::Windows::AI::MachineLearning::implementation::TensorDouble,struct ITensorNative,struct Windows::AI::MachineLearning::ILotusValueProviderPrivate> >::GetCpuResource
Windows::AI::MachineLearning::TensorBase<double,double,struct winrt::Windows::AI::MachineLearning::implementation::TensorDouble,struct winrt::Windows::AI::MachineLearning::ITensorDouble,struct winrt::Windows::AI::MachineLearning::implementation::TensorDouble_base<struct winrt::Windows::AI::MachineLearning::implementation::TensorDouble,struct ITensorNative,struct Windows::AI::MachineLearning::ILotusValueProviderPrivate> >::GetGpuResource
Windows::AI::MachineLearning::TensorBase<float,float,struct winrt::Windows::AI::MachineLearning::implementation::TensorFloat,struct winrt::Windows::AI::MachineLearning::ITensorFloat,struct winrt::Windows::AI::MachineLearning::implementation::TensorFloat_base<struct winrt::Windows::AI::MachineLearning::implementation::TensorFloat,struct ITensorNative,struct Windows::AI::MachineLearning::ILotusValueProviderPrivate> >::CPUTensorize
Windows::AI::MachineLearning::TensorBase<float,float,struct winrt::Windows::AI::MachineLearning::implementation::TensorFloat,struct winrt::Windows::AI::MachineLearning::ITensorFloat,struct winrt::Windows::AI::MachineLearning::implementation::TensorFloat_base<struct winrt::Windows::AI::MachineLearning::implementation::TensorFloat,struct ITensorNative,struct Windows::AI::MachineLearning::ILotusValueProviderPrivate> >::EnsureBufferNotInUse
Windows::AI::MachineLearning::TensorBase<float,float,struct winrt::Windows::AI::MachineLearning::implementation::TensorFloat,struct winrt::Windows::AI::MachineLearning::ITensorFloat,struct winrt::Windows::AI::MachineLearning::implementation::TensorFloat_base<struct winrt::Windows::AI::MachineLearning::implementation::TensorFloat,struct ITensorNative,struct Windows::AI::MachineLearning::ILotusValueProviderPrivate> >::GetCpuResource
Windows::AI::MachineLearning::TensorBase<float,float,struct winrt::Windows::AI::MachineLearning::implementation::TensorFloat,struct winrt::Windows::AI::MachineLearning::ITensorFloat,struct winrt::Windows::AI::MachineLearning::implementation::TensorFloat_base<struct winrt::Windows::AI::MachineLearning::implementation::TensorFloat,struct ITensorNative,struct Windows::AI::MachineLearning::ILotusValueProviderPrivate> >::GetGpuResource
Windows::AI::MachineLearning::TensorBase<int,int,struct winrt::Windows::AI::MachineLearning::implementation::TensorInt32Bit,struct winrt::Windows::AI::MachineLearning::ITensorInt32Bit,struct winrt::Windows::AI::MachineLearning::implementation::TensorInt32Bit_base<struct winrt::Windows::AI::MachineLearning::implementation::TensorInt32Bit,struct ITensorNative,struct Windows::AI::MachineLearning::ILotusValueProviderPrivate> >::CPUTensorize
Windows::AI::MachineLearning::TensorBase<int,int,struct winrt::Windows::AI::MachineLearning::implementation::TensorInt32Bit,struct winrt::Windows::AI::MachineLearning::ITensorInt32Bit,struct winrt::Windows::AI::MachineLearning::implementation::TensorInt32Bit_base<struct winrt::Windows::AI::MachineLearning::implementation::TensorInt32Bit,struct ITensorNative,struct Windows::AI::MachineLearning::ILotusValueProviderPrivate> >::EnsureBufferNotInUse
Windows::AI::MachineLearning::TensorBase<int,int,struct winrt::Windows::AI::MachineLearning::implementation::TensorInt32Bit,struct winrt::Windows::AI::MachineLearning::ITensorInt32Bit,struct winrt::Windows::AI::MachineLearning::implementation::TensorInt32Bit_base<struct winrt::Windows::AI::MachineLearning::implementation::TensorInt32Bit,struct ITensorNative,struct Windows::AI::MachineLearning::ILotusValueProviderPrivate> >::GetCpuResource
Windows::AI::MachineLearning::TensorBase<int,int,struct winrt::Windows::AI::MachineLearning::implementation::TensorInt32Bit,struct winrt::Windows::AI::MachineLearning::ITensorInt32Bit,struct winrt::Windows::AI::MachineLearning::implementation::TensorInt32Bit_base<struct winrt::Windows::AI::MachineLearning::implementation::TensorInt32Bit,struct ITensorNative,struct Windows::AI::MachineLearning::ILotusValueProviderPrivate> >::GetGpuResource
Windows::AI::MachineLearning::TensorBase<short,short,struct winrt::Windows::AI::MachineLearning::implementation::TensorInt16Bit,struct winrt::Windows::AI::MachineLearning::ITensorInt16Bit,struct winrt::Windows::AI::MachineLearning::implementation::TensorInt16Bit_base<struct winrt::Windows::AI::MachineLearning::implementation::TensorInt16Bit,struct ITensorNative,struct Windows::AI::MachineLearning::ILotusValueProviderPrivate> >::CPUTensorize
Windows::AI::MachineLearning::TensorBase<short,short,struct winrt::Windows::AI::MachineLearning::implementation::TensorInt16Bit,struct winrt::Windows::AI::MachineLearning::ITensorInt16Bit,struct winrt::Windows::AI::MachineLearning::implementation::TensorInt16Bit_base<struct winrt::Windows::AI::MachineLearning::implementation::TensorInt16Bit,struct ITensorNative,struct Windows::AI::MachineLearning::ILotusValueProviderPrivate> >::EnsureBufferNotInUse
Windows::AI::MachineLearning::TensorBase<short,short,struct winrt::Windows::AI::MachineLearning::implementation::TensorInt16Bit,struct winrt::Windows::AI::MachineLearning::ITensorInt16Bit,struct winrt::Windows::AI::MachineLearning::implementation::TensorInt16Bit_base<struct winrt::Windows::AI::MachineLearning::implementation::TensorInt16Bit,struct ITensorNative,struct Windows::AI::MachineLearning::ILotusValueProviderPrivate> >::GetGpuResource
Windows::AI::MachineLearning::TensorBase<signed char,unsigned char,struct winrt::Windows::AI::MachineLearning::implementation::TensorInt8Bit,struct winrt::Windows::AI::MachineLearning::ITensorInt8Bit,struct winrt::Windows::AI::MachineLearning::implementation::TensorInt8Bit_base<struct winrt::Windows::AI::MachineLearning::implementation::TensorInt8Bit,struct ITensorNative,struct Windows::AI::MachineLearning::ILotusValueProviderPrivate> >::CPUTensorize
Windows::AI::MachineLearning::TensorBase<signed char,unsigned char,struct winrt::Windows::AI::MachineLearning::implementation::TensorInt8Bit,struct winrt::Windows::AI::MachineLearning::ITensorInt8Bit,struct winrt::Windows::AI::MachineLearning::implementation::TensorInt8Bit_base<struct winrt::Windows::AI::MachineLearning::implementation::TensorInt8Bit,struct ITensorNative,struct Windows::AI::MachineLearning::ILotusValueProviderPrivate> >::EnsureBufferNotInUse
Windows::AI::MachineLearning::TensorBase<signed char,unsigned char,struct winrt::Windows::AI::MachineLearning::implementation::TensorInt8Bit,struct winrt::Windows::AI::MachineLearning::ITensorInt8Bit,struct winrt::Windows::AI::MachineLearning::implementation::TensorInt8Bit_base<struct winrt::Windows::AI::MachineLearning::implementation::TensorInt8Bit,struct ITensorNative,struct Windows::AI::MachineLearning::ILotusValueProviderPrivate> >::GetCpuResource
Windows::AI::MachineLearning::TensorBase<signed char,unsigned char,struct winrt::Windows::AI::MachineLearning::implementation::TensorInt8Bit,struct winrt::Windows::AI::MachineLearning::ITensorInt8Bit,struct winrt::Windows::AI::MachineLearning::implementation::TensorInt8Bit_base<struct winrt::Windows::AI::MachineLearning::implementation::TensorInt8Bit,struct ITensorNative,struct Windows::AI::MachineLearning::ILotusValueProviderPrivate> >::GetGpuResource
Windows::AI::MachineLearning::TensorBase<union onnxruntime::MLFloat16,float,struct winrt::Windows::AI::MachineLearning::implementation::TensorFloat16Bit,struct winrt::Windows::AI::MachineLearning::ITensorFloat16Bit,struct winrt::Windows::AI::MachineLearning::implementation::TensorFloat16Bit_base<struct winrt::Windows::AI::MachineLearning::implementation::TensorFloat16Bit,struct ITensorNative,struct Windows::AI::MachineLearning::ILotusValueProviderPrivate> >::CPUTensorize
Windows::AI::MachineLearning::TensorBase<union onnxruntime::MLFloat16,float,struct winrt::Windows::AI::MachineLearning::implementation::TensorFloat16Bit,struct winrt::Windows::AI::MachineLearning::ITensorFloat16Bit,struct winrt::Windows::AI::MachineLearning::implementation::TensorFloat16Bit_base<struct winrt::Windows::AI::MachineLearning::implementation::TensorFloat16Bit,struct ITensorNative,struct Windows::AI::MachineLearning::ILotusValueProviderPrivate> >::EnsureBufferNotInUse
Windows::AI::MachineLearning::TensorBase<union onnxruntime::MLFloat16,float,struct winrt::Windows::AI::MachineLearning::implementation::TensorFloat16Bit,struct winrt::Windows::AI::MachineLearning::ITensorFloat16Bit,struct winrt::Windows::AI::MachineLearning::implementation::TensorFloat16Bit_base<struct winrt::Windows::AI::MachineLearning::implementation::TensorFloat16Bit,struct ITensorNative,struct Windows::AI::MachineLearning::ILotusValueProviderPrivate> >::GetCpuResource
Windows::AI::MachineLearning::TensorBase<union onnxruntime::MLFloat16,float,struct winrt::Windows::AI::MachineLearning::implementation::TensorFloat16Bit,struct winrt::Windows::AI::MachineLearning::ITensorFloat16Bit,struct winrt::Windows::AI::MachineLearning::implementation::TensorFloat16Bit_base<struct winrt::Windows::AI::MachineLearning::implementation::TensorFloat16Bit,struct ITensorNative,struct Windows::AI::MachineLearning::ILotusValueProviderPrivate> >::GetGpuResource
Windows::AI::MachineLearning::TensorBase<unsigned __int64,unsigned __int64,struct winrt::Windows::AI::MachineLearning::implementation::TensorUInt64Bit,struct winrt::Windows::AI::MachineLearning::ITensorUInt64Bit,struct winrt::Windows::AI::MachineLearning::implementation::TensorUInt64Bit_base<struct winrt::Windows::AI::MachineLearning::implementation::TensorUInt64Bit,struct ITensorNative,struct Windows::AI::MachineLearning::ILotusValueProviderPrivate> >::CPUTensorize
Windows::AI::MachineLearning::TensorBase<unsigned __int64,unsigned __int64,struct winrt::Windows::AI::MachineLearning::implementation::TensorUInt64Bit,struct winrt::Windows::AI::MachineLearning::ITensorUInt64Bit,struct winrt::Windows::AI::MachineLearning::implementation::TensorUInt64Bit_base<struct winrt::Windows::AI::MachineLearning::implementation::TensorUInt64Bit,struct ITensorNative,struct Windows::AI::MachineLearning::ILotusValueProviderPrivate> >::EnsureBufferNotInUse
Windows::AI::MachineLearning::TensorBase<unsigned __int64,unsigned __int64,struct winrt::Windows::AI::MachineLearning::implementation::TensorUInt64Bit,struct winrt::Windows::AI::MachineLearning::ITensorUInt64Bit,struct winrt::Windows::AI::MachineLearning::implementation::TensorUInt64Bit_base<struct winrt::Windows::AI::MachineLearning::implementation::TensorUInt64Bit,struct ITensorNative,struct Windows::AI::MachineLearning::ILotusValueProviderPrivate> >::GetCpuResource
Windows::AI::MachineLearning::TensorBase<unsigned __int64,unsigned __int64,struct winrt::Windows::AI::MachineLearning::implementation::TensorUInt64Bit,struct winrt::Windows::AI::MachineLearning::ITensorUInt64Bit,struct winrt::Windows::AI::MachineLearning::implementation::TensorUInt64Bit_base<struct winrt::Windows::AI::MachineLearning::implementation::TensorUInt64Bit,struct ITensorNative,struct Windows::AI::MachineLearning::ILotusValueProviderPrivate> >::GetGpuResource
Windows::AI::MachineLearning::TensorBase<unsigned char,unsigned char,struct winrt::Windows::AI::MachineLearning::implementation::TensorUInt8Bit,struct winrt::Windows::AI::MachineLearning::ITensorUInt8Bit,struct winrt::Windows::AI::MachineLearning::implementation::TensorUInt8Bit_base<struct winrt::Windows::AI::MachineLearning::implementation::TensorUInt8Bit,struct ITensorNative,struct Windows::AI::MachineLearning::ILotusValueProviderPrivate> >::CPUTensorize
Windows::AI::MachineLearning::TensorBase<unsigned char,unsigned char,struct winrt::Windows::AI::MachineLearning::implementation::TensorUInt8Bit,struct winrt::Windows::AI::MachineLearning::ITensorUInt8Bit,struct winrt::Windows::AI::MachineLearning::implementation::TensorUInt8Bit_base<struct winrt::Windows::AI::MachineLearning::implementation::TensorUInt8Bit,struct ITensorNative,struct Windows::AI::MachineLearning::ILotusValueProviderPrivate> >::EnsureBufferNotInUse
Windows::AI::MachineLearning::TensorBase<unsigned char,unsigned char,struct winrt::Windows::AI::MachineLearning::implementation::TensorUInt8Bit,struct winrt::Windows::AI::MachineLearning::ITensorUInt8Bit,struct winrt::Windows::AI::MachineLearning::implementation::TensorUInt8Bit_base<struct winrt::Windows::AI::MachineLearning::implementation::TensorUInt8Bit,struct ITensorNative,struct Windows::AI::MachineLearning::ILotusValueProviderPrivate> >::GetCpuResource
Windows::AI::MachineLearning::TensorBase<unsigned char,unsigned char,struct winrt::Windows::AI::MachineLearning::implementation::TensorUInt8Bit,struct winrt::Windows::AI::MachineLearning::ITensorUInt8Bit,struct winrt::Windows::AI::MachineLearning::implementation::TensorUInt8Bit_base<struct winrt::Windows::AI::MachineLearning::implementation::TensorUInt8Bit,struct ITensorNative,struct Windows::AI::MachineLearning::ILotusValueProviderPrivate> >::GetGpuResource
Windows::AI::MachineLearning::TensorBase<unsigned int,unsigned int,struct winrt::Windows::AI::MachineLearning::implementation::TensorUInt32Bit,struct winrt::Windows::AI::MachineLearning::ITensorUInt32Bit,struct winrt::Windows::AI::MachineLearning::implementation::TensorUInt32Bit_base<struct winrt::Windows::AI::MachineLearning::implementation::TensorUInt32Bit,struct ITensorNative,struct Windows::AI::MachineLearning::ILotusValueProviderPrivate> >::CPUTensorize
Windows::AI::MachineLearning::TensorBase<unsigned int,unsigned int,struct winrt::Windows::AI::MachineLearning::implementation::TensorUInt32Bit,struct winrt::Windows::AI::MachineLearning::ITensorUInt32Bit,struct winrt::Windows::AI::MachineLearning::implementation::TensorUInt32Bit_base<struct winrt::Windows::AI::MachineLearning::implementation::TensorUInt32Bit,struct ITensorNative,struct Windows::AI::MachineLearning::ILotusValueProviderPrivate> >::EnsureBufferNotInUse
Windows::AI::MachineLearning::TensorBase<unsigned int,unsigned int,struct winrt::Windows::AI::MachineLearning::implementation::TensorUInt32Bit,struct winrt::Windows::AI::MachineLearning::ITensorUInt32Bit,struct winrt::Windows::AI::MachineLearning::implementation::TensorUInt32Bit_base<struct winrt::Windows::AI::MachineLearning::implementation::TensorUInt32Bit,struct ITensorNative,struct Windows::AI::MachineLearning::ILotusValueProviderPrivate> >::GetGpuResource
Windows::AI::MachineLearning::TensorBase<unsigned short,unsigned short,struct winrt::Windows::AI::MachineLearning::implementation::TensorUInt16Bit,struct winrt::Windows::AI::MachineLearning::ITensorUInt16Bit,struct winrt::Windows::AI::MachineLearning::implementation::TensorUInt16Bit_base<struct winrt::Windows::AI::MachineLearning::implementation::TensorUInt16Bit,struct ITensorNative,struct Windows::AI::MachineLearning::ILotusValueProviderPrivate> >::CPUTensorize
Windows::AI::MachineLearning::TensorBase<unsigned short,unsigned short,struct winrt::Windows::AI::MachineLearning::implementation::TensorUInt16Bit,struct winrt::Windows::AI::MachineLearning::ITensorUInt16Bit,struct winrt::Windows::AI::MachineLearning::implementation::TensorUInt16Bit_base<struct winrt::Windows::AI::MachineLearning::implementation::TensorUInt16Bit,struct ITensorNative,struct Windows::AI::MachineLearning::ILotusValueProviderPrivate> >::EnsureBufferNotInUse
Windows::AI::MachineLearning::TensorBase<unsigned short,unsigned short,struct winrt::Windows::AI::MachineLearning::implementation::TensorUInt16Bit,struct winrt::Windows::AI::MachineLearning::ITensorUInt16Bit,struct winrt::Windows::AI::MachineLearning::implementation::TensorUInt16Bit_base<struct winrt::Windows::AI::MachineLearning::implementation::TensorUInt16Bit,struct ITensorNative,struct Windows::AI::MachineLearning::ILotusValueProviderPrivate> >::GetGpuResource
Windows::AI::MachineLearning::TensorBaseHelpers::CreateGPUMLValue
Windows::AI::MachineLearning::TensorBuffer<__int64>::Set
Windows::AI::MachineLearning::TensorBuffer<bool>::Set
Windows::AI::MachineLearning::TensorBuffer<class std::basic_string<char,struct std::char_traits<char>,class std::allocator<char> > >::Set
Windows::AI::MachineLearning::TensorBuffer<double>::Set
Windows::AI::MachineLearning::TensorBuffer<float>::Set
Windows::AI::MachineLearning::TensorBuffer<int>::Set
Windows::AI::MachineLearning::TensorBuffer<short>::Set
Windows::AI::MachineLearning::TensorBuffer<signed char>::Set
Windows::AI::MachineLearning::TensorBuffer<union onnxruntime::MLFloat16>::Set
Windows::AI::MachineLearning::TensorBuffer<unsigned __int64>::Set
Windows::AI::MachineLearning::TensorBuffer<unsigned char>::Set
Windows::AI::MachineLearning::TensorBuffer<unsigned int>::Set
Windows::AI::MachineLearning::TensorBuffer<unsigned short>::Set
Windows::AI::MachineLearning::TensorMemoryBufferReference<__int64>::Capacity
Windows::AI::MachineLearning::TensorMemoryBufferReference<bool>::Capacity
Windows::AI::MachineLearning::TensorMemoryBufferReference<double>::Capacity
Windows::AI::MachineLearning::TensorMemoryBufferReference<float>::Capacity
Windows::AI::MachineLearning::TensorMemoryBufferReference<int>::Capacity
Windows::AI::MachineLearning::TensorMemoryBufferReference<signed char>::Capacity
Windows::AI::MachineLearning::TensorMemoryBufferReference<union onnxruntime::MLFloat16>::Capacity
Windows::AI::MachineLearning::TensorMemoryBufferReference<unsigned __int64>::Capacity
Windows::AI::MachineLearning::TensorMemoryBufferReference<unsigned char>::Capacity
Windows::AI::MachineLearning::TensorMemoryBufferReference<unsigned short>::Capacity
Windows::AI::MachineLearning::ZeroCopyInputStreamWrapper::ByteCount
Windows::AI::MachineLearning::ZeroCopyInputStreamWrapper::Next
Windows::AI::MachineLearning::ZeroCopyInputStreamWrapper::Skip
WindowsCreateString
WindowsCreateStringReference
WindowsDeleteString
WindowsDeleteStringBuffer
WindowsDuplicateString
WindowsGetStringLen
WindowsGetStringRawBuffer
WindowsIsStringEmpty
WindowSize
WindowsPreallocateStringBuffer
WindowsPromoteStringBuffer
WindowsStringHasEmbeddedNull
WinMLInputValidation
WinMLLogSink
WinmlRuleTransformer
winrt::hresult_error: %ls
winrt::Windows::AI::MachineLearning::factory_implementation::LearningModel::Load
winrt::Windows::AI::MachineLearning::factory_implementation::LearningModelDevice::CreateFromD3D12CommandQueue
winrt::Windows::AI::MachineLearning::implementation::AbiCustomRegistry::RegisterOperatorSetSchema
winrt::Windows::AI::MachineLearning::implementation::ApplyBatchSizeOverride
winrt::Windows::AI::MachineLearning::implementation::CreateUnboundOuputFeatureValue
winrt::Windows::AI::MachineLearning::implementation::D3DDeviceCache::CreateDetensorizePipelineState
winrt::Windows::AI::MachineLearning::implementation::D3DDeviceCache::CreateTensorizePipelineState
winrt::Windows::AI::MachineLearning::implementation::D3DDeviceCache::D3DDeviceCache
winrt::Windows::AI::MachineLearning::implementation::D3DDeviceCache::EnsureD3D11FromD3D12
winrt::Windows::AI::MachineLearning::implementation::D3DDeviceCache::EnsureSharedFences
winrt::Windows::AI::MachineLearning::implementation::D3DDeviceCache::GetConverterFenceHandle
winrt::Windows::AI::MachineLearning::implementation::D3DDeviceCache::GetDetensorizeRootSignature
winrt::Windows::AI::MachineLearning::implementation::D3DDeviceCache::GetTensorizeRootSignature
winrt::Windows::AI::MachineLearning::implementation::D3DDeviceCache::GPUSyncD3D11ToD3D12
winrt::Windows::AI::MachineLearning::implementation::D3DDeviceCache::GPUSyncD3D12ToD3D11
winrt::Windows::AI::MachineLearning::implementation::D3DDeviceCache::InitializeCommandQueue
winrt::Windows::AI::MachineLearning::implementation::D3DDeviceCache::QueueFenceToD3D12
winrt::Windows::AI::MachineLearning::implementation::D3DDeviceCache::SyncConverterToD3D11Device
winrt::Windows::AI::MachineLearning::implementation::D3DDeviceCache::SyncD3D11DeviceToConverter
winrt::Windows::AI::MachineLearning::implementation::D3DDeviceCache::WaitForFenceValue
winrt::Windows::AI::MachineLearning::implementation::EnsureModelDeviceCompatibility
winrt::Windows::AI::MachineLearning::implementation::FindValidBinding
winrt::Windows::AI::MachineLearning::implementation::GetBitmapPixelFormatFromMetadata
winrt::Windows::AI::MachineLearning::implementation::GetBoundsFromMetadata
winrt::Windows::AI::MachineLearning::implementation::GetIOBinding
winrt::Windows::AI::MachineLearning::implementation::GetIOBinding::<lambda_b9362cafba4b71e076ee374aa4660d4d>::operator ()
winrt::Windows::AI::MachineLearning::implementation::GetSizeFromTensorDataType
winrt::Windows::AI::MachineLearning::implementation::GetTensorDataTypeFromTensorKind
winrt::Windows::AI::MachineLearning::implementation::ImageFeatureValue::CenterAndCropBounds
winrt::Windows::AI::MachineLearning::implementation::LearningModelBinding::Bind
winrt::Windows::AI::MachineLearning::implementation::LearningModelBinding::CreateBinding
winrt::Windows::AI::MachineLearning::implementation::LearningModelBinding::CreateUnboundOutput
winrt::Windows::AI::MachineLearning::implementation::LearningModelBinding::Lookup
winrt::Windows::AI::MachineLearning::implementation::LearningModelBinding::UpdateProviders
winrt::Windows::AI::MachineLearning::implementation::LearningModelDevice::RegisterKernels
winrt::Windows::AI::MachineLearning::implementation::LearningModelSession::CheckClosed
winrt::Windows::AI::MachineLearning::implementation::LearningModelSession::CreateSessionBinding
winrt::Windows::AI::MachineLearning::implementation::LearningModelSession::GetOptimizedModel
winrt::Windows::AI::MachineLearning::implementation::LearningModelSession::Initialize
winrt::Windows::AI::MachineLearning::implementation::LearningModelSession::Run
winrt::Windows::AI::MachineLearning::implementation::OpKernelContextWrapper::AllocateTemporaryData
winrt::Windows::AI::MachineLearning::implementation::OpNodeInfoWrapper<class onnxruntime::ProtoHelperNodeContext,class Microsoft::WRL::RuntimeClass<struct Microsoft::WRL::RuntimeClassFlags<2>,struct Microsoft::WRL::ChainInterfaces<struct IMLOperatorKernelCreationContextPrivate,struct IMLOperatorKernelCreationContext,class Microsoft::WRL::Details::Nil,class Microsoft::WRL::Details::Nil,class Microsoft::WRL::Details::Nil,class Microsoft::WRL::Details::Nil,class Microsoft::WRL::Details::Nil,class Microsoft::WRL::Details::Nil,class Microsoft::WRL::Details::Nil,class Microsoft::WRL::Details::Nil>,struct IMLOperatorTensorShapeDescription,struct IMLOperatorAttributes1>,struct onnxruntime::null_type>::GetAttributeArrayHelper
winrt::Windows::AI::MachineLearning::implementation::OpNodeInfoWrapper<class onnxruntime::ProtoHelperNodeContext,class Microsoft::WRL::RuntimeClass<struct Microsoft::WRL::RuntimeClassFlags<2>,struct Microsoft::WRL::ChainInterfaces<struct IMLOperatorKernelCreationContextPrivate,struct IMLOperatorKernelCreationContext,class Microsoft::WRL::Details::Nil,class Microsoft::WRL::Details::Nil,class Microsoft::WRL::Details::Nil,class Microsoft::WRL::Details::Nil,class Microsoft::WRL::Details::Nil,class Microsoft::WRL::Details::Nil,class Microsoft::WRL::Details::Nil,class Microsoft::WRL::Details::Nil>,struct IMLOperatorTensorShapeDescription,struct IMLOperatorAttributes1>,struct onnxruntime::null_type>::GetAttributeHelper
winrt::Windows::AI::MachineLearning::implementation::OpNodeInfoWrapper<class onnxruntime::ProtoHelperNodeContext,class Microsoft::WRL::RuntimeClass<struct Microsoft::WRL::RuntimeClassFlags<2>,struct Microsoft::WRL::ChainInterfaces<struct IMLOperatorShapeInferenceContextPrivate,struct IMLOperatorShapeInferenceContext,class Microsoft::WRL::Details::Nil,class Microsoft::WRL::Details::Nil,class Microsoft::WRL::Details::Nil,class Microsoft::WRL::Details::Nil,class Microsoft::WRL::Details::Nil,class Microsoft::WRL::Details::Nil,class Microsoft::WRL::Details::Nil,class Microsoft::WRL::Details::Nil>,struct IMLOperatorAttributes,struct IMLOperatorAttributes1>,struct onnxruntime::null_type>::GetAttributeArrayHelper
winrt::Windows::AI::MachineLearning::implementation::OpNodeInfoWrapper<class onnxruntime::ProtoHelperNodeContext,class Microsoft::WRL::RuntimeClass<struct Microsoft::WRL::RuntimeClassFlags<2>,struct Microsoft::WRL::ChainInterfaces<struct IMLOperatorShapeInferenceContextPrivate,struct IMLOperatorShapeInferenceContext,class Microsoft::WRL::Details::Nil,class Microsoft::WRL::Details::Nil,class Microsoft::WRL::Details::Nil,class Microsoft::WRL::Details::Nil,class Microsoft::WRL::Details::Nil,class Microsoft::WRL::Details::Nil,class Microsoft::WRL::Details::Nil,class Microsoft::WRL::Details::Nil>,struct IMLOperatorAttributes,struct IMLOperatorAttributes1>,struct onnxruntime::null_type>::GetAttributeHelper
winrt::Windows::AI::MachineLearning::implementation::OpNodeInfoWrapper<struct onnx::InferenceContext,class Microsoft::WRL::RuntimeClass<struct Microsoft::WRL::RuntimeClassFlags<2>,struct Microsoft::WRL::ChainInterfaces<struct IMLOperatorShapeInferenceContextPrivate,struct IMLOperatorShapeInferenceContext,class Microsoft::WRL::Details::Nil,class Microsoft::WRL::Details::Nil,class Microsoft::WRL::Details::Nil,class Microsoft::WRL::Details::Nil,class Microsoft::WRL::Details::Nil,class Microsoft::WRL::Details::Nil,class Microsoft::WRL::Details::Nil,class Microsoft::WRL::Details::Nil>,struct IMLOperatorTypeInferenceContext,struct IMLOperatorAttributes,struct IMLOperatorAttributes1>,struct onnxruntime::null_type>::GetAttributeArrayHelper
winrt::Windows::AI::MachineLearning::implementation::OpNodeInfoWrapper<struct onnx::InferenceContext,class Microsoft::WRL::RuntimeClass<struct Microsoft::WRL::RuntimeClassFlags<2>,struct Microsoft::WRL::ChainInterfaces<struct IMLOperatorShapeInferenceContextPrivate,struct IMLOperatorShapeInferenceContext,class Microsoft::WRL::Details::Nil,class Microsoft::WRL::Details::Nil,class Microsoft::WRL::Details::Nil,class Microsoft::WRL::Details::Nil,class Microsoft::WRL::Details::Nil,class Microsoft::WRL::Details::Nil,class Microsoft::WRL::Details::Nil,class Microsoft::WRL::Details::Nil>,struct IMLOperatorTypeInferenceContext,struct IMLOperatorAttributes,struct IMLOperatorAttributes1>,struct onnxruntime::null_type>::GetAttributeHelper
winrt::Windows::AI::MachineLearning::implementation::RegisterCustomRegistry
with activation 
Wj<Y+
WordConvEmbedding
WQPQQV
wrong protocol type
WSj?Z
wstr != wconv_error
Wt+Wp
wUSVW
WWQh|
WWQhpP.
WWShpP.
WWVh`Q8
WWWh|
WWWhpP.
WWWVhP
wxQjpZjoY
X != nullptr
X and Y input types do not match: 
X dims is empty.
X input is required!
X num_dims does not match W num_dims.
x$+x 
X% !2
X%p"2
x);V(}$
X[_^]
X_ptr != nullptr
x_scale
x_scale must be 1D tensor with size 
x_scale must be a scalar or 1D tensor or size 1.
x_scale.Shape().NumDimensions() == 1 && x_scale.Shape().Size() == broadcastDim
X_squared
X_variance
x_zero_point
x_zero_point must be 1D tensor with size 
x_zero_point must be a scalar or 1D tensor or size 1.
x_zero_point.Shape().NumDimensions() == 1 && x_zero_point.Shape().Size() == broadcastDim
X->Shape().NumDimensions() == 4
X0s0'191
XhP80
X-p"2
xt+xp
Xt+Xp
XWindows::AI::MachineLearning::TensorMemoryBufferReference<short>::Capacity
Y,e^h
Y@ffn@
Y_^[]
Y__^[
y_scale
y_scale.Shape().NumDimensions() == 1 && y_scale.Shape().Size() == broadcastDim
y_zero_point
y_zero_point.Shape().NumDimensions() == 1 && y_zero_point.Shape().Size() == broadcastDim
Y95 N:
Y95(N:
Y95,N:
Y95@N:
Y95\N:
Y95|N:
Y954N:
Y958N:
Y95dN:
Y95DN:
Y95lN:
Y95LN:
Y95pN:
Y95PN:
Y95XN:
Y95xN:
Y9w\~1jR
yGj_h@
yh0Y0
Yhps+
Yj+hhh/
y'Ph0
YPhP~-
YPQhp*/
YVWRP
YY;7|
YY_^[
YY_^[]
YY_^]
YY9~,t
YYj#h` 0
YYj&h` 0
YYj,h
YYj?h\U-
YYj^hx .
YYj=h
YYj5h
YYj7h
YYjCh
YYPQQ
YYPVj
YYVQP
YYWQQ
z>2?~>
Zanabazar_Square
Zero point for doing quantization to get 'y'. It could be a scalar or a 1-D tensor, which means a per-tensoror per-axis quantization. If it's a 1-D tensor, its number of elements should be equal to the dimension value of 'axis' dimension of input 'x'.
Zero point for doing quantization to get 'y'. It's a scalar, which means a per-tensor/layer quantization. Default value is 0 if it's not specified.
Zero point for input 'x'. It could be a scalar or a 1-D tensor, which means a per-tensor or per-axis quantization.If it's a 1-D tensor, its number of elements should be equal to the dimension value of 'axis' dimension of input 'x'.
Zero point for input 'x'. It's a scalar, which means a per-tensor/layer quantization. It's optional. 0 is the default value when it's not specified.
zero point of quantized input a
zero point of quantized input b
zero point of quantized output y
Zero point tensor for input 'A'. It's optional and default value is 0. It could be a scalar or a 1-D tensor, which means a per-tensor or per-row quantization. If it's a 1-D tensor, its number of elements should be equal to the number of rows of input 'A'.
Zero point tensor for input 'x'. It's a scalar, which means a per-tensor/layer quantization.
Zero point tensor for input 'x'. It's optional and default value is 0. It's a scalar, which means a per-tensor/layer quantization.
zeropoint must be a scalar
zeropoint->Shape().NumDimensions() == 0 || (zeropoint->Shape().NumDimensions() == 1 && zeropoint->Shape().GetDims().size() == 1)
ZeroPointTensor
zeros
Zh$e0
zh|,1
ZipMap
Zipmap does not support empty dim count
Zipmap only supports 1D or 2D input tensors
Zvector<T> too long
