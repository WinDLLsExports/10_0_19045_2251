        
        <requestedExecutionLevel level='asInvoker' uiAccess='false' />
      </requestedPrivileges>
      <requestedPrivileges>
    </security>
    <security>
   ' 0 8 ; > A C G Q S S U ^ 
    Carries out batch normalization as described in the paper
    https://arxiv.org/abs/1502.03167. Depending on the mode it is being run,
    Output case #1: Y, mean, var, saved_mean, saved_var (training mode)
    Output case #2: Y (test mode)
    there are multiple cases for the number of outputs, which we list below:
  - Ct = ft (.) Ct-1 + it (.) ct
  - ct = g(Xt*(Wc^T) + Ht-1*(Rc^T) + Wbc + Rbc)
  - ft = f(Xt*(Wf^T) + Ht-1*(Rf^T) + Pf (.) Ct-1 + Wbf + Rbf)
  - Ht = (1 - zt) (.) ht + zt (.) Ht-1
  - Ht = f(Xt*(Wi^T) + Ht-1*(Ri^T) + Wbi + Rbi)
  - ht = g(Xt*(Wh^T) + (rt (.) (Ht-1*(Rh^T) + Rbh)) + Wbh) # when linear_before_reset != 0
  - ht = g(Xt*(Wh^T) + (rt (.) Ht-1)*(Rh^T) + Rbh + Wbh) # default, when linear_before_reset = 0
  - Ht = ot (.) h(Ct)
  - it = f(Xt*(Wi^T) + Ht-1*(Ri^T) + Pi (.) Ct-1 + Wbi + Rbi)
  - ot = f(Xt*(Wo^T) + Ht-1*(Ro^T) + Po (.) Ct + Wbo + Rbo)
  - rt = f(Xt*(Wr^T) + Ht-1*(Rr^T) + Wbr + Rbr)
  - zt = f(Xt*(Wz^T) + Ht-1*(Rz^T) + Wbz + Rbz)
  (NOTE: Below are optional)
  </trustInfo>
  <trustInfo xmlns="urn:schemas-microsoft-com:asm.v3">
 ' 0 C E Q S ^ } ~ 
  Affine(x)              - alpha*x + beta
  AZaz
  Else: pads[start_i] = total_padding[i] - (total_padding[i]/2); pads[end_i] = (total_padding[i]/2).
  Elu(x)                 - x if x >= 0 else alpha*(e^x - 1)
  HardSigmoid(x)         - min(max(alpha*x + beta, 0), 1)
  If (auto_pads != SAME_UPPER): pads[start_i] = total_padding[i]/2; pads[end_i] = total_padding[i] - (total_padding[i]/2)
  LeakyRelu(x)           - x if x >= 0 else alpha * x
  output_shape[i] = stride[i] * (input_size[i] - 1) + output_padding[i] + kernel_shape[i] - pads[start_i] - pads[end_i]
  Relu(x)                - max(0, x)
  ScaledTanh(x)          - alpha*Tanh(beta*x)
  shape(A) = (2, 3, 4, 5), shape(B) = (,), i.e. B is a scalar tensor
  shape(A) = (2, 3, 4, 5), shape(B) = (1, 1), i.e. B is an 1-element tensor
  shape(A) = (2, 3, 4, 5), shape(B) = (2), with axis=0
  shape(A) = (2, 3, 4, 5), shape(B) = (3, 4), with axis=1
  shape(A) = (2, 3, 4, 5), shape(B) = (4, 5)
  shape(A) = (2, 3, 4, 5), shape(B) = (5,)
  Sigmoid(x)             - 1/(1 + e^{-x})
  Softplus(x)            - log(1 + e^x)
  Softsign(x)            - x/(1 + |x|)
  Tanh(x)                - (1 - e^{-2x})/(1 + e^{-2x})
  ThresholdedRelu(x)     - x if x >= alpha else 0
  total_padding[i] = stride[i] * (input_size[i] - 1) + output_padding[i] + kernel_shape[i] - output_shape[i]
 &WH+
 ( ) / / _ _ 
 (domain: 
 (node 
 (num_rois, channels, pooled_shape[0], pooled_shape[1]).
 * . ` d f o 
 * pad_shape[i] is sum of pads along axis i
 * Rh^T
 *!+!2!2!N!N!`!
 *0-0
 . Got: 
 / / _ _ 
 : : 
 [seqno=
 [truncated]
 `auto_pad` is a DEPRECATED attribute. If you are using them currently, the output spatial shape will be following:
 {additionalDescription}
 {name} consumes an input tensor X and applies {opName} pooling across
 {name} consumes an input tensor X and applies Lp pooling across
 {opName} pooling consisting of computing the {opName} on all values of a
 |,},o-o-/./.
 ~z/$
 9 9 
 A^_^
 A^_^][
 A^A\_
 A^A]A\_^
 A_A\_
 A_A^_
 A_A^_^]
 A_A^A\
 A_A^A\_^
 A_A^A\_^][
 A_A^A]
 A_A^A]A\]
 A_A^A]A\^][
 A_A^A]A\_
 A_A^A]A\_^]
 Actual: 
 allocator already registered.
 already exist.
 and 
 And pad shape will be following if `SAME_UPPER` or `SAME_LOWER`:
' appeared multiple times.
 apply {name} pooling across each RoI, to produce output 4-D tensor of shape
 arg 
 as there's no execution provider allocated.
 at pos=
' attribute.
 Axis is 
 axis value 
 Axis=
 BackUp() can only be called after Next().
 but 
 but expected 
 but has 
 but input '
 but ngram_indexes size: 
 but subgraphs produce 
 but the actually size is: 
 bytes).  To increase the limit (or to disable these warnings), see CodedInputStream::SetTotalBytesLimit() in google/protobuf/io/coded_stream.h.
 bytes.
 cannot be safely updated in one of the subgraphs.
 Can't back up over more bytes than were returned by the last call to Next().
 Char embedding size: 
 char_embedding_size attribute: 
 conv filter size: 
 conv kernal size 1: 
 Conv kernal size 2 : 
 conv_window_size attribute: 
 d f p t ~ 
 data into the output tensor Y for further processing.
 data into the output tensor Y for further processing. The output spatial shape will be following:
 data_dim=
 device_id:
 did not match batch size of 
 did not.
' dimension 
 Dimension=
 dimensions or more but input had shape of 
 dimensions.
 does not align with rank of input data: 
 does not contain a graph.
 does not match existing output type of 
 does not match its type.
 does not specify a valid type.
' doesn't support memcpy 
 Domain mismatch: 
 E E } } 
 elements.
 else=
 embedding_size attribute: 
 Encountered following errors: 
 entries which doesn't match the number of fetches the frame was initialized with of 
 equal to the spatial dimension of input tensor.
 Execution provider mismatch.
 exists in this graph's initializers but it is not used by any node
 Expected 
 Expected DENSE or SPARSE
 Expected std::map<int64_t, float> or std::map<int64_t, std::string>
 expected to be a registered ONNX type
 expected to have tensor type
 Expected TO_FLOAT, TO_STRING or TO_INT64
 Expected:
 Expected: 
 experimental ops. In the future, we may directly 
 fail, errcode =
 fail: unexpected end
 failed
' failed
 failed.
 failed: 
 filter_number: 
 for attribute 
 for operator 
 for SizeFromDimension. Tensor has 
 found!
 found.
 Global{op_type} consumes an input tensor X and applies {op} pooling across
 Got:
 got: 
 Graph may not conform to the ONNX spec and contain initializers that are not graph inputs.
 group: 
 H;\$@
 H;T$0
 H3E H3E
 has already been loaded.
 has already been registered.
 has batch size of 
' has been deprecated since version 
' has been used as graph input names multiple times.
' has been used as output names multiple times.
 has length of 
 has mismatched dimensions of 
 has unknown expected type
 Hc\$p3
 Hc|$p3
 I;T$ 
 if ceil_mode is enabled
 Implicit input name 
 in AddToThreadq
 in ComputeFirstByte
 in initializer but not in graph input
 in KernelRegistryManager
 in node 
 in node (
 in step
 Incompatible types.
 inferred=
 Input shape=
 Input=
 inputs and requires 
 inputs but 
 inputs but Scan was only given 
 inputs but subgraph has 
 inputs. Either provide all subgraph inputs, or just the required inputs.
 inputs. Found:
' instead of '
 Invalid value for input index of node 
 is depracted in domain_version of 
' is expected to have field 'f'
' is expected to have field 'floats'
' is expected to have field 'g'
' is expected to have field 'graphs'
' is expected to have field 'i'
' is expected to have field 'ints'
' is expected to have field 's'
' is expected to have field 'strings'
' is expected to have field 't'
' is expected to have field 'tensors'
 is greater than input dim=
 is invalid for a tensor of rank 
 is marked single but has an empty string in the graph
' is missing.
 is NaN
 is not a registered function/op
 is not associated with a node. 
 is not compatible with 
 is not currently registered or supported
 is not found
' is not found
 is not implemented
 is not in (0, 
 is not in valid range [-
 is not output of any previous nodes.
 is not registered
 is not supported
 is out of bounds
 is outside range.
 is repeated.
 is required but missing.
 is required to be non-empty.
 is tensor type, but provided type is 
 is unrecognized, acceptable values are TF,IDF,TFIDF
 is used by node 
 kernel channels: 
 kernel is not supported in 
 kernel start version: 
 kernel_end_version: 
 kernel_shape: 
 L;t$`
 L;t$pH
 line 
 Lp pooling consisting of computing the Lp norm on all values of a subset
 mem_type:
 memory_type:
 message of type "
 Microsoft Corporation. All rights reserved.
 must be 1 instead of 
 must be either specified in graph inputs or graph initializers.
 must be of equal size
 name:
 node_version: 
 not found.
 not in allowed input sizes.
 not in allowed output sizes.
 not in range [min=
 not specified
 Num entries in 'split' (must equal number of outputs) was 
 num_input_channels: 
 NumOutputs=
' of 
' of input parameter (
' of node: 
 of the given input. The input is a 2-D tensor (Tensor<float>) of size
 of the input tensor according to the kernel size and downsampling the
 Operating System
 output_spatial_shape[i] = ceil((input_spatial_shape[i] + pad_shape[i] - kernel_spatial_shape[i]) / strides_spatial_shape[i] + 1)
 output_spatial_shape[i] = floor((input_spatial_shape[i] + pad_shape[i] - kernel_spatial_shape[i]) / strides_spatial_shape[i] + 1)
 outputs but Scan expects 
 outputs so the subgraph requires 
 outputs which doesn't match the subgraph's 
 outputs.
 outputs. Expected 
 P!_!
 pad_shape[i] = (output_spatial_shape[i] - 1) * strides_spatial_shape[i] + kernel_spatial_shape[i] - input_spatial_shape[i]
 Parameter to BackUp() can't be negative.
 Requested shape:
 ROI {name} pool consumes an input tensor X and region of interests (RoIs) to
 row[
 rows[
 SAME_UPPER or SAME_LOWER: output_spatial_shape[i] = ceil(input_spatial_shape[i] / strides_spatial_shape[i])
 should be of integer type and specify a type.
' should be stored in field '
 should be unidirectional broadcastable to 
 should specify a shape
 since it was ill-formed during registration
 size=
 specified. It should be either avg or max
 Status Message: 
 subset of the input tensor according to the kernel size and downsampling the
 Sum of sizes in 'split' (must equal size of selected axis) was 
 Target=
 the tensor according to kernel sizes, stride sizes, and pad lengths.
 the values in the same channel. This is equivalent to {op_type} with kernel size
 then=
 type:
 unknown
 VALID: output_spatial_shape[i] = ceil((input_spatial_shape[i] - kernel_spatial_shape[i] + 1) / strides_spatial_shape[i])
 value type: 
 Version mismatch.
 version: 
 vs. 
 was 
' was 
 was a removed 
 was false.
 was modified concurrently during serialization.
 was not
 was not a tensor.
 were provided
 wet;
 wetQ
 Windows
 Windows::AI::MachineLearning::TensorBase<short,short,struct winrt::Windows::AI::MachineLearning::implementation::TensorInt16Bit,struct winrt::Windows::AI::MachineLearning::ITensorInt16Bit,struct winrt::Windows::AI::MachineLearning::implementation::TensorInt16Bit_base<struct winrt::Windows::AI::MachineLearning::implementation::TensorInt16Bit,struct ITensorNative,struct Windows::AI::MachineLearning::ILotusValueProviderPrivate> >::GetCpuResource
 with domain_version of 
 with error: 
 with type 
!#!%!%!'!'!)!)!.!.!:!;!@!D!J!M!O!O!
!#!%!%!'!'!)!)!.!.!:!;!J!J!L!M!O!O!
!#%'**,,./:;?@\\
!#%*,/:;?@[]__{{}}
!$!$!&!&!(!(!*!-!/!9!<!?!E!I!N!N!
!$!$!&!&!(!(!*!-!0!3!>!?!E!E!
!%!'!)!,!1!3!M!O!_!
!&$@$J$`$
!(it.GetName().empty())
!/!/!4!4!9!9!<!=!F!I!N!N!
!/:@[`{~ ~
!@!D!K!K!
!0,^,a,a,e,f,h,h,j,j,l,l,q,q,s,t,v,{,
!c->in_use() && (c->bin_num != kInvalidBinNum)
!c->in_use() && (c->bin_num == kInvalidBinNum)
!c1->in_use() && !c2->in_use()
!char_tokenezation_ || mincharnum_ < 2
!chunk->in_use()
!coefficients_.empty()
!E;` }]H
!H9q s
!has_axes || attr_axes_.size() == attr_starts_.size()
!impl_->pool_strings_.empty()
!is_concrete_shape_
!L$0E3
!L$4H
!L$8E3
!nodes_treeids_.empty()
!normalize_
!scale_.empty()
!separators.empty()
!sw.empty()
!T$(H!T$ 
!This program cannot be run in DOS mode.
!tokenexp.empty()
" #!#|#|#
" : "
" because it is missing required fields: 
"7Windows::AI::MachineLearning::TensorBase<unsigned int,unsigned int,struct winrt::Windows::AI::MachineLearning::implementation::TensorUInt32Bit,struct winrt::Windows::AI::MachineLearning::ITensorUInt32Bit,struct winrt::Windows::AI::MachineLearning::implementation::TensorUInt32Bit_base<struct winrt::Windows::AI::MachineLearning::implementation::TensorUInt32Bit,struct ITensorNative,struct Windows::AI::MachineLearning::ILotusValueProviderPrivate> >::GetCpuResource
"args" : {
"dur" :
"name" :"
"ph" : "X",
"pid" :
"tid" :
"ts" :
#"#(#+#{#}#
#&$@$J$
#(#+#&$@$J$
#)#)#h'h'j'j'l'l'n'n'p'p'r'r't't'
#)#*#h'u'
#*#*#i'i'k'k'm'm'o'o'q'q's's'u'u'
#L$8;
#L$8D;
#T$8D;
#wht^
$$++<>^^``||~~
$+C$Lc
$< t6<$t,<+t"<vt
$D9A(taH
$Element
$H9C }/H
-%-'-'-----
%.0Lf
%~3a*
-%-'-'-----0-g-o-o-
-%-'-'-----A
%b %d %H : %M : %S %Y
%d / %m / %y
%H : %M
%H : %M : %S
%H!;H!{
%hs!%p: 
%hs(%d) tid(%x) %08X %ws
%hs(%d)\%hs!%p: 
%I : %M : %S %p
%I64u
%m / %d / %y
%o&o&
%Y-%m-%d_%H-%M-%S
&!&!e
&9x(t
&n&p&g'
(&Z2{x
(([[{{
((scales[0] == 1) && (scales[1] == 1))
(){}[]*+?|.^$\
(?HaveMatch:%d)
(?-m:$)
(?-m:^)
(\$PD
(|$ L
(|$@H
(|$@I
(|$`E
(|$`I
(|$PH
(|$pH
(|$PI
(|$pI
(|$PI
(|$pL
(A_A^A]A\_^][
(batch_size x input_feature_dimensions). The output tensor has the same shape
(before_insert + ngrams) == impl_->int64_set_.size()
(before_insert + ngrams) == impl_->str_set_.size()
(caller: %p) 
(cannot determine missing fields for lite message)
(D$ D
(D$ E3
(D$ f
(D$ H
(D$ I
(D$ L
(D$ M
(D$@E
(D$@f
(D$@H
(D$@I
(D$`A
(d$`D
(D$`f
(D$`fA
(D$`H
(D$`L
(d$0f
(D$0f
(D$0H
(D$0L
(D$PD
(D$pf
(D$Pf
(D$pf
(D$Pf
(D$pf
(D$Pf
(D$pf
(D$Pf
(D$pf
(D$Pf
(D$pf
(D$Pf
(D$pf
(D$Pf
(D$pf
(D$Pf
(D$pf
(D$Pf
(D$pf
(D$Pf
(D$pf
(D$Pf
(D$pf
(D$pfA
(D$pH
(D$PH
(D$pH
(D$PH
(D$pL
(default) or 
(fE9u
(float, default 0.5) the ratio of random dropout
(fmod == 0) || (fmod == 1)
(input_shape.Size() % size) == 0
(inputs_.size() - 1) == i
(int, default 0) if nonzero, run dropout in test mode where the output is simply Y = X.
(items % ngram_size == 0)
(L$ f
(L$ H
(L$@f
(L$@H
(L$@L
(L$`f
(L$0D
(L$0f
(l$0f
(L$0f
(L$0H
(L$pA
(L$PA
(l$pD
(L$Pf
(L$pf
(L$Pf
(L$pf
(L$Pf
(L$pf
(L$Pf
(L$pf
(L$Pf
(L$pf
(L$Pf
(L$pf
(L$Pf
(L$pf
(L$Pf
(L$pf
(L$Pf
(L$pf
(L$Pf
(L$pf
(L$Pf
(L$pH
(L$pL
(nodes_id_size == nodes_hitrates_.size()) || (nodes_hitrates_.empty())
(nodes_nodeids_.size() == nodes_hitrates_.size()) || (nodes_hitrates_.empty())
(null)
(op_type:
(Optional) A scalar or rank 1 tensor containing a single value to be filled if the mode chosen is `constant` (by default it is 0.0).
(Optional) Axis along which one-hot representation in added. Default: axis=-1. axis=-1 means that the additional dimension will be inserted as the innermost/last dimension in the output tensor.
(Optional) Axis along which to take slices. If not specified, input is flattened before elements being selected.
(Optional) Index of the diagonal to be populated with ones. Default is 0. If T2 is the output, this op sets T2[i, i+k] = 1. k = 0 populates the main diagonal, k > 0 populates an upper diagonal,  and k < 0 populates a lower diagonal.
(Optional) Seed to the random generator, if not specified we will auto generate one.
(Optional) Specify which axis is batch axis. Must be one of 1 (default), or 0.
(Optional) Specify which axis is time axis. Must be one of 0 (default), or 1.
(Optional) The data type for the elements of the output tensor, if not specified, we will use int32.
(Optional) The data type for the elements of the output tensor, if not specified, we will usethe data type of the input tensor.
(Optional) The data type for the elements of the output tensor. If not specified,the data type of the input tensor T1 is used. If input tensor T1 is also notspecified, then type defaults to 'float'.
(Optional) The value of the output elements.Should be a one-element tensor. If not specified, it defaults to a tensor of value 0 and datatype float32
(Optional) Whether map negative infinity to true. Default to 1 so that negative infinity induces true. Set this attribute to 0 if negative infinity should be mapped to false.
(Optional) Whether map positive infinity to true. Default to 1 so that positive infinity induces true. Set this attribute to 0 if positive infinity should be mapped to false.
(outputs_.size() - 1) == i
(t$ H
(T$@D
(t$@f
(t$@H
(t$@I
(t$@L
(t$`H
(t$`I
(t$`L
(t$0H
(t$pf
(T$pf
(t$PH
(t$pH
(t$PH
(t$pH
(t$PH
(t$pH
(t$PH
(t$pH
(t$PH
(t$pH
(t$pH;
(t$pI
(t$PI
(t$pI
(t$pL
(t$PL
(t$pL
(UINT32)message.Severity()
) != (
) , expected: (
) + (
) + bottomBorder (
) + rightBorder (
) + scale_[0] (
) + scale_[1] (
) and node 
) attribute (
) bound to different types (
) does not exist in the graph.
) does not have type information set by parent node.
) does not have type information.
) does not match expected type (
) does not match number of inputdimensions values (
) does not match the data size(
) does not match the number of channels (
) for attribute 'axis'
) from file 
) has input size 
) has more inputs (
) has more outputs (
) has output size 
) has zero input and zero output.
) in node (
) in op definition.
) in proto
) input arg (
) is 0-element but contains data!
) is invalid.
) is not equal to number of scan inputs (
) is not equal to number of scan outputs (
) is not equal to the existing dim value (
) is required but not specified.
) is stored externally and should not have data field.
) is stored externally but doesn't have a location.
) needs to be greater than the leftBorder (
) needs to be greater than the topBorder (
) of node (
) of operator (
) of output arg (
) or 1
) output arg (
) should be stored in 
) should contain one and only one value field.
) should not be stored in raw_data field
) should not contain more than one value field.
) should refer to attribute in parent node.
) than declared (
) to UNDEFINED is not allowed
) type inference failed
) vs (
)".".$.$.&.&.(.(.B.B.
)#.#.%.%.'.'.).).
))]]}}
); for more details please check [the doc](Broadcasting.md).
)\$@A
)\$@F
)\$`M
)\$pD
)\$PD
)\$PH
)\$PL
)]PfD
)|$ I
)}pfH
)4$L+
)98&F
)D$ A
)D$ D
)d$ L
)D$@A
)D$@H
)D$@I
)d$`D
)D$`E3
)D$`H
)D$`M
)D$`t/D
)D$0A
)d$0D
)D$0E
)D$0f
)D$0fH
)D$0H
)D$PA
)D$pA
)D$PA
)D$pE3
)D$pfH
)D$PfI
)D$pH
)D$pt2D
)fD9 u
)fD9$%
)l$ D
)L$@A
)L$`A
)L$`D
)L$0A
)L$0D
)L$0E3
)L$0F
)L$0f
)L$0Jc
)L$0L
)L$PA
)l$pD
)l$PD
)l$pI
)L$pJc
)MpE3
)'s input 
)'s output 
)s+v+
)t$ H
)t$ I
)T$ M
)T$@D
)t$@H
)t$@I
)t$`H
)t$`L
)t$`M
)t$0D
)t$0H
)T$PA
)T$pD
)t$PH
)t$pH
)T$PM
)t$pM
-*0/0
*0+D+G+L+)
-*0-0
*out_size >= 0
, am_attn_size}, Got:
, aw_attn_size}. Got:
, block in memory pattern size is: 
, block not found in target location. fall back to default allocation behavior
, but it doesn't exist or is not accessible.
, but it is already registered from file 
, but it its domain is not
, but it its version is higher
, but it its version is not 
, fall back to default allocation behavior
, got 
, Got 
', location: 
, max=
, name:
, requested shape:
, type: 
,.,`,`,b,d,g,g,i,i,k,k,m,p,r,r,u,u,~,
,.,0,^,
,.,0,^,`,
,p-p-
,s(H;
. . .
'. 0 == forward. 1 == reverse.
. batch_size=
. Dimension 0 is 
. Do you have duplicated calls to SessionState::AddInitializedTensor function?
. Initializers may not be overridden by feeds if model IR version is less than 4.
. Input rank=
. Input tensor rank was 
. It can only be 
. Must be 0 or 1
'. Must be one of 'forward', 'reverse', or 'bidirectional'.
. Num args is 
. Output tensor rank was 
. Shape:
. shape=
.!.!.
.*...0.9.<.?.A.A.C.N.
...0.N.
.:.;.@.@.
.?AU?$default_delete@VBFCArena@onnxruntime@@@std@@
.?AU?$default_delete@VDummyArena@onnxruntime@@@std@@
.?AU?$default_delete@VIDeviceAllocator@onnxruntime@@@std@@
.?AU?$DefaultKernel@U?$BitDepthParams@U?$OperandRange@$0A@$0PP@@gemmlowp@@U12@@gemmlowp@@@gemmlowp@@
.?AU?$DefaultKernelImpl@$0A@$0A@@gemmlowp@@
.?AU?$GemmWithPackedRhsTask@U?$KernelFormat@U?$KernelSideFormat@U?$CellFormat@$03$0BA@$00@gemmlowp@@$00@gemmlowp@@U12@@gemmlowp@@EEU?$BitDepthParams@U?$OperandRange@$0A@$0PP@@gemmlowp@@U12@@2@$00$00$00V?$VectorDup@$$CBH$0A@@2@V?$VectorDup@$$CBH$00@2@V?$tuple@U?$OutputStageBiasAddition@V?$VectorMap@$$CBH$0A@@gemmlowp@@@gemmlowp@@UOutputStageQuantizeDownInt32ByFixedPoint@2@UOutputStageSaturatingCastToUint8@2@@std@@VGemmContext@2@@gemmlowp@@
.?AU?$GemmWithPackedRhsTask@U?$KernelFormat@U?$KernelSideFormat@U?$CellFormat@$03$0BA@$00@gemmlowp@@$00@gemmlowp@@U12@@gemmlowp@@EEU?$BitDepthParams@U?$OperandRange@$0A@$0PP@@gemmlowp@@U12@@2@$00$00$00V?$VectorDup@$$CBH$0A@@2@V?$VectorDup@$$CBH$00@2@V?$tuple@UOutputStageQuantizeDownInt32ByFixedPoint@gemmlowp@@UOutputStageSaturatingCastToUint8@2@@std@@VGemmContext@2@@gemmlowp@@
.?AU?$GemmWithPackedRhsTask@U?$KernelFormat@U?$KernelSideFormat@U?$CellFormat@$03$0BA@$00@gemmlowp@@$00@gemmlowp@@U12@@gemmlowp@@EEU?$BitDepthParams@U?$OperandRange@$0A@$0PP@@gemmlowp@@U12@@2@$0A@$0A@$0A@V?$VectorDup@$$CBH$00@2@V?$VectorDup@$$CBH$0A@@2@V?$tuple@U?$OutputStageBiasAddition@V?$VectorMap@$$CBH$00@gemmlowp@@@gemmlowp@@UOutputStageQuantizeDownInt32ByFixedPoint@2@UOutputStageSaturatingCastToUint8@2@@std@@VGemmContext@2@@gemmlowp@@
.?AU?$GemmWithPackedRhsTask@U?$KernelFormat@U?$KernelSideFormat@U?$CellFormat@$03$0BA@$00@gemmlowp@@$00@gemmlowp@@U12@@gemmlowp@@EEU?$BitDepthParams@U?$OperandRange@$0A@$0PP@@gemmlowp@@U12@@2@$0A@$0A@$0A@V?$VectorDup@$$CBH$00@2@V?$VectorDup@$$CBH$0A@@2@V?$tuple@UOutputStageQuantizeDownInt32ByFixedPoint@gemmlowp@@UOutputStageSaturatingCastToUint8@2@@std@@VGemmContext@2@@gemmlowp@@
.?AU?$GemmWithPackedRhsTask@U?$KernelFormat@U?$KernelSideFormat@U?$CellFormat@$03$0BA@$00@gemmlowp@@$00@gemmlowp@@U12@@gemmlowp@@EHU?$BitDepthParams@U?$OperandRange@$0A@$0PP@@gemmlowp@@U12@@2@$00$00$00V?$VectorDup@$$CBH$0A@@2@V?$VectorDup@$$CBH$00@2@V?$tuple@$$V@std@@VGemmContext@2@@gemmlowp@@
.?AU?$GemmWithPackedRhsTask@U?$KernelFormat@U?$KernelSideFormat@U?$CellFormat@$03$0BA@$00@gemmlowp@@$00@gemmlowp@@U12@@gemmlowp@@EHU?$BitDepthParams@U?$OperandRange@$0A@$0PP@@gemmlowp@@U12@@2@$0A@$0A@$0A@V?$VectorDup@$$CBH$00@2@V?$VectorDup@$$CBH$0A@@2@V?$tuple@$$V@std@@VGemmContext@2@@gemmlowp@@
.?AU?$ImplementsHelper@U?$RuntimeClassFlags@$01@WRL@Microsoft@@$00$$V@Details@WRL@Microsoft@@
.?AU?$ImplementsHelper@U?$RuntimeClassFlags@$01@WRL@Microsoft@@$00UIWinmlExecutionProvider@implementation@MachineLearning@AI@Windows@winrt@@@Details@WRL@Microsoft@@
.?AU?$ImplementsHelper@U?$RuntimeClassFlags@$01@WRL@Microsoft@@$0A@UIExecutionProvider@Dml@@UIWinmlExecutionProvider@implementation@MachineLearning@AI@Windows@winrt@@@Details@WRL@Microsoft@@
.?AU?$ImplementsHelper@U?$RuntimeClassFlags@$01@WRL@Microsoft@@$0A@UIMLOperatorKernel@@@Details@WRL@Microsoft@@
.?AU?$ImplementsHelper@U?$RuntimeClassFlags@$01@WRL@Microsoft@@$0A@UIMLOperatorKernelFactory@@@Details@WRL@Microsoft@@
.?AU?$ImplementsHelper@U?$RuntimeClassFlags@$01@WRL@Microsoft@@$0A@UIMLOperatorShapeInferrer@@@Details@WRL@Microsoft@@
.?AU?$ImplementsHelper@U?$RuntimeClassFlags@$01@WRL@Microsoft@@$0A@UIUnknown@@@Details@WRL@Microsoft@@
.?AU?$Pad@M@contrib@onnxruntime@@
.?AU?$Pad@M@onnxruntime@@
.?AU?$ReferenceKernel@U?$KernelFormat@U?$KernelSideFormat@U?$CellFormat@$03$0BA@$00@gemmlowp@@$00@gemmlowp@@U12@@gemmlowp@@@gemmlowp@@
.?AU?$RuntimeClassFlags@$03@WRL@Microsoft@@
.?AU?$Slice@_J$00@onnxruntime@@
.?AU?$Slice@_J$0A@@onnxruntime@@
.?AU?$Slice@_K$00@onnxruntime@@
.?AU?$Slice@_K$0A@@onnxruntime@@
.?AU?$Slice@_N$00@onnxruntime@@
.?AU?$Slice@_N$0A@@onnxruntime@@
.?AU?$Slice@C$00@onnxruntime@@
.?AU?$Slice@C$0A@@onnxruntime@@
.?AU?$Slice@E$00@onnxruntime@@
.?AU?$Slice@E$0A@@onnxruntime@@
.?AU?$Slice@F$00@onnxruntime@@
.?AU?$Slice@F$0A@@onnxruntime@@
.?AU?$Slice@G$00@onnxruntime@@
.?AU?$Slice@G$0A@@onnxruntime@@
.?AU?$Slice@H$00@onnxruntime@@
.?AU?$Slice@H$0A@@onnxruntime@@
.?AU?$Slice@I$00@onnxruntime@@
.?AU?$Slice@I$0A@@onnxruntime@@
.?AU?$Slice@M$00@onnxruntime@@
.?AU?$Slice@M$0A@@onnxruntime@@
.?AU?$Slice@N$00@onnxruntime@@
.?AU?$Slice@N$0A@@onnxruntime@@
.?AU?$Slice@TMLFloat16@onnxruntime@@$00@onnxruntime@@
.?AU?$Slice@TMLFloat16@onnxruntime@@$0A@@onnxruntime@@
.?AU?$Slice@V?$basic_string@DU?$char_traits@D@std@@V?$allocator@D@2@@std@@$00@onnxruntime@@
.?AU?$Slice@V?$basic_string@DU?$char_traits@D@std@@V?$allocator@D@2@@std@@$0A@@onnxruntime@@
.?AU_Crt_new_delete@std@@
.?AUContainer@?$InternalMetadataWithArenaBase@V?$basic_string@DU?$char_traits@D@std@@V?$allocator@D@2@@std@@VInternalMetadataWithArenaLite@internal@protobuf@google@@@internal@protobuf@google@@
.?AUctype_base@std@@
.?AUfail_fast@gsl@@
.?AUhresult_access_denied@winrt@@
.?AUhresult_canceled@winrt@@
.?AUhresult_changed_state@winrt@@
.?AUhresult_class_not_available@winrt@@
.?AUhresult_error@winrt@@
.?AUhresult_illegal_delegate_assignment@winrt@@
.?AUhresult_illegal_method_call@winrt@@
.?AUhresult_illegal_state_change@winrt@@
.?AUhresult_invalid_argument@winrt@@
.?AUhresult_no_interface@winrt@@
.?AUhresult_not_implemented@winrt@@
.?AUhresult_out_of_bounds@winrt@@
.?AUhresult_wrong_thread@winrt@@
.?AUIExecutionProvider@Dml@@
.?AUIMLOperatorKernel@@
.?AUIMLOperatorKernelFactory@@
.?AUIMLOperatorShapeInferrer@@
.?AUInferenceContext@onnx@@
.?AUInferenceContextImpl@shape_inference@onnx@@
.?AUIUnknown@@
.?AUIWinmlExecutionProvider@implementation@MachineLearning@AI@Windows@winrt@@
.?AUKernelBase@gemmlowp@@
.?AUmessages_base@std@@
.?AUmoney_base@std@@
.?AUnarrowing_error@gsl@@
.?AUNodeCompare@onnxruntime@@
.?AUOrtValue@@
.?AUSequentialExecutionPlan@onnxruntime@@
.?AUTask@gemmlowp@@
.?AUTile@onnxruntime@@
.?AUtime_base@std@@
.?AV?$_Associated_state@H@std@@
.?AV?$_Binder@U_Unforced@std@@A6AXJ_NV?$function@$$A6AXJ@Z@2@@ZAEBU?$_Ph@$00@2@AEBU?$_Ph@$01@2@AEAV32@@std@@
.?AV?$_Binder@U_Unforced@std@@A6AXJUILearningModelFeatureValue@MachineLearning@AI@Windows@winrt@@UILearningModelFeatureDescriptor@4567@@ZAEBU?$_Ph@$00@2@AEAU34567@AEAU84567@@std@@
.?AV?$_Binder@U_Unforced@std@@A6AXJV?$function@$$A6AXJ@Z@2@@ZAEBU?$_Ph@$00@2@AEAV32@@std@@
.?AV?$_Binder@U_Unforced@std@@AEAV?$function@$$A6AXH@Z@2@AEAH@std@@
.?AV?$_Func_base@_NH@std@@
.?AV?$_Func_base@_NI@std@@
.?AV?$_Func_base@_NPEBVNode@onnxruntime@@PEBV12@@std@@
.?AV?$_Func_base@HPEAUComputeContext@onnxruntime@@PEAPEAX@std@@
.?AV?$_Func_base@HPEAXPEBUOrtCustomOpApi@@PEAUOrtKernelContext@@@std@@
.?AV?$_Func_base@MMMM@std@@
.?AV?$_Func_base@PEAVOpKernel@onnxruntime@@AEBVOpKernelInfo@2@@std@@
.?AV?$_Func_base@V?$ComPtr@UIMLOperatorTensor@@@WRL@Microsoft@@I@std@@
.?AV?$_Func_base@V?$unique_ptr@VIDeviceAllocator@onnxruntime@@U?$default_delete@VIDeviceAllocator@onnxruntime@@@std@@@std@@H@std@@
.?AV?$_Func_base@VStatus@common@onnxruntime@@AEAV?$shared_ptr@VModel@onnxruntime@@@std@@@std@@
.?AV?$_Func_base@VStatus@common@onnxruntime@@AEAVGraph@3@@std@@
.?AV?$_Func_base@VStatus@common@onnxruntime@@AEBVNode@3@AEAVGraph@3@AEBV?$vector@PEBVTypeProto@onnx@@V?$allocator@PEBVTypeProto@onnx@@@std@@@std@@AEAV67@@std@@
.?AV?$_Func_base@VStatus@common@onnxruntime@@AEBVNodeArg@3@_K@std@@
.?AV?$_Func_base@VStatus@common@onnxruntime@@AEBVTensorShape@3@AEBUOrtAllocatorInfo@@AEAUOrtValue@@AEA_N@std@@
.?AV?$_Func_base@X$$QEAVOpSchema@onnx@@@std@@
.?AV?$_Func_base@X$$V@std@@
.?AV?$_Func_base@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_base@XAEAVNodeConnection@MLGraph@@@std@@
.?AV?$_Func_base@XAEAVOpSchema@onnx@@@std@@
.?AV?$_Func_base@XAEBVNodeArg@onnxruntime@@_N@std@@
.?AV?$_Func_base@XH@std@@
.?AV?$_Func_base@XPEAH@std@@
.?AV?$_Func_base@XPEAM@std@@
.?AV?$_Func_base@XPEAUILogger@CommonLogging@@@std@@
.?AV?$_Func_base@XPEAX@std@@
.?AV?$_Func_base@XPEBUNodeConnectionCompileState@Compilation@MLGraph@@@std@@
.?AV?$_Func_base@XPEBVDataTypeImpl@onnxruntime@@@std@@
.?AV?$_Func_base@XPEBVNode@onnxruntime@@@std@@
.?AV?$_Func_base@XV?$Map@V?$Matrix@M$0?0$00$0A@$0?0$00@Eigen@@$0A@V?$Stride@$0A@$0A@@2@@Eigen@@V?$Map@$$CBV?$Matrix@M$0?0$00$0A@$0?0$00@Eigen@@$0A@V?$Stride@$0A@$0A@@2@@2@M@std@@
.?AV?$_Func_impl_no_alloc@P6A?AVStatus@common@onnxruntime@@AEBVNode@3@AEAVGraph@3@AEBV?$vector@PEBVTypeProto@onnx@@V?$allocator@PEBVTypeProto@onnx@@@std@@@std@@AEAV67@@ZV123@AEBV43@AEAV53@AEBV67@AEAV67@@std@@
.?AV?$_Func_impl_no_alloc@P6AMMMM@ZMMMM@std@@
.?AV?$_Func_impl_no_alloc@P6APEAVOpKernel@onnxruntime@@AEBVOpKernelInfo@2@@ZPEAV12@AEBV32@@std@@
.?AV?$_Func_impl_no_alloc@P6AX$$QEAVOpSchema@onnx@@@ZX$$QEAV12@@std@@
.?AV?$_Func_impl_no_alloc@P6AXAEAUInferenceContext@onnx@@@ZXAEAU12@@std@@
.?AV?$_Func_impl_no_alloc@UNodeCompare@onnxruntime@@_NPEBVNode@2@PEBV32@@std@@
.?AV?$_Func_impl_no_alloc@V?$_Binder@U_Unforced@std@@AEAV?$function@$$A6AXH@Z@2@AEAH@std@@X$$V@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_006f042491572090b778a6887556c541>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_00bc1d3067b0daca44118c6bf6182fe6>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_01985760e667ba58bff711ef31d8e638>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_027f0b72d20b824e4e30fa2ccfde3681>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_034757adb6c60162404ac40e8e741709>@@VStatus@common@onnxruntime@@AEBVTensorShape@4@AEBUOrtAllocatorInfo@@AEAUOrtValue@@AEA_N@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_05139462a1d0ad358a8c7449ca410e71>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_054344795ce74e2e037e3c05c0b91898>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_08accd2c56d1c3539bdbe39ead72e813>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_12c274da604ed254f4e0fb7954f6465d>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_1476157c6a284e4f379191854345eea5>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_17b8c13e1e1532971a7e111d63079828>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_1b40e5da70f80ebc1265da7a4b002f1d>@@XAEAVOpSchema@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_1e705c9d678933c457ee9dd44824e26c>@@XAEAVOpSchema@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_221457049dd6e599b1e592be3898266a>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_2258ee131c6ebb61b9c83defdba7af66>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_23ae0d8678653f1ba32dea59d99f813c>@@VStatus@common@onnxruntime@@AEBVNodeArg@4@_K@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_24ef3fd2004740c74f45387687b5966c>@@XAEAVOpSchema@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_27eb941e257b57f9cf2ee9f3ef3087b3>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_29460ba72c9a9f61937f695b212c2385>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_2997ea06f466f3cb7af7580139e0e9b1>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_2a231a5ff616b0ae2274b38ac58ff666>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_2a39988023ade309aa40582a95355447>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_2a3b1f1fbc2b924051eedcd518441330>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_2c336c69e37df1f232f1301ffdf6cbc8>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_2cda3ec4180407fdb66cae08f370124f>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_2ff8e0e61b396ff915eaef7150818ea5>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_30c3e62ccde4a098c007b12bb428e908>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_31044cbb2065f4b8855bbdc646057e42>@@XPEAM@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_31999e24a5713e2726b236a23ffe8e9c>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_3354f944db7877754471d985be3fe29b>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_3461d2aa8a1d8f58d04263e3bb305fab>@@XAEBVNodeArg@onnxruntime@@_N@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_36fc80f79cd957d31685eab011dabdfa>@@_NI@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_3749a2cd3b1b084d4974335060b45681>@@XPEBVNode@onnxruntime@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_3baacc98cc06d4e909f66b6a18be3e29>@@XV?$Map@V?$Matrix@M$0?0$00$0A@$0?0$00@Eigen@@$0A@V?$Stride@$0A@$0A@@2@@Eigen@@V?$Map@$$CBV?$Matrix@M$0?0$00$0A@$0?0$00@Eigen@@$0A@V?$Stride@$0A@$0A@@2@@3@M@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_3f547353f02d28ad34875ee8e051184c>@@XAEBVNodeArg@onnxruntime@@_N@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_4025341259f86dc630242dff69fca9b8>@@XPEBUNodeConnectionCompileState@Compilation@MLGraph@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_404084d3edacc8294adecb096c00b5ef>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_423c7f4514cb0f580d17c1969d94ab4d>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_4338c9c561d330121c572f512ed1a9cc>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_44f740f4362270fce5c964ebb50cbf77>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_4619be3804f026cfd3e188fd9832729a>@@HPEAUComputeContext@onnxruntime@@PEAPEAX@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_493755c0718e549fc6eb6376aaf1c076>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_51e7ce4347ad68176c6a114dbe1a7fb9>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_53958a524045125d538038a834c170f9>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_5428f58de3b11d0182bfa5186053ab5a>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_56616cb04d479ecbbef60d16cb985ff3>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_57767bf65a043efa89050ec956e6375f>@@XV?$Map@V?$Matrix@M$0?0$00$0A@$0?0$00@Eigen@@$0A@V?$Stride@$0A@$0A@@2@@Eigen@@V?$Map@$$CBV?$Matrix@M$0?0$00$0A@$0?0$00@Eigen@@$0A@V?$Stride@$0A@$0A@@2@@3@M@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_57e3ab15547653f4c24a6180872eafc8>@@VStatus@common@onnxruntime@@AEAV?$shared_ptr@VModel@onnxruntime@@@std@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_57f53ac28d9e46be7f6f5796ae7a2fef>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_5865299a878cc4536f06dd6ac2dafee9>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_5a03cad439a535c73c9479bab198ff8a>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_5be986e07125e16816e6ac7c3f8a6e4e>@@XAEAVOpSchema@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_5f1d94f8ca558702930bc8409fa6a0fd>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_664899aa3b288611d62300fea2993872>@@XAEAVOpSchema@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_66eda435998e6ddaa9b30be02eae90c7>@@XAEAVOpSchema@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_6a32611970906250c6b47d8292ad00e7>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_6bd810bb96d3f9038457669c0e958c1e>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_6c179269bbdc04c069c0be4c3276758c>@@XAEAVOpSchema@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_6c33f24f6b037a5d3fc1e56941c40a5c>@@XAEAVOpSchema@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_6ca09521f0419cdfacda156e3fc4c98d>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_6f80d65fbc6388042df99a3b220305d1>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_71346983b6599c47894abb35bff4747e>@@XAEAVOpSchema@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_747f5a5054cea5042105b3988bb8e54a>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_769d1db7652c71c0ccf3896a4532b7cf>@@VStatus@common@onnxruntime@@AEBVNodeArg@4@_K@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_7bf0c45af15d48ff0bf3482d9ab1530d>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_7d18ce867b586dae3ed4309094f85b3d>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_7d7cf49bce0e19787ec70235e54b100e>@@PEAVOpKernel@onnxruntime@@AEBVOpKernelInfo@3@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_821c7f43d2593552b63657225f3e2a2a>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_8250122591c954547730909874f35ed1>@@XPEAUILogger@CommonLogging@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_82fc727948fa2cc155864c30c0053c56>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_84c0c09494d01cc30f16e3449edead54>@@XPEAH@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_8566b012fc155a827dac5a26db00bb0f>@@VStatus@common@onnxruntime@@AEAVGraph@4@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_860fd138c338317eb60a40ddc8d3d604>@@XAEAVOpSchema@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_87377fe9a7b55ca099852704c7649a37>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_87c68c0967c94d566f6bd8e49e4156e6>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_87f27c7b79f82015223cdf844a99cbbd>@@XAEAVOpSchema@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_893cc8251b60de6ccc992b54f6f31db9>@@VStatus@common@onnxruntime@@AEAVGraph@4@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_898e7ddf86c5cb2fdbd52719563437ef>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_8a3f03cf93ba764f7eebf7fd98d3a893>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_8a4566bfd5826af470180d3d3cb61fee>@@VStatus@common@onnxruntime@@AEBVTensorShape@4@AEBUOrtAllocatorInfo@@AEAUOrtValue@@AEA_N@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_8d7ff4e398bab3b109ccce388181bf44>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_8e3498b106c5788a8387a435fcfed696>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_8e59199324395720fba09bee90960ebd>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_8ff3f73c945873491aaa70354b23f874>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_9239155d58e7ea4f2b7e8d2c9c494e5c>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_9289ae269610356b68d5c3f46e89bf66>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_933bfb96b2260d5634eb1eb6a83fa0fe>@@VStatus@common@onnxruntime@@AEAVGraph@4@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_93e11c159179365582bd72579ec478d7>@@VStatus@common@onnxruntime@@AEBVNodeArg@4@_K@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_96977307008117beb1e0c08617e9e024>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_974421a2166ea3684014171d0d75f69e>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_977aa0989600c553e6ad21ef5f183702>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_98813516cd70625548f3dca86c17f6e0>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_98e58702055b3dda6030ac966651b812>@@XAEBVNodeArg@onnxruntime@@_N@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_991d63fb8a809dc84e4e523068ce486a>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_9a6ebfb355f6f72365de0d099f01e46c>@@XH@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_9a80c5c6458e824bfa0876a779605b0b>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_9abb244ecf1fe7549bfa1b3b46427d69>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_9baa1cdad376a56943ca503609534da1>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_9dc19add650df7a8dd3a2c037757be68>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_a0e644278ef4f4a57b9573e7ded643ef>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_a300a011522f597640fb7738ddb3c3c8>@@XAEAVOpSchema@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_a30982bdf1dc90ee13caf4d420ec5e7f>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_a4a8f47c88f81824ff45fecdeb8c2272>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_a4fe3bd39dcd0107f90455cb45c21429>@@_NH@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_a6f452e793f181bfdb21f8008d20a820>@@XAEAVOpSchema@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_a730596af2436ac6f02571ed7ec62d9c>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_a83a31e9654ec6fec79c12c296cc64ae>@@VStatus@common@onnxruntime@@AEBVNodeArg@4@_K@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_a8dc603fd8183714a0dc357fc9b787c1>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_ac4668adfa184e73086660d1e23189e7>@@XAEAVOpSchema@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_ae651a2f316754e5b872f0242e285a17>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_af2c39467b4484bc2a2f611cf533daa7>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_b39fcf5d316099631cb4151a025dde22>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_b43d1a9e0f80c81cf46233421502eec9>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_b4e5149275d4fcb7878125bc83ce3063>@@XAEAVOpSchema@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_b4f16af0ac2265b9b3b07c19294b18f2>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_b51428820b3477616d25ebf36e7dd645>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_b5a8e22fc972999c473eeef0d861144d>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_b708da6ab938dbf5aa385eabacde06c3>@@VStatus@common@onnxruntime@@AEBVNodeArg@4@_K@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_b937f7d4f097577d4fa0e0107ad25600>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_ba5c1a9f30e9a8c00dc647ceccb205fa>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_ba9cfe2bb13e49d1f5f6d627965891ec>@@V?$unique_ptr@VIDeviceAllocator@onnxruntime@@U?$default_delete@VIDeviceAllocator@onnxruntime@@@std@@@std@@H@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_bb49b7cc5cd2d94ca99a48a4c0d13f14>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_bc9a9f99cbeabaf2d0a936a0cad6b782>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_bd5b9427a54fdb45586e1dbfc607a955>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_be85bfcd5fbfc31b6743eea1ac54b897>@@XAEAVOpSchema@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_beaafeb3eab8e63d67c0320e51be9f3d>@@XAEAVOpSchema@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_bf5458cf82f5faac082f67dd8814164d>@@XAEBVNodeArg@onnxruntime@@_N@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_c3c25e82dec0fc98e0076356943111e7>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_c41fc543d857db8b3ca85cea5cadd247>@@XAEAVOpSchema@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_c5cebd529b61d3173fae5d666977fc08>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_c88091b3530d152097f987ae77b5c865>@@XAEBVNodeArg@onnxruntime@@_N@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_c903e10f9792b7526fde45e82dd96aa5>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_ca87e505bf8a7e1f26579083c3683d94>@@_NH@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_cda3c60f0bca96d0a80bc61bce840378>@@_NH@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_ce473b479310095c7321cd7e93391654>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_cf356a63b9d34af3b27fd0e5246bed98>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_d01cb7d72935562762275ef2725e3ce2>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_d1f3e1ff52e7a73d61aa38c424d43183>@@XH@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_d45413077830f41d06c2c81e573871c9>@@XPEAX@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_d54ceb046acf4eb66ab9f93fa1a2d6c2>@@X$$V@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_d7ecd0f53fc3c91f5a3fd89598f9d860>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_d8797e74ae02acf212ef74610c438126>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_d8a9ac16dd775f4bb1f670ae469711dc>@@XPEBVDataTypeImpl@onnxruntime@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_d8b06a4dd6f551b1fc6c7009ad0ed428>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_dc8816ded3bdec37e07aeaf5a6aef6d5>@@HPEAXPEBUOrtCustomOpApi@@PEAUOrtKernelContext@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_dda5ab6aaf4f2b6f6f3016e64f840ab7>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_df8dc5d18b005334d023e86e4d511fb0>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_e0b2d86bba8462f4713d43f91e59ae58>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_e0d793c456966319eaa2c9c55a133238>@@XAEBVNodeArg@onnxruntime@@_N@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_e5d35051c862b1e1cd0b6f4bf8ef53ea>@@XAEAVNodeConnection@MLGraph@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_e647d51565c9d7d9a3fcd7b8e568467d>@@XAEAVOpSchema@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_e750230a2e347f07ba6ac8b497fd00d5>@@VStatus@common@onnxruntime@@AEBVNodeArg@4@_K@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_ea73e250586924fb71aef6e9068c74b3>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_ea8abc52251f3f611eeda54804632370>@@XAEAVOpSchema@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_eaa767ebfb9d3cd125f4e7ccc1fad9c5>@@XAEAVNodeConnection@MLGraph@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_eedfabccf04dae8365cd4a4775f4c12a>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_efb13713d16ec9cd372290e4d816e310>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_f075aa67626267fd6c7787bb3fe85619>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_f44d466c71e5c3d26fd6845c3725c13d>@@X$$V@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_f548a62cea92aefa0287b3e74564a99c>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_f78d8769dd40946ef61ad5956cbf10fe>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_f85d256fbdca304989cfd95ad15eb2ed>@@XH@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_f985edc73297b31100389b5211e3935e>@@XAEAVOpSchema@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_fab0569e655d52f18af3ccf270ee645c>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_fac57b2a462d98ae525cfef4586eb109>@@XH@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_fb426100134d266bc87188ebcc3c94ac>@@XV?$Map@V?$Matrix@M$0?0$00$0A@$0?0$00@Eigen@@$0A@V?$Stride@$0A@$0A@@2@@Eigen@@V?$Map@$$CBV?$Matrix@M$0?0$00$0A@$0?0$00@Eigen@@$0A@V?$Stride@$0A@$0A@@2@@3@M@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_fb687073b1db878d0682acf9348b6e79>@@V?$ComPtr@UIMLOperatorTensor@@@WRL@Microsoft@@I@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_fd66f022da42b8a18d5e26e8560bfb59>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_fe5896b63222887f4439a4ae3de8a244>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_ff02a1c545380d90edd1bec0e08a1239>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Iosb@H@std@@
.?AV?$_Mpunct@_W@std@@
.?AV?$_Mpunct@D@std@@
.?AV?$_Mpunct@G@std@@
.?AV?$_Packaged_state@$$A6AXXZ@std@@
.?AV?$_Ref_count@VModel@onnxruntime@@@std@@
.?AV?$_Ref_count_obj@V?$unordered_map@V?$basic_string@DU?$char_traits@D@std@@V?$allocator@D@2@@std@@UFuncInfo@FuncManager@onnxruntime@@U?$hash@V?$basic_string@DU?$char_traits@D@std@@V?$allocator@D@2@@std@@@2@U?$equal_to@V?$basic_string@DU?$char_traits@D@std@@V?$allocator@D@2@@std@@@2@V?$allocator@U?$pair@$$CBV?$basic_string@DU?$char_traits@D@std@@V?$allocator@D@2@@std@@UFuncInfo@FuncManager@onnxruntime@@@std@@@2@@std@@@std@@
.?AV?$_Ref_count_obj@V?$unordered_map@V?$basic_string@DU?$char_traits@D@std@@V?$allocator@D@2@@std@@VTensorProto@onnx@@U?$hash@V?$basic_string@DU?$char_traits@D@std@@V?$allocator@D@2@@std@@@2@U?$equal_to@V?$basic_string@DU?$char_traits@D@std@@V?$allocator@D@2@@std@@@2@V?$allocator@U?$pair@$$CBV?$basic_string@DU?$char_traits@D@std@@V?$allocator@D@2@@std@@VTensorProto@onnx@@@std@@@2@@std@@@std@@
.?AV?$_Ref_count_obj@V__ExceptionPtr@@@std@@
.?AV?$_Ref_count_obj@VBarrierAssignment@Compilation@MLGraph@@@std@@
.?AV?$_Ref_count_obj@VBucketizedBufferAllocator@Dml@@@std@@
.?AV?$_Ref_count_obj@VBucketizedTensorAllocationAssignment@Compilation@MLGraph@@@std@@
.?AV?$_Ref_count_obj@VCommandQueue@Dml@@@std@@
.?AV?$_Ref_count_obj@VCompileOperators@Compilation@MLGraph@@@std@@
.?AV?$_Ref_count_obj@VCPUAllocator@Dml@@@std@@
.?AV?$_Ref_count_obj@VCustomRegistry@onnxruntime@@@std@@
.?AV?$_Ref_count_obj@VDMLOpaqueOperationDesc@DML@MLGraph@@@std@@
.?AV?$_Ref_count_obj@VExecutionContext@Dml@@@std@@
.?AV?$_Ref_count_obj@VExecutionOrder@Compilation@MLGraph@@@std@@
.?AV?$_Ref_count_obj@VExecutionPlan@DMLExecutionPlan@@@std@@
.?AV?$_Ref_count_obj@VInitializeLayout@Compilation@MLGraph@@@std@@
.?AV?$_Ref_count_obj@VKernelRegistry@onnxruntime@@@std@@
.?AV?$_Ref_count_obj@VLayoutAssignment@Compilation@MLGraph@@@std@@
.?AV?$_Ref_count_obj@VLiveness@Compilation@MLGraph@@@std@@
.?AV?$_Ref_count_obj@VNode@MLGraph@@@std@@
.?AV?$_Ref_count_obj@VNoOpRemoval@Compilation@MLGraph@@@std@@
.?AV?$_Ref_count_obj@VOnnxRuntimeOpSchemaRegistry@onnxruntime@@@std@@
.?AV?$_Ref_count_obj@VSchemaRegistryManager@onnxruntime@@@std@@
.?AV?$_Ref_count_obj@VTensor@MLGraph@@@std@@
.?AV?$_Ref_count_obj@VTensorAlignment@Compilation@MLGraph@@@std@@
.?AV?$_Ref_count_obj@VTensorAssignment@Compilation@MLGraph@@@std@@
.?AV?$_Ref_count_obj@VTensorConstness@Compilation@MLGraph@@@std@@
.?AV?$_Ref_count_obj_alloc@V__ExceptionPtr@@U?$_StaticAllocator@H@@@std@@
.?AV?$_Ref_count_resource@PEAVBFCArena@onnxruntime@@U?$default_delete@VBFCArena@onnxruntime@@@std@@@std@@
.?AV?$_Ref_count_resource@PEAVDummyArena@onnxruntime@@U?$default_delete@VDummyArena@onnxruntime@@@std@@@std@@
.?AV?$_Ref_count_resource@PEAVIDeviceAllocator@onnxruntime@@U?$default_delete@VIDeviceAllocator@onnxruntime@@@std@@@std@@
.?AV?$_Ref_count_resource@PEAXP6AXPEAX@Z@std@@
.?AV?$Abs@_J@onnxruntime@@
.?AV?$Abs@_K@onnxruntime@@
.?AV?$Abs@C@onnxruntime@@
.?AV?$Abs@E@onnxruntime@@
.?AV?$Abs@F@onnxruntime@@
.?AV?$Abs@G@onnxruntime@@
.?AV?$Abs@H@onnxruntime@@
.?AV?$Abs@I@onnxruntime@@
.?AV?$Abs@M@onnxruntime@@
.?AV?$Abs@N@onnxruntime@@
.?AV?$Acos@M@onnxruntime@@
.?AV?$Acosh@M@onnxruntime@@
.?AV?$Add@_J@onnxruntime@@
.?AV?$Add@H@onnxruntime@@
.?AV?$Add@M@onnxruntime@@
.?AV?$Affine@M@contrib@onnxruntime@@
.?AV?$ArgMax@H@onnxruntime@@
.?AV?$ArgMax@M@onnxruntime@@
.?AV?$ArgMin@H@onnxruntime@@
.?AV?$ArgMin@M@onnxruntime@@
.?AV?$ArrayFeatureExtractorOp@_J@ml@onnxruntime@@
.?AV?$ArrayFeatureExtractorOp@H@ml@onnxruntime@@
.?AV?$ArrayFeatureExtractorOp@M@ml@onnxruntime@@
.?AV?$ArrayFeatureExtractorOp@N@ml@onnxruntime@@
.?AV?$ArrayFeatureExtractorOp@V?$basic_string@DU?$char_traits@D@std@@V?$allocator@D@2@@std@@@ml@onnxruntime@@
.?AV?$Asin@M@onnxruntime@@
.?AV?$Asinh@M@onnxruntime@@
.?AV?$Atan@M@onnxruntime@@
.?AV?$Atanh@M@onnxruntime@@
.?AV?$AttentionWrapper@M@contrib@onnxruntime@@
.?AV?$BahdanauAttention@M@contrib@onnxruntime@@
.?AV?$basic_filebuf@DU?$char_traits@D@std@@@std@@
.?AV?$basic_ifstream@DU?$char_traits@D@std@@@std@@
.?AV?$basic_ios@_WU?$char_traits@_W@std@@@std@@
.?AV?$basic_ios@DU?$char_traits@D@std@@@std@@
.?AV?$basic_iostream@DU?$char_traits@D@std@@@std@@
.?AV?$basic_istream@DU?$char_traits@D@std@@@std@@
.?AV?$basic_ofstream@DU?$char_traits@D@std@@@std@@
.?AV?$basic_ostream@_WU?$char_traits@_W@std@@@std@@
.?AV?$basic_ostream@DU?$char_traits@D@std@@@std@@
.?AV?$basic_ostringstream@_WU?$char_traits@_W@std@@V?$allocator@_W@2@@std@@
.?AV?$basic_ostringstream@DU?$char_traits@D@std@@V?$allocator@D@2@@std@@
.?AV?$basic_streambuf@_WU?$char_traits@_W@std@@@std@@
.?AV?$basic_streambuf@DU?$char_traits@D@std@@@std@@
.?AV?$basic_string@DU?$char_traits@D@std@@V?$allocator@D@2@@std@@
.?AV?$basic_stringbuf@_WU?$char_traits@_W@std@@V?$allocator@_W@2@@std@@
.?AV?$basic_stringbuf@DU?$char_traits@D@std@@V?$allocator@D@2@@std@@
.?AV?$basic_stringstream@DU?$char_traits@D@std@@V?$allocator@D@2@@std@@
.?AV?$BatchNorm@M@onnxruntime@@
.?AV?$BinarizerOp@M@ml@onnxruntime@@
.?AV?$Cast@_J@onnxruntime@@
.?AV?$Cast@_K@onnxruntime@@
.?AV?$Cast@_N@onnxruntime@@
.?AV?$Cast@C@onnxruntime@@
.?AV?$Cast@E@onnxruntime@@
.?AV?$Cast@F@onnxruntime@@
.?AV?$Cast@G@onnxruntime@@
.?AV?$Cast@H@onnxruntime@@
.?AV?$Cast@I@onnxruntime@@
.?AV?$Cast@M@onnxruntime@@
.?AV?$Cast@N@onnxruntime@@
.?AV?$Cast@TMLFloat16@onnxruntime@@@onnxruntime@@
.?AV?$Cast@V?$basic_string@DU?$char_traits@D@std@@V?$allocator@D@2@@std@@@onnxruntime@@
.?AV?$Ceil@M@onnxruntime@@
.?AV?$Clip@M@onnxruntime@@
.?AV?$codecvt@_WDU_Mbstatet@@@std@@
.?AV?$codecvt@DDU_Mbstatet@@@std@@
.?AV?$codecvt@GDU_Mbstatet@@@std@@
.?AV?$codecvt_utf8@_W$0BAPPPP@$0A@@std@@
.?AV?$collate@_W@std@@
.?AV?$collate@D@std@@
.?AV?$collate@G@std@@
.?AV?$Conv@M@onnxruntime@@
.?AV?$ConvTranspose@M@onnxruntime@@
.?AV?$Cos@M@onnxruntime@@
.?AV?$Cosh@M@onnxruntime@@
.?AV?$Crop@M@contrib@onnxruntime@@
.?AV?$ctype@_W@std@@
.?AV?$ctype@D@std@@
.?AV?$ctype@G@std@@
.?AV?$DepthToSpace@M@onnxruntime@@
.?AV?$DequantizeLinear@C@onnxruntime@@
.?AV?$DequantizeLinear@E@onnxruntime@@
.?AV?$DictVectorizerOp@_JM@ml@onnxruntime@@
.?AV?$DictVectorizerOp@_JN@ml@onnxruntime@@
.?AV?$DictVectorizerOp@_JV?$basic_string@DU?$char_traits@D@std@@V?$allocator@D@2@@std@@@ml@onnxruntime@@
.?AV?$DictVectorizerOp@V?$basic_string@DU?$char_traits@D@std@@V?$allocator@D@2@@std@@_J@ml@onnxruntime@@
.?AV?$DictVectorizerOp@V?$basic_string@DU?$char_traits@D@std@@V?$allocator@D@2@@std@@M@ml@onnxruntime@@
.?AV?$DictVectorizerOp@V?$basic_string@DU?$char_traits@D@std@@V?$allocator@D@2@@std@@N@ml@onnxruntime@@
.?AV?$Div@_J@onnxruntime@@
.?AV?$Div@H@onnxruntime@@
.?AV?$Div@M@onnxruntime@@
.?AV?$DmlOperatorActivationTemplate@$0CD@@Dml@@
.?AV?$DmlOperatorActivationTemplate@$0CE@@Dml@@
.?AV?$DmlOperatorActivationTemplate@$0CF@@Dml@@
.?AV?$DmlOperatorActivationTemplate@$0CG@@Dml@@
.?AV?$DmlOperatorActivationTemplate@$0CH@@Dml@@
.?AV?$DmlOperatorActivationTemplate@$0CJ@@Dml@@
.?AV?$DmlOperatorActivationTemplate@$0CK@@Dml@@
.?AV?$DmlOperatorActivationTemplate@$0CL@@Dml@@
.?AV?$DmlOperatorActivationTemplate@$0CM@@Dml@@
.?AV?$DmlOperatorActivationTemplate@$0CN@@Dml@@
.?AV?$DmlOperatorActivationTemplate@$0CO@@Dml@@
.?AV?$DmlOperatorActivationTemplate@$0CP@@Dml@@
.?AV?$DmlOperatorActivationTemplate@$0DA@@Dml@@
.?AV?$DmlOperatorActivationTemplate@$0DB@@Dml@@
.?AV?$DmlOperatorActivationTemplate@$0DC@@Dml@@
.?AV?$DmlOperatorActivationTemplate@$0DD@@Dml@@
.?AV?$DmlOperatorActivationTemplate@$0DE@@Dml@@
.?AV?$DmlOperatorActivationTemplate@$0FK@@Dml@@
.?AV?$DmlOperatorConvolutionTemplate@$00$00@Dml@@
.?AV?$DmlOperatorConvolutionTemplate@$00$0A@@Dml@@
.?AV?$DmlOperatorElementwiseBinary@UDML_ELEMENT_WISE_ADD_OPERATOR_DESC@@@Dml@@
.?AV?$DmlOperatorElementwiseBinary@UDML_ELEMENT_WISE_ADD1_OPERATOR_DESC@@@Dml@@
.?AV?$DmlOperatorElementwiseBinary@UDML_ELEMENT_WISE_DIVIDE_OPERATOR_DESC@@@Dml@@
.?AV?$DmlOperatorElementwiseBinary@UDML_ELEMENT_WISE_LOGICAL_AND_OPERATOR_DESC@@@Dml@@
.?AV?$DmlOperatorElementwiseBinary@UDML_ELEMENT_WISE_LOGICAL_EQUALS_OPERATOR_DESC@@@Dml@@
.?AV?$DmlOperatorElementwiseBinary@UDML_ELEMENT_WISE_LOGICAL_GREATER_THAN_OPERATOR_DESC@@@Dml@@
.?AV?$DmlOperatorElementwiseBinary@UDML_ELEMENT_WISE_LOGICAL_LESS_THAN_OPERATOR_DESC@@@Dml@@
.?AV?$DmlOperatorElementwiseBinary@UDML_ELEMENT_WISE_LOGICAL_OR_OPERATOR_DESC@@@Dml@@
.?AV?$DmlOperatorElementwiseBinary@UDML_ELEMENT_WISE_LOGICAL_XOR_OPERATOR_DESC@@@Dml@@
.?AV?$DmlOperatorElementwiseBinary@UDML_ELEMENT_WISE_MULTIPLY_OPERATOR_DESC@@@Dml@@
.?AV?$DmlOperatorElementwiseBinary@UDML_ELEMENT_WISE_SUBTRACT_OPERATOR_DESC@@@Dml@@
.?AV?$DmlOperatorElementwiseBinaryLoop@UDML_ELEMENT_WISE_ADD_OPERATOR_DESC@@@Dml@@
.?AV?$DmlOperatorElementwiseBinaryLoop@UDML_ELEMENT_WISE_ADD1_OPERATOR_DESC@@@Dml@@
.?AV?$DmlOperatorElementwiseBinaryLoop@UDML_ELEMENT_WISE_MAX_OPERATOR_DESC@@@Dml@@
.?AV?$DmlOperatorElementwiseBinaryLoop@UDML_ELEMENT_WISE_MIN_OPERATOR_DESC@@@Dml@@
.?AV?$DmlOperatorElementwiseQLinear@UDML_ELEMENT_WISE_DEQUANTIZE_LINEAR_OPERATOR_DESC@@@Dml@@
.?AV?$DmlOperatorElementwiseQLinear@UDML_ELEMENT_WISE_QUANTIZE_LINEAR_OPERATOR_DESC@@@Dml@@
.?AV?$DmlOperatorElementwiseUnary@UDML_ELEMENT_WISE_ABS_OPERATOR_DESC@@@Dml@@
.?AV?$DmlOperatorElementwiseUnary@UDML_ELEMENT_WISE_ACOS_OPERATOR_DESC@@@Dml@@
.?AV?$DmlOperatorElementwiseUnary@UDML_ELEMENT_WISE_ACOSH_OPERATOR_DESC@@@Dml@@
.?AV?$DmlOperatorElementwiseUnary@UDML_ELEMENT_WISE_ASIN_OPERATOR_DESC@@@Dml@@
.?AV?$DmlOperatorElementwiseUnary@UDML_ELEMENT_WISE_ASINH_OPERATOR_DESC@@@Dml@@
.?AV?$DmlOperatorElementwiseUnary@UDML_ELEMENT_WISE_ATAN_OPERATOR_DESC@@@Dml@@
.?AV?$DmlOperatorElementwiseUnary@UDML_ELEMENT_WISE_ATANH_OPERATOR_DESC@@@Dml@@
.?AV?$DmlOperatorElementwiseUnary@UDML_ELEMENT_WISE_CEIL_OPERATOR_DESC@@@Dml@@
.?AV?$DmlOperatorElementwiseUnary@UDML_ELEMENT_WISE_COS_OPERATOR_DESC@@@Dml@@
.?AV?$DmlOperatorElementwiseUnary@UDML_ELEMENT_WISE_COSH_OPERATOR_DESC@@@Dml@@
.?AV?$DmlOperatorElementwiseUnary@UDML_ELEMENT_WISE_ERF_OPERATOR_DESC@@@Dml@@
.?AV?$DmlOperatorElementwiseUnary@UDML_ELEMENT_WISE_EXP_OPERATOR_DESC@@@Dml@@
.?AV?$DmlOperatorElementwiseUnary@UDML_ELEMENT_WISE_FLOOR_OPERATOR_DESC@@@Dml@@
.?AV?$DmlOperatorElementwiseUnary@UDML_ELEMENT_WISE_IS_NAN_OPERATOR_DESC@@@Dml@@
.?AV?$DmlOperatorElementwiseUnary@UDML_ELEMENT_WISE_LOG_OPERATOR_DESC@@@Dml@@
.?AV?$DmlOperatorElementwiseUnary@UDML_ELEMENT_WISE_LOGICAL_NOT_OPERATOR_DESC@@@Dml@@
.?AV?$DmlOperatorElementwiseUnary@UDML_ELEMENT_WISE_RECIP_OPERATOR_DESC@@@Dml@@
.?AV?$DmlOperatorElementwiseUnary@UDML_ELEMENT_WISE_SIGN_OPERATOR_DESC@@@Dml@@
.?AV?$DmlOperatorElementwiseUnary@UDML_ELEMENT_WISE_SIN_OPERATOR_DESC@@@Dml@@
.?AV?$DmlOperatorElementwiseUnary@UDML_ELEMENT_WISE_SINH_OPERATOR_DESC@@@Dml@@
.?AV?$DmlOperatorElementwiseUnary@UDML_ELEMENT_WISE_SQRT_OPERATOR_DESC@@@Dml@@
.?AV?$DmlOperatorElementwiseUnary@UDML_ELEMENT_WISE_TAN_OPERATOR_DESC@@@Dml@@
.?AV?$DmlOperatorPoolingTemplate@$0DI@$00@Dml@@
.?AV?$DmlOperatorPoolingTemplate@$0DI@$0A@@Dml@@
.?AV?$DmlOperatorPoolingTemplate@$0DJ@$00@Dml@@
.?AV?$DmlOperatorPoolingTemplate@$0DJ@$0A@@Dml@@
.?AV?$DmlOperatorPoolingTemplate@$0DK@$00@Dml@@
.?AV?$DmlOperatorPoolingTemplate@$0FL@$0A@@Dml@@
.?AV?$DmlOperatorReduceTemplate@$00@Dml@@
.?AV?$DmlOperatorReduceTemplate@$01@Dml@@
.?AV?$DmlOperatorReduceTemplate@$02@Dml@@
.?AV?$DmlOperatorReduceTemplate@$03@Dml@@
.?AV?$DmlOperatorReduceTemplate@$04@Dml@@
.?AV?$DmlOperatorReduceTemplate@$05@Dml@@
.?AV?$DmlOperatorReduceTemplate@$06@Dml@@
.?AV?$DmlOperatorReduceTemplate@$07@Dml@@
.?AV?$DmlOperatorReduceTemplate@$08@Dml@@
.?AV?$DmlOperatorReduceTemplate@$09@Dml@@
.?AV?$DmlOperatorReduceTemplate@$0A@@Dml@@
.?AV?$DmlOperatorReduceTemplate@$0L@@Dml@@
.?AV?$Elu@M@onnxruntime@@
.?AV?$Equal@_J@onnxruntime@@
.?AV?$Equal@_N@onnxruntime@@
.?AV?$Equal@H@onnxruntime@@
.?AV?$Erf@M@onnxruntime@@
.?AV?$Exp@M@onnxruntime@@
.?AV?$Expand_8@_J@onnxruntime@@
.?AV?$Expand_8@_K@onnxruntime@@
.?AV?$Expand_8@_N@onnxruntime@@
.?AV?$Expand_8@C@onnxruntime@@
.?AV?$Expand_8@E@onnxruntime@@
.?AV?$Expand_8@F@onnxruntime@@
.?AV?$Expand_8@G@onnxruntime@@
.?AV?$Expand_8@H@onnxruntime@@
.?AV?$Expand_8@I@onnxruntime@@
.?AV?$Expand_8@M@onnxruntime@@
.?AV?$Expand_8@N@onnxruntime@@
.?AV?$Expand_8@TMLFloat16@onnxruntime@@@onnxruntime@@
.?AV?$Floor@M@onnxruntime@@
.?AV?$FusedConv@M@contrib@onnxruntime@@
.?AV?$FusedGemm@MMMM@contrib@onnxruntime@@
.?AV?$Gemm@MMMM@onnxruntime@@
.?AV?$Greater@H@onnxruntime@@
.?AV?$Greater@M@onnxruntime@@
.?AV?$Hardmax@M@onnxruntime@@
.?AV?$HardSigmoid@M@onnxruntime@@
.?AV?$IAttentionMechanism@M@contrib@onnxruntime@@
.?AV?$IdentityOp@$00@onnxruntime@@
.?AV?$IdentityOp@$0A@@onnxruntime@@
.?AV?$ImageScaler@M@contrib@onnxruntime@@
.?AV?$InstanceNorm@M@onnxruntime@@
.?AV?$IsNaN@M@onnxruntime@@
.?AV?$IsNaN@TMLFloat16@onnxruntime@@@onnxruntime@@
.?AV?$LeakyRelu@M@onnxruntime@@
.?AV?$Less@H@onnxruntime@@
.?AV?$Less@M@onnxruntime@@
.?AV?$LinearClassifier@_J@ml@onnxruntime@@
.?AV?$LinearClassifier@H@ml@onnxruntime@@
.?AV?$LinearClassifier@M@ml@onnxruntime@@
.?AV?$LinearClassifier@N@ml@onnxruntime@@
.?AV?$LinearRegressor@M@ml@onnxruntime@@
.?AV?$Log@M@onnxruntime@@
.?AV?$LogSoftmax@M@onnxruntime@@
.?AV?$LpNorm@M@onnxruntime@@
.?AV?$LRN@M@onnxruntime@@
.?AV?$map@_JMU?$less@_J@std@@V?$allocator@U?$pair@$$CB_JM@std@@@2@@std@@
.?AV?$map@V?$basic_string@DU?$char_traits@D@std@@V?$allocator@D@2@@std@@MU?$less@V?$basic_string@DU?$char_traits@D@std@@V?$allocator@D@2@@std@@@2@V?$allocator@U?$pair@$$CBV?$basic_string@DU?$char_traits@D@std@@V?$allocator@D@2@@std@@M@std@@@2@@std@@
.?AV?$MapType@V?$map@_J_JU?$less@_J@std@@V?$allocator@U?$pair@$$CB_J_J@std@@@2@@std@@@onnxruntime@@
.?AV?$MapType@V?$map@_JMU?$less@_J@std@@V?$allocator@U?$pair@$$CB_JM@std@@@2@@std@@@onnxruntime@@
.?AV?$MapType@V?$map@_JNU?$less@_J@std@@V?$allocator@U?$pair@$$CB_JN@std@@@2@@std@@@onnxruntime@@
.?AV?$MapType@V?$map@_JV?$basic_string@DU?$char_traits@D@std@@V?$allocator@D@2@@std@@U?$less@_J@2@V?$allocator@U?$pair@$$CB_JV?$basic_string@DU?$char_traits@D@std@@V?$allocator@D@2@@std@@@std@@@2@@std@@@onnxruntime@@
.?AV?$MapType@V?$map@V?$basic_string@DU?$char_traits@D@std@@V?$allocator@D@2@@std@@_JU?$less@V?$basic_string@DU?$char_traits@D@std@@V?$allocator@D@2@@std@@@2@V?$allocator@U?$pair@$$CBV?$basic_string@DU?$char_traits@D@std@@V?$allocator@D@2@@std@@_J@std@@@2@@std@@@onnxruntime@@
.?AV?$MapType@V?$map@V?$basic_string@DU?$char_traits@D@std@@V?$allocator@D@2@@std@@MU?$less@V?$basic_string@DU?$char_traits@D@std@@V?$allocator@D@2@@std@@@2@V?$allocator@U?$pair@$$CBV?$basic_string@DU?$char_traits@D@std@@V?$allocator@D@2@@std@@M@std@@@2@@std@@@onnxruntime@@
.?AV?$MapType@V?$map@V?$basic_string@DU?$char_traits@D@std@@V?$allocator@D@2@@std@@NU?$less@V?$basic_string@DU?$char_traits@D@std@@V?$allocator@D@2@@std@@@2@V?$allocator@U?$pair@$$CBV?$basic_string@DU?$char_traits@D@std@@V?$allocator@D@2@@std@@N@std@@@2@@std@@@onnxruntime@@
.?AV?$MapType@V?$map@V?$basic_string@DU?$char_traits@D@std@@V?$allocator@D@2@@std@@V12@U?$less@V?$basic_string@DU?$char_traits@D@std@@V?$allocator@D@2@@std@@@2@V?$allocator@U?$pair@$$CBV?$basic_string@DU?$char_traits@D@std@@V?$allocator@D@2@@std@@V12@@std@@@2@@std@@@onnxruntime@@
.?AV?$MatMul@_J@onnxruntime@@
.?AV?$MatMul@_K@onnxruntime@@
.?AV?$MatMul@H@onnxruntime@@
.?AV?$MatMul@I@onnxruntime@@
.?AV?$MatMul@M@onnxruntime@@
.?AV?$MatMul@N@onnxruntime@@
.?AV?$MatMulInteger@EEH@onnxruntime@@
.?AV?$Max_6@M@onnxruntime@@
.?AV?$Max_8@M@onnxruntime@@
.?AV?$Mean_6@M@onnxruntime@@
.?AV?$Mean_8@M@onnxruntime@@
.?AV?$MeanVarianceNormalization_0@M@onnxruntime@@
.?AV?$MeanVarianceNormalization_1@M@onnxruntime@@
.?AV?$messages@_W@std@@
.?AV?$messages@D@std@@
.?AV?$messages@G@std@@
.?AV?$Min_6@M@onnxruntime@@
.?AV?$Min_8@M@onnxruntime@@
.?AV?$MLOperatorKernel@V?$DmlOperatorActivationTemplate@$0CD@@Dml@@@@
.?AV?$MLOperatorKernel@V?$DmlOperatorActivationTemplate@$0CE@@Dml@@@@
.?AV?$MLOperatorKernel@V?$DmlOperatorActivationTemplate@$0CF@@Dml@@@@
.?AV?$MLOperatorKernel@V?$DmlOperatorActivationTemplate@$0CG@@Dml@@@@
.?AV?$MLOperatorKernel@V?$DmlOperatorActivationTemplate@$0CH@@Dml@@@@
.?AV?$MLOperatorKernel@V?$DmlOperatorActivationTemplate@$0CJ@@Dml@@@@
.?AV?$MLOperatorKernel@V?$DmlOperatorActivationTemplate@$0CK@@Dml@@@@
.?AV?$MLOperatorKernel@V?$DmlOperatorActivationTemplate@$0CL@@Dml@@@@
.?AV?$MLOperatorKernel@V?$DmlOperatorActivationTemplate@$0CM@@Dml@@@@
.?AV?$MLOperatorKernel@V?$DmlOperatorActivationTemplate@$0CN@@Dml@@@@
.?AV?$MLOperatorKernel@V?$DmlOperatorActivationTemplate@$0CO@@Dml@@@@
.?AV?$MLOperatorKernel@V?$DmlOperatorActivationTemplate@$0CP@@Dml@@@@
.?AV?$MLOperatorKernel@V?$DmlOperatorActivationTemplate@$0DA@@Dml@@@@
.?AV?$MLOperatorKernel@V?$DmlOperatorActivationTemplate@$0DB@@Dml@@@@
.?AV?$MLOperatorKernel@V?$DmlOperatorActivationTemplate@$0DC@@Dml@@@@
.?AV?$MLOperatorKernel@V?$DmlOperatorActivationTemplate@$0DD@@Dml@@@@
.?AV?$MLOperatorKernel@V?$DmlOperatorActivationTemplate@$0DE@@Dml@@@@
.?AV?$MLOperatorKernel@V?$DmlOperatorActivationTemplate@$0FK@@Dml@@@@
.?AV?$MLOperatorKernel@V?$DmlOperatorConvolutionTemplate@$00$00@Dml@@@@
.?AV?$MLOperatorKernel@V?$DmlOperatorConvolutionTemplate@$00$0A@@Dml@@@@
.?AV?$MLOperatorKernel@V?$DmlOperatorElementwiseBinary@UDML_ELEMENT_WISE_ADD_OPERATOR_DESC@@@Dml@@@@
.?AV?$MLOperatorKernel@V?$DmlOperatorElementwiseBinary@UDML_ELEMENT_WISE_ADD1_OPERATOR_DESC@@@Dml@@@@
.?AV?$MLOperatorKernel@V?$DmlOperatorElementwiseBinary@UDML_ELEMENT_WISE_DIVIDE_OPERATOR_DESC@@@Dml@@@@
.?AV?$MLOperatorKernel@V?$DmlOperatorElementwiseBinary@UDML_ELEMENT_WISE_LOGICAL_AND_OPERATOR_DESC@@@Dml@@@@
.?AV?$MLOperatorKernel@V?$DmlOperatorElementwiseBinary@UDML_ELEMENT_WISE_LOGICAL_EQUALS_OPERATOR_DESC@@@Dml@@@@
.?AV?$MLOperatorKernel@V?$DmlOperatorElementwiseBinary@UDML_ELEMENT_WISE_LOGICAL_GREATER_THAN_OPERATOR_DESC@@@Dml@@@@
.?AV?$MLOperatorKernel@V?$DmlOperatorElementwiseBinary@UDML_ELEMENT_WISE_LOGICAL_LESS_THAN_OPERATOR_DESC@@@Dml@@@@
.?AV?$MLOperatorKernel@V?$DmlOperatorElementwiseBinary@UDML_ELEMENT_WISE_LOGICAL_OR_OPERATOR_DESC@@@Dml@@@@
.?AV?$MLOperatorKernel@V?$DmlOperatorElementwiseBinary@UDML_ELEMENT_WISE_LOGICAL_XOR_OPERATOR_DESC@@@Dml@@@@
.?AV?$MLOperatorKernel@V?$DmlOperatorElementwiseBinary@UDML_ELEMENT_WISE_MULTIPLY_OPERATOR_DESC@@@Dml@@@@
.?AV?$MLOperatorKernel@V?$DmlOperatorElementwiseBinary@UDML_ELEMENT_WISE_SUBTRACT_OPERATOR_DESC@@@Dml@@@@
.?AV?$MLOperatorKernel@V?$DmlOperatorElementwiseBinaryLoop@UDML_ELEMENT_WISE_ADD_OPERATOR_DESC@@@Dml@@@@
.?AV?$MLOperatorKernel@V?$DmlOperatorElementwiseBinaryLoop@UDML_ELEMENT_WISE_ADD1_OPERATOR_DESC@@@Dml@@@@
.?AV?$MLOperatorKernel@V?$DmlOperatorElementwiseBinaryLoop@UDML_ELEMENT_WISE_MAX_OPERATOR_DESC@@@Dml@@@@
.?AV?$MLOperatorKernel@V?$DmlOperatorElementwiseBinaryLoop@UDML_ELEMENT_WISE_MIN_OPERATOR_DESC@@@Dml@@@@
.?AV?$MLOperatorKernel@V?$DmlOperatorElementwiseQLinear@UDML_ELEMENT_WISE_DEQUANTIZE_LINEAR_OPERATOR_DESC@@@Dml@@@@
.?AV?$MLOperatorKernel@V?$DmlOperatorElementwiseQLinear@UDML_ELEMENT_WISE_QUANTIZE_LINEAR_OPERATOR_DESC@@@Dml@@@@
.?AV?$MLOperatorKernel@V?$DmlOperatorElementwiseUnary@UDML_ELEMENT_WISE_ABS_OPERATOR_DESC@@@Dml@@@@
.?AV?$MLOperatorKernel@V?$DmlOperatorElementwiseUnary@UDML_ELEMENT_WISE_ACOS_OPERATOR_DESC@@@Dml@@@@
.?AV?$MLOperatorKernel@V?$DmlOperatorElementwiseUnary@UDML_ELEMENT_WISE_ACOSH_OPERATOR_DESC@@@Dml@@@@
.?AV?$MLOperatorKernel@V?$DmlOperatorElementwiseUnary@UDML_ELEMENT_WISE_ASIN_OPERATOR_DESC@@@Dml@@@@
.?AV?$MLOperatorKernel@V?$DmlOperatorElementwiseUnary@UDML_ELEMENT_WISE_ASINH_OPERATOR_DESC@@@Dml@@@@
.?AV?$MLOperatorKernel@V?$DmlOperatorElementwiseUnary@UDML_ELEMENT_WISE_ATAN_OPERATOR_DESC@@@Dml@@@@
.?AV?$MLOperatorKernel@V?$DmlOperatorElementwiseUnary@UDML_ELEMENT_WISE_ATANH_OPERATOR_DESC@@@Dml@@@@
.?AV?$MLOperatorKernel@V?$DmlOperatorElementwiseUnary@UDML_ELEMENT_WISE_CEIL_OPERATOR_DESC@@@Dml@@@@
.?AV?$MLOperatorKernel@V?$DmlOperatorElementwiseUnary@UDML_ELEMENT_WISE_COS_OPERATOR_DESC@@@Dml@@@@
.?AV?$MLOperatorKernel@V?$DmlOperatorElementwiseUnary@UDML_ELEMENT_WISE_COSH_OPERATOR_DESC@@@Dml@@@@
.?AV?$MLOperatorKernel@V?$DmlOperatorElementwiseUnary@UDML_ELEMENT_WISE_ERF_OPERATOR_DESC@@@Dml@@@@
.?AV?$MLOperatorKernel@V?$DmlOperatorElementwiseUnary@UDML_ELEMENT_WISE_EXP_OPERATOR_DESC@@@Dml@@@@
.?AV?$MLOperatorKernel@V?$DmlOperatorElementwiseUnary@UDML_ELEMENT_WISE_FLOOR_OPERATOR_DESC@@@Dml@@@@
.?AV?$MLOperatorKernel@V?$DmlOperatorElementwiseUnary@UDML_ELEMENT_WISE_IS_NAN_OPERATOR_DESC@@@Dml@@@@
.?AV?$MLOperatorKernel@V?$DmlOperatorElementwiseUnary@UDML_ELEMENT_WISE_LOG_OPERATOR_DESC@@@Dml@@@@
.?AV?$MLOperatorKernel@V?$DmlOperatorElementwiseUnary@UDML_ELEMENT_WISE_LOGICAL_NOT_OPERATOR_DESC@@@Dml@@@@
.?AV?$MLOperatorKernel@V?$DmlOperatorElementwiseUnary@UDML_ELEMENT_WISE_RECIP_OPERATOR_DESC@@@Dml@@@@
.?AV?$MLOperatorKernel@V?$DmlOperatorElementwiseUnary@UDML_ELEMENT_WISE_SIGN_OPERATOR_DESC@@@Dml@@@@
.?AV?$MLOperatorKernel@V?$DmlOperatorElementwiseUnary@UDML_ELEMENT_WISE_SIN_OPERATOR_DESC@@@Dml@@@@
.?AV?$MLOperatorKernel@V?$DmlOperatorElementwiseUnary@UDML_ELEMENT_WISE_SINH_OPERATOR_DESC@@@Dml@@@@
.?AV?$MLOperatorKernel@V?$DmlOperatorElementwiseUnary@UDML_ELEMENT_WISE_SQRT_OPERATOR_DESC@@@Dml@@@@
.?AV?$MLOperatorKernel@V?$DmlOperatorElementwiseUnary@UDML_ELEMENT_WISE_TAN_OPERATOR_DESC@@@Dml@@@@
.?AV?$MLOperatorKernel@V?$DmlOperatorPoolingTemplate@$0DI@$00@Dml@@@@
.?AV?$MLOperatorKernel@V?$DmlOperatorPoolingTemplate@$0DI@$0A@@Dml@@@@
.?AV?$MLOperatorKernel@V?$DmlOperatorPoolingTemplate@$0DJ@$00@Dml@@@@
.?AV?$MLOperatorKernel@V?$DmlOperatorPoolingTemplate@$0DJ@$0A@@Dml@@@@
.?AV?$MLOperatorKernel@V?$DmlOperatorPoolingTemplate@$0DK@$00@Dml@@@@
.?AV?$MLOperatorKernel@V?$DmlOperatorPoolingTemplate@$0FL@$0A@@Dml@@@@
.?AV?$MLOperatorKernel@V?$DmlOperatorReduceTemplate@$00@Dml@@@@
.?AV?$MLOperatorKernel@V?$DmlOperatorReduceTemplate@$01@Dml@@@@
.?AV?$MLOperatorKernel@V?$DmlOperatorReduceTemplate@$02@Dml@@@@
.?AV?$MLOperatorKernel@V?$DmlOperatorReduceTemplate@$03@Dml@@@@
.?AV?$MLOperatorKernel@V?$DmlOperatorReduceTemplate@$04@Dml@@@@
.?AV?$MLOperatorKernel@V?$DmlOperatorReduceTemplate@$05@Dml@@@@
.?AV?$MLOperatorKernel@V?$DmlOperatorReduceTemplate@$06@Dml@@@@
.?AV?$MLOperatorKernel@V?$DmlOperatorReduceTemplate@$07@Dml@@@@
.?AV?$MLOperatorKernel@V?$DmlOperatorReduceTemplate@$08@Dml@@@@
.?AV?$MLOperatorKernel@V?$DmlOperatorReduceTemplate@$09@Dml@@@@
.?AV?$MLOperatorKernel@V?$DmlOperatorReduceTemplate@$0A@@Dml@@@@
.?AV?$MLOperatorKernel@V?$DmlOperatorReduceTemplate@$0L@@Dml@@@@
.?AV?$MLOperatorKernel@VDmlOperatorAffine@Dml@@@@
.?AV?$MLOperatorKernel@VDmlOperatorBatchNormalization@Dml@@@@
.?AV?$MLOperatorKernel@VDmlOperatorCast@Dml@@@@
.?AV?$MLOperatorKernel@VDmlOperatorConcat@Dml@@@@
.?AV?$MLOperatorKernel@VDmlOperatorConstantOfShape@Dml@@@@
.?AV?$MLOperatorKernel@VDmlOperatorCopy@Dml@@@@
.?AV?$MLOperatorKernel@VDmlOperatorCrop@Dml@@@@
.?AV?$MLOperatorKernel@VDmlOperatorDepthToSpace@Dml@@@@
.?AV?$MLOperatorKernel@VDmlOperatorElementwiseClip@Dml@@@@
.?AV?$MLOperatorKernel@VDmlOperatorElementwiseIf@Dml@@@@
.?AV?$MLOperatorKernel@VDmlOperatorElementwiseMean@Dml@@@@
.?AV?$MLOperatorKernel@VDmlOperatorElementwisePow@Dml@@@@
.?AV?$MLOperatorKernel@VDmlOperatorExpand@Dml@@@@
.?AV?$MLOperatorKernel@VDmlOperatorEyeLike@Dml@@@@
.?AV?$MLOperatorKernel@VDmlOperatorGatedRecurrentUnit@Dml@@@@
.?AV?$MLOperatorKernel@VDmlOperatorGather@Dml@@@@
.?AV?$MLOperatorKernel@VDmlOperatorGemm@Dml@@@@
.?AV?$MLOperatorKernel@VDmlOperatorInstanceNormalization@Dml@@@@
.?AV?$MLOperatorKernel@VDmlOperatorLocalResponseNormalization@Dml@@@@
.?AV?$MLOperatorKernel@VDmlOperatorLongShortTermUnit@Dml@@@@
.?AV?$MLOperatorKernel@VDmlOperatorLpNormalization@Dml@@@@
.?AV?$MLOperatorKernel@VDmlOperatorMatMul@Dml@@@@
.?AV?$MLOperatorKernel@VDmlOperatorMaxUnpool@Dml@@@@
.?AV?$MLOperatorKernel@VDmlOperatorMeanVarNormalization@Dml@@@@
.?AV?$MLOperatorKernel@VDmlOperatorMemcpy@Dml@@@@
.?AV?$MLOperatorKernel@VDmlOperatorNeg@Dml@@@@
.?AV?$MLOperatorKernel@VDmlOperatorOneHot@Dml@@@@
.?AV?$MLOperatorKernel@VDmlOperatorPadding@Dml@@@@
.?AV?$MLOperatorKernel@VDmlOperatorRecurrentNeuralNetwork@Dml@@@@
.?AV?$MLOperatorKernel@VDmlOperatorRegionOfInterestPooling@Dml@@@@
.?AV?$MLOperatorKernel@VDmlOperatorResize@Dml@@@@
.?AV?$MLOperatorKernel@VDmlOperatorScatter@Dml@@@@
.?AV?$MLOperatorKernel@VDmlOperatorSlice@Dml@@@@
.?AV?$MLOperatorKernel@VDmlOperatorSpaceToDepth@Dml@@@@
.?AV?$MLOperatorKernel@VDmlOperatorSplit@Dml@@@@
.?AV?$MLOperatorKernel@VDmlOperatorTile@Dml@@@@
.?AV?$MLOperatorKernel@VDmlOperatorTopK@Dml@@@@
.?AV?$MLOperatorKernel@VDmlOperatorTranspose@Dml@@@@
.?AV?$MLOperatorKernel@VDmlOperatorValueScale2d@Dml@@@@
.?AV?$money_get@_WV?$istreambuf_iterator@_WU?$char_traits@_W@std@@@std@@@std@@
.?AV?$money_get@DV?$istreambuf_iterator@DU?$char_traits@D@std@@@std@@@std@@
.?AV?$money_get@GV?$istreambuf_iterator@GU?$char_traits@G@std@@@std@@@std@@
.?AV?$money_put@_WV?$ostreambuf_iterator@_WU?$char_traits@_W@std@@@std@@@std@@
.?AV?$money_put@DV?$ostreambuf_iterator@DU?$char_traits@D@std@@@std@@@std@@
.?AV?$money_put@GV?$ostreambuf_iterator@GU?$char_traits@G@std@@@std@@@std@@
.?AV?$moneypunct@_W$00@std@@
.?AV?$moneypunct@_W$0A@@std@@
.?AV?$moneypunct@D$00@std@@
.?AV?$moneypunct@D$0A@@std@@
.?AV?$moneypunct@G$00@std@@
.?AV?$moneypunct@G$0A@@std@@
.?AV?$Mul@_J@onnxruntime@@
.?AV?$Mul@H@onnxruntime@@
.?AV?$Mul@M@onnxruntime@@
.?AV?$Mul@N@onnxruntime@@
.?AV?$Neg@C@onnxruntime@@
.?AV?$Neg@H@onnxruntime@@
.?AV?$Neg@M@onnxruntime@@
.?AV?$NonOnnxType@_J@onnxruntime@@
.?AV?$NonOnnxType@_K@onnxruntime@@
.?AV?$NonOnnxType@_N@onnxruntime@@
.?AV?$NonOnnxType@C@onnxruntime@@
.?AV?$NonOnnxType@E@onnxruntime@@
.?AV?$NonOnnxType@F@onnxruntime@@
.?AV?$NonOnnxType@G@onnxruntime@@
.?AV?$NonOnnxType@H@onnxruntime@@
.?AV?$NonOnnxType@I@onnxruntime@@
.?AV?$NonOnnxType@M@onnxruntime@@
.?AV?$NonOnnxType@N@onnxruntime@@
.?AV?$NonOnnxType@TMLFloat16@onnxruntime@@@onnxruntime@@
.?AV?$NonOnnxType@UBFloat16@onnxruntime@@@onnxruntime@@
.?AV?$NonOnnxType@V?$basic_string@DU?$char_traits@D@std@@V?$allocator@D@2@@std@@@onnxruntime@@
.?AV?$NonTensorType@V?$map@_J_JU?$less@_J@std@@V?$allocator@U?$pair@$$CB_J_J@std@@@2@@std@@@onnxruntime@@
.?AV?$NonTensorType@V?$map@_JMU?$less@_J@std@@V?$allocator@U?$pair@$$CB_JM@std@@@2@@std@@@onnxruntime@@
.?AV?$NonTensorType@V?$map@_JNU?$less@_J@std@@V?$allocator@U?$pair@$$CB_JN@std@@@2@@std@@@onnxruntime@@
.?AV?$NonTensorType@V?$map@_JV?$basic_string@DU?$char_traits@D@std@@V?$allocator@D@2@@std@@U?$less@_J@2@V?$allocator@U?$pair@$$CB_JV?$basic_string@DU?$char_traits@D@std@@V?$allocator@D@2@@std@@@std@@@2@@std@@@onnxruntime@@
.?AV?$NonTensorType@V?$map@V?$basic_string@DU?$char_traits@D@std@@V?$allocator@D@2@@std@@_JU?$less@V?$basic_string@DU?$char_traits@D@std@@V?$allocator@D@2@@std@@@2@V?$allocator@U?$pair@$$CBV?$basic_string@DU?$char_traits@D@std@@V?$allocator@D@2@@std@@_J@std@@@2@@std@@@onnxruntime@@
.?AV?$NonTensorType@V?$map@V?$basic_string@DU?$char_traits@D@std@@V?$allocator@D@2@@std@@MU?$less@V?$basic_string@DU?$char_traits@D@std@@V?$allocator@D@2@@std@@@2@V?$allocator@U?$pair@$$CBV?$basic_string@DU?$char_traits@D@std@@V?$allocator@D@2@@std@@M@std@@@2@@std@@@onnxruntime@@
.?AV?$NonTensorType@V?$map@V?$basic_string@DU?$char_traits@D@std@@V?$allocator@D@2@@std@@NU?$less@V?$basic_string@DU?$char_traits@D@std@@V?$allocator@D@2@@std@@@2@V?$allocator@U?$pair@$$CBV?$basic_string@DU?$char_traits@D@std@@V?$allocator@D@2@@std@@N@std@@@2@@std@@@onnxruntime@@
.?AV?$NonTensorType@V?$map@V?$basic_string@DU?$char_traits@D@std@@V?$allocator@D@2@@std@@V12@U?$less@V?$basic_string@DU?$char_traits@D@std@@V?$allocator@D@2@@std@@@2@V?$allocator@U?$pair@$$CBV?$basic_string@DU?$char_traits@D@std@@V?$allocator@D@2@@std@@V12@@std@@@2@@std@@@onnxruntime@@
.?AV?$NonTensorType@V?$vector@_JV?$allocator@_J@std@@@std@@@onnxruntime@@
.?AV?$NonTensorType@V?$vector@MV?$allocator@M@std@@@std@@@onnxruntime@@
.?AV?$NonTensorType@V?$vector@NV?$allocator@N@std@@@std@@@onnxruntime@@
.?AV?$NonTensorType@V?$vector@V?$basic_string@DU?$char_traits@D@std@@V?$allocator@D@2@@std@@V?$allocator@V?$basic_string@DU?$char_traits@D@std@@V?$allocator@D@2@@std@@@2@@std@@@onnxruntime@@
.?AV?$NonTensorType@V?$vector@V?$map@_JMU?$less@_J@std@@V?$allocator@U?$pair@$$CB_JM@std@@@2@@std@@V?$allocator@V?$map@_JMU?$less@_J@std@@V?$allocator@U?$pair@$$CB_JM@std@@@2@@std@@@2@@std@@@onnxruntime@@
.?AV?$NonTensorType@V?$vector@V?$map@V?$basic_string@DU?$char_traits@D@std@@V?$allocator@D@2@@std@@MU?$less@V?$basic_string@DU?$char_traits@D@std@@V?$allocator@D@2@@std@@@2@V?$allocator@U?$pair@$$CBV?$basic_string@DU?$char_traits@D@std@@V?$allocator@D@2@@std@@M@std@@@2@@std@@V?$allocator@V?$map@V?$basic_string@DU?$char_traits@D@std@@V?$allocator@D@2@@std@@MU?$less@V?$basic_string@DU?$char_traits@D@std@@V?$allocator@D@2@@std@@@2@V?$allocator@U?$pair@$$CBV?$basic_string@DU?$char_traits@D@std@@V?$allocator@D@2@@std@@M@std@@@2@@std@@@2@@std@@@onnxruntime@@
.?AV?$NonZero@_J@onnxruntime@@
.?AV?$NonZero@_N@onnxruntime@@
.?AV?$NonZero@H@onnxruntime@@
.?AV?$NonZero@M@onnxruntime@@
.?AV?$num_get@_WV?$istreambuf_iterator@_WU?$char_traits@_W@std@@@std@@@std@@
.?AV?$num_get@DV?$istreambuf_iterator@DU?$char_traits@D@std@@@std@@@std@@
.?AV?$num_get@GV?$istreambuf_iterator@GU?$char_traits@G@std@@@std@@@std@@
.?AV?$num_put@_WV?$ostreambuf_iterator@_WU?$char_traits@_W@std@@@std@@@std@@
.?AV?$num_put@DV?$ostreambuf_iterator@DU?$char_traits@D@std@@@std@@@std@@
.?AV?$num_put@GV?$ostreambuf_iterator@GU?$char_traits@G@std@@@std@@@std@@
.?AV?$numpunct@_W@std@@
.?AV?$numpunct@D@std@@
.?AV?$numpunct@G@std@@
.?AV?$OneHotEncoderOp@_J@ml@onnxruntime@@
.?AV?$OneHotEncoderOp@M@ml@onnxruntime@@
.?AV?$OneHotEncoderOp@N@ml@onnxruntime@@
.?AV?$OneHotEncoderOp@V?$basic_string@DU?$char_traits@D@std@@V?$allocator@D@2@@std@@@ml@onnxruntime@@
.?AV?$OneHotOp@_J_J_J@onnxruntime@@
.?AV?$OneHotOp@_JHM@onnxruntime@@
.?AV?$OneHotOp@_JM_J@onnxruntime@@
.?AV?$OneHotOp@_JV?$basic_string@DU?$char_traits@D@std@@V?$allocator@D@2@@std@@_J@onnxruntime@@
.?AV?$OneHotOp@M_J_J@onnxruntime@@
.?AV?$OneHotOp@MMM@onnxruntime@@
.?AV?$OneHotOp@MV?$basic_string@DU?$char_traits@D@std@@V?$allocator@D@2@@std@@_J@onnxruntime@@
.?AV?$ParametricSoftplus@M@onnxruntime@@
.?AV?$Pool@MV?$MaxPool@$00@onnxruntime@@@onnxruntime@@
.?AV?$Pool@MV?$MaxPool@$07@onnxruntime@@@onnxruntime@@
.?AV?$Pool@MVAveragePool@onnxruntime@@@onnxruntime@@
.?AV?$Pool@MVLpPool@onnxruntime@@@onnxruntime@@
.?AV?$Pow@M@onnxruntime@@
.?AV?$PRelu@M@onnxruntime@@
.?AV?$QLinearMatMul@EEE@onnxruntime@@
.?AV?$QuantizeLinear@C@onnxruntime@@
.?AV?$QuantizeLinear@E@onnxruntime@@
.?AV?$Reciprocal@M@onnxruntime@@
.?AV?$ReduceKernel@$00@onnxruntime@@
.?AV?$ReduceKernel@$0A@@onnxruntime@@
.?AV?$ReduceKernelBase@$00@onnxruntime@@
.?AV?$ReduceKernelBase@$0A@@onnxruntime@@
.?AV?$ReduceL1@H@onnxruntime@@
.?AV?$ReduceL1@M@onnxruntime@@
.?AV?$ReduceL2@H@onnxruntime@@
.?AV?$ReduceL2@M@onnxruntime@@
.?AV?$ReduceLogSum@H@onnxruntime@@
.?AV?$ReduceLogSum@M@onnxruntime@@
.?AV?$ReduceLogSumExp@H@onnxruntime@@
.?AV?$ReduceLogSumExp@M@onnxruntime@@
.?AV?$ReduceMax@H@onnxruntime@@
.?AV?$ReduceMax@M@onnxruntime@@
.?AV?$ReduceMean@H@onnxruntime@@
.?AV?$ReduceMean@M@onnxruntime@@
.?AV?$ReduceMin@H@onnxruntime@@
.?AV?$ReduceMin@M@onnxruntime@@
.?AV?$ReduceProd@H@onnxruntime@@
.?AV?$ReduceProd@M@onnxruntime@@
.?AV?$ReduceSum@H@onnxruntime@@
.?AV?$ReduceSum@M@onnxruntime@@
.?AV?$ReduceSumSquare@H@onnxruntime@@
.?AV?$ReduceSumSquare@M@onnxruntime@@
.?AV?$Relu@M@onnxruntime@@
.?AV?$Resize@E@onnxruntime@@
.?AV?$Resize@H@onnxruntime@@
.?AV?$Resize@M@onnxruntime@@
.?AV?$RNN@M@onnxruntime@@
.?AV?$RoiAlign@M@onnxruntime@@
.?AV?$RoiAlign@N@onnxruntime@@
.?AV?$RoiPool@M@onnxruntime@@
.?AV?$RuntimeClass@U?$RuntimeClassFlags@$01@WRL@Microsoft@@UIExecutionProvider@Dml@@UIWinmlExecutionProvider@implementation@MachineLearning@AI@Windows@winrt@@@WRL@Microsoft@@
.?AV?$RuntimeClass@U?$RuntimeClassFlags@$01@WRL@Microsoft@@UIMLOperatorKernel@@@WRL@Microsoft@@
.?AV?$RuntimeClass@U?$RuntimeClassFlags@$01@WRL@Microsoft@@UIMLOperatorKernelFactory@@@WRL@Microsoft@@
.?AV?$RuntimeClass@U?$RuntimeClassFlags@$01@WRL@Microsoft@@UIMLOperatorShapeInferrer@@@WRL@Microsoft@@
.?AV?$RuntimeClass@U?$RuntimeClassFlags@$01@WRL@Microsoft@@UIUnknown@@@WRL@Microsoft@@
.?AV?$RuntimeClassBaseT@$01@Details@WRL@Microsoft@@
.?AV?$RuntimeClassImpl@U?$RuntimeClassFlags@$01@WRL@Microsoft@@$00$0A@$00UIExecutionProvider@Dml@@UIWinmlExecutionProvider@implementation@MachineLearning@AI@Windows@winrt@@@Details@WRL@Microsoft@@
.?AV?$RuntimeClassImpl@U?$RuntimeClassFlags@$01@WRL@Microsoft@@$00$0A@$00UIMLOperatorKernel@@@Details@WRL@Microsoft@@
.?AV?$RuntimeClassImpl@U?$RuntimeClassFlags@$01@WRL@Microsoft@@$00$0A@$00UIMLOperatorKernelFactory@@@Details@WRL@Microsoft@@
.?AV?$RuntimeClassImpl@U?$RuntimeClassFlags@$01@WRL@Microsoft@@$00$0A@$00UIMLOperatorShapeInferrer@@@Details@WRL@Microsoft@@
.?AV?$RuntimeClassImpl@U?$RuntimeClassFlags@$01@WRL@Microsoft@@$00$0A@$00UIUnknown@@@Details@WRL@Microsoft@@
.?AV?$SampleOp@M@contrib@onnxruntime@@
.?AV?$Scale@M@contrib@onnxruntime@@
.?AV?$ScaledTanh@M@contrib@onnxruntime@@
.?AV?$ScalerOp@_J@ml@onnxruntime@@
.?AV?$ScalerOp@H@ml@onnxruntime@@
.?AV?$ScalerOp@M@ml@onnxruntime@@
.?AV?$ScalerOp@N@ml@onnxruntime@@
.?AV?$Scan@$07@onnxruntime@@
.?AV?$Scan@$08@onnxruntime@@
.?AV?$Selu@M@onnxruntime@@
.?AV?$SequenceType@V?$vector@_JV?$allocator@_J@std@@@std@@@onnxruntime@@
.?AV?$SequenceType@V?$vector@MV?$allocator@M@std@@@std@@@onnxruntime@@
.?AV?$SequenceType@V?$vector@NV?$allocator@N@std@@@std@@@onnxruntime@@
.?AV?$SequenceType@V?$vector@V?$basic_string@DU?$char_traits@D@std@@V?$allocator@D@2@@std@@V?$allocator@V?$basic_string@DU?$char_traits@D@std@@V?$allocator@D@2@@std@@@2@@std@@@onnxruntime@@
.?AV?$SequenceType@V?$vector@V?$map@_JMU?$less@_J@std@@V?$allocator@U?$pair@$$CB_JM@std@@@2@@std@@V?$allocator@V?$map@_JMU?$less@_J@std@@V?$allocator@U?$pair@$$CB_JM@std@@@2@@std@@@2@@std@@@onnxruntime@@
.?AV?$SequenceType@V?$vector@V?$map@V?$basic_string@DU?$char_traits@D@std@@V?$allocator@D@2@@std@@MU?$less@V?$basic_string@DU?$char_traits@D@std@@V?$allocator@D@2@@std@@@2@V?$allocator@U?$pair@$$CBV?$basic_string@DU?$char_traits@D@std@@V?$allocator@D@2@@std@@M@std@@@2@@std@@V?$allocator@V?$map@V?$basic_string@DU?$char_traits@D@std@@V?$allocator@D@2@@std@@MU?$less@V?$basic_string@DU?$char_traits@D@std@@V?$allocator@D@2@@std@@@2@V?$allocator@U?$pair@$$CBV?$basic_string@DU?$char_traits@D@std@@V?$allocator@D@2@@std@@M@std@@@2@@std@@@2@@std@@@onnxruntime@@
.?AV?$Sigmoid@M@onnxruntime@@
.?AV?$Sin@M@onnxruntime@@
.?AV?$Sinh@M@onnxruntime@@
.?AV?$Softmax@M@onnxruntime@@
.?AV?$Softsign@M@onnxruntime@@
.?AV?$SpaceToDepth@M@onnxruntime@@
.?AV?$Sqrt@M@onnxruntime@@
.?AV?$Sub@_J@onnxruntime@@
.?AV?$Sub@H@onnxruntime@@
.?AV?$Sub@M@onnxruntime@@
.?AV?$Sum_6@M@onnxruntime@@
.?AV?$Sum_8@M@onnxruntime@@
.?AV?$SVMClassifier@_J@ml@onnxruntime@@
.?AV?$SVMClassifier@H@ml@onnxruntime@@
.?AV?$SVMClassifier@M@ml@onnxruntime@@
.?AV?$SVMClassifier@N@ml@onnxruntime@@
.?AV?$SVMCommon@_J@ml@onnxruntime@@
.?AV?$SVMCommon@H@ml@onnxruntime@@
.?AV?$SVMCommon@M@ml@onnxruntime@@
.?AV?$SVMCommon@N@ml@onnxruntime@@
.?AV?$SVMRegressor@M@ml@onnxruntime@@
.?AV?$Tan@M@onnxruntime@@
.?AV?$Tanh@M@onnxruntime@@
.?AV?$TensorType@_J@onnxruntime@@
.?AV?$TensorType@_K@onnxruntime@@
.?AV?$TensorType@_N@onnxruntime@@
.?AV?$TensorType@C@onnxruntime@@
.?AV?$TensorType@E@onnxruntime@@
.?AV?$TensorType@F@onnxruntime@@
.?AV?$TensorType@G@onnxruntime@@
.?AV?$TensorType@H@onnxruntime@@
.?AV?$TensorType@I@onnxruntime@@
.?AV?$TensorType@M@onnxruntime@@
.?AV?$TensorType@N@onnxruntime@@
.?AV?$TensorType@TMLFloat16@onnxruntime@@@onnxruntime@@
.?AV?$TensorType@UBFloat16@onnxruntime@@@onnxruntime@@
.?AV?$TensorType@V?$basic_string@DU?$char_traits@D@std@@V?$allocator@D@2@@std@@@onnxruntime@@
.?AV?$ThresholdedRelu@M@onnxruntime@@
.?AV?$time_get@_WV?$istreambuf_iterator@_WU?$char_traits@_W@std@@@std@@@std@@
.?AV?$time_get@DV?$istreambuf_iterator@DU?$char_traits@D@std@@@std@@@std@@
.?AV?$time_get@GV?$istreambuf_iterator@GU?$char_traits@G@std@@@std@@@std@@
.?AV?$time_put@_WV?$ostreambuf_iterator@_WU?$char_traits@_W@std@@@std@@@std@@
.?AV?$time_put@DV?$ostreambuf_iterator@DU?$char_traits@D@std@@@std@@@std@@
.?AV?$time_put@GV?$ostreambuf_iterator@GU?$char_traits@G@std@@@std@@@std@@
.?AV?$TopK@$08M@onnxruntime@@
.?AV?$TopK@$09M@onnxruntime@@
.?AV?$TreeEnsembleClassifier@_J@ml@onnxruntime@@
.?AV?$TreeEnsembleClassifier@H@ml@onnxruntime@@
.?AV?$TreeEnsembleClassifier@M@ml@onnxruntime@@
.?AV?$TreeEnsembleClassifier@N@ml@onnxruntime@@
.?AV?$TreeEnsembleRegressor@M@ml@onnxruntime@@
.?AV?$Unique@M@contrib@onnxruntime@@
.?AV?$Upsample@E@onnxruntime@@
.?AV?$Upsample@H@onnxruntime@@
.?AV?$Upsample@M@onnxruntime@@
.?AV?$Walker@H@Regexp@re2@@
.?AV?$Walker@PEAVRegexp@re2@@@Regexp@re2@@
.?AV?$Walker@UFrag@re2@@@Regexp@re2@@
.?AV?$Where@H@onnxruntime@@
.?AV?$Where@M@onnxruntime@@
.?AV?$Where@V?$basic_string@DU?$char_traits@D@std@@V?$allocator@D@2@@std@@@onnxruntime@@
.?AV?$wstring_convert@V?$codecvt_utf8@_W$0BAPPPP@$0A@@std@@_WV?$allocator@_W@2@V?$allocator@D@2@@std@@
.?AV_Facet_base@std@@
.?AV_Future_error_category@std@@
.?AV_Generic_error_category@std@@
.?AV_Iostream_error_category@std@@
.?AV_Locimp@locale@std@@
.?AV_Ref_count_base@std@@
.?AV_System_error@std@@
.?AV_System_error_category@std@@
.?AV<lambda_006f042491572090b778a6887556c541>@@
.?AV<lambda_00bc1d3067b0daca44118c6bf6182fe6>@@
.?AV<lambda_01985760e667ba58bff711ef31d8e638>@@
.?AV<lambda_027f0b72d20b824e4e30fa2ccfde3681>@@
.?AV<lambda_034757adb6c60162404ac40e8e741709>@@
.?AV<lambda_0351f7594bfe071c86edac3fec023b45>@@
.?AV<lambda_05139462a1d0ad358a8c7449ca410e71>@@
.?AV<lambda_054344795ce74e2e037e3c05c0b91898>@@
.?AV<lambda_05c6980e4d0ac207717a211414d8f278>@@
.?AV<lambda_07d4dc670413b2a4e0a4da00ec96c8fc>@@
.?AV<lambda_08accd2c56d1c3539bdbe39ead72e813>@@
.?AV<lambda_1245b42f1da301d1dd67408c8b1d4fbe>@@
.?AV<lambda_12c274da604ed254f4e0fb7954f6465d>@@
.?AV<lambda_1476157c6a284e4f379191854345eea5>@@
.?AV<lambda_17b8c13e1e1532971a7e111d63079828>@@
.?AV<lambda_1ab53215f2c83fd1a81285787d0b12a3>@@
.?AV<lambda_1b40e5da70f80ebc1265da7a4b002f1d>@@
.?AV<lambda_1e705c9d678933c457ee9dd44824e26c>@@
.?AV<lambda_221457049dd6e599b1e592be3898266a>@@
.?AV<lambda_2258ee131c6ebb61b9c83defdba7af66>@@
.?AV<lambda_22aec519ccb7e3db8c6745addf3c6448>@@
.?AV<lambda_23ae0d8678653f1ba32dea59d99f813c>@@
.?AV<lambda_24ef3fd2004740c74f45387687b5966c>@@
.?AV<lambda_26c7076e2c32cb7819f715b407d6306a>@@
.?AV<lambda_276b8b89e1dfcb112bdeb48d28d4bec1>@@
.?AV<lambda_27eb941e257b57f9cf2ee9f3ef3087b3>@@
.?AV<lambda_290f5065ffeb082360179e4c8119a9df>@@
.?AV<lambda_29460ba72c9a9f61937f695b212c2385>@@
.?AV<lambda_2997ea06f466f3cb7af7580139e0e9b1>@@
.?AV<lambda_2a231a5ff616b0ae2274b38ac58ff666>@@
.?AV<lambda_2a39988023ade309aa40582a95355447>@@
.?AV<lambda_2a3b1f1fbc2b924051eedcd518441330>@@
.?AV<lambda_2c336c69e37df1f232f1301ffdf6cbc8>@@
.?AV<lambda_2cda3ec4180407fdb66cae08f370124f>@@
.?AV<lambda_2ff8e0e61b396ff915eaef7150818ea5>@@
.?AV<lambda_30947474d124e6310a9f85f72b080207>@@
.?AV<lambda_30c3e62ccde4a098c007b12bb428e908>@@
.?AV<lambda_31044cbb2065f4b8855bbdc646057e42>@@
.?AV<lambda_31999e24a5713e2726b236a23ffe8e9c>@@
.?AV<lambda_3354f944db7877754471d985be3fe29b>@@
.?AV<lambda_3461d2aa8a1d8f58d04263e3bb305fab>@@
.?AV<lambda_36fc80f79cd957d31685eab011dabdfa>@@
.?AV<lambda_3749a2cd3b1b084d4974335060b45681>@@
.?AV<lambda_3baacc98cc06d4e909f66b6a18be3e29>@@
.?AV<lambda_3cdfc8dc1c09b5c62abe721acaa38783>@@
.?AV<lambda_3cf12ecdb8347aca0b39d04786f2c5c1>@@
.?AV<lambda_3f547353f02d28ad34875ee8e051184c>@@
.?AV<lambda_4025341259f86dc630242dff69fca9b8>@@
.?AV<lambda_404084d3edacc8294adecb096c00b5ef>@@
.?AV<lambda_423c7f4514cb0f580d17c1969d94ab4d>@@
.?AV<lambda_4338c9c561d330121c572f512ed1a9cc>@@
.?AV<lambda_44f740f4362270fce5c964ebb50cbf77>@@
.?AV<lambda_4619be3804f026cfd3e188fd9832729a>@@
.?AV<lambda_493755c0718e549fc6eb6376aaf1c076>@@
.?AV<lambda_51e7ce4347ad68176c6a114dbe1a7fb9>@@
.?AV<lambda_53958a524045125d538038a834c170f9>@@
.?AV<lambda_5428f58de3b11d0182bfa5186053ab5a>@@
.?AV<lambda_5597f31027cefda5c75758934e5aed3d>@@
.?AV<lambda_56616cb04d479ecbbef60d16cb985ff3>@@
.?AV<lambda_57767bf65a043efa89050ec956e6375f>@@
.?AV<lambda_57e06211fe7a659ce07289270fd3ee52>@@
.?AV<lambda_57e3ab15547653f4c24a6180872eafc8>@@
.?AV<lambda_57f53ac28d9e46be7f6f5796ae7a2fef>@@
.?AV<lambda_5865299a878cc4536f06dd6ac2dafee9>@@
.?AV<lambda_5a03cad439a535c73c9479bab198ff8a>@@
.?AV<lambda_5be986e07125e16816e6ac7c3f8a6e4e>@@
.?AV<lambda_5f1d94f8ca558702930bc8409fa6a0fd>@@
.?AV<lambda_6075061d5dc57bd363f78060cbc006c9>@@
.?AV<lambda_664899aa3b288611d62300fea2993872>@@
.?AV<lambda_66eda435998e6ddaa9b30be02eae90c7>@@
.?AV<lambda_67018284eb06a00e3e506152039543af>@@
.?AV<lambda_6a32611970906250c6b47d8292ad00e7>@@
.?AV<lambda_6bd810bb96d3f9038457669c0e958c1e>@@
.?AV<lambda_6c179269bbdc04c069c0be4c3276758c>@@
.?AV<lambda_6c33f24f6b037a5d3fc1e56941c40a5c>@@
.?AV<lambda_6ca09521f0419cdfacda156e3fc4c98d>@@
.?AV<lambda_6f48aff9e19635bc9e9581f6bc21910b>@@
.?AV<lambda_6f80d65fbc6388042df99a3b220305d1>@@
.?AV<lambda_71346983b6599c47894abb35bff4747e>@@
.?AV<lambda_747f5a5054cea5042105b3988bb8e54a>@@
.?AV<lambda_769d1db7652c71c0ccf3896a4532b7cf>@@
.?AV<lambda_78db65b9ada40a873888589dab5ab53f>@@
.?AV<lambda_7bf0c45af15d48ff0bf3482d9ab1530d>@@
.?AV<lambda_7d18ce867b586dae3ed4309094f85b3d>@@
.?AV<lambda_7d7cf49bce0e19787ec70235e54b100e>@@
.?AV<lambda_821c7f43d2593552b63657225f3e2a2a>@@
.?AV<lambda_8250122591c954547730909874f35ed1>@@
.?AV<lambda_82fc727948fa2cc155864c30c0053c56>@@
.?AV<lambda_844ac8d870d6c05cc5af1ac622e6548a>@@
.?AV<lambda_84c0c09494d01cc30f16e3449edead54>@@
.?AV<lambda_8566b012fc155a827dac5a26db00bb0f>@@
.?AV<lambda_860fd138c338317eb60a40ddc8d3d604>@@
.?AV<lambda_87377fe9a7b55ca099852704c7649a37>@@
.?AV<lambda_87c68c0967c94d566f6bd8e49e4156e6>@@
.?AV<lambda_87f27c7b79f82015223cdf844a99cbbd>@@
.?AV<lambda_893cc8251b60de6ccc992b54f6f31db9>@@
.?AV<lambda_898e7ddf86c5cb2fdbd52719563437ef>@@
.?AV<lambda_8a3f03cf93ba764f7eebf7fd98d3a893>@@
.?AV<lambda_8a4566bfd5826af470180d3d3cb61fee>@@
.?AV<lambda_8d7ff4e398bab3b109ccce388181bf44>@@
.?AV<lambda_8e3498b106c5788a8387a435fcfed696>@@
.?AV<lambda_8e59199324395720fba09bee90960ebd>@@
.?AV<lambda_8ff3f73c945873491aaa70354b23f874>@@
.?AV<lambda_9239155d58e7ea4f2b7e8d2c9c494e5c>@@
.?AV<lambda_9289ae269610356b68d5c3f46e89bf66>@@
.?AV<lambda_933bfb96b2260d5634eb1eb6a83fa0fe>@@
.?AV<lambda_93e11c159179365582bd72579ec478d7>@@
.?AV<lambda_96977307008117beb1e0c08617e9e024>@@
.?AV<lambda_974421a2166ea3684014171d0d75f69e>@@
.?AV<lambda_977aa0989600c553e6ad21ef5f183702>@@
.?AV<lambda_97ee5446122b04ffc7a1bfadcedd1856>@@
.?AV<lambda_98813516cd70625548f3dca86c17f6e0>@@
.?AV<lambda_98e58702055b3dda6030ac966651b812>@@
.?AV<lambda_991d63fb8a809dc84e4e523068ce486a>@@
.?AV<lambda_9a6ebfb355f6f72365de0d099f01e46c>@@
.?AV<lambda_9a80c5c6458e824bfa0876a779605b0b>@@
.?AV<lambda_9abb244ecf1fe7549bfa1b3b46427d69>@@
.?AV<lambda_9baa1cdad376a56943ca503609534da1>@@
.?AV<lambda_9dc19add650df7a8dd3a2c037757be68>@@
.?AV<lambda_9f49f0af15bc5711a0ad828188e277d2>@@
.?AV<lambda_a0e644278ef4f4a57b9573e7ded643ef>@@
.?AV<lambda_a300a011522f597640fb7738ddb3c3c8>@@
.?AV<lambda_a30982bdf1dc90ee13caf4d420ec5e7f>@@
.?AV<lambda_a4a8f47c88f81824ff45fecdeb8c2272>@@
.?AV<lambda_a4fe3bd39dcd0107f90455cb45c21429>@@
.?AV<lambda_a6f452e793f181bfdb21f8008d20a820>@@
.?AV<lambda_a730596af2436ac6f02571ed7ec62d9c>@@
.?AV<lambda_a83a31e9654ec6fec79c12c296cc64ae>@@
.?AV<lambda_a8dc603fd8183714a0dc357fc9b787c1>@@
.?AV<lambda_a92b151253c6a8077f28133661f111c1>@@
.?AV<lambda_ac4668adfa184e73086660d1e23189e7>@@
.?AV<lambda_ae651a2f316754e5b872f0242e285a17>@@
.?AV<lambda_af2c39467b4484bc2a2f611cf533daa7>@@
.?AV<lambda_b39fcf5d316099631cb4151a025dde22>@@
.?AV<lambda_b43d1a9e0f80c81cf46233421502eec9>@@
.?AV<lambda_b4e5149275d4fcb7878125bc83ce3063>@@
.?AV<lambda_b4f16af0ac2265b9b3b07c19294b18f2>@@
.?AV<lambda_b51428820b3477616d25ebf36e7dd645>@@
.?AV<lambda_b5a8e22fc972999c473eeef0d861144d>@@
.?AV<lambda_b708da6ab938dbf5aa385eabacde06c3>@@
.?AV<lambda_b937f7d4f097577d4fa0e0107ad25600>@@
.?AV<lambda_ba5c1a9f30e9a8c00dc647ceccb205fa>@@
.?AV<lambda_ba9cfe2bb13e49d1f5f6d627965891ec>@@
.?AV<lambda_bb49b7cc5cd2d94ca99a48a4c0d13f14>@@
.?AV<lambda_bc9a9f99cbeabaf2d0a936a0cad6b782>@@
.?AV<lambda_bd5b9427a54fdb45586e1dbfc607a955>@@
.?AV<lambda_be85bfcd5fbfc31b6743eea1ac54b897>@@
.?AV<lambda_beaafeb3eab8e63d67c0320e51be9f3d>@@
.?AV<lambda_bf5458cf82f5faac082f67dd8814164d>@@
.?AV<lambda_c3c25e82dec0fc98e0076356943111e7>@@
.?AV<lambda_c3f051bc4642a4e7930691f847088405>@@
.?AV<lambda_c41fc543d857db8b3ca85cea5cadd247>@@
.?AV<lambda_c5cebd529b61d3173fae5d666977fc08>@@
.?AV<lambda_c88091b3530d152097f987ae77b5c865>@@
.?AV<lambda_c903e10f9792b7526fde45e82dd96aa5>@@
.?AV<lambda_ca87e505bf8a7e1f26579083c3683d94>@@
.?AV<lambda_cda3c60f0bca96d0a80bc61bce840378>@@
.?AV<lambda_ce473b479310095c7321cd7e93391654>@@
.?AV<lambda_cf356a63b9d34af3b27fd0e5246bed98>@@
.?AV<lambda_d01cb7d72935562762275ef2725e3ce2>@@
.?AV<lambda_d1c8da933c44d492bf216840c231dd20>@@
.?AV<lambda_d1f3e1ff52e7a73d61aa38c424d43183>@@
.?AV<lambda_d45413077830f41d06c2c81e573871c9>@@
.?AV<lambda_d54ceb046acf4eb66ab9f93fa1a2d6c2>@@
.?AV<lambda_d7ecd0f53fc3c91f5a3fd89598f9d860>@@
.?AV<lambda_d8797e74ae02acf212ef74610c438126>@@
.?AV<lambda_d8a9ac16dd775f4bb1f670ae469711dc>@@
.?AV<lambda_d8b06a4dd6f551b1fc6c7009ad0ed428>@@
.?AV<lambda_db7b633e35029a3bbec6f104f8732ca0>@@
.?AV<lambda_dc8816ded3bdec37e07aeaf5a6aef6d5>@@
.?AV<lambda_dda5ab6aaf4f2b6f6f3016e64f840ab7>@@
.?AV<lambda_df8dc5d18b005334d023e86e4d511fb0>@@
.?AV<lambda_e0b2d86bba8462f4713d43f91e59ae58>@@
.?AV<lambda_e0d793c456966319eaa2c9c55a133238>@@
.?AV<lambda_e5d35051c862b1e1cd0b6f4bf8ef53ea>@@
.?AV<lambda_e647d51565c9d7d9a3fcd7b8e568467d>@@
.?AV<lambda_e750230a2e347f07ba6ac8b497fd00d5>@@
.?AV<lambda_e84bed965c8370be7a99e2ed5b79591f>@@
.?AV<lambda_ea73e250586924fb71aef6e9068c74b3>@@
.?AV<lambda_ea8abc52251f3f611eeda54804632370>@@
.?AV<lambda_eaa767ebfb9d3cd125f4e7ccc1fad9c5>@@
.?AV<lambda_ebad15d5126e2f0bdb7db9175dabd4d8>@@
.?AV<lambda_ec45355d70f5ac203bc93300e0df3c05>@@
.?AV<lambda_eedfabccf04dae8365cd4a4775f4c12a>@@
.?AV<lambda_efb13713d16ec9cd372290e4d816e310>@@
.?AV<lambda_f075aa67626267fd6c7787bb3fe85619>@@
.?AV<lambda_f44d466c71e5c3d26fd6845c3725c13d>@@
.?AV<lambda_f548a62cea92aefa0287b3e74564a99c>@@
.?AV<lambda_f7661b1b55685c4906bf1a97d7310774>@@
.?AV<lambda_f78d8769dd40946ef61ad5956cbf10fe>@@
.?AV<lambda_f85d256fbdca304989cfd95ad15eb2ed>@@
.?AV<lambda_f985edc73297b31100389b5211e3935e>@@
.?AV<lambda_fab0569e655d52f18af3ccf270ee645c>@@
.?AV<lambda_fac57b2a462d98ae525cfef4586eb109>@@
.?AV<lambda_fb426100134d266bc87188ebcc3c94ac>@@
.?AV<lambda_fb687073b1db878d0682acf9348b6e79>@@
.?AV<lambda_fd66f022da42b8a18d5e26e8560bfb59>@@
.?AV<lambda_fd6d582fe0677f0646e62ecab0800698>@@
.?AV<lambda_fe5896b63222887f4439a4ae3de8a244>@@
.?AV<lambda_ff02a1c545380d90edd1bec0e08a1239>@@
.?AVAllocationInfo@Dml@@
.?AVAnd@onnxruntime@@
.?AVArrayOutputStream@io@protobuf@google@@
.?AVAttributeProto@onnx@@
.?AVbad_alloc@std@@
.?AVbad_array_new_length@std@@
.?AVbad_cast@std@@
.?AVbad_exception@std@@
.?AVbad_function_call@std@@
.?AVbad_optional_access@std@@
.?AVbad_variant_access@std@@
.?AVbad_weak_ptr@std@@
.?AVBarrierAssignment@Compilation@MLGraph@@
.?AVBatchNormalizationAddFusion@onnxruntime@@
.?AVBatchNormalizationMulFusion@onnxruntime@@
.?AVBFCArena@onnxruntime@@
.?AVBucketizedBufferAllocator@Dml@@
.?AVBucketizedTensorAllocationAssignment@Compilation@MLGraph@@
.?AVCastMap@ml@onnxruntime@@
.?AVCategoryMapper@ml@onnxruntime@@
.?AVCoalesceWalker@re2@@
.?AVcodecvt_base@std@@
.?AVCompileOperators@Compilation@MLGraph@@
.?AVCompiler@re2@@
.?AVCompress@onnxruntime@@
.?AVConcat@onnxruntime@@
.?AVConcatBase@onnxruntime@@
.?AVConcatHelper@OperatorHelper@@
.?AVConcatNodeImpl@MLGraph@@
.?AVConstantFolding@onnxruntime@@
.?AVConstantOfShape@onnxruntime@@
.?AVConstantOfShapeHelper@OperatorHelper@@
.?AVControlNodeImpl@MLGraph@@
.?AVConvActivationFusion@onnxruntime@@
.?AVConvAddFusion@onnxruntime@@
.?AVConvBase@onnxruntime@@
.?AVConvBNFusion@onnxruntime@@
.?AVConvInteger@onnxruntime@@
.?AVConvMulFusion@onnxruntime@@
.?AVConvolutionHelperBase@OperatorHelper@@
.?AVConvTransposeBase@onnxruntime@@
.?AVCopyingFileInputStream@FileInputStream@io@protobuf@google@@
.?AVCopyingInputStream@io@protobuf@google@@
.?AVCopyingInputStreamAdaptor@io@protobuf@google@@
.?AVCopyNodeImpl@MLGraph@@
.?AVCPUAllocator@Dml@@
.?AVCPUAllocator@onnxruntime@@
.?AVCPUDataTransfer@onnxruntime@@
.?AVCPUExecutionProvider@onnxruntime@@
.?AVCropBase@contrib@onnxruntime@@
.?AVCropHelper@OperatorHelper@@
.?AVDataTransfer@Dml@@
.?AVDataTypeImpl@onnxruntime@@
.?AVDeepCpuAttnLstmOp@contrib@onnxruntime@@
.?AVDeepCpuGruOp@onnxruntime@@
.?AVDeepCpuLstmOp@onnxruntime@@
.?AVDepthToSpaceHelper@OperatorHelper@@
.?AVDmlCommandRecorder@Dml@@
.?AVDMLOpaqueOperationDesc@DML@MLGraph@@
.?AVDmlOperator@Dml@@
.?AVDmlOperatorActivation@Dml@@
.?AVDmlOperatorAffine@Dml@@
.?AVDmlOperatorBatchNormalization@Dml@@
.?AVDmlOperatorCast@Dml@@
.?AVDmlOperatorConcat@Dml@@
.?AVDmlOperatorConstantOfShape@Dml@@
.?AVDmlOperatorConvolution@Dml@@
.?AVDmlOperatorCopy@Dml@@
.?AVDmlOperatorCrop@Dml@@
.?AVDmlOperatorDepthToSpace@Dml@@
.?AVDmlOperatorElementwiseClip@Dml@@
.?AVDmlOperatorElementwiseIf@Dml@@
.?AVDmlOperatorElementwiseMean@Dml@@
.?AVDmlOperatorElementwisePow@Dml@@
.?AVDmlOperatorExpand@Dml@@
.?AVDmlOperatorEyeLike@Dml@@
.?AVDmlOperatorGatedRecurrentUnit@Dml@@
.?AVDmlOperatorGather@Dml@@
.?AVDmlOperatorGemm@Dml@@
.?AVDmlOperatorInstanceNormalization@Dml@@
.?AVDmlOperatorLocalResponseNormalization@Dml@@
.?AVDmlOperatorLongShortTermUnit@Dml@@
.?AVDmlOperatorLpNormalization@Dml@@
.?AVDmlOperatorMatMul@Dml@@
.?AVDmlOperatorMaxUnpool@Dml@@
.?AVDmlOperatorMeanVarNormalization@Dml@@
.?AVDmlOperatorMemcpy@Dml@@
.?AVDmlOperatorNeg@Dml@@
.?AVDmlOperatorOneHot@Dml@@
.?AVDmlOperatorPadding@Dml@@
.?AVDmlOperatorPooling@Dml@@
.?AVDmlOperatorRecurrentBase@Dml@@
.?AVDmlOperatorRecurrentNeuralNetwork@Dml@@
.?AVDmlOperatorReduce@Dml@@
.?AVDmlOperatorRegionOfInterestPooling@Dml@@
.?AVDmlOperatorResize@Dml@@
.?AVDmlOperatorScatter@Dml@@
.?AVDmlOperatorSlice@Dml@@
.?AVDmlOperatorSpaceToDepth@Dml@@
.?AVDmlOperatorSplit@Dml@@
.?AVDmlOperatorTile@Dml@@
.?AVDmlOperatorTopK@Dml@@
.?AVDmlOperatorTranspose@Dml@@
.?AVDmlOperatorValueScale2d@Dml@@
.?AVDontUseNewUseMake@Details@WRL@Microsoft@@
.?AVDummyArena@onnxruntime@@
.?AVEliminateDropout@onnxruntime@@
.?AVEliminateIdentity@onnxruntime@@
.?AVEliminateSlice@onnxruntime@@
.?AVEnv@onnxruntime@@
.?AVEnvTime@onnxruntime@@
.?AVerror_category@std@@
.?AVexception@std@@
.?AVExecutionFrame@onnxruntime@@
.?AVExecutionOrder@Compilation@MLGraph@@
.?AVExecutionPlanBase@onnxruntime@@
.?AVExecutionProvider@Dml@@
.?AVExecutionProviderImpl@Dml@@
.?AVExLibLoader@onnxruntime@@
.?AVExpandDims@contrib@onnxruntime@@
.?AVExpandHelper@OperatorHelper@@
.?AVEyeLike@onnxruntime@@
.?AVfacet@locale@std@@
.?AVfailure@ios_base@std@@
.?AVFatalException@protobuf@google@@
.?AVFeatureVectorizer@ml@onnxruntime@@
.?AVFileInputStream@io@protobuf@google@@
.?AVFlatten@onnxruntime@@
.?AVFunction@onnxruntime@@
.?AVFunctionImpl@onnxruntime@@
.?AVFunctionKernel@onnxruntime@@
.?AVFunctionProto@onnx@@
.?AVFusedGraphKernel@Dml@@
.?AVfuture_error@std@@
.?AVGather@onnxruntime@@
.?AVGatherBase@onnxruntime@@
.?AVGatherHelper@OperatorHelper@@
.?AVGatherND@contrib@onnxruntime@@
.?AVGatherNDBase@contrib@onnxruntime@@
.?AVGemmActivationFusion@onnxruntime@@
.?AVGemmHelper@OperatorHelper@@
.?AVGraph@onnxruntime@@
.?AVGraphEdgeNodeImpl@MLGraph@@
.?AVGraphInferencer@onnx@@
.?AVGraphInferencerImpl@onnxruntime@@
.?AVGraphInferencerImpl@shape_inference@onnx@@
.?AVGraphProto@onnx@@
.?AVGraphTransformer@Dml@@
.?AVGraphTransformer@onnxruntime@@
.?AVIAllocator@onnxruntime@@
.?AVIArenaAllocator@onnxruntime@@
.?AVICommandRecorder@Dml@@
.?AVIDataTransfer@onnxruntime@@
.?AVIDeviceAllocator@onnxruntime@@
.?AVIExecutionFrame@onnxruntime@@
.?AVIExecutionProvider@onnxruntime@@
.?AVIExecutor@onnxruntime@@
.?AVIf@onnxruntime@@
.?AVImputerOp@ml@onnxruntime@@
.?AVInferenceContextImpl@onnxruntime@@
.?AVInferenceError@onnx@@
.?AVInferenceSession@onnxruntime@@
.?AVInitializeLayout@Compilation@MLGraph@@
.?AVInsertCastTransformer@onnxruntime@@
.?AVinvalid_argument@std@@
.?AVIOnnxRuntimeOpSchemaCollection@onnxruntime@@
.?AVIOpaqueOperator@MLGraph@@
.?AVIOperatorCompilationContext@MLGraph@@
.?AVIOperatorContext@MLGraph@@
.?AVIOperatorLayoutContext@MLGraph@@
.?AVios_base@std@@
.?AVIPass@MLGraph@@
.?AVISchemaRegistry@onnx@@
.?AVISequentialPlannerContext@onnxruntime@@
.?AVIsInf@onnxruntime@@
.?AVITensorAllocator@onnxruntime@@
.?AVLabelEncoder@ml@onnxruntime@@
.?AVLayoutAssignment@Compilation@MLGraph@@
.?AVlength_error@std@@
.?AVLiveness@Compilation@MLGraph@@
.?AVlogic_error@std@@
.?AVLoop@onnxruntime@@
.?AVMatMulAddFusion@onnxruntime@@
.?AVMaxpoolWithMask@contrib@onnxruntime@@
.?AVMaxUnpool@onnxruntime@@
.?AVMemcpyTransformer@onnxruntime@@
.?AVMessageLite@protobuf@google@@
.?AVMLOperatorKernelFactory@@
.?AVMLOperatorShapeInferrer@@
.?AVMod@onnxruntime@@
.?AVModelProto@onnx@@
.?AVMultinomial@onnxruntime@@
.?AVMurmurHash3@contrib@onnxruntime@@
.?AVNodeConnection@MLGraph@@
.?AVNodeEdgeInputConnection@MLGraph@@
.?AVNodeEdgeOutputConnection@MLGraph@@
.?AVNodeImpl@MLGraph@@
.?AVNodeProto@onnx@@
.?AVNonMaxSuppression@onnxruntime@@
.?AVNonTensorTypeBase@onnxruntime@@
.?AVNoOpRemoval@Compilation@MLGraph@@
.?AVNormalizer@ml@onnxruntime@@
.?AVNot@onnxruntime@@
.?AVNotImplementedException@onnxruntime@@
.?AVNumCapturesWalker@re2@@
.?AVOneHotHelper@OperatorHelper@@
.?AVOnnxRuntimeException@onnxruntime@@
.?AVOnnxRuntimeOpSchemaRegistry@onnxruntime@@
.?AVOpaqueOperationDesc@MLGraph@@
.?AVOperationDesc@MLGraph@@
.?AVOperationNodeImpl@MLGraph@@
.?AVOperatorContext@MLGraph@@
.?AVOperatorSetIdProto@onnx@@
.?AVOpKernel@onnxruntime@@
.?AVOpKernelContext@onnxruntime@@
.?AVOpKernelContextInternal@onnxruntime@@
.?AVOpSchemaRegistry@onnx@@
.?AVOptimizerExecutionFrame@onnxruntime@@
.?AVOr@onnxruntime@@
.?AVout_of_range@std@@
.?AVPadBase@onnxruntime@@
.?AVPaddingHelper@OperatorHelper@@
.?AVParallelExecutor@onnxruntime@@
.?AVPoolBase@onnxruntime@@
.?AVPoolingHelperBase@OperatorHelper@@
.?AVQLinearConv@onnxruntime@@
.?AVRandomNormal@onnxruntime@@
.?AVRandomNormalLike@onnxruntime@@
.?AVRandomUniform@onnxruntime@@
.?AVRandomUniformLike@onnxruntime@@
.?AVRange@contrib@onnxruntime@@
.?AVrange_error@std@@
.?AVRecurrentHelper@OperatorHelper@@
.?AVReduceHelperBase@OperatorHelper@@
.?AVRemoveDuplicateCastTransformer@onnxruntime@@
.?AVRepetitionWalker@re2@@
.?AVReshape@onnxruntime@@
.?AVReshape_1@onnxruntime@@
.?AVResizeHelper@OperatorHelper@@
.?AVResultException@wil@@
.?AVReverseSequenceOp@onnxruntime@@
.?AVRewriteRule@onnxruntime@@
.?AVRoiPoolingHelper@OperatorHelper@@
.?AVRuleBasedGraphTransformer@onnxruntime@@
.?AVruntime_error@std@@
.?AVRuntimeClassBase@Details@WRL@Microsoft@@
.?AVScatter@onnxruntime@@
.?AVSchemaError@onnx@@
.?AVSchemaRegistryManager@onnxruntime@@
.?AVSequentialExecutor@onnxruntime@@
.?AVSequentialPlannerContext@onnxruntime@@
.?AVShape@onnxruntime@@
.?AVShrink@onnxruntime@@
.?AVSign@onnxruntime@@
.?AVSimpleTensorAllocator@onnxruntime@@
.?AVSimplifyWalker@re2@@
.?AVSize@onnxruntime@@
.?AVSliceBase@onnxruntime@@
.?AVSliceHelper@OperatorHelper@@
.?AVSpaceDepthBase@onnxruntime@@
.?AVSpaceToDepthHelper@OperatorHelper@@
.?AVSplit@onnxruntime@@
.?AVSplitBase@onnxruntime@@
.?AVSplitHelper@OperatorHelper@@
.?AVSplitNodeImpl@MLGraph@@
.?AVSqueeze@onnxruntime@@
.?AVSqueezeBase@onnxruntime@@
.?AVstl_condition_variable_interface@details@Concurrency@@
.?AVstl_condition_variable_win7@details@Concurrency@@
.?AVstl_critical_section_interface@details@Concurrency@@
.?AVstl_critical_section_win7@details@Concurrency@@
.?AVStringNormalizer@onnxruntime@@
.?AVStringOutputStream@io@protobuf@google@@
.?AVStringStringEntryProto@onnx@@
.?AVsystem_error@std@@
.?AVTensorAlignment@Compilation@MLGraph@@
.?AVTensorAllocationAssignment@Compilation@MLGraph@@
.?AVTensorAllocatorWithMemPattern@onnxruntime@@
.?AVTensorAnnotation@onnx@@
.?AVTensorAssignment@Compilation@MLGraph@@
.?AVTensorConstness@Compilation@MLGraph@@
.?AVTensorProto@onnx@@
.?AVTensorProto_Segment@onnx@@
.?AVTensorShapeProto@onnx@@
.?AVTensorShapeProto_Dimension@onnx@@
.?AVTensorTypeBase@onnxruntime@@
.?AVTfIdfVectorizer@onnxruntime@@
.?AVTileHelper@OperatorHelper@@
.?AVTokenizer@contrib@onnxruntime@@
.?AVTopKHelper@OperatorHelper@@
.?AVToStringWalker@re2@@
.?AVTranspose@onnxruntime@@
.?AVTransposeBase@onnxruntime@@
.?AVTransposeHelper@OperatorHelper@@
.?AVtype_info@@
.?AVTypeProto@onnx@@
.?AVTypeProto_Map@onnx@@
.?AVTypeProto_Opaque@onnx@@
.?AVTypeProto_Sequence@onnx@@
.?AVTypeProto_SparseTensor@onnx@@
.?AVTypeProto_Tensor@onnx@@
.?AVUnpoolingHelper@OperatorHelper@@
.?AVUnsqueeze@onnxruntime@@
.?AVUnsqueezeBase@onnxruntime@@
.?AVUnsqueezeElimination@onnxruntime@@
.?AVUpsampleBase@onnxruntime@@
.?AVValidationError@checker@onnx@@
.?AVValueInfoProto@onnx@@
.?AVWindowsEnv@?A0x623e052b@onnxruntime@@
.?AVWindowsEnvTime@?A0x6c33eedb@onnxruntime@@
.?AVWordConvEmbedding@contrib@onnxruntime@@
.?AVXor@onnxruntime@@
.?AVZeroCopyInputStream@io@protobuf@google@@
.?AVZeroCopyOutputStream@io@protobuf@google@@
.?AVZipMapOp@ml@onnxruntime@@
.0/0#
.0/011
.00cfg
.CRT$XCA
.CRT$XCC
.CRT$XCL
.CRT$XCU
.CRT$XCZ
.CRT$XIA
.CRT$XIC
.CRT$XIZ
.CRT$XLA
.CRT$XLZ
.CRT$XPA
.CRT$XPZ
.CRT$XTA
.CRT$XTZ
.data
.data$r
.didat$2
.didat$3
.didat$4
.didat$5
.didat$6
.didat$7
.edata
.gfids
.giats
.H9F(H
.idata$2
.idata$3
.idata$4
.idata$5
.idata$6
.json
.P6A?AVStatus@common@onnxruntime@@AEBVNode@2@AEAVGraph@2@AEBV?$vector@PEBVTypeProto@onnx@@V?$allocator@PEBVTypeProto@onnx@@@std@@@std@@AEAV56@@Z
.P6AMMMM@Z
.P6APEAVOpKernel@onnxruntime@@AEBVOpKernelInfo@1@@Z
.P6AX$$QEAVOpSchema@onnx@@@Z
.P6AXAEAUInferenceContext@onnx@@@Z
.P6AXPEAX@Z
.pdata
.rdata
.rdata$r
.rdata$T
.rdata$zETW0
.rdata$zETW1
.rdata$zETW2
.rdata$zETW9
.rdata$zzzdbg
.rsrc
.rsrc$01
.rsrc$02
.rtc$IAA
.rtc$IZZ
.rtc$TAA
.rtc$TZZ
.stls
.text
.text$di
.text$mn
.text$mn$00
.text$x
.text$yd
.tls$
.tls$ZZZ
.xdata
.xdata$x
-/./.
/48vA
/D$`v
/t$Pv
: Conflicting with a registered kernel with op versions.
: failed validating the check: 
:\<&;
:ALu<H
:AM:am:PM:pm
:AMuEA
:Jan:January:Feb:February:Mar:March:Apr:April:May:May:Jun:June:Jul:July:Aug:August:Sep:September:Oct:October:Nov:November:Dec:December
:LEAFu
:Please, install necessary language-pack-XX and configure locales
:Sun:Sunday:Mon:Monday:Tue:Tuesday:Wed:Wednesday:Thu:Thursday:Fri:Friday:Sat:Saturday
;\$0r
;~,}&L
;D+A0D+
;E(|WA
;L$ H
;L9l$p
;w,~_
? @ T T 3
?\u8A
?I;~X
?L9d$x
?Windows::AI::MachineLearning::TensorBase<unsigned short,unsigned short,struct winrt::Windows::AI::MachineLearning::implementation::TensorUInt16Bit,struct winrt::Windows::AI::MachineLearning::ITensorUInt16Bit,struct winrt::Windows::AI::MachineLearning::implementation::TensorUInt16Bit_base<struct winrt::Windows::AI::MachineLearning::implementation::TensorUInt16Bit,struct ITensorNative,struct Windows::AI::MachineLearning::ILotusValueProviderPrivate> >::GetCpuResource
@ 9B t
@ E;E
@ H;A t?A
@ H;A tGA
@ H;H
@ H+A
@ I+@
@$A9A
@(A9A
@(Hct$(H
@(I+@ H
@(L9t$Xt
@,A9A
@.data
@.didat
@.reloc
@?fff?
@0A9A
@0H9V
@0I9U
@0L+@(I
@8{%@
@8{pt@H
@8|$ ttM+
@8|$(t
@8|$4t'A
@8|$Q
@8} u
@8}pt
@8=G`T
@83t6E3
@84;u
@88uJ@
@8H;A@u
@8I;@@
@8l$xt
@8qht3I
@8qPu
@8t$@t
@8t$@tPI
@8t$`t
@8t$1t7H
@8upt
@8u't
@8x8u
@A\_]
@A\_^[]
@A^_]
@A^_^
@A^_^[]
@A^_^][
@A__]
@A_A^]
@A_A^_
@A_A^_^[
@A_A^_^]
@A_A^A\
@A_A^A\_[
@A_A^A\_^
@A_A^A\_^[]
@A_A^A\_^][
@A_A^A]
@A_A^A]A\_^[
@A_A^A]A\_^]
@bq|H
@bq|I
@ffn@ffn@ffn@ffn@
@H;T$8
@L;l$@
@pI9@hu
@SUVATAUAVAWH
@SUVWATAUAVAWH
@SUVWATAVAWH
@SUVWAVH
@SUVWH
@SUWATAUAVAWH
@SVWATAUAVAWH
@SVWATAVAWH
@SVWAVAWH
@SVWAVH
@SVWH
@SWATAUAVAWH
@SWAVAWH
@UATAUAVAWH
@UAUAVH
@USVH
@USVWATAUAVAWH
@USVWATAUAVH
@USVWATAUAWH
@USVWATAVAWH
@USVWATAWH
@USVWAUAVAWH
@USVWAVAWH
@USVWAVH
@USVWAWH
@USVWH
@USWATAUAVAWH
@USWH
@UVWATAUAVAWH
@UVWAUAVH
@UVWAVAWH
@UVWH
@UWATH
@UWAUAVAWH
@UWAVH
@UWAWH
@VATAUAVAWH
@VWATAVAWH
@VWAVH
@WAVAWH
[%hs(%hs)]
[%hs]
[:^alnum:]
[:^alpha:]
[:^ascii:]
[:^blank:]
[:^cntrl:]
[:^digit:]
[:^graph:]
[:^lower:]
[:^print:]
[:^punct:]
[:^space:]
[:^upper:]
[:^word:]
[:^xdigit:]
[:alnum:]
[:alpha:]
[:ascii:]
[:blank:]
[:cntrl:]
[:digit:]
[:graph:]
[:lower:]
[:print:]
[:punct:]
[:space:]
[:upper:]
[:word:]
[:xdigit:]
[]^-\
[^\x00-\x{10ffff}]
[E9X,~
[E9XD~
[E9Xt~
[libprotobuf %s %s:%d] %s
[ONNXRuntimeError]
[ShapeInferenceError] 
[TypeInferenceError] 
\$ 8Y
\$ 8Y 
\$ 8Y(
\$ E3
\$ H;_8u
\$ H+
\$ H9Y
\$ HcR
\$ I+
\$ UH
\$ UVWATAUAVAWH
\$ UVWATAV
\$ UVWAVAW
\$ VWAVH
\$ WH
\$$E3
\$(@2
\$(H;
\$(H;_
\$(H+
\$(Hc
\$(Hi
\$(Hk
\$@;C0
\$@D;
\$@E3
\$@H;
\$@H+
\$@Hk
\$@I;
\$@L+
\$`E3
\$`H;
\$`I+
\$0;^ |
\$0A9>|
\$0E3
\$0H!\$0H
\$0H#
\$0H;
\$0H;\$X
\$0H;_@
\$0H+\$(H
\$0H9|$@t
\$0HcH
\$0I;
\$0I+
\$0L!L$(I
\$0L;
\$0L;]
\$0L;m
\$0L9l$8
\$0Lc
\$0Mi
\$8H;
\$8H+
\$8H+\$(
\$8H+\$0H
\$8H9W
\$8Hi
\$8I;
\$8L;
\$8L9l$0t
\$H9T$0u
\$HE3
\$hE3
\$HE3
\$hE3
\$HfD
\$HH;
\$hH+
\$HH+
\$hH+\$`H
\$hH9
\$HH9\$Pt
\$hHc
\$HHc
\$hI;
\$HL;
\$HL9|$Xt
\$HM;
\$PA8
\$PD;w
\$pE3
\$PE3
\$pE3
\$PH;
\$pH;
\$pH+
\$PH+
\$pH+
\$PH+
\$PHcG(H
\$PHk
\$PI;
\$pI;
\$PI;
\$pI;
\$pJ9,
\$PLc
\$pM;
\$PM;
\$x;~
\$XA9\$8
\$xD9,
\$XE;}8H
\$XE;e 
\$XE3
\$xH;
\$XH;
\$xH;]
\$xH+
\$xH9\$h
\$XHc
\$xI;
\$XI;
\$xI;]`
\$XL;
\$xL;
\$XL;
\$XL+
\$XL9
\$XL9l$8t
\$xM;
\$XM;
\<:ut
\3JCy7
\H`l3
\Windows::AI::MachineLearning::TensorMemoryBufferReference<unsigned int>::Capacity
\x%02x
\x{%x}
] != number of classlabels[
] (usually, this means you 
] HcE
] should not be greater than specified axis dim value [
](H9;u_H
], while 
]|pIX
]E9XD~
]hueH
]oH;]
]XfE9}
]XL;]
^ ;C 
^$;^,}7
^|*W?
^8I+^0H
^HcB@H
^uaH;
^uSH;
_(H9^@~E
_@H9^@
___lc_codepage_func
___lc_collate_cp_func
___lc_locale_name_func
___mb_cur_max_func
__acrt_iob_func
__AdjustPointer
__C_specific_handler
__current_exception
__CxxFrameHandler3
__pctype_func
__processing_throw
__RTtypeid
__std_exception_copy
__std_exception_destroy
__std_terminate
__std_type_info_compare
__std_type_info_destroy_list
__std_type_info_name
__stdio_common_vfprintf
__stdio_common_vsnprintf_s
__stdio_common_vsprintf
__stdio_common_vsprintf_s
__stdio_common_vswprintf
__strncnt
__uncaught_exception
_aligned_free
_aligned_malloc
_beginthreadex
_callnewh
_calloc_base
_cexit
_close
_configure_narrow_argv
_create_locale
_crt_atexit
_CxxThrowException
_difftime64
_DmlExecutionProvider_
_dtest
_errno
_execute_onexit_table
_fdtest
_fence_after
_fence_before
_free_base
_free_locale
_fseeki64
_fsopen
_get_errno
_get_stream_buffer_pointers
_Getdays
_Getmonths
_Gettnames
_gmtime64_s
_initialize_narrow_environment
_initialize_onexit_table
_initterm
_initterm_e
_invalid_parameter_noinfo
_invalid_parameter_noinfo_noreturn
_kernel_time
_localtime64_s
_lock_file
_lock_locales
_malloc_base
_McFTL
_mktime64
_purecall
_read
_realloc_base
_register_onexit_function
_RuleBasedTransformer
_seh_filter_dll
_set_errno
_sopen_s
_Strftime
_stricmp
_strtoi64
_towlower_l
_towupper_l
_unlock_file
_unlock_locales
_Unused
_W_Getdays
_W_Getmonths
_W_Gettnames
_wcsdup
_Wcsftime
_wcsicmp
_wfsopen
_wsopen_s
` AUAVAWH
` L+`
` UAVAWH
`.rdata
`A^_]
`A^_^
`A^_^[]
`A^_^][
`A^A\_^]
`A_A^_^[
`A_A^_^]
`A_A^A\_^
`A_A^A\_^[]
`A_A^A\_^][
`A_A^A]_^[]
`A_A^A]A\_^[
`A_A^A]A\_^]
`c` - cell gate
`f(x) = x for x >= 0`., is applied to the data tensor elementwise.
`f` - forget gate
`H;A u
`H;F8t_
`h` - hidden gate
`H` - Hidden state
`i` - input gate
`num_directions` - 2 if direction == bidirectional else 1
`o` - output gate
`P[iof]`  - P peephole weight vector for input, output, and forget gates
`PB[iof]`  - P peephole weight vector for backward input, output, and forget gates
`R[iofc]` - R recurrence weight matrix for input, output, forget, and cell gates
`R[zrh]` - R recurrence weight matrix for update, reset, and hidden gates
`r` - reset gate
`Rb[iofc]` - R bias vectors for input, output, forget, and cell gates
`RB[iofc]` - R recurrence weight matrix for backward input, output, forget, and cell gates
`Rb[zrh]` - R bias vectors for update, reset, and hidden gates
`RB[zrh]` - R recurrence weight matrix for backward update, reset, and hidden gates
`RBb[iofc]` - R bias vectors for backward input, output, forget, and cell gates
`RBb[zrh]` - R bias vectors for backward update, reset, and hidden gates
`RBbi` - RR bias vectors for backward input gate
`Rbi` - R parameter bias vector for input gate
`RBi` - R recurrence weight matrix for backward input gate
`Ri` - R recurrence weight matrix for input gate
`t` - time step (t-1 means previous time step)
`W[iofc]` - W parameter weight matrix for input, output, forget, and cell gates
`W[zrh]` - W parameter weight matrix for update, reset, and hidden gates
`Wb[iofc]` - W bias vectors for input, output, forget, and cell gates
`WB[iofc]` - W parameter weight matrix for backward input, output, forget, and cell gates
`Wb[zrh]` - W bias vectors for update, reset, and hidden gates
`WB[zrh]` - W parameter weight matrix for backward update, reset, and hidden gates
`WBb[iofc]` - W bias vectors for backward input, output, forget, and cell gates
`WBb[zrh]` - W bias vectors for backward update, reset, and hidden gates
`WBbi` - WR bias vectors for backward input gate
`Wbi` - W parameter bias vector for input gate
`WBi` - W parameter weight matrix for backward input gate
`Wi` - W parameter weight matrix for input gate
`X` - input tensor
`z` - update gate
{ @8z t
{ AVH
{"cat" : "
{%d,%d}
{%d,}
{(fD9f
{additionalDescription}
{broadcast_doc}
{description}
{filter_desc}
{name}
{op_type}
{opName}
{P@8zPt
|$ @8y
|$ 9{(t
|$ 9y0tV
|$ AVH
|$ E;
|$ E3
|$ H;
|$ J9<
|$ M;
|$ UATAUAVAWH
|$ UAVAWH
|$(A^
|$(E3
|$(H;
|$(H+
|$(I+
|$(K9<
|$@8X
|$@A_A^A]A\
|$@A8G8
|$@A9]
|$@E3
|$@fA
|$@H;
|$@H;t$P
|$@H+
|$@H9
|$@H9M
|$@H9u
|$@HcD$ H
|$@I;
|$@L;
|$@L+
|$@L9
|$@M+
|$`E3
|$`H;
|$`H9\$@t
|$`H9|$0upI
|$`H9|$h
|$`I;
|$`t6I
|$|;~
|$<H+
|$=I+
|$0A_A^
|$0D;
|$0E3
|$0H;
|$0H9|$h
|$0Hi
|$0IcFhH
|$0L98tUf
|$0M;
|$4D8d$<tEH
|$4D8d$2u
|$8A_A^A\
|$8D8|$0tNH
|$8E3
|$8fA
|$8H;
|$8H;\$h
|$8Hi
|$8I;
|$8I+
|$8Ic
|$8L;
|$8L;7
|$8Li
|$hA8
|$hE3
|$HH#
|$hH;
|$HH+
|$hH+
|$HH+|$8H
|$HH9|$Pt
|$hI+
|$hL;
|$HL;
|$PA;
|$PD!|$`H
|$pD;}
|$PE3
|$PH;
|$pH;
|$PH;
|$PHcBhH
|$pI;
|$PI;
|$pI;
|$PI;
|$PIc
|$PIkP
|$PL;
|$pL;
|$PL;
|$PL;M
|$pL9}
|$PM+
|$pM9<$t
|$tD;}
|$xA;
|$XD9,>u
|$XE3
|$XE9,>u
|$XH;
|$xH;
|$XH;
|$xH;
|$XH;}
|$XH+
|$xL;
|$XL;
|$xLcL$TM
|$XO;4
|H(L"
|HcK(H
|mISink must be provided.
|u"L;
} H92u
}, actural: 
}, Got: 
}, input shape = {
}. Actual:
}. Got: 
}?HcG
}@H9U
}@HcP
}`L;eX
}8D9:uQH
}8L;m
}8McP,
}g@8{Xtp@8{pup
}gH9T$@t
}GHcA I;
}hH+u
}hL+}`I
}HM9uh
}PD;}X
}RHcG
}XHcuPI
~(H;~0tGA
~*L!D$ L!D$(
~3a*~3a*~3a*~3a*
~4fD9$W
~fD9}
~HL9k
~L$0fH
~LcJ@L;L$xt
~PHc3D
~wHc,
~winrt::Windows::AI::MachineLearning::implementation::LearningModelDevice::RegisterKernels
~XH+~PH
+/+E+F+M+s+v+
++<>||~~
++Q5@.
++Q5@.Q5@.Q5@.Q5@.
+>7:Z
+9Zt~
+C,;C0}
+F Hc
+G Hc
+G@Lc
+v$x+v$xv$+xv+$xv$+x+$vx+$vx$v+x+$vx$+vx+v $+v $v $+v +$v $++$ v+$ v$ v++$ v$+ v+xv$+ v$v$ +v+ $v$ ++x$v+ $v$v ++ $v$ +v
<$D8O
<$I9|
<$I9<
<%ucL
<%ufL
</assembly>
<:u,H
<:u0H
<:wBH
<:wsH
<:wuH
<?xml version='1.0' encoding='UTF-8' standalone='yes'?>
<}wRI
<}wTI
<2?~>
<assembly xmlns='urn:schemas-microsoft-com:asm.v1' manifestVersion='1.0'>
<QuiI
<RueH
<xu}H
<xuG@
<ZuwH
=;F$u
=;Flu
=;FTu
==> Context: 
=4?~?
=t4A+
>3B>Windows::AI::MachineLearning::TensorMemoryBufferReference<class std::basic_string<char,struct std::char_traits<char>,class std::allocator<char> > >::Capacity
>bA|I
>HiL$ x
>The stream failed to parse.
0 == center_point_box_ || 1 == center_point_box_
0 == memory_size % kMinAllocationSize
0 0 06070>0?0
0 00070<0?0
0!0)080:0
0!0)080;0
0< t6<$t,<+t"<vt
0<0<0A0
0=0=0
00000
00000=0=0
01050;0;0
01050;0<0A0
0123456789-
0123456789-+Ee
0123456789ABCDEFabcdef-+Xx
0123456789ABCDEFabcdef-+XxPp
0123456789abcdefghijklmnopqrstuvwxyz
040904E4
09AFafAZ
09AZ__az!~
09AZ__az09az
09AZaz
0A^_^
0A^_^[]
0A^_^][
0A_A^_
0A_A^_^]
0A_A^A\
0A_A^A\_^
0A_A^A\_^][
0A_A^A]
0A_A^A]_]
0A_A^A]A\^
0A_A^A]A\_
0A_A^A]A\_^[
0A_A^A]A\_^]
0-g-o-p-
0H;t$@u
0HcL$ H
0L9&t
0tmfE
1 == capability->nodes.size()
1 2)2H2O2Q2_2
1 2_2
1 for the first maximum value, and 0 for all others
1.0.200713-1013.1.vb.07142e1
1/111
1A9p 
1D input tensor
1-D input tensor
1D int64 tensor of the same length as input's dimension number, includes numbers of repeated copies along input's dimensions.
1D output tensor
1-D tensor of axes that `starts` and `ends` apply to.
1-D tensor of ending indices (exclusive) of corresponding axis in `axes`
1-D tensor of ending indices (exclusive) of corresponding axis in axes
1-D tensor of floats
1-D tensor of shape (num_rois,) with each element denoting the index of the corresponding image in the batch.
1-D tensor of slice step of corresponding axis in `axes`. Default to 1. 
1-D tensor of starting indices of corresponding axis in `axes`
1-D Tensor of the range.
1D tensor. The shape of the expected output tensor. If empty tensor is given, the output would be a scalar.
2*2G2P2P2`2
2`2~2`
2333333
2D input tensor to copy shape, and optionally, type information from.
2IcG H
32-bit hash value.
3333333
3D9x(t
4$I94
4-D tensor after resizing, [N,C,H,W]
4-D tensor, [N,C,H,W]
4H9u@t
4I9>t/H
5!8!0-g-
6bA|H
6JCy7JCy7JCy7JCy7
7/ER}
78|As
78l3fC
7H;>tg
'7JCy7
8*u,H
8,u5H
8\$ u
8\$0t
8\$0u
8\$1u
8\$pt
8\$qt
8\$rt
8]tmH
8^u3H
8_^[]
8_^][
89:u6
8A^_^[
8A_A^_^[]
8A_A^_^][
8A_A^A]A\_^[]
8A_A^A]A\_^][
8ai.ou"f
8D$pt
8D$pu
8D1yu
8giP9giP9giP9giP9
8H9|$ 
8H9|$(
8H9|$@
8H9|$`
8H9|$0
8H9|$8
8H9|$H
8H9|$P
8H9|$X
8L$0u
8Loopu<I
8NONEu
8Q tHH
8Qpt_8Q
8SOFTu
8-u!E
8-uCH
8-uGH
8-uuH
8V(tb3
8Z8tzH
8ZuFH
9;~'D
9\$0viD
9^(~/
9_ v%Hc
9{(~4H
9+~ 3
9=?{4
9=Bw4
9=C~4
9=Jm4
9=-o4
9=qr4
90ut@8{8tnL
91~,3
99~1E3
9A(t!
9C |j
9C }'L
9C$|_I
9C(uRI
9C@u5H
9CDuGA
9CHu>A
9E ugH
9H },
9H@u5H
9HDuE
9HHu=
9I9x 
9kLvqMc
9MPtmH
9p ~2
9Q ~!LcA H
9s(~SE3
9T$ s1
9X(u*H
9z ~b
a != nullptr && b != nullptr
A + (M * lda - (lda - K)) <= A_end
A' = transpose(A) if transA else A
A 1-D input tensor that is to be processed.
A 1-D INT64 tensor containing the the count of each element of 'uniques' in the input 'x'
A 1-D INT64 tensor of the same size as 'x' containing the indices for each value in 'x' in the output 'uniques'
A 1-D tensor containing a single positive value corresponding to the number of top elements to retrieve
A 1-D tensor holding values from the input dictionary.
A 1-D tensor indicates the shape you want to expand to, following the broadcast rule
A 1-D tensor of the same type as 'x' containing all the unique values in 'x' sorted in the same order that they occur in the input 'x'
A 1-D values of (height, width).
A 1-D values of (leftBorder, topBorder, rightBorder, bottomBorder).
A 2D tensor with the contents of the input tensor, with input dimensions up to axis flattened to the outer dimension of the output and remaining input dimensions flattened into the inner dimension of the output.
A 9B 
A boolean termination condition. Optional. Pass empty string to skip.
A collection of intercepts.
A collection of weights of the model(s).
A D8B t:H
A dictionary.
A dimension cannot be less than -1.
A dso with name 
a filter
A float.
A H+A
A H9t$@t
A I+A
A L+A
A L9`
A list of 2 (or 4 if bidirectional) activation functions for update, reset, and hidden gates. The activation functions must be one of the activation functions specified above. Optional: See the equations for default if not specified.
A list of 3 (or 6 if bidirectional) activation functions for input, output, forget, cell, and hidden. The activation functions must be one of the activation functions specified above. Optional: See the equations for default if not specified.
A list of floats.
A list of integers, along which to reduce. The default is to caculate along axes [0,2,3] for calculating mean and variance along each channel. Two variables with the same C-coordinate are associated with the same mean and variance.
A list of integers, along which to reduce. The default is to reduce over all the dimensions of the input tensor.
A list of integers. By default, reverse the dimensions, otherwise permute the axes according to the values given.
A list of ints.
A list of labels.
A list of strings. One and only one of 'keys_*'s should be set.
A list of strings. One and only one of 'value_*'s should be set.
A maximum trip-count for the loop specified at runtime. Optional. Pass empty string to skip.
A protocol message was rejected because it was too big (more than 
A shape tensor must be a vector tensor.
A string indicating the desired element type of the output tensor, one of 'TO_FLOAT', 'TO_STRING', 'TO_INT64'.
A string to use when an input integer value is not found in the map.<br>One and only one of the 'default_*' attributes must be defined.
A string vocabulary array.<br>One and only one of the vocabularies must be defined.
A string.
A tensor of rank >= axis.
A tensor representing the same data as the input map, ordered by their keys
A tensor that concats all the intermediate output values of the hidden. It has shape `[seq_length, num_directions, batch_size, hidden_size]`
A tensor that concats all the intermediate output values of the hidden. It has shape `[seq_length, num_directions, batch_size, hidden_size]`. 
A tensor that concats all the intermediate output values of the hidden. It has shape `[seq_length, num_directions, batch_size, hidden_size]`. It is optional if `output_sequence` is 0.
A value that needs replacing.
A$A9B
A(A9B
A(A9F
A(H;A0t
A(H90
A(L9(
A(L98
A(LcI A
A,A9B
A,A9F
A;@(u
A;@,u
A;@0t
A;_ |
A;~ |
A;EHs
A;P }
A;q }5
A;t$ 
A;u\|
A;V ~
A@L9IHt
A]A\]
A^_^[]
A^_^][
A^A\]
A^A\_
A^A\_^]
A^A]]
A^A]_^]
A^A]A\_]
A^A]A\_^
A^A]A\_^[]
A__^[]
A_A\]
A_A\_^[]
A_A\_^]
A_A]]
A_A]A\_]
A_A]A\_^
A_A]A\_^[]
A_A^]
A_A^_
A_A^_[
A_A^_^[
A_A^_^[]
A_A^_^]
A_A^A\
A_A^A\_]
A_A^A\_^
A_A^A\_^[
A_A^A\_^[]
A_A^A\_^][
A_A^A]
A_A^A]_]
A_A^A]_^
A_A^A]_^[]
A_A^A]A\]
A_A^A]A\^[]
A_A^A]A\_
A_A^A]A\_[
A_A^A]A\_[]
A_A^A]A\_^[
A_A^A]A\_^[]
A_A^A]A\_^]
A_A^A]A\_^][
a_scale
a_zero_point
a_zero_point->Shape().NumDimensions() == 0 || (a_zero_point->Shape().NumDimensions() == 1 && a_zero_point->Shape().GetDims().size() == 1)
A`H+AXH
A`H9Ah
A|U@ 
A+H$A+H
A+H,A+H
A+V I
A0;A(
A0A9F
A0H+A(H
A4XH 
A8_pt
A8~ H
A8~ L
A8+A0
A8A+A0;
A8D8B8t4L
A8H;A@
A8H+A0H
A8I+A0H
A9@$|
A9@$}aM
A9@(u
A9@,u
A9\$ 
A9^ u
A9_ ~
A9A |
A9A(u
A9A,u
A9A0t
A9ETu=H
A9H(u
A9H,u
A9L$ 
A9NTuLL
A9NTuWL
A9q }@I
A9u\~0E3
A9vTu
A9wTu
A9y0t
abort
acosf
Acosh
acoshf
AcquireSRWLockExclusive
AcquireSRWLockShared
across_channels
activatibleClassId
activation
Activation functions:
activation_alpha
activation_beta
activation_func_names.size() == static_cast<size_t>(num_directions_) * 2
activation_func_names.size() == static_cast<size_t>(num_directions_) * 3
ActivationDescCount
ActivationDescs
activations
activations_.size() == static_cast<size_t>(num_directions)
adapterLuidHighPart
adapterLuidLowPart
add the enum type to the switch statement
AddFoldedRange recurses too much.
Adding default CPU execution provider.
addition
address family not supported
address in use
address not available
Adlam
affine
Affine
aggregate_function
AhH;A`}[
AHH+A@H
AHLcI@A
AhLcI`A
ai.of
ai.onnx
ai.onnx.ml
All implicit inputs should have OrtValue instances by now. 
All inputs and outputs must have the same data type.
All inputs must have the same shape
All inputs to Concat must have same rank
All Tensor types
Allocated memory at 
allocation failure
Allocation of tensor types requires a shape.
allocator != nullptr
allocator_ptr_ != nullptr
Allowed values are 1 and 2. Current level is set to 
allowed_activations.find(activations_[direction]) != allowed_activations.end()
allowed_directions.find(direction_) != allowed_directions.end()
alpha
Alpha
alpha_ > 0.0f
already connected
AMDiuA
An attribute specifying the number of scan_inputs M. 
An axis tensor must be a scalar tensor.
An input tensor to hash.
An input tensor with shape [num_batches, num_classes, spatial_dimension]
An input tensor with shape [num_batches, spatial_dimension, 4]. The single box data format is indicated by center_point_box.
An input tensor.
An integer to use when an input string value is not found in the map.<br>One and only one of the 'default_*' attributes must be defined.
An integer vocabulary array.<br>One and only one of the vocabularies must be defined.
An integer.
An optional list of K flags, one for each scan_output. The i-th element of the list specifies whether the i-th scan_output should be constructed by appending or prepending a new value in each iteration: 0 indicates appending and 1 indicates prepending. If omitted, all scan_output tensors will be produced by appending a value in each iteration.
An optional list of K flags. The i-th element of the list specifies the axis for the i-th scan_output. The scan outputs are accumulated along the specified axis. If omitted, 0 will be used as the scan axis for every scan_output.
An optional list of M flags. The i-th element of the list specifies the axis to be scanned (the sequence axis) for the i-th scan_input. If omitted, 0 will be used as the scan axis for every scan_input.
An optional list of M flags. The i-th element of the list specifies the direction to be scanned for the i-th scan_input tensor: 0 indicates forward direction and 1 indicates reverse direction. If omitted, all scan_input tensors will be scanned in the forward direction.
an optional list of strings attribute that contains a list of separators - regular expressions to match separators Two consecutive segments in X connected by a separator would be divided into two tokens. For example, if the input is "Hello World!" and this attribute contains only one space character, the corresponding output would be ["Hello", "World!"]. To achieve character-level tokenization, one should set the 'separators' to [""], which contains an empty string.
An optional string. Token's regular expression in basic POSIX format (http://pubs.opengroup.org/onlinepubs/9699919799/basedefs/V1_chap09.html#tag_09_03). If set, tokenizer may produce tokens matching the specified pattern. Note that one and only of 'tokenexp' and 'separators' should be set.
An ordered collection of tensors, all with the same element type.
Anatolian_Hieroglyphs
and computes the output.
and contains the {name} values of the corresponding input.
and output tensor Y has shape (M, N). A will be transposed before doing the
APD8BP
ApH9Ah
APHc8I+
api-ms-win-core-com-l1-1-0.dll
api-ms-win-core-com-l1-1-1.dll
api-ms-win-core-debug-l1-1-0.dll
api-ms-win-core-errorhandling-l1-1-0.dll
api-ms-win-core-file-l1-1-0.dll
api-ms-win-core-handle-l1-1-0.dll
api-ms-win-core-heap-l1-1-0.dll
api-ms-win-core-interlocked-l1-1-0.dll
api-ms-win-core-libraryloader-l1-2-0.dll
api-ms-win-core-libraryloader-l1-2-1.dll
api-ms-win-core-localization-l1-2-0.dll
api-ms-win-core-memory-l1-1-0.dll
api-ms-win-core-processthreads-l1-1-0.dll
api-ms-win-core-processthreads-l1-1-1.dll
api-ms-win-core-profile-l1-1-0.dll
api-ms-win-core-psapi-l1-1-0.dll
api-ms-win-core-rtlsupport-l1-1-0.dll
api-ms-win-core-string-l1-1-0.dll
api-ms-win-core-synch-l1-1-0.dll
api-ms-win-core-synch-l1-2-0.dll
api-ms-win-core-sysinfo-l1-1-0.dll
api-ms-win-core-sysinfo-l1-2-0.dll
api-ms-win-core-threadpool-l1-2-0.dll
api-ms-win-core-util-l1-1-0.dll
api-ms-win-core-winrt-error-l1-1-0.dll
api-ms-win-core-winrt-error-l1-1-1.dll
api-ms-win-core-winrt-l1-1-0.dll
api-ms-win-core-winrt-string-l1-1-0.dll
api-ms-win-crt-convert-l1-1-0.dll
api-ms-win-crt-filesystem-l1-1-0.dll
api-ms-win-crt-heap-l1-1-0.dll
api-ms-win-crt-locale-l1-1-0.dll
api-ms-win-crt-math-l1-1-0.dll
api-ms-win-crt-private-l1-1-0.dll
api-ms-win-crt-runtime-l1-1-0.dll
api-ms-win-crt-stdio-l1-1-0.dll
api-ms-win-crt-string-l1-1-0.dll
api-ms-win-crt-time-l1-1-0.dll
api-ms-win-eventing-provider-l1-1-0.dll
AQ5@.
Arabic
Arbitrary input
Arbitrary output
Arbitrated channel order
Arbitrated channel order reason
arg_num < arg_counts.size()
ArgMax
ArgMin
argument list too long
Argument mismatch when removing edge.
argument out of domain
Argument size (%d) exceeds the tensor size (%d).
Argument size (%u) exceeds the tensor size (%u).
Argument type mismatch when adding edge.
Armenian
Array of sequence lengths.  len(seq_lengths) should equal batch size N.
ArrayFeatureExtractor
as possible.
asinf
Asinh
asinhf
ASMc{
At least one output should be requested.
At most one dimension can be -1.
atanf
Atanh
atanhf
ATAVAWH
ATensor
Attempt to retrieve final output before it was set.
Attempt to use DefaultLogger but none has been registered.
Attempting to broadcast an axis by a dimension other than 1. 
Attempting to get an input that does not exist.
Attempting to get an output that does not exist.
Attention layer weight shape error! Expected: {
Attention mechanism memory sequence lengths must have shape {
Attention mechanism memory sequence lengths value must in (0, 
Attention mechanism memory shape error! Expected: {
Attention memory layer weight shape error! Expected:{
Attention query layer weight shape error! Expected:{
Attention v weight shape error! Expected:{
Attibute name and type don't match
AttnLSTM
Attribute 
Attribute '
Attribute (name: 
Attribute `broadcast=1` needs to be passed to enable broadcasting.
Attribute axes has incorrect length
Attribute axes is not set.
Attribute blocksize is not set.
Attribute border needs to be specified with four border elements, got 
attribute case_change_action has invalid value
attribute case_change_action is not set
Attribute dilations has incorrect size
Attribute expected to have a one-dim tensor
Attribute expected to have tensor type
attribute is_case_sensitive is not set
Attribute kernel_shape has incorrect size
Attribute kernel_shape has incorrect size.
Attribute kernel_shape must be specified
Attribute kernel_shape must be specified.
attribute mark is not set
attribute mincharnum is not set
attribute mincharnum must have a positive value
attribute pad_value is not set
Attribute pads has incorrect length
Attribute pads has incorrect size
Attribute pads has incorrect size.
Attribute perm of Transpose has an invalid value. Value 
Attribute pooled_shape has incorrect length
Attribute pooled_shape must be specified
Attribute shape is not set.
Attribute specification type mismatch.
Attribute strides has incorrect size
Attribute strides has incorrect size.
Attribute to is not set.
Attribute value for pads is required
Attribute 'value' of Constant node must exist with 'Tensor' data.
attributeCount
AUAVAWH
author
Authu
auto_pad
auto_pad must be either NOTSET, SAME_UPPER, SAME_LOWER or VALID. Where default value is NOTSET, which means explicit padding is used. SAME_UPPER or SAME_LOWER mean pad the input so that the output size match the input.In case of odd number add the extra padding at the end for SAME_UPPER and at the beginning for SAME_LOWER. VALID mean no padding.
auto_pad must be either NOTSET, SAME_UPPER, SAME_LOWER or VALID. Where default value is NOTSET, which means explicit padding is used. SAME_UPPER or SAME_LOWER mean pad the input so that the output size match the input.In case of odd number add the extra padding at the end for SAME_UPPER and at the beginning for SAME_LOWER. VALID mean no padding. DEPRECATION NOTE: auto_pad is only intended to support legacy uses, and for framework authors, one is explicitly encouraged to use explicit padding specified in the pads attribute.
auto_padH
AVERAGE
average
AveragePool
Avestan
avgCpuUsage
avgPageFaultCount
avgTime
avgWorkingSetMemory
'axes' has a duplicate axis
'axes' has an axis outside of the tensor dimension count
'axes' has an out of range axis
'axes' has duplicates
Axes that `starts` and `ends` apply to. It's optional. If not present, will be treated as [0, 1, ..., len(`starts`) - 1].
axes_right_stride >= 0 && static_cast<uint64_t>(axes_right_stride) < std::numeric_limits<size_t>::max()
axes3
axesD
axis 
axis <= X_NumDims && axis >= -X_NumDims
axis == 1 || axis == largest
axis >= -tensor_rank && axis <= tensor_rank - 1
Axis along which to repeat.
'axis' attribute must have a value in the range [
axis greater than input data dimension!
Axis has less than the requested k elements.
axis must be in [-r, r-1]
'axis' must be in [-rank(indices)-1, rank(indices)]
Axis must be within range [
axis_ < static_cast<int64_t>(rank)
axis_tensor->Shape().IsScalar()
AxisCount
B + (N * ldb - (ldb - K)) <= B_end
B' = transpose(B) if transB else B
B 9A t
B H+B
B H9_
B H9A 
B$A9C
B(I9B@u
B@H+B8H
b_scale
b_zero_point
b_zero_point->Shape().NumDimensions() == 0 || (b_zero_point->Shape().NumDimensions() == 1 && b_zero_point->Shape().GetDims().size() == 1)
B`H+BXH
B`H9BX
B|$8H
b},4C
b}.<C
B09G t
B84+u
B8H+B0H
B8H+B0L;
B8H9B0t
BA;F$u
ba|H(
BackUp() can only be called after a successful Next().
bad address
bad allocation
Bad arg in kInstAltMatch: 
Bad arg in kInstCapture: 
Bad args: nsubmatch=
bad array new length
Bad call to ParseState::ParsePerlFlags
bad cast
bad conversion
bad exception
bad file descriptor
Bad final char: 
bad function call
Bad hex digit 
bad locale name
bad message
Bad node spec: 
Bad optional access
Bad reference count 
bad repetition operator
bad variant access
bad_weak_ptr
Balinese
Bamum
Base values for classification, added to final class score; the size must be the same as the classes or can be left unassigned (assumed 0)
base_values
base_values_.empty() || base_values_.size() == static_cast<size_t>(class_count_) || base_values_.size() == weights_classes_.size()
base_values_.empty() || base_values_.size() == static_cast<size_t>(n_targets_)
Bassa_Vah
Batak
batch_axis
batch_axis != time_axis
batch_axis < 2
batch_indices
batch_indices shape input tensor has wrong dimension
batch_size is < 1
BatchNormalization
BatchNormalization kernel for CPU provider does not support non-spatial cases
BatchNormalizationAddFusion
BatchNormalizationMulFusion
Begin execution
Bengali
beta_ > 0.0f
bfloat16H
Bgra8
Bhaiksuki
BHH+B@H
Bias applied to each channel, same size as C.
Bias size (
Bias tensor of shape (C).
BiasTensor
bidirectional
BILINEAR
bilinear
Binarized output data
Binarizer
Binding
BinForSize(bin_size * 2 - 1) == BinFromIndex(b)
BinForSize(bin_size * 2) != BinFromIndex(b)
BinForSize(bin_size + 255) == BinFromIndex(b)
BinForSize(bin_size) == BinFromIndex(b)
BinFromIndex(c->bin_num)->free_chunks.erase(h) > 0
BitmapBounds
BitmapBounds must reference a property value with type UInt32Array with 4 elements.
BitmapPixelFormat
bitmappixelformat
BitmapPixelFormat must be either Rgba8, Bgra8, or Gray8
BL$ H
Blocks of [blocksize, blocksize] are moved.
blocksize
BlockSize
Blocksize must be positive
body@
bodyD
Bool to determine if hidden state is zeroes or passed along for timesteps past the given sequence_length.
Boolean
boolean
Boolean whether to mark the beginning/end character with start of text character (0x02)/end of text character (0x03).
Boolean. Whether the identification of stop words in X is case-sensitive. Default is false
Bopomofo
border
both data and indices tensor need to have rank larger than zero.
boxes
boxes and scores should have same num_batches.
boxes and scores should have same spatial_dimention.
boxes must be a 3D tensor.
BPI+BHH
BQhI+
Brahmi
Braille
BRANCH_EH9
BRANCH_EQ
BRANCH_GI
BRANCH_GT
BRANCH_GTE
BRANCH_LEQ
BRANCH_LI
BRANCH_LT
broadcast
broken pipe
broken promise
Bt$(H
BTensor
buffer
buffers_.find(mem_patterns_->locations[i]) == buffers_.end()
Buginese
Buhid
bumped the operator version but 
BxH+BpH
ByhI+
Byte size calculation and serialization were inconsistent.  This may indicate a bug in protocol buffers or it may be caused by concurrent modification of 
bytemap range 
C + (M * ldc - (ldc - N)) <= C_end
C H;p
C H+C
C HcL
C L+C
C(D9t
C(H9C 
C)#3r
C:\apilot\agent\_work\2\s\dml/Common/ApiHelpers.h
C:\apilot\agent\_work\2\s\dml/Common/GeneratedSchemaHelpers.h
C:\apilot\agent\_work\2\s\engine/OperatorAuthorHelper/MLOperatorAuthorHelper.h
C:\apilot\agent\_work\2\s\engine/OperatorAuthorHelper/OperatorHelper.h
C:\apilot\agent\_work\2\s\engine/OperatorAuthorHelper/SchemaInferenceOverrider.h
C:\apilot\agent\_work\2\s\engine\DmlExecutionProvider\src\BucketizedBufferAllocator.cpp
C:\apilot\agent\_work\2\s\engine\DmlExecutionProvider\src\CommandAllocatorRing.h
C:\apilot\agent\_work\2\s\engine\DmlExecutionProvider\src\CommandQueue.cpp
C:\apilot\agent\_work\2\s\engine\DmlExecutionProvider\src\DescriptorPool.cpp
C:\apilot\agent\_work\2\s\engine\DmlExecutionProvider\src\DmlCommandRecorder.cpp
C:\apilot\agent\_work\2\s\engine\DmlExecutionProvider\src\DmlCommon.cpp
C:\apilot\agent\_work\2\s\engine\DmlExecutionProvider\src\ExecutionContext.cpp
C:\apilot\agent\_work\2\s\engine\DmlExecutionProvider\src\ExecutionPlanBuilder.cpp
C:\apilot\agent\_work\2\s\engine\DmlExecutionProvider\src\ExecutionProvider.cpp
C:\apilot\agent\_work\2\s\engine\DmlExecutionProvider\src\FusedGraphKernel.cpp
C:\apilot\agent\_work\2\s\engine\DmlExecutionProvider\src\GpuEvent.h
C:\apilot\agent\_work\2\s\engine\DmlExecutionProvider\src\GraphTransformer.cpp
C:\apilot\agent\_work\2\s\engine\DmlExecutionProvider\src\Operators\DmlOperator.cpp
C:\apilot\agent\_work\2\s\engine\DmlExecutionProvider\src\Operators\DmlOperatorActivation.cpp
C:\apilot\agent\_work\2\s\engine\DmlExecutionProvider\src\Operators\DmlOperatorAffine.cpp
C:\apilot\agent\_work\2\s\engine\DmlExecutionProvider\src\Operators\DmlOperatorBatchNormalization.cpp
C:\apilot\agent\_work\2\s\engine\DmlExecutionProvider\src\Operators\DmlOperatorCast.cpp
C:\apilot\agent\_work\2\s\engine\DmlExecutionProvider\src\Operators\DmlOperatorConcat.cpp
C:\apilot\agent\_work\2\s\engine\DmlExecutionProvider\src\Operators\DmlOperatorConstantOfShape.cpp
C:\apilot\agent\_work\2\s\engine\DmlExecutionProvider\src\Operators\DmlOperatorConvolution.cpp
C:\apilot\agent\_work\2\s\engine\DmlExecutionProvider\src\Operators\DmlOperatorCopy.cpp
C:\apilot\agent\_work\2\s\engine\DmlExecutionProvider\src\Operators\DmlOperatorCrop.cpp
C:\apilot\agent\_work\2\s\engine\DmlExecutionProvider\src\Operators\DmlOperatorDepthToSpace.cpp
C:\apilot\agent\_work\2\s\engine\DmlExecutionProvider\src\Operators\DmlOperatorElementWise.cpp
C:\apilot\agent\_work\2\s\engine\DmlExecutionProvider\src\Operators\DmlOperatorExpand.cpp
C:\apilot\agent\_work\2\s\engine\DmlExecutionProvider\src\Operators\DmlOperatorEyeLike.cpp
C:\apilot\agent\_work\2\s\engine\DmlExecutionProvider\src\Operators\DmlOperatorGather.cpp
C:\apilot\agent\_work\2\s\engine\DmlExecutionProvider\src\Operators\DmlOperatorGemm.cpp
C:\apilot\agent\_work\2\s\engine\DmlExecutionProvider\src\Operators\DmlOperatorInstanceNormalization.cpp
C:\apilot\agent\_work\2\s\engine\DmlExecutionProvider\src\Operators\DmlOperatorLocalResponseNormalization.cpp
C:\apilot\agent\_work\2\s\engine\DmlExecutionProvider\src\Operators\DmlOperatorLpNormalization.cpp
C:\apilot\agent\_work\2\s\engine\DmlExecutionProvider\src\Operators\DmlOperatorMatMul.cpp
C:\apilot\agent\_work\2\s\engine\DmlExecutionProvider\src\Operators\DmlOperatorMeanVarianceNormalization.cpp
C:\apilot\agent\_work\2\s\engine\DmlExecutionProvider\src\Operators\DmlOperatorMemcpy.cpp
C:\apilot\agent\_work\2\s\engine\DmlExecutionProvider\src\Operators\DmlOperatorNeg.cpp
C:\apilot\agent\_work\2\s\engine\DmlExecutionProvider\src\Operators\DmlOperatorOneHot.cpp
C:\apilot\agent\_work\2\s\engine\DmlExecutionProvider\src\Operators\DmlOperatorPadding.cpp
C:\apilot\agent\_work\2\s\engine\DmlExecutionProvider\src\Operators\DmlOperatorPooling.cpp
C:\apilot\agent\_work\2\s\engine\DmlExecutionProvider\src\Operators\DmlOperatorRecurrentNeuralNetwork.cpp
C:\apilot\agent\_work\2\s\engine\DmlExecutionProvider\src\Operators\DmlOperatorReduce.cpp
C:\apilot\agent\_work\2\s\engine\DmlExecutionProvider\src\Operators\DmlOperatorResize.cpp
C:\apilot\agent\_work\2\s\engine\DmlExecutionProvider\src\Operators\DmlOperatorRoiPooling.cpp
C:\apilot\agent\_work\2\s\engine\DmlExecutionProvider\src\Operators\DmlOperatorScatter.cpp
C:\apilot\agent\_work\2\s\engine\DmlExecutionProvider\src\Operators\DmlOperatorSlice.cpp
C:\apilot\agent\_work\2\s\engine\DmlExecutionProvider\src\Operators\DmlOperatorSpaceToDepth.cpp
C:\apilot\agent\_work\2\s\engine\DmlExecutionProvider\src\Operators\DmlOperatorSplit.cpp
C:\apilot\agent\_work\2\s\engine\DmlExecutionProvider\src\Operators\DmlOperatorTile.cpp
C:\apilot\agent\_work\2\s\engine\DmlExecutionProvider\src\Operators\DmlOperatorTopk.cpp
C:\apilot\agent\_work\2\s\engine\DmlExecutionProvider\src\Operators\DmlOperatorTranspose.cpp
C:\apilot\agent\_work\2\s\engine\DmlExecutionProvider\src\Operators\DmlOperatorValueScale2D.cpp
C:\apilot\agent\_work\2\s\engine\DmlExecutionProvider\src\Operators\OperatorRegistration.cpp
C:\apilot\agent\_work\2\s\engine\DmlExecutionProvider\src\Operators\OperatorUtility.cpp
C:\apilot\agent\_work\2\s\engine\DmlExecutionProvider\src\PooledUploadHeap.cpp
C:\apilot\agent\_work\2\s\engine\DmlExecutionProvider\src\ReadbackHeap.cpp
C:\apilot\agent\_work\2\s\engine\DmlExecutionProvider\src\TensorDesc.cpp
C:\apilot\agent\_work\2\s\engine\lotus\cmake\external\onnx\onnx\defs\controlflow\defs.cc
C:\apilot\agent\_work\2\s\engine\lotus\cmake\external\onnx\onnx\defs\controlflow\old.cc
C:\apilot\agent\_work\2\s\engine\lotus\cmake\external\onnx\onnx\defs\generator\defs.cc
C:\apilot\agent\_work\2\s\engine\lotus\cmake\external\onnx\onnx\defs\generator\old.cc
C:\apilot\agent\_work\2\s\engine\lotus\cmake\external\onnx\onnx\defs\logical\defs.cc
C:\apilot\agent\_work\2\s\engine\lotus\cmake\external\onnx\onnx\defs\logical\old.cc
C:\apilot\agent\_work\2\s\engine\lotus\cmake\external\onnx\onnx\defs\math\defs.cc
C:\apilot\agent\_work\2\s\engine\lotus\cmake\external\onnx\onnx\defs\math\old.cc
C:\apilot\agent\_work\2\s\engine\lotus\cmake\external\onnx\onnx\defs\nn\defs.cc
C:\apilot\agent\_work\2\s\engine\lotus\cmake\external\onnx\onnx\defs\nn\old.cc
C:\apilot\agent\_work\2\s\engine\lotus\cmake\external\onnx\onnx\defs\object_detection\defs.cc
C:\apilot\agent\_work\2\s\engine\lotus\cmake\external\onnx\onnx\defs\quantization\defs.cc
C:\apilot\agent\_work\2\s\engine\lotus\cmake\external\onnx\onnx\defs\reduction\defs.cc
C:\apilot\agent\_work\2\s\engine\lotus\cmake\external\onnx\onnx\defs\rnn\defs.cc
C:\apilot\agent\_work\2\s\engine\lotus\cmake\external\onnx\onnx\defs\rnn\old.cc
C:\apilot\agent\_work\2\s\engine\lotus\cmake\external\onnx\onnx\defs\tensor\defs.cc
C:\apilot\agent\_work\2\s\engine\lotus\cmake\external\onnx\onnx\defs\tensor\old.cc
C:\apilot\agent\_work\2\s\engine\lotus\cmake\external\onnx\onnx\defs\traditionalml\defs.cc
C:\apilot\agent\_work\2\s\engine\lotus\cmake\external\onnx\onnx\defs\traditionalml\old.cc
C:\apilot\agent\_work\2\s\engine\lotus\cmake\external\protobuf\src\google\protobuf\arena.cc
C:\apilot\agent\_work\2\s\engine\lotus\cmake\external\protobuf\src\google\protobuf\generated_message_util.cc
C:\apilot\agent\_work\2\s\engine\lotus\cmake\external\protobuf\src\google\protobuf\io\coded_stream.cc
C:\apilot\agent\_work\2\s\engine\lotus\cmake\external\protobuf\src\google\protobuf\io\zero_copy_stream.cc
C:\apilot\agent\_work\2\s\engine\lotus\cmake\external\protobuf\src\google\protobuf\io\zero_copy_stream_impl_lite.cc
C:\apilot\agent\_work\2\s\engine\lotus\cmake\external\protobuf\src\google\protobuf\message_lite.cc
C:\apilot\agent\_work\2\s\engine\lotus\cmake\external\protobuf\src\google\protobuf\repeated_field.cc
C:\apilot\agent\_work\2\s\engine\lotus\cmake\external\protobuf\src\google\protobuf\wire_format_lite.cc
C:\apilot\agent\_work\2\s\engine\lotus\cmake\external\re2\re2/walker-inl.h
C:\apilot\agent\_work\2\s\engine\lotus\cmake\external\re2\re2\bitstate.cc
C:\apilot\agent\_work\2\s\engine\lotus\cmake\external\re2\re2\compile.cc
C:\apilot\agent\_work\2\s\engine\lotus\cmake\external\re2\re2\dfa.cc
C:\apilot\agent\_work\2\s\engine\lotus\cmake\external\re2\re2\nfa.cc
C:\apilot\agent\_work\2\s\engine\lotus\cmake\external\re2\re2\onepass.cc
C:\apilot\agent\_work\2\s\engine\lotus\cmake\external\re2\re2\parse.cc
C:\apilot\agent\_work\2\s\engine\lotus\cmake\external\re2\re2\prog.cc
C:\apilot\agent\_work\2\s\engine\lotus\cmake\external\re2\re2\re2.cc
C:\apilot\agent\_work\2\s\engine\lotus\cmake\external\re2\re2\regexp.cc
C:\apilot\agent\_work\2\s\engine\lotus\cmake\external\re2\re2\simplify.cc
C:\apilot\agent\_work\2\s\engine\lotus\cmake\external\re2\re2\tostring.cc
C:\apilot\agent\_work\2\s\engine\lotus\include\onnxruntime\core/common/const_pointer_container.h
C:\apilot\agent\_work\2\s\engine\lotus\include\onnxruntime\core/framework/data_types.h
C:\apilot\agent\_work\2\s\engine\lotus\include\onnxruntime\core/framework/ml_value.h
C:\apilot\agent\_work\2\s\engine\lotus\include\onnxruntime\core/framework/op_kernel.h
C:\apilot\agent\_work\2\s\engine\lotus\include\onnxruntime\core/framework/tensor.h
C:\apilot\agent\_work\2\s\engine\lotus\include\onnxruntime\core/graph/graph.h
C:\apilot\agent\_work\2\s\engine\lotus\onnxruntime\contrib_ops\cpu\attnlstm\bahdanau_attention.cc
C:\apilot\agent\_work\2\s\engine\lotus\onnxruntime\contrib_ops\cpu\attnlstm\deep_cpu_attn_lstm.cc
C:\apilot\agent\_work\2\s\engine\lotus\onnxruntime\contrib_ops\cpu\attnlstm\deep_cpu_attn_lstm.h
C:\apilot\agent\_work\2\s\engine\lotus\onnxruntime\contrib_ops\cpu\element_wise_exp_ops.h
C:\apilot\agent\_work\2\s\engine\lotus\onnxruntime\contrib_ops\cpu\expand_dims.h
C:\apilot\agent\_work\2\s\engine\lotus\onnxruntime\contrib_ops\cpu\gather_nd.cc
C:\apilot\agent\_work\2\s\engine\lotus\onnxruntime\contrib_ops\cpu\image_scaler.h
C:\apilot\agent\_work\2\s\engine\lotus\onnxruntime\contrib_ops\cpu\maxpool_with_mask.h
C:\apilot\agent\_work\2\s\engine\lotus\onnxruntime\contrib_ops\cpu\murmur_hash3.cc
C:\apilot\agent\_work\2\s\engine\lotus\onnxruntime\contrib_ops\cpu\pad.cc
C:\apilot\agent\_work\2\s\engine\lotus\onnxruntime\contrib_ops\cpu\tokenizer.cc
C:\apilot\agent\_work\2\s\engine\lotus\onnxruntime\core/framework/bfc_arena.h
C:\apilot\agent\_work\2\s\engine\lotus\onnxruntime\core/framework/execution_frame.h
C:\apilot\agent\_work\2\s\engine\lotus\onnxruntime\core/framework/execution_providers.h
C:\apilot\agent\_work\2\s\engine\lotus\onnxruntime\core/framework/func_kernel.h
C:\apilot\agent\_work\2\s\engine\lotus\onnxruntime\core/framework/node_index_info.h
C:\apilot\agent\_work\2\s\engine\lotus\onnxruntime\core/framework/ort_value_tensor_slicer.h
C:\apilot\agent\_work\2\s\engine\lotus\onnxruntime\core/optimizer/initializer.h
C:\apilot\agent\_work\2\s\engine\lotus\onnxruntime\core/providers/common.h
C:\apilot\agent\_work\2\s\engine\lotus\onnxruntime\core/providers/cpu/controlflow/if.h
C:\apilot\agent\_work\2\s\engine\lotus\onnxruntime\core/providers/cpu/controlflow/loop.h
C:\apilot\agent\_work\2\s\engine\lotus\onnxruntime\core/providers/cpu/controlflow/scan_utils.h
C:\apilot\agent\_work\2\s\engine\lotus\onnxruntime\core/providers/cpu/generator/random.h
C:\apilot\agent\_work\2\s\engine\lotus\onnxruntime\core/providers/cpu/math/clip.h
C:\apilot\agent\_work\2\s\engine\lotus\onnxruntime\core/providers/cpu/math/element_wise_ops.h
C:\apilot\agent\_work\2\s\engine\lotus\onnxruntime\core/providers/cpu/math/gemm.h
C:\apilot\agent\_work\2\s\engine\lotus\onnxruntime\core/providers/cpu/math/matmul_helper.h
C:\apilot\agent\_work\2\s\engine\lotus\onnxruntime\core/providers/cpu/ml/cast_map.h
C:\apilot\agent\_work\2\s\engine\lotus\onnxruntime\core/providers/cpu/ml/category_mapper.h
C:\apilot\agent\_work\2\s\engine\lotus\onnxruntime\core/providers/cpu/ml/dictvectorizer.h
C:\apilot\agent\_work\2\s\engine\lotus\onnxruntime\core/providers/cpu/ml/feature_vectorizer.h
C:\apilot\agent\_work\2\s\engine\lotus\onnxruntime\core/providers/cpu/ml/label_encoder.h
C:\apilot\agent\_work\2\s\engine\lotus\onnxruntime\core/providers/cpu/ml/ml_common.h
C:\apilot\agent\_work\2\s\engine\lotus\onnxruntime\core/providers/cpu/ml/normalizer.h
C:\apilot\agent\_work\2\s\engine\lotus\onnxruntime\core/providers/cpu/ml/svmclassifier.h
C:\apilot\agent\_work\2\s\engine\lotus\onnxruntime\core/providers/cpu/nn/autopad_type.h
C:\apilot\agent\_work\2\s\engine\lotus\onnxruntime\core/providers/cpu/nn/batch_norm.h
C:\apilot\agent\_work\2\s\engine\lotus\onnxruntime\core/providers/cpu/nn/conv_base.h
C:\apilot\agent\_work\2\s\engine\lotus\onnxruntime\core/providers/cpu/nn/flatten.h
C:\apilot\agent\_work\2\s\engine\lotus\onnxruntime\core/providers/cpu/nn/instance_norm.h
C:\apilot\agent\_work\2\s\engine\lotus\onnxruntime\core/providers/cpu/nn/lp_norm.h
C:\apilot\agent\_work\2\s\engine\lotus\onnxruntime\core/providers/cpu/nn/lrn.h
C:\apilot\agent\_work\2\s\engine\lotus\onnxruntime\core/providers/cpu/nn/pool_base.h
C:\apilot\agent\_work\2\s\engine\lotus\onnxruntime\core/providers/cpu/nn/roi_pool.h
C:\apilot\agent\_work\2\s\engine\lotus\onnxruntime\core/providers/cpu/nn/shrink.h
C:\apilot\agent\_work\2\s\engine\lotus\onnxruntime\core/providers/cpu/nn/unpool.h
C:\apilot\agent\_work\2\s\engine\lotus\onnxruntime\core/providers/cpu/reduction/reduction_ops.h
C:\apilot\agent\_work\2\s\engine\lotus\onnxruntime\core/providers/cpu/rnn/deep_cpu_gru.h
C:\apilot\agent\_work\2\s\engine\lotus\onnxruntime\core/providers/cpu/rnn/deep_cpu_lstm.h
C:\apilot\agent\_work\2\s\engine\lotus\onnxruntime\core/providers/cpu/rnn/rnn.h
C:\apilot\agent\_work\2\s\engine\lotus\onnxruntime\core/providers/cpu/rnn/rnn_helpers.h
C:\apilot\agent\_work\2\s\engine\lotus\onnxruntime\core/providers/cpu/tensor/concat.h
C:\apilot\agent\_work\2\s\engine\lotus\onnxruntime\core/providers/cpu/tensor/gather.h
C:\apilot\agent\_work\2\s\engine\lotus\onnxruntime\core/providers/cpu/tensor/identity_op.h
C:\apilot\agent\_work\2\s\engine\lotus\onnxruntime\core/providers/cpu/tensor/mean_variance_normalization.h
C:\apilot\agent\_work\2\s\engine\lotus\onnxruntime\core/providers/cpu/tensor/pad.h
C:\apilot\agent\_work\2\s\engine\lotus\onnxruntime\core/providers/cpu/tensor/reshape.h
C:\apilot\agent\_work\2\s\engine\lotus\onnxruntime\core/providers/cpu/tensor/slice.h
C:\apilot\agent\_work\2\s\engine\lotus\onnxruntime\core/providers/cpu/tensor/space_depth_ops.h
C:\apilot\agent\_work\2\s\engine\lotus\onnxruntime\core/providers/cpu/tensor/split.h
C:\apilot\agent\_work\2\s\engine\lotus\onnxruntime\core/providers/cpu/tensor/squeeze.h
C:\apilot\agent\_work\2\s\engine\lotus\onnxruntime\core/providers/cpu/tensor/transpose.h
C:\apilot\agent\_work\2\s\engine\lotus\onnxruntime\core/providers/cpu/tensor/unsqueeze.h
C:\apilot\agent\_work\2\s\engine\lotus\onnxruntime\core/providers/cpu/tensor/upsample.h
C:\apilot\agent\_work\2\s\engine\lotus\onnxruntime\core/providers/cpu/tensor/utils.h
C:\apilot\agent\_work\2\s\engine\lotus\onnxruntime\core/util/math.h
C:\apilot\agent\_work\2\s\engine\lotus\onnxruntime\core\common\profiler.cc
C:\apilot\agent\_work\2\s\engine\lotus\onnxruntime\core\common\status.cc
C:\apilot\agent\_work\2\s\engine\lotus\onnxruntime\core\common\task_thread_pool.h
C:\apilot\agent\_work\2\s\engine\lotus\onnxruntime\core\framework\allocation_planner.cc
C:\apilot\agent\_work\2\s\engine\lotus\onnxruntime\core\framework\bfc_arena.cc
C:\apilot\agent\_work\2\s\engine\lotus\onnxruntime\core\framework\data_transfer.cc
C:\apilot\agent\_work\2\s\engine\lotus\onnxruntime\core\framework\data_types.cc
C:\apilot\agent\_work\2\s\engine\lotus\onnxruntime\core\framework\environment.cc
C:\apilot\agent\_work\2\s\engine\lotus\onnxruntime\core\framework\ex_lib_loader.cc
C:\apilot\agent\_work\2\s\engine\lotus\onnxruntime\core\framework\execution_frame.cc
C:\apilot\agent\_work\2\s\engine\lotus\onnxruntime\core\framework\execution_provider.cc
C:\apilot\agent\_work\2\s\engine\lotus\onnxruntime\core\framework\feeds_fetches_manager.cc
C:\apilot\agent\_work\2\s\engine\lotus\onnxruntime\core\framework\graph_partitioner.cc
C:\apilot\agent\_work\2\s\engine\lotus\onnxruntime\core\framework\kernel_registry.cc
C:\apilot\agent\_work\2\s\engine\lotus\onnxruntime\core\framework\mldata_type_utils.cc
C:\apilot\agent\_work\2\s\engine\lotus\onnxruntime\core\framework\mlvalue_tensor_slicer.cc
C:\apilot\agent\_work\2\s\engine\lotus\onnxruntime\core\framework\node_index_info.cc
C:\apilot\agent\_work\2\s\engine\lotus\onnxruntime\core\framework\op_kernel.cc
C:\apilot\agent\_work\2\s\engine\lotus\onnxruntime\core\framework\op_kernel_info.cc
C:\apilot\agent\_work\2\s\engine\lotus\onnxruntime\core\framework\op_node_proto_helper.cc
C:\apilot\agent\_work\2\s\engine\lotus\onnxruntime\core\framework\parallel_executor.cc
C:\apilot\agent\_work\2\s\engine\lotus\onnxruntime\core\framework\sequential_executor.cc
C:\apilot\agent\_work\2\s\engine\lotus\onnxruntime\core\framework\session_state.cc
C:\apilot\agent\_work\2\s\engine\lotus\onnxruntime\core\framework\session_state_initializer.cc
C:\apilot\agent\_work\2\s\engine\lotus\onnxruntime\core\framework\tensor.cc
C:\apilot\agent\_work\2\s\engine\lotus\onnxruntime\core\framework\tensor_shape.cc
C:\apilot\agent\_work\2\s\engine\lotus\onnxruntime\core\framework\utils.cc
C:\apilot\agent\_work\2\s\engine\lotus\onnxruntime\core\graph\contrib_ops\contrib_defs.cc
C:\apilot\agent\_work\2\s\engine\lotus\onnxruntime\core\graph\function.cc
C:\apilot\agent\_work\2\s\engine\lotus\onnxruntime\core\graph\graph.cc
C:\apilot\agent\_work\2\s\engine\lotus\onnxruntime\core\graph\graph_utils.cc
C:\apilot\agent\_work\2\s\engine\lotus\onnxruntime\core\optimizer\constant_folding.cc
C:\apilot\agent\_work\2\s\engine\lotus\onnxruntime\core\optimizer\graph_transformer_utils.cc
C:\apilot\agent\_work\2\s\engine\lotus\onnxruntime\core\optimizer\optimizer_execution_frame.cc
C:\apilot\agent\_work\2\s\engine\lotus\onnxruntime\core\optimizer\transformer_memcpy.cc
C:\apilot\agent\_work\2\s\engine\lotus\onnxruntime\core\platform\windows\env.cc
C:\apilot\agent\_work\2\s\engine\lotus\onnxruntime\core\providers\cpu\controlflow\if.cc
C:\apilot\agent\_work\2\s\engine\lotus\onnxruntime\core\providers\cpu\controlflow\loop.cc
C:\apilot\agent\_work\2\s\engine\lotus\onnxruntime\core\providers\cpu\controlflow\scan_8.cc
C:\apilot\agent\_work\2\s\engine\lotus\onnxruntime\core\providers\cpu\controlflow\scan_9.cc
C:\apilot\agent\_work\2\s\engine\lotus\onnxruntime\core\providers\cpu\controlflow\scan_utils.cc
C:\apilot\agent\_work\2\s\engine\lotus\onnxruntime\core\providers\cpu\generator\constant_of_shape.cc
C:\apilot\agent\_work\2\s\engine\lotus\onnxruntime\core\providers\cpu\generator\random.cc
C:\apilot\agent\_work\2\s\engine\lotus\onnxruntime\core\providers\cpu\math\element_wise_ops.cc
C:\apilot\agent\_work\2\s\engine\lotus\onnxruntime\core\providers\cpu\math\gemm_helper.h
C:\apilot\agent\_work\2\s\engine\lotus\onnxruntime\core\providers\cpu\math\matmul_integer.cc
C:\apilot\agent\_work\2\s\engine\lotus\onnxruntime\core\providers\cpu\math\quantize_linear_matmul.cc
C:\apilot\agent\_work\2\s\engine\lotus\onnxruntime\core\providers\cpu\math\top_k.cc
C:\apilot\agent\_work\2\s\engine\lotus\onnxruntime\core\providers\cpu\ml\cast_map.cc
C:\apilot\agent\_work\2\s\engine\lotus\onnxruntime\core\providers\cpu\ml\feature_vectorizer.cc
C:\apilot\agent\_work\2\s\engine\lotus\onnxruntime\core\providers\cpu\ml\imputer.cc
C:\apilot\agent\_work\2\s\engine\lotus\onnxruntime\core\providers\cpu\ml\linearclassifier.cc
C:\apilot\agent\_work\2\s\engine\lotus\onnxruntime\core\providers\cpu\ml\linearregressor.cc
C:\apilot\agent\_work\2\s\engine\lotus\onnxruntime\core\providers\cpu\ml\ml_common.h
C:\apilot\agent\_work\2\s\engine\lotus\onnxruntime\core\providers\cpu\ml\normalizer.cc
C:\apilot\agent\_work\2\s\engine\lotus\onnxruntime\core\providers\cpu\ml\onehotencoder.cc
C:\apilot\agent\_work\2\s\engine\lotus\onnxruntime\core\providers\cpu\ml\scaler.cc
C:\apilot\agent\_work\2\s\engine\lotus\onnxruntime\core\providers\cpu\ml\svmclassifier.cc
C:\apilot\agent\_work\2\s\engine\lotus\onnxruntime\core\providers\cpu\ml\svmclassifier.h
C:\apilot\agent\_work\2\s\engine\lotus\onnxruntime\core\providers\cpu\ml\svmregressor.cc
C:\apilot\agent\_work\2\s\engine\lotus\onnxruntime\core\providers\cpu\ml\tree_ensemble_classifier.cc
C:\apilot\agent\_work\2\s\engine\lotus\onnxruntime\core\providers\cpu\ml\treeregressor.cc
C:\apilot\agent\_work\2\s\engine\lotus\onnxruntime\core\providers\cpu\ml\zipmap.cc
C:\apilot\agent\_work\2\s\engine\lotus\onnxruntime\core\providers\cpu\nn\conv_transpose.cc
C:\apilot\agent\_work\2\s\engine\lotus\onnxruntime\core\providers\cpu\nn\lrn.cc
C:\apilot\agent\_work\2\s\engine\lotus\onnxruntime\core\providers\cpu\nn\pool.cc
C:\apilot\agent\_work\2\s\engine\lotus\onnxruntime\core\providers\cpu\nn\qlinearconv.cc
C:\apilot\agent\_work\2\s\engine\lotus\onnxruntime\core\providers\cpu\nn\roi_pool.cc
C:\apilot\agent\_work\2\s\engine\lotus\onnxruntime\core\providers\cpu\nn\shrink.cc
C:\apilot\agent\_work\2\s\engine\lotus\onnxruntime\core\providers\cpu\nn\string_normalizer.cc
C:\apilot\agent\_work\2\s\engine\lotus\onnxruntime\core\providers\cpu\nn\tfidfvectorizer.cc
C:\apilot\agent\_work\2\s\engine\lotus\onnxruntime\core\providers\cpu\nn\Unpool.cc
C:\apilot\agent\_work\2\s\engine\lotus\onnxruntime\core\providers\cpu\object_detection\non_max_suppression.cc
C:\apilot\agent\_work\2\s\engine\lotus\onnxruntime\core\providers\cpu\object_detection\non_max_suppression.h
C:\apilot\agent\_work\2\s\engine\lotus\onnxruntime\core\providers\cpu\object_detection\roialign.h
C:\apilot\agent\_work\2\s\engine\lotus\onnxruntime\core\providers\cpu\reduction\reduction_ops.cc
C:\apilot\agent\_work\2\s\engine\lotus\onnxruntime\core\providers\cpu\rnn\deep_cpu_gru.cc
C:\apilot\agent\_work\2\s\engine\lotus\onnxruntime\core\providers\cpu\rnn\deep_cpu_lstm.cc
C:\apilot\agent\_work\2\s\engine\lotus\onnxruntime\core\providers\cpu\rnn\rnn_helpers.cc
C:\apilot\agent\_work\2\s\engine\lotus\onnxruntime\core\providers\cpu\tensor\cast_op.cc
C:\apilot\agent\_work\2\s\engine\lotus\onnxruntime\core\providers\cpu\tensor\compress.cc
C:\apilot\agent\_work\2\s\engine\lotus\onnxruntime\core\providers\cpu\tensor\concat.cc
C:\apilot\agent\_work\2\s\engine\lotus\onnxruntime\core\providers\cpu\tensor\eye_like.cc
C:\apilot\agent\_work\2\s\engine\lotus\onnxruntime\core\providers\cpu\tensor\isinf.cc
C:\apilot\agent\_work\2\s\engine\lotus\onnxruntime\core\providers\cpu\tensor\nonzero_op.cc
C:\apilot\agent\_work\2\s\engine\lotus\onnxruntime\core\providers\cpu\tensor\pad.cc
C:\apilot\agent\_work\2\s\engine\lotus\onnxruntime\core\providers\cpu\tensor\quantize_linear.cc
C:\apilot\agent\_work\2\s\engine\lotus\onnxruntime\core\providers\cpu\tensor\reshape_helper.h
C:\apilot\agent\_work\2\s\engine\lotus\onnxruntime\core\providers\cpu\tensor\reverse_sequence.cc
C:\apilot\agent\_work\2\s\engine\lotus\onnxruntime\core\providers\cpu\tensor\reverse_sequence.h
C:\apilot\agent\_work\2\s\engine\lotus\onnxruntime\core\providers\cpu\tensor\scatter.cc
C:\apilot\agent\_work\2\s\engine\lotus\onnxruntime\core\providers\cpu\tensor\slice.cc
C:\apilot\agent\_work\2\s\engine\lotus\onnxruntime\core\providers\cpu\tensor\space_depth_ops.cc
C:\apilot\agent\_work\2\s\engine\lotus\onnxruntime\core\providers\cpu\tensor\split.cc
C:\apilot\agent\_work\2\s\engine\lotus\onnxruntime\core\providers\cpu\tensor\tile.cc
C:\apilot\agent\_work\2\s\engine\lotus\onnxruntime\core\providers\cpu\tensor\transpose.cc
C:\apilot\agent\_work\2\s\engine\lotus\onnxruntime\core\providers\cpu\tensor\unsqueeze.cc
C:\apilot\agent\_work\2\s\engine\lotus\onnxruntime\core\providers\cpu\tensor\upsample.cc
C:\apilot\agent\_work\2\s\engine\lotus\onnxruntime\core\providers\cpu\tensor\where_op.cc
C:\apilot\agent\_work\2\s\engine\lotus\onnxruntime\core\session\inference_session.cc
C:\apilot\agent\_work\2\s\engine\lotus\onnxruntime\core\util\protobuf_parsing_utils.cc
C:\apilot\agent\_work\2\s\engine\OperatorAuthorHelper\MLOperatorAuthorHelper.h
C:\apilot\agent\_work\2\s\engine\OperatorAuthorHelper\OperatorHelper.cpp
C:\apilot\agent\_work\2\s\engine\OperatorAuthorHelper\OperatorHelper.h
C:\apilot\agent\_work\2\s\graph\DML\GraphCompiler.cpp
C:\apilot\agent\_work\2\s\graph\DML\OpaqueOperationDesc.cpp
C:\apilot\agent\_work\2\s\packages\Microsoft.Windows.Wil.Internal.0.2.46\inc\wil\opensource/wil/wrl.h
C:\apilot\agent\_work\2\s\packages\Microsoft.Windows.Wil.Internal.0.2.46\inc\wil\opensource\wil\resource.h
C:\apilot\agent\_work\2\s\winml\common\DeviceHelpers.cpp
C:\apilot\agent\_work\2\s\winml\dll\D3DDeviceCache.cpp
C:\apilot\agent\_work\2\s\winml\dll\FeatureCompatibility.h
C:\apilot\agent\_work\2\s\winml\dll\ImageConversionHelpers.cpp
C:\apilot\agent\_work\2\s\winml\dll\ImageConverter.cpp
C:\apilot\agent\_work\2\s\winml\dll\ImageFeatureValue.cpp
C:\apilot\agent\_work\2\s\winml\dll\LearningModel.cpp
C:\apilot\agent\_work\2\s\winml\dll\LearningModelBinding.cpp
C:\apilot\agent\_work\2\s\winml\dll\LearningModelDevice.cpp
C:\apilot\agent\_work\2\s\winml\dll\LearningModelSession.cpp
C:\apilot\agent\_work\2\s\winml\dll\MapBase.h
C:\apilot\agent\_work\2\s\winml\dll\MLOperatorAuthorImpl.cpp
C:\apilot\agent\_work\2\s\winml\dll\MLOperatorAuthorImpl.h
C:\apilot\agent\_work\2\s\winml\dll\module.cpp
C:\apilot\agent\_work\2\s\winml\dll\SequenceBase.h
C:\apilot\agent\_work\2\s\winml\dll\TelemetryEvent.cpp
C:\apilot\agent\_work\2\s\winml\dll\TensorBase.h
C:\apilot\agent\_work\2\s\winml\dll\TensorBaseHelpers.h
C:\apilot\agent\_work\2\s\winml\dll\TensorBuffer.h
C:\apilot\agent\_work\2\s\winml\dll\TensorToVideoFrameConverter.cpp
C:\apilot\agent\_work\2\s\winml\dll\VideoFrameToTensorConverter.cpp
C:\apilot\agent\_work\2\s\winml\lib\Core\CpuOrtSessionBuilder.cpp
C:\apilot\agent\_work\2\s\winml\lib\Core\DmlOrtSessionBuilder.cpp
C:\apilot\agent\_work\2\s\winml\lib\Core\FeatureDescriptorFactory.cpp
C:\apilot\agent\_work\2\s\winml\lib\Core\ModelInfo.cpp
C:\apilot\agent\_work\2\s\winml\lib\Core\ZeroCopyInputStreamWrapper.cpp
C@H+C8H
C@LcK8I
C`H9CX
C++/WinRT version:2.0.190605.7
c->in_use() && (c->bin_num == kInvalidBinNum)
C0;C(
C0HcF
C0I;_pH
c2->prev == h1
C4;C8}
C49D$0
C8H;C@u
C8H+C0
C8H+C0H
C8H9C0t8
C8H9C0tA
CalculateNodeIndexInfo must be called prior to GetExecutionInfo.
callContext
CallContext:[%hs] 
calloc
cAMDt
Can not digest separators: 
Can not digest tokenexp: 
Can not find the execution provider 
Can not find the node 
Can not get shape initializer data!
Canadian_Aboriginal
Cannot allocate buffer larger than kint32max for 
Cannot concatenate scalars
Cannot creat GPU tensor on CPU device
cannot find allocator
Cannot slice scalars
Cannot split using values in 'split' attribute. Axis=
Cannot use SearchOnePass for unanchored matches.
Can't 
Can't merge shape info. Both source and target dimension have values but they differ. Source=
Can't slice a non-tensor OrtValue. Type was 
Can't use func with null ptr
Carian
Carries out batch normalization as described in the paper
Case not handled in ComputeSimple: 
case where axis=1, this means the input tensor will be coerced into a 2D tensor
case_change_action
cast node to cast from float16 to float32 on cpu
Cast op must have 'to' argument of type DataType
cast_to
CastD
CastDef_%d
CastFloat16Transformer
Casting to and from strings is not supported yet.
CastMap
Category
CategoryMapper
cats_int64s
cats_strings
Caucasian_Albanian
Caught exception while destructing CustomOpsLoader with message: 
Caught exception while loading custom ops with message: 
CD$HM
ceil_mode
ceilf
Cell clip threshold. Clipping bounds the elements of a tensor in the range of [-threshold, +threshold] and is applied to the input of activations. No clip if not specified.
CellMemInitTensor
CellMemoryMinusOneTensor
CellMemoryTensor
center_point_box
center_point_box only support 0 or 1
Chakma
Channel order changed for fused conversion
ChannelCount
Char embedding size does not match char_embedding_size attribute.
Char embedding size does not match conv kernal size 2.
char_embedding_size
CHECK failed: !coded_out.HadError(): 
CHECK failed: !is_closed_: 
CHECK failed: (backup_bytes_) == (0): 
CHECK failed: (buffer_size) >= (0): 
CHECK failed: (byte_size_before_serialization) == (byte_size_after_serialization): 
CHECK failed: (bytes_produced_by_serialization) == (byte_size_before_serialization): 
CHECK failed: (count) <= (buffer_used_): 
CHECK failed: (count) <= (last_returned_size_): 
CHECK failed: (count) <= (target_->size()): 
CHECK failed: (count) >= (0): 
CHECK failed: (last_returned_size_) > (0): 
CHECK failed: (min_bytes) <= (std::numeric_limits<size_t>::max() - kBlockHeaderSize): 
CHECK failed: (new_size) <= ((std::numeric_limits<size_t>::max() - kRepHeaderSize) / sizeof(old_rep->elements[0])): 
CHECK failed: (scc->visit_status.load(std::memory_order_relaxed)) == (SCCInfoBase::kRunning): 
CHECK failed: (value.size()) <= (kint32max): 
CHECK failed: backup_bytes_ == 0 && buffer_.get() != NULL: 
CHECK failed: target_ != NULL: 
checks.input_copy_needed != DeviceCopyCheck::Unknown && checks.output_copy_needed != DeviceCopyCheck::Unknown
checksum
Cherokee
Child node if expression is false
Child node if expression is false.
Child node if expression is true
Child node if expression is true.
Chosen support vectors
CL$(L
Class labels if using integer labels.<br>One and only one of the 'classlabels_*' attributes must be defined.
Class labels if using string labels.<br>One and only one of the 'classlabels_*' attributes must be defined.
Class labels when using integer labels. One and only one 'classlabels' attribute must be defined.
Class labels when using string labels. One and only one 'classlabels' attribute must be defined.
Class scores (one per class per example), if prob_a and prob_b are provided they are probabilities for each class, otherwise they are raw scores.
class_ids
class_nodeids
class_nodeids_.size() == class_ids_.size()
class_nodeids_.size() == class_weights_.size()
class_treeids
class_weights
classes_strings
Classification outputs (one class per example).
Classification scores ([N,E] - one score for each class and example
classlabels_int64s
classlabels_ints
classlabels_strings
classlabels_strings_.empty() ^ classlabels_int64s_.empty()
classlabels_strings_.size() > 0 || classlabels_ints_.size() > 0
clip@
clip_ > 0.f
clipD
ClipThreshold
close() failed: 
CloseHandle
CloseThreadpoolWork
CM'L+
CoalesceWalker::ShortVisit called
CoCreateFreeThreadedMarshaler
CoCreateGuid
code != static_cast<int>(MLStatus::OK)
Coefficient of ELU default to 1.0.
Coefficient of ELU.
Coefficient of leakage default to 0.01.
Coefficient of leakage.
Coefficient of SELU default to 1.0507.
Coefficient of SELU default to 1.05070102214813232421875 (i.e., float32 approximation of 1.0507009873554804934193349852946).
Coefficient of SELU default to 1.6732.
Coefficient of SELU default to 1.67326319217681884765625 (i.e., float32 approximation of 1.6732632423543772848170429916717).
coefficients
coefficients_.size() > 0
coerced into one. For an arbitrary n-dimensional tensor
CoIncrementMTAUsage
colorspacegamma
com.microsoft
Common
CompanyName
CompareStringEx
Compatible layouts
Compiler::Copy called!
complex128
Complex128
Complex64
complex64
Compress
computation if attribute transA is non-zero, same for B and transB.
Compute failed for node: 
Compute Y = alpha * A' * B' + beta * C, where input tensor A has shape (M, K) or (K, M),
Compute_
Computes an one-layer GRU. This operator is usually supported via some custom
Computes an one-layer LSTM. This operator is usually supported via some
Computes an one-layer simple RNN. This operator is usually supported
Computes the {name} of the input tensor's element along the provided axes. The resulted
Computes the indices of the {name} elements of the input tensor's element along the 
computes the output.
Concat
Concat of 
concat_result
Concatenated tensor
condition
condition && X && Y
Condition for the if
condition, X, and Y inputs are required!
ConditionTensor
connection aborted
connection already in progress
connection refused
connection reset
Constant
constant
ConstantFill
ConstantFolding
constantH
ConstantOfShape
Constrain bias type to 32-bit integer tensor.
Constrain filter type to 8-bit integer tensor.
Constrain index tensor to int64
Constrain indice type to int32 or int64
Constrain indices to integer types
Constrain input a and its zero point data type to 8-bit integer tensor.
Constrain input A data type to 8-bit integer tensor.
Constrain input and output  types to float tensors.
Constrain input and output to all tensor types.
Constrain input and output types to all numeric tensors.
Constrain input and output types to all tensor types.
Constrain input and output types to all tensors.
Constrain input and output types to any tensor type.
Constrain input and output types to float tensors
Constrain input and output types to float tensors.
Constrain input and output types to float/int tensors.
Constrain input and output types to high-precision numeric tensors.
Constrain input and output types to signed numeric tensors.
Constrain input and output types.
Constrain input b and its zero point data type to 8-bit integer tensor.
Constrain input B data type to 8-bit integer tensor.
Constrain input type to 8-bit integer tensor.
Constrain input type to unsigned or signed 32-bit integer tensor, or string tensor. It should be utf-8 encoded if using unicode.
Constrain input types to float tensors.
Constrain input types.
Constrain input types. Casting from complex is not supported.
Constrain input types. Casting from strings and complex are not supported.
Constrain input types. Strings and complex are not supported.
Constrain input w and its zero point data type to 8-bit integer tensor.
Constrain input x and its zero point data type to 8-bit integer tensor.
Constrain input 'X' and output 'Y' to all tensor types.
Constrain input0 and output types to float tensors
Constrain output data type to 32-bit integer tensor.T2 must be tensor(uint32) when T1 is tensor(uint8),or must be tensor(int32) when T1 is tensor(int8).
Constrain output mask types to boolean tensors.
Constrain output to int64 tensor, which should be a scalar though.
Constrain output to int64 tensor.
Constrain output type to 8-bit integer tensor.
Constrain output type to unsigned and signed 32-bit integer tensor.
Constrain output types to any tensor type.
Constrain output types to be numerics.
Constrain output types to bool, int32, int64, float16, float, double tensors.
Constrain output types to boolean tensors.
Constrain output types to float tensors.
Constrain output types to integral tensors.
Constrain output types. Casting to complex is not supported.
Constrain output types. Casting to strings and complex are not supported.
Constrain output types. Strings and complex are not supported.
Constrain output y and its zero point data type to 8-bit integer tensor.
Constrain output Y data type as 32-bit integer tensor.
Constrain output y data type to 32-bit integer tensor.
Constrain repeat's type to int64 tensors.
Constrain seq_lens to integer tensor.
Constrain seq_lens to integral tensors.
Constrain tiles and axis's type to int64 tensors.
Constrain to all tensor types.
Constrain to any tensor type.
Constrain to any tensor type. If the dtype attribute is not provided this must be a valid output type.
Constrain to boolean tensors.
Constrain to tensor(float).
Constrain to tensor(int32).
Constrain types to float tensors.
Constrain types to int tensors.
Constrain 'x' to float or int32 tensor.
Constrain 'x', 'y_scale' to float tensors.
Constrain 'x_zero_point' and 'x' to 8-bit integer tensors.
Constrain 'x_zero_point' and 'x' to 8-bit/32-bit integer tensor.
Constrain 'y', 'x_scale' to float tensors.
Constrain 'y_zero_point' and 'y' to 8-bit integer tensor.
Constrain 'y_zero_point' and 'y' to 8-bit integer tensors.
Constrains input to boolean tensor.
Constrains input to float tensors.
Constrains input to integral tensors.
Constrains input to only numeric types.
Constrains input types to all numeric tensors.
Constrains input/output to boolean tensors.
Constrains output to boolean tensor.
Constrains to boolean tensors.
consumed_inputs
context does not contain text
context.GetTempSpaceAllocator(&allocator_).IsOK()
Conv filter size does not match embedding_size attribute.
Conv kernal size 1 does not match conv_window_size attribute .
conv_window_size
ConvActivationFusion
ConvAddFusion
ConvBNFusion
ConvD
Conversion Error
Convert
ConvertCPUTensorToVideoFrameWithSoftwareBitmap
ConvertVideoFrameWithSoftwareBitmapToCPUTensor
ConvInteger
ConvMulFusion
ConvTranspose
Coptic
Copy from/to host memory
copy of the input. Note that our implementation of Dropout does scaling in
copy_info.size() == num_feeds
copy_to_new_fetches_cached_values.size() == num_outputs
corrupted protobuf data: tensor shape size(
coshf
CoTaskMemAlloc
CoTaskMemFree
Could not create kernel for node: 
Could not find an implementation for the node 
Could not find chunk in bin
Could not find OrtValue with name '
Could not find Region for 
Could not infer data type from input tensor with data type 
Could not write a profile because no model was loaded.
count
count_include_pad
counts
Couple the input and forget gates if 1, default 0.
Couple the input and forget gates if 1.
CoupleInputAndForget
CoupleInputForget
CPL;CXtLI
CPUExecutionProvider
create_func(&context, &func_state_) == 0
Create_State_
CreateDirect3D11DeviceFromDXGIDevice
CreateDirect3D11SurfaceFromDXGISurface
CreateDXGIFactory1
CreateEventW
CreateFileW
CreateMutexExW
CreateSemaphoreExW
CreateSubgraphSessionState should have created an entry earlier.
CreateThreadpoolWork
Creating bin of max chunk size 
CropD
cross device link
CrossChannel
CT$0L
CT$XHcD$0H
CT$xL
CTensor
CUDAExecutionProvider
Cuneiform
cur + size <= end
cur_input == end_input || cur_input->first >= 0
cur_iteration_ < num_iterations_
currentContextId
currentContextMessage
currentContextName
Currently only scalar zero_point is supported. TODO: add per channel zero point support.
custom implementation such as CuDNN.
custom_logger != nullptr
CXH9CPH
CXLcKPI
CxN&C
Cypriot
Cyrillic
D D R R z | 
D!|$XD
D!D$<D!D$PD!D$@H
D!l$<3
D!l$DD!l$XH
D$ .fD
D$ D+
D$ D8xPt
D$ E3
d$ E3
D$ E3
D$ E8F
D$ endsD
D$ fA
D$ H;
D$ H;C
D$ H;E
D$ H;G
D$ H;H
D$ H;U
D$ H+
D$ H=
D$ H9
D$ H9V
D$ HcH
D$ I;
D$ I+
D$ I+D$
D$ J9
D$ L#
D$ L;
D$ L;D$ u
D$ L9(u
D$ M;
D$ Mc
d$$H;
D$$Hi
D$$L;E
D$( L
D$(,fD
D$(8T$0I
D$(E3
d$(E3
D$(E3
D$(fD
D$(H;
d$(H;
D$(H;
D$(H;0
D$(H;G
d$(H;T$@
D$(H+
D$(H+\
D$(HcA 9B 
D$(I;
D$(I;E
D$(I+
D$(L;
D$(L;D
D$(L+
D$(M+
D$(Mc
D$,I9Q
D$@ H;]
D$@A9F
D$@beta@
D$@D;D$T
D$@D8
D$@D8`Pt
D$@E3
d$@E3
D$@E3
d$@E3
D$@E3
D$@fA
D$@H!\$`I
D$@H;
D$@H;D$H
D$@H;E
D$@H+
D$@H+D$8H
D$@H9D$8
D$@H9E
D$@H9S
D$@H9U
D$@H9u
D$@Hc
D$@I;
D$@I;E
D$@I;G 
D$@I+
D$@L;
D$@L;Hxr1I
D$@L+
D$@L9d$8
D$@L9d$pt
D$@L9l$ 
D$@Lc
D$@M;
D$@norm
D$`ATenD
D$`axes
D$`E3
D$`fA
D$`fB
D$`fD
D$`fmod
D$`H;
D$`H;D$htqH
D$`H;D$Pt
D$`H;E
D$`H;H0
D$`H+
D$`H9D$ht
D$`H9D$X
D$`H9X
D$`I;
D$`I9
D$`L;
D$`L+
D$`Lc
D$`M;
D$<;D$@
D$<@B
D$<E3
D$<Hc
d$0D!L$(
D$0D8h$
D$0D9{0
D$0D9p(t
D$0E3
d$0E3
D$0E3
d$0E3
D$0E3
d$0E3
D$0E3
d$0E3
D$0E3
d$0E3
D$0E3
D$0fH
D$0H!|$@L
D$0H!L$@H
D$0H;
D$0H;C
D$0H;C u
d$0H;T$H
D$0H+
D$0H+D$(H
D$0H9_
D$0H9|$Pt
D$0H9C
D$0H9D$8t
D$0Hc
d$0Hc
D$0Hc
D$0HcH
D$0I;
d$0I;
D$0I;
D$0I;G t
D$0I+
D$0L;\$0u
d$0L;d$h
d$0L;d$HE
d$0L9't
D$0Lc
d$0M;
D$0M;
D$0tk
d$4@2
d$48\$<tKH
d$48_
d$4D8t$1u
d$4E3
D$4Hc
D$8;h(
D$8;h(|,M
d$8A_A^A]
D$8Conv
D$8D8h8
D$8E3
d$8E3
D$8H;
D$8H;8
D$8H;C 
D$8H+
d$8H+
D$8H+D$0H
D$8H=
D$8H9D$xu M
D$8Hc
D$8HcM
d$8I;
D$8I;
d$8I;
D$8I;F
D$8Ic
D$8L;
D$8L;0
d$8L+
D$8L+D$0I
D$8L9$
D$8L9,
d$8M;
D$8M;i
D$8Mc
D$D@B
D$DDtRH
D$h0I
D$HA9uH
D$HaxesD
D$Hbias
D$Hbias@
D$Hbody
D$HbodyD
D$HE3
D$hE3
D$HE3
D$hE3
D$HE3
D$hE3
D$HE3
D$hE3
D$HE3
D$hE3
D$HE3
D$HendsD
D$HfH
D$HfI
D$hH!t$xH
D$HH;
D$hH;
D$HH;
D$hH;
D$HH;
D$HH+
D$hH+D$`H
D$hH+D$HH
D$HH9
D$hH9
D$HH9D$Pt
D$HH9E
D$HH9O
D$HH9U(t
D$HH9V
D$hHcEhH
D$HHcQ H
D$HI;
D$hI;
D$HI;
D$HI+
D$hI+
D$hL;
D$hL;XxrBL
D$hL;XxrRL
D$HL+
D$hL+
D$HL+
D$HL+<0x
D$hL98u
D$HL9t$0t
D$hM;
D$HM+
d$hM9't
D$Hmode
D$hpadsD
D$l9D$\
D$LD;
D$LE3
D$LH9t$@t
D$P%H
D$P;D$@umH
D$P8\$0ueH
d$p8F9
d$PA;
d$PA8
D$Pbeta@
D$Pbias@
D$PbodyD
D$pD8h8t
D$PD8wQt2
D$PE;F |
D$PE;F8|
D$PE2
D$pE3
D$PE3
D$pE3
D$PE3
D$pE3
D$PE3
D$pE3
D$PE3
D$pE3
D$PE3
D$pE3
D$PE3
D$pE3
d$PE9f8~lE
D$pH!}
D$PH;
D$pH;
D$PH;
D$pH;
D$PH;
D$pH;
D$PH;
D$pH;
D$PH;
D$pH;
D$PH;
D$pH;
D$PH;A0t6H
D$PH;A8t6H
D$PH;A8t'H
D$pH;C
D$PH;C
D$pH;D$xtqH
D$PH;E
D$PH;F
D$PH;G
D$PH+
D$PH+D$HH
D$pH+D$hH
d$PH+z
D$pH9
D$PH9
D$PH9D$H
D$pH9D$HwlD
D$PH9D$Xt
d$PH9U
D$PHc
D$pHcQ(H
D$PHcT$@H;
D$Phigh
D$PI;
D$pI;G
D$PI+
D$pI+
D$PI9W
D$PIc
D$pL;
D$PL;
d$PL;
D$pL;
D$PL;
D$pL;
D$PL;
D$pL;
D$pL;8
d$PL+
D$PL9
d$pL9
d$pL9u
D$pLc
D$PLc
D$pLc
D$PLcD$@I;
D$PLcF$H
D$pM;
D$PM; 
d$PM+
D$PMc
D$Pmean
D$PmodeD
D$PNONED
D$Pseed@
D$Psize
D$QE3
D$SMcZ
D$T@B
D$t@B
D$tA;F
D$tA9~
d$tD;
d$tE3
D$VE3
d$wfD
D$XaxesD
D$XD8N
D$XE3
D$xE3
D$XE3
D$xE3
D$XE3
D$XfA
D$xH;
D$XH;
D$xH;
D$XH;
d$XH;
D$xH;
D$XH;
D$xH;]
D$XH;C u
D$xH;C8tiH
D$xH+
D$XH+D$PH
D$xH+D$pH
D$XH+D$PH
D$xH9
D$XH9D$P
D$XH9D$x
D$XH9P
D$XI;
d$XI;
D$XI;D$
D$XI;E t
D$XI;E u
D$XI9T$
D$XL;
d$XL;
D$XL;
D$XL;}
D$xM;
d$xM;
D$xM;
D$xM9
D$xmode
D$xNONE
D$xNONE@
D$xpads
D$Xpads@
D$ZE3
D$zH9D$Hu
d%w{f
d%w{f[
D,$< 
D,0< 
D;@ A
D;{(|
D;|$ 
D;|$0
D;|$8|
D;~ |
D;~,|
D;A u<
D;A ucE
D;C }ZL
D;C8|
D;G |
D;g(|
D;h$L
D;l$4
D;n }
D;P }
D;s@s$H
D;t$@
D;t$D
D;t$Pr
D;t$Xr
D;w8|
D;x |
D\$@H
D\$`H
D\$0H
D\$8H
d_iter[d_i] < d_max
D|$0H
D|$8H
D=oH3
d3d11.dll
D3D11On12CreateDevice
d3d12.dll
D3D12SerializeRootSignature
D3D12SerializeVersionedRootSignature
D8$.u
D8,8u
D8;tSD
D8\$4
D8{Dt
D8|$0u
D8<+u
D8<>u
D848D
D8A t
D8b8t
D8cDt
D8d$(
D8d$`
D8d$H
D8e8u
D8ePu
D8ewu
D8f$I
D8fDt
D8fPt&D
D8g$I
D8h$t(
D8k$I
D8k&t
D8k`t 
D8k|t
D8k5H
D8l$@E
D8L$0
D8l$0
D8L$1t
D8l$4
D8oDt
D8p$I
D8r8t 
D8r8t$
D8t$pt
D8t$Xt
D8uou
D8uwu
D8vHu
D8yhu
D9 t$H
D9@ }
D9@hu
D9@Pu
D9`(t
D9`(u
D9{0D
D9{Lv{Mc
D943u
D97~+
D97t|
D9a }EL
D9a(u
D9B,~
D9BD~
D9Bt~
D9c(t
D9c(u
D9C8~73
D9d$P
D9e@u
D9f(u
D9G ~93
D9g(t
D9g8~9I
D9h(t
D9h(u
D9H0t
D9H0t1
D9i(u
D9i(uwH
D9k(t
D9K(t
D9l$@@
D9l$0u
D9mhu7A
D9n(u
D9o(u
D9o\u:H
D9o\u;H
D9p(t
D9p(u
D9P,I
D9P0t
D9phu
D9pPu
D9q ~!H
D9q ~0L
D9q(u
D9q8~*I
D9s8~!H
D9s8v
D9t$(u
D9t$0
D9t$Hu(H
D9t$PvnD
D9t$XvqD
D9u ~0H
D9u8~0H
D9uov
D9uP~!H
D9V@t
D9w(~
D9w@~
D9wp~
D9wX~
D9x ~v3
D9x(t
D9x(u
D9y u
D9Y0t
D9z(u
D9z`u
Data of TensorProto ( tensor name: 
data overflow
data tensor must have rank >= 1
Data to be binarized
Data to be classified.
Data to be encoded, a tensor of shape [N,C] or [C]
Data to be encoded.
Data to be processed.
Data to be regressed.
Data to be scaled.
Data to be selected
Data type for starts and ends inputs' need to be int32_t or int64_t, but instead got 
data type is different from updates type
data type is not supported
Data type X must be float or double, but instead got 
data_0
data_1.Shape() == shape
DATA_BATCH
data_n.Shape() == shape
data_transfer registered is nullptr.
data_type
DataTypeImpl::GetType<T>() == dtype_
DeadState in RunStateOnByte
DebugBreak
DecodePointer
DEEPCPU_ATTN_LSTM
DEEPCPU_LSTM
Default
default 1; Pooled output Y's height.
default 1; Pooled output Y's width.
Default logger already set. 
default_float
default_int64
default_string
defaultAttributeCount
Defines how to aggregate leaf values within a target. <br>One of 'AVERAGE,' 'SUM,' 'MIN,' 'MAX.'
DeleteCriticalSection
delta
delta in Range operator can not be zero!
delta in Range operator should be scalar like tensor, yet got shape:
DENSE
depth
Depth is negative.
DepthToSpace
DequantizeLinear
deque<T> too long
Describes the axis of the inputs when coerced to 2D; defaults to one because the 0th axis most likely describes the batch_size
description
Deseret
Deserialize tensor 
destination address required
detailed description of the broadcasting rules.
detect_negative
detect_positive
Detensorization for this format is unsupported on the current device.
Detensorize Descriptor Heap
Detensorize Rootsignature
Devanagari
device or resource busy
Device: [
device_copy_checks.status == DeviceCopyCheck::Unknown
DFA out of memory: size 
DictVectorizer
dilation == 1
Dilation not supported for AutoPadType::SAME_UPPER or AutoPadType::SAME_LOWER.
Dilation value along each axis of filter.
dilation value along each axis of the filter.
dilation value along each axis of the filter. If not present, the dilation defaults to 1 along each axis.
Dilations
dilations
Dilations dimensions should match kernel shape
dilations_.size() == kernel_shape_.size()
dim0_offset < dim0_size
dimension <= num_dims
Dimension could not be inferred: incompatible shapes
Dimension of input 
Dimension on which to do the sort.
Dimension value inferred (
dimension_count * 2 == pads.size()
dimension_count > 0
DimensionCount
dimensions [a_0 * ... * a_{k-1}, a_k * ... * a_{n-1}]. For the default
dimstart <= dimend && dimend <= size()
direction
Direction
directions
DirectML.dll
directory not empty
DisableThreadLibraryCalls
Dividend tensor
division
Divisor tensor
DL$`H
DllCanUnloadNow
DllGetActivationFactory
DML allocator
DML CPU
DML_OPERATOR_ACTIVATION_ELU
DML_OPERATOR_ACTIVATION_HARD_SIGMOID
DML_OPERATOR_ACTIVATION_HARDMAX
DML_OPERATOR_ACTIVATION_IDENTITY
DML_OPERATOR_ACTIVATION_LEAKY_RELU
DML_OPERATOR_ACTIVATION_LINEAR
DML_OPERATOR_ACTIVATION_LOG_SOFTMAX
DML_OPERATOR_ACTIVATION_PARAMETERIZED_RELU
DML_OPERATOR_ACTIVATION_PARAMETRIC_SOFTPLUS
DML_OPERATOR_ACTIVATION_RELU
DML_OPERATOR_ACTIVATION_SCALED_ELU
DML_OPERATOR_ACTIVATION_SCALED_TANH
DML_OPERATOR_ACTIVATION_SHRINK
DML_OPERATOR_ACTIVATION_SIGMOID
DML_OPERATOR_ACTIVATION_SOFTMAX
DML_OPERATOR_ACTIVATION_SOFTPLUS
DML_OPERATOR_ACTIVATION_SOFTSIGN
DML_OPERATOR_ACTIVATION_TANH
DML_OPERATOR_ACTIVATION_THRESHOLDED_RELU
DML_OPERATOR_AVERAGE_POOLING
DML_OPERATOR_BATCH_NORMALIZATION
DML_OPERATOR_CAST
DML_OPERATOR_CONVOLUTION
DML_OPERATOR_DEPTH_TO_SPACE
DML_OPERATOR_DIAGONAL_MATRIX
DML_OPERATOR_ELEMENT_WISE_ABS
DML_OPERATOR_ELEMENT_WISE_ACOS
DML_OPERATOR_ELEMENT_WISE_ACOSH
DML_OPERATOR_ELEMENT_WISE_ADD
DML_OPERATOR_ELEMENT_WISE_ADD1
DML_OPERATOR_ELEMENT_WISE_ASIN
DML_OPERATOR_ELEMENT_WISE_ASINH
DML_OPERATOR_ELEMENT_WISE_ATAN
DML_OPERATOR_ELEMENT_WISE_ATANH
DML_OPERATOR_ELEMENT_WISE_CEIL
DML_OPERATOR_ELEMENT_WISE_CLIP
DML_OPERATOR_ELEMENT_WISE_CONSTANT_POW
DML_OPERATOR_ELEMENT_WISE_COS
DML_OPERATOR_ELEMENT_WISE_COSH
DML_OPERATOR_ELEMENT_WISE_DEQUANTIZE_LINEAR
DML_OPERATOR_ELEMENT_WISE_DIVIDE
DML_OPERATOR_ELEMENT_WISE_ERF
DML_OPERATOR_ELEMENT_WISE_EXP
DML_OPERATOR_ELEMENT_WISE_FLOOR
DML_OPERATOR_ELEMENT_WISE_IDENTITY
DML_OPERATOR_ELEMENT_WISE_IF
DML_OPERATOR_ELEMENT_WISE_IS_NAN
DML_OPERATOR_ELEMENT_WISE_LOG
DML_OPERATOR_ELEMENT_WISE_LOGICAL_AND
DML_OPERATOR_ELEMENT_WISE_LOGICAL_EQUALS
DML_OPERATOR_ELEMENT_WISE_LOGICAL_GREATER_THAN
DML_OPERATOR_ELEMENT_WISE_LOGICAL_LESS_THAN
DML_OPERATOR_ELEMENT_WISE_LOGICAL_NOT
DML_OPERATOR_ELEMENT_WISE_LOGICAL_OR
DML_OPERATOR_ELEMENT_WISE_LOGICAL_XOR
DML_OPERATOR_ELEMENT_WISE_MAX
DML_OPERATOR_ELEMENT_WISE_MEAN
DML_OPERATOR_ELEMENT_WISE_MIN
DML_OPERATOR_ELEMENT_WISE_MULTIPLY
DML_OPERATOR_ELEMENT_WISE_POW
DML_OPERATOR_ELEMENT_WISE_QUANTIZE_LINEAR
DML_OPERATOR_ELEMENT_WISE_RECIP
DML_OPERATOR_ELEMENT_WISE_SIGN
DML_OPERATOR_ELEMENT_WISE_SIN
DML_OPERATOR_ELEMENT_WISE_SINH
DML_OPERATOR_ELEMENT_WISE_SQRT
DML_OPERATOR_ELEMENT_WISE_SUBTRACT
DML_OPERATOR_ELEMENT_WISE_TAN
DML_OPERATOR_ELEMENT_WISE_TANH
DML_OPERATOR_ELEMENT_WISE_THRESHOLD
DML_OPERATOR_GATHER
DML_OPERATOR_GEMM
DML_OPERATOR_GRU
DML_OPERATOR_GRU_ELEMENT_WISE
DML_OPERATOR_JOIN
DML_OPERATOR_LOCAL_RESPONSE_NORMALIZATION
DML_OPERATOR_LP_NORMALIZATION
DML_OPERATOR_LP_POOLING
DML_OPERATOR_LSTM
DML_OPERATOR_LSTM_FUSED_ACTIVATION
DML_OPERATOR_MAX_POOLING
DML_OPERATOR_MAX_POOLING1
DML_OPERATOR_MAX_UNPOOLING
DML_OPERATOR_MEAN_VARIANCE_NORMALIZATION
DML_OPERATOR_ONE_HOT
DML_OPERATOR_PADDING
DML_OPERATOR_REDUCE
DML_OPERATOR_RESAMPLE
DML_OPERATOR_RNN
DML_OPERATOR_RNN_FUSED_ACTIVATION
DML_OPERATOR_RNN_GATHER
DML_OPERATOR_RNN_OVERWRITE
DML_OPERATOR_RNN_ZERO
DML_OPERATOR_ROI_POOLING
DML_OPERATOR_SCATTER
DML_OPERATOR_SLICE
DML_OPERATOR_SPACE_TO_DEPTH
DML_OPERATOR_SPLIT
DML_OPERATOR_TILE
DML_OPERATOR_TOP_K
DML_OPERATOR_UPSAMPLE_2D
DML_OPERATOR_VALUE_SCALE_2D
DMLCreateDevice1
DmlExecutionProvider
DmlFusedNode_
DmlFusedNodeDomain
DoCoalesce failed: r1->op() is 
DoCoalesce failed: r2->op() is 
does not have a kernel registry.
Dogra
domain
Domain already set in registry
Done saving initialized tensors
Done saving kernels.
Done saving OrtValue mappings.
Double
double
double_data
drop_states
Dropout
Dropout takes one input data (Tensor<float>) and produces two Tensor outputs,
Dropout takes one input floating tensor and produces two tensor outputs,
DT$HH
DT$PL
dtype
dup_replacements.find(&arg) == dup_replacements.end()
Duplicate name in feeds: 
Duplicate stopwords not allowed
Duplicate type constraint name
duplicated allocator
duplicated location
duplicated ort_value index:
Duployan
Duration (us)
dword
DX12TextureToGPUTensor
DXBC#
DXBC.
DXBC\8
DXBC_9
DXBC1w
DXBC7
DXBC70
DXBCd=
DXBCF
DXBCN
DXBCO
DXBCT0
DXCoreCreateAdapterFactory
dxgi.dll
DynamicSlice
E body
E H!]0L
E H;H
E HcL
e IcE
E J;L
E(A;D$(
E(H!E82
E(H;C
E(H;E
E(H9E0t
E(NONED
E;a }:H
E;E(D
E;f8r
E;o`H
E;P M
E;t$8
E;w A
E;X |
E@body@
E@H9EHt
E_Xsquared
E`body
E`Conv
E|$(H
E+pL3
E+pLH
e0A^A]A\_^[]
E0H;E
E0H+E(
E0I+E(H
E0reluD
E0TanhD
E8$6u
E8,>u
E8,6u
E8,9u
E8<6u
E84?u
e8D9"
e8D9"uz
E8H+E0H
E8l$X
E8Mjt
E8Mjt.I
E8nPt
E9~ ~
E9~x~7I
E9<$t
E9<$u
E9f ~lE
E9f(u
E9n(t
E9n8vnH
E9o u
E9P }
E9X |
E9X,~
E9X0t
E9XD~
E9Xt~
Each of these dimensions must be matched correctly, or else the operator
ED$(H
EdgeConsistency
eE9`X
effffff
EgH9U
Egyptian_Hieroglyphs
EhGemm
EHH+E@H
Either both scale and offset can be of feature size (
Either one of the separators OR tokenexp attributes required but none is set
Elbasan
elem_proto != nullptr
elem_type
Element type of input 
Element type of input was unknown
elements, but feeds has 
Element-wise {name} of each of the input tensors (with Numpy-style broadcasting support).
elementwise on the input tensors `A` and `B` (with Numpy-style broadcasting support).
elementwise on the input tensors `A` and `B`.
EliminateDropout
EliminateIdentity
EliminateSlice
else_branch
embedding_size
Empty dimensions for input tensor
Empty input dimensions.
Empty scale in attributes
Empty stopwords not allowed
Empty value of imputed values.
Enable broadcasting
EnableDebugOutput
Encoded output data
Encoded output data, having one more dimension than X.
EncodePointer
Encountered unknown exception in Initialize()
Encountered unknown exception in Load()
Encountered unknown exception in Run()
end_idx >= start_idx && end_idx <= total_items
Ending indices (exclusive) of corresponding axis in axes`
EndPadding
endpos: 
Ends must be a 1-D array
endsD
ENGINE_ERROR
EnterCriticalSection
entiu
Entry exists in node 
entry.second
en-US
Environment dependent string that denotes the locale according to which output strings needs to be upper/lowercased.Default en_US or platform specific equivalent as decided by the implementation.
Environment must be initialized before creating an InferenceSession.
Environment::IsInitialized()
Eo9F@
Epbody
EPCropD
EpH;}
epH+u
EPHc@
EPpermD
epsilon
Epsilon
EPtanhD
EpTanhD
equal
Equal
Equations (Default: f=Sigmoid, g=Tanh):
Equations (Default: f=Sigmoid, g=Tanh, h=Tanh):
Equations (Default: f=Tanh):
ERROR
Error compiling '
Error during EndProfiling(): 
Error mapping feeds: 
Error mapping output names: 
Error parsing '
Error reverse compiling '
Error: Duplicate definition-site for (
errormessage
Ethiopic
E'uUH
evalModelCounters
Evaluation
Evaluation produced unexpected output variables.
event
Event Name
eventId
EventRegister
EventSetInformation
EventUnregister
EventWriteTransfer
EX_squared
Exceeded maximum protobuf size of 2GB: 
Exception
Exception caught: 
Exception during initialization: 
Exception during loading: 
Exception joining threads in TaskThreadPool: 
exec_plan_ptr
executable format error
Execution frame was null
Execution plan was not found in SessionState. CreatePlan must be called first.
Execution Provider
Execution provider 
Execution type '
execution_frame_->GetOrCreateNodeOutputMLValue(output_arg_index, nullptr, p_value).IsOK()
executionType
EXECUTOR
existing_entries.find(attribute_name) == existing_entries.cend()
Exiting due to terminate flag being set to true.
exM9&t
Expand
ExpandDims
expanded
Expected AllocateFinalOutput to have been called to before we increment the iterator
Expected AllocateFinalOutput to have been called to before we read the OrtValue from the iterator.
Expected 'replace_value_int64' attribute since 'imputed_values_int64' is specified
Expected 'replaced_value_float' attribute since 'imputed_value_floats' is specified
Expecting a non-empty tokenexp
Expecting activation to be one of Affine, Relu, LeakyRelu, ThresholdedRelu, Tanh, ScaledTanh, Sigmoid, HardSigmoid, Elu, Softsign, Softplus. Got 
Expecting indices to be either int32_t or int64_t
Exponent
ExponentTensor
Extending allocation by 
ext-ms-win-dxcore-l1-1-0.dll
extra_shape
EyeLike
EyeLike : Input tensor dimension is not 2
F F ~ ~ 
F H;G 
F H+F
F I+F
F I9F
F Mc~
f#L$@f
F$A9G 
f;ANuNA
F@I+F8H
F78|As
F8<+u
F8I+F0H
f9,Au
f9,Ou
f9,Qu
f9,Yu
f9<Bu
fA9<@u
fA94Qu
fA99}
Factor used in computing the running mean and variance.e.g., running_mean = running_mean * momentum + mean * (1 - momentum), default is 0.9f.
Factor used in computing the running mean and variance.e.g., running_mean = running_mean * momentum + mean * (1 - momentum).
Failed
Failed to acquire buffer from model stream.
Failed to add kernel for 
Failed to analyze start state.
Failed to center crop the provided input image. The calculated bounds exceed the dimensions of the image, or do not match the model inputs dimensions.
Failed to construct locale with name:
Failed to copy tensor to execution provider: 
Failed to create kernel for op: 
Failed to create LearningModel. Ivalid argument model_path_size.
Failed to create LearningModel. Ivalid argument p_model_path.
Failed to create LearningModel. Ivalid argument pp_model_unk.
Failed to create LearningModelDevice. Ivalid argument device.
Failed to create LearningModelDevice. Ivalid argument queue.
Failed to create operator registry.
Failed to create output tensor for 
Failed to create output tensor for If output 
Failed to create output tensor for output #
Failed to find input name in the mapping: 
Failed to find kernel for 
Failed to find symbol in library
Failed to get allocator for initializer '
Failed to get allocator for location: 
Failed to get allocator for optimizer
failed to get first output!
Failed to get initialized tensor 
Failed to load model with error: 
Failed to obtain detect_negative
Failed to obtain detect_positive
Failed to return bound object for model variable output %s
Failed to unload DSO: 
Failed to unload library
Failed to update bound object for model variable output %s
FailFast
failureCount
failureId
failureType
FallbackError
false
False instead of True.
FATAL
Fatal error: 
Fatal error: 0 count processors from GetLogicalProcessorInformation
Fatal error: 0 count processors from GetSystemInfo
fclose
fD9$Pu
fD9<Au
fD9<Hu
fD9t}
fD9UP
fD9UP}
fD9UPv
fE99t A
Feature id for each node.
FeatureVectorizer
feed_mlvalue
feed_names.size() == num_feeds
feeds.size() == feed_mlvalue_idxs.size()
fesetround
Fetches vector passed to GetOutputs contains 
fetches.empty() || fetches.size() == fetch_mlvalue_idxs.size()
fetches.size() == node->OutputDefs().size()
fffff
ffffff
fffffff
fflush
fgetc
fgetpos
FHH;FP
FHI+F@H
Field '
file exists
File not found: %s
file too large
FileDescription
fileName
filename too long
FileVersion
filter number not equal to input channel number.
FilterTensor
Final N loop carried dependency values then K scan_outputs
Final values of the loop's N state variables followed by K scan_outputs
final_output_mlvalue_
final_state_and_scan_outputs
First dimension (num_rois) of batch_indices and rois don't match
First input does not have rank 2
First input operand for the logical operator.
first input tensor has wrong dimension
First input tensor must have rank 3
First operand, base of the exponent.
First operand, should share the type with the second operand.
First operand.
First set of probability coefficients.
First, offset by this.<br>Can be length of features in an [N,F] tensor or length 1, in which case it applies to all features, regardless of dimension count.
FixedLayout
FixedLayoutAndOperatorPreference
Flag indicating whether the regression is a one-class SVM or not.
Flatten
Flist<T> too long
float
Float
Float representing the threshold for deciding when to remove boxes based on score. It is a scalar
Float representing the threshold for deciding whether boxes overlap too much with respect to IOU. It is scalar. Value range [0, 1].
float_data
Float16
float16
FLOAT16 is not supported
Floor
floorf
fmaxf
fmod attribute must be true for float, float16 and double types
fmod must have value either 0 or 1
fmod_
fmodf
For each node, define what to do in the presence of a missing value: if a value is missing (NaN), use the 'true' or 'false' branch based on the value in this array.<br>This attribute may be left undefined, and the defalt value is false (0) for all nodes.
For each node, define what to do in the presence of a NaN: use the 'true' (if the attribute value is 1) or 'false' (if the attribute value is 0) branch based on the value in this array.<br>This attribute may be left undefined and the defalt value is false (0) for all nodes.
For example, the following tensor shapes are supported (with broadcast=1):
For ort_value with index: 
For previous (depreciated) non-spatial cases, implementors are suggested
forgot to update the version range in DomainToVersionRange 
Format was input image %d. Input image format must Bgra8, Rgba8 or Gray8.
Format was output image %d. Output image format must be Bgra8, Rgba8 or Gray8.
FormatMessageW
forward
found
found duplicated provider 
foward
FPH+FHH
FPLc 3
fputc
frame != nullptr
fread
FreeLibrary
frexp
fromStream
fsetpos
func info for node: 
FuncKernel call failed with error code: 
function
Function
function
function not supported
Fused
fused 
fused Conv 
fused Gemm 
fused Matmul and Add 
fused op (
fused_
fused_activation
fused_activation_domain
fused_activation_since_version
fused_alpha
fused_beta
fused_function_subgraph
fused_gamma
fused_ratio
FusedActivation
FusedAdd
FusedBatchNormalization
FusedConv
FusedConvTranspose
FusedGemm
FusedInstanceNormalization
FusedMatMul
FusedMeanVarianceNormalization
FusedSum
future
future already retrieved
fwrite
FXI+FPH
FXL+FPI
FXM+FPI
G A;E
G H;H
G H+G
G$A9F 
G(D;0
G(D9 
G(HcG F
G(L9e
G0I;F0tjH
G0I+G(H
G8H+G0H
gamma
Gamma
gates
Gather
GatherND
GatherND requires two tensor inputs.
GEMM: Dimension mismatch, W: 
Gemm: Invalid bias shape for broadcast
GemmActivationFusion
gemmlowp error: %s
GENERAL ERROR
General Matrix multiplication:
generic
GenuD
GenuH
Georgian
Get preallocated buffer for initializer '
GetCPInfo
GetCurrentProcess
GetCurrentProcessId
GetCurrentThreadId
GetExitCodeThread
GetFileSizeEx
GetFileSizeEx 
GetLastError
GetLocaleInfoEx
GetLogicalProcessorInformation
GetModuleFileNameA
GetModuleHandleExW
GetModuleHandleW
GetNativeSystemInfo
GetOrCreateOutputMLValue(index, p_ml_value).IsOK()
GetProcAddress
GetProcessHeap
GetProcessTimes
GetRestrictedErrorInfo
GetStringTypeW
GetSystemInfo
GetSystemTimeAsFileTime
GetSystemTimePreciseAsFileTime
GetTickCount64
gfffffffH
gfffffffH+
gfffffffI
gHc@(L;
gHcr@H
GHI+G@H
GivenTensorFill
Glagolitic
GlobalAveragePool
GlobalLpPool
GlobalMaxPool
Got nullptr from GetKernel for node: 
Got weights of size: 
Gothic
GPH+GHH
GPUTensorToDX12Texture
-grams
-grams detected
Grantha
graph
Graph attribute inferencing failed: 
Graph attribute inferencing returned type information for 
Graph ctor should have created NodeArg for initializer.
Graph has 
Graph in 'body' attribute of Loop should have 
Graph input #
Graph input with name 
Graph must be in single static assignment (SSA) form, however '
Graph to run if condition is false. Has N outputs: values you wish to be live-out to the enclosing scope. The number of outputs must match the number of outputs in the then_branch.
Graph to run if condition is true. Has N outputs: values you wish to be live-out to the enclosing scope. The number of outputs must match the number of outputs in the else_branch.
Graph::InferAndVerifySubgraphTypes should have already validated that num_variadic_inputs matched the subgraph inputs or required inputs.
graph_optimization_level < TransformerLevel::MaxTransformerLevel
graph_proto != nullptr
graph_proto cannot be null
graph_viewer_
GraphProto attribute inferencing is not enabled in this InferenceContextImpl instance.
Gray8
greater
Greater
Greek
group
group count is <= 0
GroupCount
GrowStack() failed: 
GRU operator does not support double yet
GRUUnit
GSL: Postcondition failure at C:\apilot\agent\_work\2\s\engine\lotus\cmake\external\gsl\include\gsl/pointers: 91
GSL: Precondition failure at C:\apilot\agent\_work\2\s\engine\lotus\cmake\external\gsl\include\gsl/gsl_algorithm: 53
GSL: Precondition failure at C:\apilot\agent\_work\2\s\engine\lotus\cmake\external\gsl\include\gsl/pointers: 77
GSL: Precondition failure at C:\apilot\agent\_work\2\s\engine\lotus\cmake\external\gsl\include\gsl/span: 150
GSL: Precondition failure at C:\apilot\agent\_work\2\s\engine\lotus\cmake\external\gsl\include\gsl/span: 162
GSL: Precondition failure at C:\apilot\agent\_work\2\s\engine\lotus\cmake\external\gsl\include\gsl/span: 176
GSL: Precondition failure at C:\apilot\agent\_work\2\s\engine\lotus\cmake\external\gsl\include\gsl/span: 196
GSL: Precondition failure at C:\apilot\agent\_work\2\s\engine\lotus\cmake\external\gsl\include\gsl/span: 211
GSL: Precondition failure at C:\apilot\agent\_work\2\s\engine\lotus\cmake\external\gsl\include\gsl/span: 475
GSL: Precondition failure at C:\apilot\agent\_work\2\s\engine\lotus\cmake\external\gsl\include\gsl/span: 524
GSL: Precondition failure at C:\apilot\agent\_work\2\s\engine\lotus\cmake\external\gsl\include\gsl/span: 555
GSL: Precondition failure at C:\apilot\agent\_work\2\s\engine\lotus\cmake\external\gsl\include\gsl/span: 561
gsl::narrow_cast<int64_t>(input_axes_.size()) == num_scan_inputs_
gsl::narrow_cast<int64_t>(input_shape.Size()) == size
gsl::narrow_cast<int64_t>(output_axes_.size()) == num_scan_outputs
gsl::narrow_cast<int64_t>(tensor_shape.NumDimensions()) >= slice_dimension
gsl::narrow_cast<int64_t>(X_shape.NumDimensions()) >= axis_
Gujarati
Gunjala_Gondi
Gurmukhi
GXD8 tFH
GXD8o
GXH9GP
GXI+GPH
h != kInvalidChunkHandle
h < chunks_.size()
H 9MXu:I
H H+H
H L+H
H L9i
H SVWH
H SWH
H UATAUAVAWH
H UVWATAUAVAWH
H UWAVH
H VWATAVAWH
H VWAUAVAWH
H WATAUAVAWH
H WAVAWH
H!\$(L
H!\$8H
H!\$8I
H!\$hE3
H!D$@I
H!L$(3
H!L$@
H!L$@H
H!L$`3
H!L$0E3
H!L$83
H!L$8E3
H!L$HL
H!L$Ht
H!L$p3
H!L$X
H!T$0D
H!T$XH!U
H#i0H
H#K(H
H#L$pH
H#q0L
H#S0L
H#U H
H#U0H
H#UPH
H#V0L
H(A9J
H(A9K
H(H!H0H!H0H!H8H!H@
H(I+H H
H)^`H
H)L$h
H)L$p
H,A9J
H,A9K
H;:uyH;
H;\$(
H;\$(tMH
H;\$@
H;\$`
H;\$`r
H;\$8t
H;\$Hu
H;\$xu
H;]g|
H;{ |
H;{ r
H;|$(L
H;|$@tIH
H;|$0tqH
H;|$8tuH
H;|$Hu
H;|$p
H;|$PL
H;|$Xr
H;|$xtNH
H;|80u
H;}o|
H;~0u
H;>tx
H;0u2
H;0u5
H;8u/H
H;8u2H
H;9u"H;
H;A@u
H;A0u
H;AHt
H;AHu
H;APu
H;C }
H;C rLH
H;C u
H;C0}
H;C0u
H;CXt
H;D$(u
H;D$@
H;D$@|?L
H;D$`A
H;D$0t
H;D$x
H;D$X
H;D$x
H;D$X
H;D$x
H;D$xt!H
H;E8t
H;Eg|
H;EoH
H;EX|
H;F@|
H;G0r<
H;H }
H;H A
H;H s
H;H(I
H;K sNH
H;K0t
H;L$8tGI;
H;L$Ht
H;L$X
H;l$xH
H;l$xJ
H;Mo|
H;NPu
H;O }\H
H;O }MH
H;O sVH
H;O`tI
H;P s
H;p s
H;Q }
H;q L
H;Q s
H;Q tgL9
H;QhH
H;r s
H;s r
H;S8v
H;t$ seH
H;T$(|
H;t$(I
H;T$(t'I;
H;T$`
H;t$0|
H;T$8t6L;
H;T$8t'I;
H;T$H
H;t$H
H;T$h
H;t$H
H;t$h
H;T$h|
H;T$Hu
H;T$P
H;T$P}oE3
H;T$X
H;t$x
H;T$X}yE3
H;ug|
H;w s
H;wxL
H;X }
H;y s
H;Y0tLH
H;yhH
H;z u
H@H+H8H
h_^[]
h_^][
H+\$@H
H+\$0H
H+_0H
H+|$hH
H+}0H
H+BXH
H+C H
H+C0H
H+D$8L
H+D$8O
H+D$hH
H+D$pH
H+D$PH
H+D$xH
H+D$xL
H+l$(H
H+L$(H
H+L$(x@H
H+L$(xBH
H+l$0I
H+L$hH
H+L$xH
H+N8A
H+NPE2
H+NPE3
H+O0H
H+Q H
H+Q0H
H+Q8H
H+S H
H+T$@I
H+t$0H
H+T$hH
H+t$PH
H+V0H
H0H+H(H
H0I;H0t
H1K H
H1O H
H8I;H@t
H9:tjL
H9[8t
H9\$ 
H9\$ u
H9\$`
H9\$`t
H9\$`v8H;
H9\$0
H9\$0t
H9\$8
H9\$8t
H9\$h
H9\$ht
H9\$pt
H9\$Pt1L
H9\$Pu7H
H9\$Xt
H9]g~"f
H9_Xt
H9|$ 
H9|$(
H9|$@t
H9|$0
H9|$0t
H9|$0u7
H9|$8
H9|$ht
H9}g~
H9}Pu
H9~0L
H90u;I9?u
H91wPH
H93uOH
H98t(
H98t{
H9A }
H9A v\H
H9C }!H
H9C }!L
H9C s!L
H9C s)H
H9C0u(H
H9D$(t
H9D$(u
H9D$@t
H9D$0
H9D$0uO
H9D$8t&
H9D$8t.H
H9D$8t1
H9D$P
H9D$p
H9D$P
H9D$X
H9G0u&H
H9Gxt+H
H9H }
H9H },
H9H s
H9J(H
H9L$@t
H9L$PL
H9L$x
H9L$xu I
H9l>HsI
H9MHu
H9N t/H
H9n(H
H9n8H
H9O uz
H9P }
H9p }
H9P }
H9P s
H9Q }
H9Q0L
H9s0t%H
H9sX~eH
H9t$@
H9t$@t
H9t$`
H9t$0
H9T$0t
H9t$8
H9t$8t
H9t$8u;H
H9t$8u6H
H9T$ht
H9t$P
H9t$XH
H9u8t
H9uHH
H9uHt
H9UHt
H9v8t
H9x }
H9Y }
H9Y u\
HA^_^[
hA^_^[
HA^_^[
hA_A^_^[]
HA_A^_^][
HA_A^A\_^[
HA_A^A]A\^[
HA_A^A]A\_^[]
hA_A^A]A\_^[]
HA_A^A]A\_^[]
hA_A^A]A\_^][
HA_A^A]A\_^][
hA_A^A]A\_^][
Hangul
Hanifi_Rohingya
Hanunoo
hardmax
Hardmax
Hardmax inputs N, D and N * D must be < 
HardSigmoid
hardsigmoid
has output size 
has_starts && has_ends && attr_starts_.size() == attr_ends_.size()
Hatran
Hb$EfkJ
Hc@ I9
Hc@ J9
Hc@ L;
Hc^$H
Hc|$4
Hc|$HH
Hc|$PH
Hc}pM
HcB@H
HcC H9
HcC(H
HcC0A
HcC0H
HcC0HcK,H+
HcD$ H
HcD$$H
HcD$(H
HcD$@H
HcD$\H
HcD$`I9E
HcD$|H
HcD$8
HcD$8H
HcD$8I
HcD$P
HcD$X
HcEHLcM@LcE8H
HcEXLcMPLcEHH
HcF A9D$ 
HcF H
HcF$H
HcF8H
HcFPH
HcG$L
HcG@H;
HcG@I
HcGPH
HcH0H
Hci H
HcIHL
HcJ H
HcJ8H
HcJPH
HcK@H
Hck8H
HcL$ H
HcL$(H
HcL$xH
HcN H
HcN$H
HcNhH
HcNPH
HcOpH
HcOPH
HcOXH
HcP$L
HcQ(H
HcQ0H
Hcr@H
HcS,H
HcSPH
HcT$@H
HcT$8H
HcT$8L
HcT$HH
HcT$xH
HcU0H
HcV H
HcV$H
HcW H
Hcx t
HeapAlloc
HeapFree
Hebrew
height
Height
height
Height
height
Height
height
height_scale
HHtfH
Hi7@B
hidden
hidden_prev
hidden_size
HiddenInitTensor
HiddenTensor
Hiragana
host unreachable
HRESULT
hResult
hresult
HRESULT
https://arxiv.org/abs/1502.03167. Depending on the mode it is being run,
https://en.wikipedia.org/wiki/Basic_Linear_Algebra_Subprograms#Level_3
HUSVH
HUSVWH
HXH+HPH
HXI+HPH
HXI+HPI
HxLcHpI
i < input_shape.NumDimensions()
I E8H t:I
I#h H
I#J0L
I#V0H
I;@@u
I;^0|
I;^0}wA
I;|$XL
I;>}>
I;>ts
I;A8t
I;F u
I;F@|
I;F0u
I;F8u
I;FPL
I;FPu
I;H0t
I;HHsD
I;I8u
I;N@|
I;NPI
I;Opu
I;P@u
I;VPI
I;y }2H
I;y s2H
I@I+I8H
I+@hH
I+NxH
I+O8A
I0;O(
I1Q H
I1U I
I9?t&
I9^ tGA
I9_ht1H
I9_ht2H
I9<$t%
I9>t`LcK$E3
I9Jhs
I9Khs
I9O0I
I9T$(t
I9X0I
I9Xxu
I9y }=I
I9y s=I
Ic,$E
Ic@(H
Ic@@H
Ic@pH
Ic_PH
IcA H
IcA8H
IcAhH
IcAPH
IcD$ A
IcD$ H
IcF H
IcFhL
IcFPH
IcFTH
IcG H
IcG H;
IcG8H
IcGTH
IcH H
IcH(H;
IcH@H;
IcH8H
IcHhH
IcHHL
IcHPH
IcHpH;
IcI H
IcIhH
IcIPH
IcL$8H
IcL$hH
IcL$PH
IcMPH
IcN I
IcN8H
IcNPH
IcNTH
IcOPH
IcV8H
id >= 0 && static_cast<size_t>(id) < ml_value_info_.size()
identifier removed
Identity
IdentityH9
IdentityI
If 0, normalize the mean only.  Default is 1.
If 1, mean and variance are computed across channels. Default is 0.
If broadcasting is enabled, the right-hand-side argument will be broadcasted
If keepdims equal 0, then the resulted tensor have the reduced dimension pruned. 
If necessary the right-hand-side argument will be broadcasted to match the
If node has 
'If' node has 
If set to nonzero, run spatial batch normalization in test mode, default is 0.
If set, defines the broadcast dimensions.
If set, defines the broadcast dimensions. See doc for details.
If shape was concrete we shouldn't be using a custom allocator
If spatial is true, the dimension of bias is (C). If spatial is false, the dimensions of bias are (C x D1 x ... x Dn)
If spatial is true, the dimension of scale is (C). If spatial is false, the dimensions of scale are (C x D1 x ... x Dn)
If spatial is true, the dimension of the running mean (training) or the estimated mean (testing) is (C). If spatial is false, the dimensions of the running mean (training) or the estimated mean (testing) are (C x D1 x ... x Dn).
If spatial is true, the dimension of the running variance(training) or the estimated variance (testing) is (C). If spatial is false, the dimensions of the running variance(training) or the estimated variance (testing) are (C x D1 x ... x Dn).
If the pads parameter is provided the shape of the output is calculated via the following equation:
If the value of map_form is 'SPARSE,' this attribute indicates the total length of the output tensor.
If true and category is not present, will return all zeros; if false and a category if not found, the operator will fail.
If true, compute the mean and variance across all spatial elements If false, compute the mean and variance across per feature.Default is 1.
If true, compute the mean and variance across per activation. If false, compute the mean and variance across per feature over each mini-batch.
If value is 1, output type is uint32_t, else int32_t. Default value is 1.
iFormat
iHeight
IhM9ZXt
illegal byte sequence
illegal input path:
iLuid
IMAGE
Image.BitmapPixelFormat
Image.ColorSpaceGamma
Image.NominalPixelRange
Image[
ImageScaler
Imperial_Aramaic
impl_->max_gram_length_ >= impl_->min_gram_length_
impl_->max_skip_count_ >= 0
impl_->min_gram_length_ > 0
impl_->weighting_criteria_ != kNone
impl_->weights_.size() == impl_->ngram_indexes_.size()
implementation such as CuDNN.
Imputed output data
imputed_value_floats
imputed_value_int64s
imputed_values_float_.empty() ^ imputed_values_int64_.empty()
Imputer
in onnx/defs/schema.h).
in test mode or not, the output Y will either be a random dropout, or a simple
in the inclusive range [
In this situation, we must have a_0 = N and a_1 * ... * a_{n-1} = D.
inappropriate io control operation
IncludePadding
Incompatible dimensions
Incompatible dimensions for matrix multiplication
Inconsistent shape in loop output for output 
Incorrect or missing attribute value for starts and ends
Incorrect or missing input value for starts and ends
Incorrect output shape
index < data_.size()
index >= 0 && static_cast<size_t>(index) < inputs.size()
index >= 0 && static_cast<size_t>(index) < outputs.size()
index out of range
Index tensor shape should be same as that of the input data tensor to unpool.
IndexDimensions
Indicate up to which input dimensions (exclusive) should be flattened to the outer dimension of the output. The value for axis must be in the range [0, R], where R is the rank of the input tensor. When axis = 0, the shape of the output tensor is (1, (d_0 X d_1 ... d_n), where the shape of the input tensor is (d_0, d_1, ... d_n). 
Indicates the transform to apply to the regression output vector.<br>One of 'NONE,' 'SOFTMAX,' 'LOGISTIC,' 'SOFTMAX_ZERO,' or 'PROBIT'
Indicates the transform to apply to the score. <br> One of 'NONE,' 'SOFTMAX,' 'LOGISTIC,' 'SOFTMAX_ZERO,' or 'PROBIT.'
Indicates the transform to apply to the score. <br>One of 'NONE,' 'SOFTMAX,' 'LOGISTIC,' 'SOFTMAX_ZERO,' or 'PROBIT'
Indicates the transform to apply to the score. <br>One of 'NONE,' 'SOFTMAX,' 'LOGISTIC,' 'SOFTMAX_ZERO,' or 'PROBIT.'
Indicates the transform to apply to the scores vector.<br>One of 'NONE,' 'SOFTMAX,' 'LOGISTIC,' 'SOFTMAX_ZERO,' or 'PROBIT'
Indicates whether to do OvR or multinomial (0=OvR is the default).
Indicates whether to only output as many values as are in the input (dense), or position the input based on using the key of the map as the index of the output (sparse).<br>One of 'DENSE', 'SPARSE'.
indice_tensor != nullptr
indices
Indices
Indices and updates must have the same rank
Indices dim=
indices element out of data bounds, idx=
Indices must have the same rank as Input. Indices rank=
Indices tensor from max pooling across the input tensor. The dimensions of indices are the same as output tensor. The values in indices of are the indices of the selected values during pooling. The indices are computed as flatten 1-D tensor, and the indices do not consider padding. So the values in indices are in [0, N x C x D1 x ... x Dn).
indices tensor must has rank larger than 0
Indices tensor must have rank >= 1
Indices vs updates dimensions differs at position=
IndicesTensor
ineIu
Inferred elem type differs from existing elem type: (
Inferred shape and existing shape differ in dimension 
Inferred shape and existing shape differ in rank: (
info.GetAttr("alpha", &alpha_).IsOK()
info.GetAttr("beta", &beta_).IsOK()
info.GetAttr("blocksize", &blocksize_).IsOK()
info.GetAttr("direction", &direction).IsOK()
info.GetAttr("direction", &direction_).IsOK()
info.GetAttr("hidden_size", &hidden_size_).IsOK()
info.GetAttr("hidden_size", &int64_value).IsOK() && int64_value > 0
info.GetAttr("keepdims", &keepdims).IsOK()
info.GetAttr("linear_before_reset", &int64_value).IsOK()
info.GetAttr("scale", &scale_).IsOK()
info.GetAttr<float>("alpha", &alpha_).IsOK()
info.GetAttr<float>("beta", &beta_).IsOK()
info.GetAttr<float>("high", &high_).IsOK()
info.GetAttr<float>("low", &low_).IsOK()
info.GetAttr<float>("mean", &mean_).IsOK()
info.GetAttr<float>("scale", &scale_).IsOK()
info.GetAttr<float>("spatial_scale", &spatial_scale_).IsOK()
info.GetAttr<int64_t>("across_channels", &across_channels_).IsOK()
info.GetAttr<int64_t>("axis", &axis_).IsOK()
info.GetAttr<int64_t>("batch_axis", &batch_axis).IsOK()
info.GetAttr<int64_t>("count_include_pad", &temp).IsOK()
info.GetAttr<int64_t>("default_int64", &default_int_).IsOK()
info.GetAttr<int64_t>("dtype", &dtype).IsOK()
info.GetAttr<int64_t>("max_map", &max_map_).IsOK()
info.GetAttr<int64_t>("n_targets", &n_targets_).IsOK()
info.GetAttr<int64_t>("normalize_variance", &normalize_variance_).IsOK()
info.GetAttr<int64_t>("num_scan_inputs", &num_scan_inputs_).IsOK()
info.GetAttr<int64_t>("p", &p_).IsOK()
info.GetAttr<int64_t>("sample_size", &num_samples_).IsOK()
info.GetAttr<int64_t>("size", &size).IsOK()
info.GetAttr<int64_t>("targets", &targets_).IsOK()
info.GetAttr<int64_t>("time_axis", &time_axis).IsOK()
info.GetAttr<int64_t>("transA", &temp).IsOK()
info.GetAttr<int64_t>("transB", &temp).IsOK()
info.GetAttr<ONNX_NAMESPACE::GraphProto>("body", &proto).IsOK()
info.GetAttr<ONNX_NAMESPACE::GraphProto>("else_branch", &proto).IsOK()
info.GetAttr<ONNX_NAMESPACE::GraphProto>("then_branch", &proto).IsOK()
info.GetAttr<std::string>("auto_pad", &auto_padding).IsOK()
info.GetAttr<std::string>("cast_to", &attr).IsOK()
info.GetAttr<std::string>("default_string", &default_string_).IsOK()
info.GetAttr<std::string>("map_form", &attr).IsOK()
info.GetAttr<std::string>("mode", &mode).IsOK()
info.GetAttr<std::string>("norm", &norm).IsOK()
info.GetAttr<T>("max", &max_).IsOK()
info.GetAttr<T>("min", &min_).IsOK()
info.GetAttrs("activations", activations_).IsOK()
info.GetAttrs("axes", axes_).IsOK()
info.GetAttrs(std::is_same<AttrType, std::string>::value ? "string_vocabulary" : "int64_vocabulary", vocabulary_).IsOK()
info.GetAttrs<float>("bias", bias_).IsOK()
info.GetAttrs<float>("coefficients", coefficients_).IsOK()
info.GetAttrs<float>("kernel_params", kernel_params).IsOK()
info.GetAttrs<float>("rho", rho_).IsOK()
info.GetAttrs<float>("scales", scales_).IsOK()
info.GetAttrs<int64_t>("cats_int64s", int_categories).IsOK()
info.GetAttrs<int64_t>("kernel_shape", kernel_shape_).IsOK()
info.GetAttrs<int64_t>("pooled_shape", pooled_shape).IsOK()
info.GetAttrs<int64_t>("shape", shape).IsOK()
info.GetAttrs<std::string>("cats_strings", string_categories).IsOK()
info.GetAttrs<std::string>("classes_strings", string_classes).IsOK()
info.GetAttrs<std::string>("classlabels_strings", classlabels_strings_).IsOK() || info.GetAttrs<int64_t>("classlabels_ints", classlabels_ints_).IsOK()
Inherited
Initial values of the loop's N state variables followed by M scan_inputs
initial_c
initial_h
initial_state_and_scan_inputs
initialize preallocated buffer failed
InitializeConditionVariable
InitializeCriticalSection
InitializeCriticalSectionAndSpinCount
InitializeCriticalSectionEx
Initialized tensor with unexpected type: 
InitializeSListHead
InitializeSRWLock
Initializing session.
InitOnceBeginInitialize
InitOnceComplete
InitOnceExecuteOnce
input
Input 
input 
input \in [a_0, a_1, ..., a_{k-1}, a_k, ..., a_{n-1}] and k is
Input and output types can be of any tensor type.
input and zero_point pair is expected to have be same type.
input and zero_point pair is expected to have same type.
Input axes has incorrect length
Input axes has invalid data
Input axis is invalid: 
Input B must have shape {
Input can be of any tensor type.
Input cannot be split evenly on selected axis. Input shape=
Input channels C is not equal to kernel channels * group.
Input channels is not divisible by group.
Input contains invalid utf8 chars at: 
input count mismatch
input count mismatch, expected 1 input - the tensor to be processed
input count mismatch, expected 2 inputs - the tensor to be processed and a tensor containing k value
Input count of Tile OP mismatch, the first one is empty
Input count of Tile OP mismatch, the second one is empty
Input data
Input data tensor containing the indices corresponding to elements in the first input tensor X.This tensor is typically the second output of the MaxPool op.Dimensions must be the same as input tensor X. The indices are linear, i.e. computed considering the tensor as flattened 1-D tensor, assuming row-major storage. Also, the linear indices should not consider padding. So the values in indices are in the range [0, N x C x D1 x ... x Dn).
Input data tensor from previous layer; has size (N x C x H x W), where N is the batch size, C is the number of channels, and H and W are the height and width. Note that this is for the 2D image. Otherwise the size is (N x C x D1 x D2 ... x Dn)
Input data tensor from previous layer; has size (N x C x H x W), where N is the batch size, C is the number of channels, and H and W are the height and width. Note that this is for the 2D image. Otherwise the size is (N x C x D1 x D2 ... x Dn). Optionally, if dimension denotation is in effect, the operation expects input data tensor to arrive with the dimension denotation of [DATA_BATCH, DATA_CHANNEL, DATA_FEATURE, DATA_FEATURE ...].
Input data tensor from the previous operator; 4-D feature map of shape (N, C, H, W), where N is the batch size, C is the number of channels, and H and W are the height and the width of the data.
Input data tensor from the previous operator; dimensions are in the form of (N x C x D1 x D2 ... Dn), where N is the batch size, C is the number of channels. Statistics are computed for every channel of C over N and D1 to Dn dimensions. For image data, input dimensions become (N x C x H x W). The op also accepts single dimension input of size N in which case C is assumed to be 1
Input data tensor from the previous operator; dimensions for image case are (N x C x H x W), where N is the batch size, C is the number of channels, and H and W are the height and the width of the data.
Input data tensor from the previous operator; dimensions for image case are (N x C x H x W), where N is the batch size, C is the number of channels, and H and W are the height and the width of the data. For non image case, the dimension are in the form of (N x C x D1 x D2 ... Dn), where N is the batch size.
Input data tensor from the previous operator; dimensions for image case are (N x C x H x W), where N is the batch size, C is the number of channels, and H and W are the height and the width of the data. For non image case, the dimensions are in the form of (N x C x D1 x D2 ... Dn), where N is the batch size.
Input data tensor from the previous operator; dimensions for image case are (N x C x H x W), where N is the batch size, C is the number of channels, and H and W are the height and the width of the data. For non image case, the dimensions are in the form of (N x C x D1 x D2 ... Dn), where N is the batch size. Optionally, if dimension denotation is in effect, the operation expects the input data tensor to arrive with the dimension denotation of [DATA_BATCH, DATA_CHANNEL, DATA_FEATURE, DATA_FEATURE ...].
Input data tensor that has to be unpooled. This tensor is typically the first output of the MaxPool op.Dimensions for image case are (N x C x H x W), where N is the batch size, C is the number of channels, and H and W are the height and the width of the data. For non-image case, the dimensions are in the form of (N x C x D1 x D2 ... Dn), where N is the batch size. Optionally, if dimension denotation is in effect, the operation expects the input data tensor to arrive with the dimension denotation of [DATA_BATCH, DATA_CHANNEL, DATA_FEATURE, DATA_FEATURE ...].
Input data to be scaled
Input data with index: 
Input data.
Input data. It can be either tensor or scalar.
Input 'depth' must be rank 1 tensor.
Input 'depth' must have exactly one element.
Input dimension cannot be less than 3.
Input dimensions are either [C] or [N][C] allowed
Input dimensions are either[C > 0] or [1][C > 0] allowed
Input does not need to explicitly be a 2D vector; rather, it will be
Input element type of 
Input features_per_batch[
Input for n-gram extraction
Input initial_c must have shape {
Input initial_h must have shape {
Input is ether string UTF-8 or int32/int64
Input is expected to have four dimensions corresponding to [N,C,H,W]
Input is expected to have four dimensions corresponding to [N,C,H,W], got 
Input is missing. The operator Cast expects one and only one input
Input matrix
'input' must have rank >= 2
Input of int64 must have output of string 
Input of shape [N,F]
Input of string must have output of int64
Input of tensor(int64) must have output of tensor(string)
Input of tensor(string) must have output of tensor(int64)
Input P must have shape {
Input R must have shape {
Input scales's element type must be float.
Input sequence_lens must have shape {
Input shape must have either [C] or [1,C] dimensions where C > 0
Input shape must have either [C] or [B,C] dimensions with B > 0.
Input shape needs to be at least a single dimension.
Input steps has incorrect length
Input string contains invalid utf8 chars: 
Input tensor
Input tensor A
Input tensor A. The shape of A should be (M, K) if transA is 0, or (K, M) if transA is non-zero.
Input tensor B
input tensor B has shape (K, N) or (N, K), input tensor C is broadcastable to shape (M, N),
Input tensor B. The shape of B should be (K, N) if transB is 0, or (N, K) if transB is non-zero.
Input tensor C
Input tensor C, can be inplace.
Input tensor C. The shape of C should be unidirectional broadcastable to (M, N).
Input tensor can be of arbitrary type.
Input tensor containing indices. The values must be non-negative integers. Any entries in the 'indices' input tensor with values outside the range [0, depth) will result in one-hot representation with all 'off_value' values in the output tensor.In case 'indices' is of non-integer type, the values will be casted to int64 before use.
Input tensor expected to contain int64 data
Input tensor has no dimensions
Input tensor must be 2-dimensional
Input tensor must be 4-dimensional
Input tensor must have at least 2 dimensions
Input tensor must have atleast 2 dimensions
Input tensor must have rank 1 or 2
Input tensor must have rank 2
Input tensor of [N,C,H,W], where N is the batch axis, C is the channel or depth, H is the height and W is the width.
Input tensor of any shape broadcastable to X shape, the exponent component.
Input tensor of any shape, base of the exponent.
Input tensor of any shape.
Input tensor of shape [N,C,H,W]
Input tensor to be cast.
Input tensor to copy shape and optionally type information from.
Input tensor to Unique op should be 1D
Input tensor whose elements to be clipped
Input tensor with shape [batch_size, class_size], where class_size is the number of all possible outcomes. Each value along the axis zero represents the unnormalized log-probability of each corresponding outcome in a batch.
input tensor X
Input tensor X must have atleast 2 dimensions.
Input tensor.
Input tensors of wrong rank (0).
Input type is not float tensor but keys_floats is set
Input type is not int64 tensor but keys_int64s is set
Input type is not string tensor but key_strings is set
Input type was null
Input types for the Shrink operator are constrained to all numeric types only. Got bool type here.
Input types for the Shrink operator are constrained to all numeric types only. Got std::string type here.
Input 'values' must be rank 1 tensor.
Input 'values' must have exactly two elements.
Input W must have shape {
Input was expected to have tensor type. Got 
Input X must be 4-dimensional.
Input X must have 3 dimensions only. Actual:
input.Shape().NumDimensions() == 4
Input/Output is a string tensor
input_as_shape
input_count >= 0 && static_cast<size_t>(input_count) == input_dimensions_.size()
input_count >= 1
input_depth % (blocksize_ * blocksize_) == 0
input_dims.size() >= 2
input_forget
input_height % this->blocksize_ == 0
input_shape.NumDimensions() <= 2
input_shape.Size() > 0
input_shape[i] == 1
input_tensor != nullptr
input_tensor_ptr != nullptr
input_width % this->blocksize_ == 0
InputCount
inputCount
inputCount >= 1
inputdimensions
inputdimensions attribute must be provided
inputs
Inputs
inputs are expected to have tensor type and output type should not be null.
inputs are expected to have tensor type.
Input's height (
Input's width (
inputs_n_rank == inputs_0_rank
InputTensor
InputTensors
InputVideoFrame
Inscriptional_Pahlavi
Inscriptional_Parthian
InstanceNormalization
Insufficient dimensions to slice on 
int16
Int16
int32
Int32
int32_data
int64
Int64
Int64 tensor
int64_data
int64_vocabulary
int8@
Integer indicate the format of the box data. The default is 0.0 - the box data is supplied as [y1, x1, y2, x2] where (y1, x1) and (y2, x2) are the coordinates of any diagonal pair of box cornersand the coordinates can be provided as normalized (i.e., lying in the interval [0, 1]) or absolute. Mostly used for TF models.1 - the box data is supplied as [x_center, y_center, width, height]. Mostly used for Pytoch models.
Integer representing the embedding vector size for each char.If not provide, use the char embedding size of embedding vector.
Integer representing the embedding vector size for each word.If not provide, use the fileter size of conv weight
Integer representing the maximum number of boxes to be selected per batch per class. It is a scalar.
intercepts
InterlockedPushEntrySList
Internal error in BatchNormalizationMulFusion. BatchNormalization_B_tensor_proto is NULL
Internal error in ConvMulFusion. conv_B_tensor_proto is NULL
Internal error.
Internal error. The preallocated buffer is too small. Requires 
InternalName
InterpolationMode
interrupted
Invalid activation function of 
Invalid allocation info. Provider name = 
Invalid allocation kind: 
invalid allocator
Invalid arg_num of 
invalid argument
Invalid argument for depth; it's not a scalar.
Invalid argument for values; either it's rank is more than 1 or it has more than 2 elements
Invalid argument: input has empty dimensions.
Invalid argument: X input has empty dimensions.
Invalid attribute perm {
Invalid axes attribute, axes attribute (if present) should have the same size as starts/ends attributes
Invalid batch_axis of 
Invalid CAST_TO value of 
invalid character class
invalid character class range
Invalid data type for GRU operator of 
Invalid data type for LSTM operator of 
Invalid data type of 
Invalid destination node arg slot specified when adding edge.
Invalid destination node arg slot specified when removing edge.
Invalid dim0_offset of 
Invalid dimension of 
Invalid dimension value: 
Invalid 'direction' argument of '
Invalid dtype of 
Invalid entries in sequence_lens. Max sequence length was 
invalid escape sequence
Invalid Feed Input Name:
Invalid GRU hidden gate activation function: 
Invalid GRU reset gate activation function: 
invalid hash bucket count
invalid index 
invalid indice found, indice = 
Invalid input B: 0th dimension != 
Invalid input B: number of dimensions is not 1: 
Invalid input B: NumDimensions() != 
Invalid input data: number of dimensions is less than 3: 
Invalid input image height provided. Height is set to zero.
Invalid input image height provided. Width is set to zero.
Invalid input image width provided. Height is set to zero.
Invalid input mean: 0th dimension != 
Invalid input mean: NumDimensions() != 
Invalid input scale: 0th dimension != 
Invalid input scale: number of dimensions is not 1: 
Invalid input scale: NumDimensions() != 
Invalid input shape: 
Invalid input type of 
Invalid input type of value: 
Invalid input type:
Invalid input var: 0th dimension != 
Invalid input var: NumDimensions() != 
Invalid input X: Empty dimensions
Invalid LSTM merge activation function of 
Invalid 'mode' attribute value
Invalid mode of value 
Invalid mode of value: 
invalid named capture group
Invalid node indexes specified when adding edge.
Invalid node indexes specified when removing edge.
Invalid normalize value of 
invalid ort_value_index:
Invalid Output Name:
Invalid PACK_MAP value of 
Invalid 'pads' attribute value
invalid perl operator
Invalid position of 0
Invalid RE2: 
invalid repetition size
Invalid scan input:
invalid seek
Invalid shape value: 
Invalid source node arg slot specified when adding edge.
Invalid source node arg slot specified when removing edge.
invalid stod argument
invalid stof argument
invalid stoi argument
invalid stol argument
invalid stoll argument
invalid stoul argument
invalid stoull argument
invalid string position
Invalid Target shape product of 0
Invalid tensor shape slice argument.
Invalid TensorProto
Invalid time_axis of 
Invalid type
Invalid type of the input argument
invalid unordered_map<K, T> key
invalid UTF-8
Invalid value for attribute axis
Invalid value for attribute k
Invalid value in scan_input_axes for input 
Invalid value in scan_output_axes for output 
Invalid value in 'split' attribute. All values must be > 0
Invalid value of attribute 'axis'
Invalid value(
Invalid value/s in sequence_lens. All values must be > 0 and < seq_length. seq_length=
Invalid values in '
invalid vector<T> subscript
Invalid Y argument: index is out of range: Y[
Invalid Y argument: num_indices = 0
INVALID_ARGUMENT
INVALID_GRAPH
INVALID_PROTOBUF
io error
ios_base::badbit set
ios_base::eofbit set
ios_base::failbit set
iostream
iostream stream error
iou_threshold
iou_threshold must be in range [0, 1].
is a directory
is applied to the data tensor elementwise.
'is defined.
is_case_sensitive
is_concrete_shape_
is_test
isalpha
isCpu
IsDebuggerPresent
isdigit
IsInf
islower
IsNaN
IsNan
IsProcessorFeaturePresent
IsScalarOr1ElementVector(&x_scale)
IsScalarOr1ElementVector(&x_zero_point)
IsScalarOr1ElementVector(&y_scale)
IsScalarOr1ElementVector(&y_zero_point)
isspace
isupper
iswspace
it != indices.end()
it != parents.end()
iteration_num_ < sequence_len_
iWidth
IXI+IPH
J&WTh
Javanese
JHI;J0u#A
job_.size() = 
JWindows::AI::MachineLearning::TensorMemoryBufferReference<unsigned char>::Capacity
JXH+JPH
JxLcJpI
k <= dims.size()
k argment [
K H+K
K H99t
K input must be a one-dimensional tensor of size 1.
K input must be of type int64.
K SUVWAVAWH
K t"H
k tensor should be a 1D tensor of size 1
K(H99t
K@H;H@t43
K@H9>t.H
K@t"H
k_temp > 0
K`H+KXH
K09H0
K0H99t
K0Hcs(H
K32GetProcessMemoryInfo
K8D8CXtSI
K8H+K0I
K8H99t
K8Hc@
Kaithi
Kannada
Katakana
Kayah_Li
Keep the reduced dimension or not, default 1 mean keep reduced dimension.
keepdims
keepdimsH
kernel != nullptr
Kernel creation failed for node: 
kernel_create_info != nullptr && kernel_create_info->kernel_def != nullptr
kernel_params
kernel_shape
kernel_shape is not compatible with W shape.
kernel_shape num_dims is not compatible with W num_dims.
kernel_shape num_dims is not compatible with X num_dims.
kernel_shape_[dim] > 0
kernel_type
KERNEL32.DLL
kernel32.dll
kernelbase.dll
key_type
keys_floats
keys_int64s
keys_strings
Kharoshthi
KhL9RXt
Khmer
Khojki
Khudawadi
known by the checker.
kRegexpCapture cap() == 0
KxLcKpI
L!|$@I
L!l$03
L!l$PL!m
L!l$X
L!l$x3
L!T$@E8T$X
L!t$`H
L#I0L
l$ 8\$(
l$ E3
L$ E3
L$ H;
L$ H+
L$ Hc
L$ I;
l$ L;L$h
L$ M;
L$ SUVWH
L$ SVWATAUAVAWH
L$ SWH
L$ UH
L$ UVWATAUAVAWH
L$ UWAVH
l$ VWATAVAWH
l$ VWAUAVAWH
l$ VWAVH
L$(@8|$0t
L$(A8y8tcH
L$(H;
L$(H+
L$(H+L$ H
L$(H3
L$(I;
L$(I+
L$(Lc
L$@;W
L$@A8_pt
L$@D8a$
L$@D8B8
l$@D8i
L$@E3
l$@E3
L$@E3
l$@E3
L$@H;
L$@H+
L$@H3
L$@H9S
L$@I;
L$@I+
L$@L;
l$@Lc
L$@Lc
l$\Ic
L$`A8
L$`E3
l$`fD
L$`H;
L$`H;L$ht
L$`H;M
L$`H;N
L$`H+
L$`H+L$XH
L$`H3
L$`Hc
L$`Hi
L$`I;
l$`Ik
L$`J;D
L$`L;
L$`L+
L$`M+
l$|E;~
l$0D8
L$0E3
L$0fD
L$0H;
l$0H;
L$0H;
L$0H;N
L$0H+
L$0H+L$(H
L$0H3
L$0H9L$Pt
L$0Hc
L$0I;
L$0I;L$
L$0I;Ppu8I
L$0I+
L$0L;
l$0L9\$
l$0M9o
l$4D8d$2u
l$4E;
L$4H;
L$89u
L$89X(
L$8D;~P
l$8D;l$<
L$8D9u8~lM
L$8E3
L$8fD
L$8H!L$`L
L$8H;
l$8H+
L$8H3
L$8H9L$@t
L$8H9L$0
L$8H9L$ht
L$8I;
L$8I+
l$8IcE
L$8L;
L$8L9L$Xt
L$8Mc
L$D Hc|$HH
L$DHcP
L$h@"
L$HD;
L$hE3
L$HE3
L$hE3
l$HE3
L$hE3
L$HE3
L$hE3
L$HE3
L$HfH
L$HH;
L$hH;
L$HH;
L$hH;
L$hH+
L$HH+
L$hH+
L$HH+
L$hH+L$`H
L$HH3
L$hH3
L$HH3
L$hH3
L$HH3
L$hH3
L$HH3
L$hH3
L$HH3
L$hH3
L$HH3
L$hH3
L$HH3
L$hH3
L$HH3
L$hH3
L$HH3
L$hH3
L$HH3
L$hH3
L$HH3
L$hH3
L$HH3
L$hH9
L$hH9L$pu'H
l$HHi
l$HHk
L$HI;
L$hI;
l$HI;
L$HI+
L$hI+
L$HI+
l$HIi
l$HIk
L$hL)
L$hL;
L$HL;
L$hL;
l$HL;m
L$HL+
l$HL+
L$hM;
L$HM;
L$hM;
L$ht!H
l$LD;
l$PA_A^A]A\_^
L$pE3
L$PE3
L$pE3
L$PE3
L$pE3
L$PE9M 
L$PfD
L$PfH
L$PH;
L$pH;
L$PH;
L$PH+
L$pH+L$`H
L$pH+L$hH
L$PH+L$HH
L$PH3
L$pH3
L$PH3
L$pH3
L$PH3
L$pH3
L$PH3
L$pH3
L$PH3
L$pH3
L$PH3
L$pH3
L$PH3
L$pH3
L$PH3
L$pH3
L$PH3
l$pHcA
L$PI;
L$pI+
l$pL;
L$PL;
l$PL;
L$PL;
L$pL;
L$PL;
L$PL;!
L$PL;9
L$PL+
L$PL9d$X
L$PL9t$pt
l$pLc
L$pLc
L$pM;
l$pM+
L$xE3
L$XE3
L$xE3
L$XE3
L$xE3
l$XE3
L$xE3
L$xH;
L$XH;
L$xH;
L$XH;
L$xH;M
L$xH;NX
L$XH+
L$xH+
L$XH+
L$xH+L$pH
L$XH+L$PH
L$XH3
L$xH3
L$XH3
L$xH3
L$XH3
L$xH3
L$XH3
L$XH9L$`t
L$XH9L$`t:L
L$XH9L$`t7L
L$xHc
l$XIk
L$XL;
l$XL;
l$xL;
L$XL;
L$xL9~XL
l$xM+
L)h u
L)l$`
L;@ }
L;@ A
L;@ s
L;\$hL
L;|$(
L;|$`
L;|$0H
L;|$0u<H
L;|$huaI
L;|$pu
L;|$X
L;~ r
L;~0H
L;A H
L;A s
L;B }
L;C }NH
L;C }QH
L;C sNH
L;D$(uYH
L;D$0u
L;d$8s
L;d$puDH
L;JHsK
L;JHwbA
L;L$ L
L;L$(|
L;L$(A
L;L$(t
L;L$0u
L;l$h
L;l$P
L;l$p
L;L$pH
L;l$pL
L;P s
L;q s
L;t$ s
L;T$@|
L;T$H
L;t$Hs
L;Z s
l?4?~?
l?4?~?4?~?4?~?4?~?
L+!M+
L+)I+
L+9H+]
L+A0H
L+A8H
L+APH
L+F(3
L+F0I
L+Q8E3
L+Q8H
L>2?~>2?~>2?~>2?~>
L1 norm
L2 norm
L9 ~yH
L9 t1L
L9#udH
L9#uYH
'L9&t
L9(u2H
L9)tjH
L9.t`LcK$E3
L9;u+H
L9@ }
L9@ s
L9{ht1H
L9|$ t
L9|$(t
L9|$@
L9|$0t%
L9|$h
L9|$Ht
L9|$Pt
L9|$Xt
L9}g~,L
L9}Ht
L9=|J6
L9=Bs6
L9=tI6
L9>uBH
L90u H
L92uQL
L97tr
L98~2H
L98u0H
L9A s
L9A t
L9A(L
L9cx~&H
L9d$ uML
L9D$(
L9d$(t
L9d$@t
L9d$`t
L9d$0
L9d$0s
L9d$0t
L9d$8
L9d$8s
L9d$8t
L9d$8u
L9d$8u$H
L9d$Ht
L9D$ht+H
L9d$Pt
L9d$pt
L9d$Pt
L9d$pt
L9d$Pt
L9d$pt
L9d$Pt
L9d$pt
L9d$Pt
L9d$pt
L9D$XL
L9d$xt
L9d$Xt
L9d$xt
L9d$Xt
L9d$xt
L9d$Xt
L9d$xt
L9E`u
L9e`u
L9E`u
L9Eg~,
L9ePu@H
L9Ewu L
L9EX~*D
L9eX~7H
L9fht1H
L9g t
L9H }
L9i0H
L9i8t
L9iht
L9iHt
L9IHu
L9ixt
L9iXt
L9j(H
L9j(t
L9j0L
L9k t
L9l$@
L9l$0
L9l$0t
L9L$8t
L9l$8w
L9l$h
L9l$H
L9l$Ht
L9l$ht
L9l$Ht
L9l$htZH
L9l$p
L9l$Pt
L9L$Pt
L9l$Xv
L9mHt
L9mPt
L9mXt
L9n tA
L9RXt
L9S t
L9s t
L9s u%H;
L9s u=D8
L9t$(
L9t$@
L9t$@uHH
L9t$`
L9t$`t
L9t$0
L9t$8
L9t$H
L9t$Pt
L9t$pt
L9t$Xt
L9t$xt$3
L9u@t
L9uHt
L9x(H
L9y8t
L9yHt
L9yXt
L9z0L
Label encoder has only one input.
Label encoder has only one output.
LabelEncoder
lambd
last dimension of indices must not be larger and rank of data tensor
last dimension of indices must not be larger than rank of input tensor
Latin
Layout conversion
Lc:I;
Lc{(M
Lc{@M
Lc|$H
LcA$H
LcC$M
LcC0A
LcD$@I
LcD$`L9A
LcD$xH
Lce M
LcF H
LcF$H
LcF(I
LcF@I
Lcg M;
Lcg$M
LcG(I
LcG@H
LcG@I
LcG@M
LcGpI
Lch H
LcI,L
LcJ(H
LcJ@H
LcJ`L;L$ht
LcJHIc
LcK$A+
LcL$0E
Lcl$XL;oX
LCMapStringEx
LcMwI
LcO$A
LcQ A
Lcr(I
Lcr@I
Lcr@K
LcrpI
Lcs M
Lcs`M
Lcs8M
LcsPM
Lct$ L
LcT$(M
LcT$TE;
LD$XL
lda >= K && ldb >= K && ldc >= N
ldexp
LDXBCd
leaky_relu_
leaky_relu_alpha
leakyrelu
LeakyRelu
LeaveCriticalSection
Left input tensor for the logical operator.
left operand cannot broadcast on dim 
left.NumDimensions() == 2 || left.NumDimensions() == 1
legacy optimization attribute.
LegalCopyright
len <= op_schema.inputs().size()
len > 0
length
length of each output
length overflow
Lepcha
Level
Limbu
limit
limit in Range operator should be scalar like tensor, yet got shape:
Linear
linear
LINEAR
Linear_A
Linear_B
linear_before_reset
LinearBeforeReset
LinearClassifier
LinearRegressor
lineNumber
list count 
List of 3 elements containing gamma, coef0, and degree, in that order. Zero if unused for the kernel.
List of categories, ints.<br>One and only one of the 'cats_*' attributes must be defined.
List of categories, strings.<br>One and only one of the 'cats_*' attributes must be defined.
list of floats. This attribute stores the weight of each n-gram in pool. The i-th element in weights is the weight of the i-th n-gram in pool. Its length equals to the size of ngram_indexes. By default, weights is an all-one tensor.This attribute is used when mode is "IDF" or "TFIDF" to scale the associated word counts.
List of int64 n-grams learned from the training set. Either this or pool_strings attributes must be present but not both. It's an 1-D tensor starting with the collections of all 1-grams and ending with the collections of n-grams. The i-th element in pool stores the n-gram that should be mapped to coordinate ngram_indexes[i] in the output vector.
list of int64s (type: AttributeProto::INTS). This list is parallel to the specified 'pool_*' attribute. The i-th element in ngram_indexes indicate the coordinate of the i-th n-gram in the output tensor.
List of integers indicate the padding element count at the beginning and end of each axis, for 2D it is the number of pixel. `paddings` rank should be double of the input's rank. `paddings` format should be as follow [x1_begin, x2_begin...x1_end, x2_end,...], where xi_begin the number of pixels added at the beginning of axis `i` and xi_end, the number of pixels added at the end of axis `i`.
List of integers indicating the number of padding elements to add or remove (if negative) at the beginning and end of each axis. For 2D it is the number of pixels. `pads` rank should be double of the input's rank. `pads` format should be as follow [x1_begin, x2_begin...x1_end, x2_end,...], where xi_begin the number of pixels added at the beginning of axis `i` and xi_end, the number of pixels added at the end of axis `i`.
List of non-negative integers, indicate the dimensions to be inserted
List of non-negative integers, indicate the dimensions to squeeze.
List of stop words. If not set, no word would be removed from X.
List of strings n-grams learned from the training set. Either this or pool_int64s attributes must be present but not both. It's an 1-D tensor starting with the collections of all 1-grams and ending with the collections of n-grams. The i-th element in pool stores the n-gram that should be mapped to coordinate ngram_indexes[i] in the output vector.
List of tensors for 
List of tensors for concatenation
List of tensors for Max.
List of tensors for Mean.
List of tensors for Min
List of tensors for Sum.
LoadLibraryA
LoadLibraryExA
LoadLibraryW
loadModelCounters
Local\SM0:%d:%d:%hs
locale
localeconv
LocalSize
localtime_s(&local_tm, &in_time_t) == 0
location
log of softmax
log sum
log sum exponent
log_stream.str().c_str()
log2f
LogHr
LOGISTIC
LOGISTICL9
logsoftmax
LogSoftmax
Loop 'body' subgraph outputs should all be tensors but output 
'Loop' node has 
LOWER
Lower boundary of the output values.
lp pool
LpNormalization
LpPool
lstd::exception: %hs
LSTM operator does not support double yet
Lt$XL
Lycian
Lydian
M 9H 
M H1E
M H9M(t
M L)u
M McE
M#}0M
M#J0M
M(;y |
M(;Y8|
M(D9q ~*I
M(L9 
M(L9 u,H
M/H+M'H
M;H I
M;P M
M@H+M8H
M_ >= 0 && K_ > 0 && N_ >= 0
M_E;H
M_H9t$@uNL
m_runtimeSessionId
M`E9e$
M+,$I
M+4$I
M9(tDH
M9,$t
M9,$t_H
M9.t&
M9/t$
M9<$t
M9<$u
M90tNM
M94$t(I
M97t'I
M9H }
M9H s
M9h0I
M9l$(I
M9l$(M
M9n t
M9n(I
M9n(M
M9P s
M9SXt
M9u8tE
M9YXt
M9ZXt
Mahajani
Main Graph instance should have populated all subgraphs when being resolved.
Makasar
Malayalam
Malformed onnx file.
Malformed repeat 
malloc
Mandaic
Manichaean
Map with key type: 
map(int64, double)
map(int64, float)
map(int64, string)
map(string, double)
map(string, float)
map(string, int64)
map/set<T> too long
map_form
map_form_ != PACK_MAP::SPARSE || max_map_ > 0
map_formH
Marchen
Masaram_Gondi
Match contains invalid utf8 chars: 
MatMul
MatMul dimension mismatch
MatMulAddFusion
MatMulInteger
Matrix after normalization
Matrix multiply results from A * B
max_gram_length
max_gram_length must be inbounds of ngram_counts: 
max_map
max_map must be > 0 if map_form is SPARSE
max_output_boxes_per_class
max_skip_count
max_skip_count is required
max_skip_count must be non-negative: 
maxCpuUsage
Maximum n-gram length. If this value is 3, 3-grams will be used to generate the output.
Maximum number of events reached, could not record profile event.
Maximum number of items (integers/strings) to be skipped when constructing an n-gram from X. If max_skip_count=1, min_gram_length=2, max_gram_length=3, this operator may generate 2-grams with skip_count=0 and skip_count=1, and 3-grams with skip_count=0 and skip_count=1
Maximum value, above which element is replaced by max
maxPageFaultCount
MaxPool
MaxpoolWithMask
MaxRoiPool
maxTime
MaxUnpool
MaxUnpool op must have either two or three inputs.
maxWorkingSetMemory
MC:\apilot\agent\_work\2\s\winml\dll\TensorMemoryBufferReference.h
Mc|$ H
McFpH
McFTL
Mcg M;
McGTL
Mcl$ L
Mco D
Mco I
Mco L
McP(I
McP@I
McPpI
Mcw H
ME9`(
MeanTensor
MeanVarianceNormalization
Medefaidrin
Meetei_Mayek
Mem pattern for initializer 
mem_steps <= max_memory_steps_ && mem_steps > 0
memchr
memcmp
Memcpy
memcpy
MemcpyFrL9
MemcpyFromHost
MemcpyToH9
MemcpyToHost
MemcpyTransformer
memmove
Memory pattern planner is not enabled on this execution framework.
memory_seq_lens
memset
Mende_Kikakui
Meroitic_Cursive
Meroitic_Hieroglyphs
message
message size
message.Category()
message.Location().ToString(onnxruntime::CodeLocation::kFilenameAndPath).c_str()
message.Message().c_str()
metaDataCount
metaDataKeys
metaDataValues
MGH+M?H
MgIcQ8H
M'H;M/
MH9L8
MHH;A
MHI+M@H
Microsoft
Microsoft (R) HLSL Shader Compiler 10.1
Microsoft Corporation
Microsoft.Windows.AI.MachineLearning
min_gram_length
min_gram_length >= max_gram_length required: 
min_gram_length is required
min_gram_length must be inbounds of ngram_counts: 
minATL$__a
minATL$__m
minATL$__z
mincharnum
mincharnum is too big for char level tokenezation
mincharnum_ > 0
minCpuUsage
Minimum n-gram length. If this value is 2 and max_gram_length is 3, output may contain counts of 2-grams and 3-grams.
Minimum number of characters allowed in the output. For example, if mincharnum is 2, tokens such as "A" and "B" would be ignored
Minimum value, under which element is replaced by min
minPageFaultCount
minTime
minWorkingSetMemory
Mismatch between expected shape and shape from first output
Mismatch between input data and B: size of B != input channel count 
Mismatch between input data and scale: size of scale != input channel count 
Mismatch between number of source and target dimensions. Source=
Mismatched attribute type in '
Mismatched data types between input and output Tensors. 
Mismatched tensor element type for output 
Mismatched type for output 
missing )
missing ]
Missing case in Compiler: 
Missing input tensor to be processed
Missing Input: 
Missing opset in the model. All ModelProtos MUST have at least one entry that specifies which version of the ONNX OperatorSet is being imported.
Missing or invalid starts and ends attribute
Missing/Invalid 'axes' attribute value
Missing/Invalid 'axis' attribute value
Misuse of LoopStateVariable. Attempt to move beyond end of sequence
MKLDNNExecutionProvider
MLCreateOperatorRegistry
mode attribute is 
mode is required
mode: 
model format error!
model format error! Missing 'location'
model format error! Need a key for the external data info
model format error! Need a value for the external data info
Model image inputs must have tensor type of Float or Float16.
Model load
Model stream is invalid.
Model variable %s, expects %s, but binding was attempted with an incompatible type %s.
Model was not loaded
Model was not loaded.
MODEL_LOADED
model_loading_proto
model_run
ModelCreation
modelname
ModelProto does not have a graph.
ModelProto was null.
module
momentum
Mongolian
Msg:[%ws] 
Multani
multi_class
MultiByteToWideChar
Multinomial
multiplication
Multiplicative spatial scale factor to translate ROI coordinates from their input scale to the scale used when pooling.
Multiplicative spatial scale factor to translate ROI coordinates from their input spatial scale to the scale used when pooling, i.e., spatial scale of the input feature map X relative to the input image. E.g.; default is 1.0f. 
MurmurHash3
Must have 1 or more inputs
Must have a single dimension
Must have a single dimension of 1
Must have valid 'axis' attribute
Must provide classlabels_strings or classlabels_int64s but not both.
Must provide imputed_values_float_ or imputed_values_int64_ but not both.
mutually equal shape is specified by the argument "axis", and if it is not set,
mX9~ 
MXH+MPH
MXH+MPI
MXI+MPH
Myanmar
n >= 0 && static_cast<size_t>(n) < ml_value_info_.size()
n >= 0 && static_cast<size_t>(n) < plan_.allocation_plan.size()
N classes
N HcV
N I+N
N IcV
N LcV
N M+N
N$9H0
N, Top class for each point
N@H+N8H
N@I+N8H
n_supports
n_targets
n0L9l$0t
N8A+~
N8H+N0H
Nabataean
N-D full precision Input tensor to be quantized.
N-D full precision output tensor. It has same shape as input 'x'.
N-D quantized Input tensor to be de-quantized.
N-D quantized input tensor to be de-quantized.
N-D quantized output tensor. It has same shape as input 'x'.
N-D tensor
N-D tensor after resizing
nD$(f
nD$8f
NDHCW
NDHWC
N-dimensional matrix A
N-dimensional matrix B
N-dimensional quantized matrix a
N-dimensional quantized matrix b
nearbyintf
NEAREST
nearest
Negative index values are not permitted. First entry in map has index value of 
Negative ngram_indexes values are not allowed
Negative values are not allowed in a shape specification
network down
network reset
network unreachable
New shape
new_fetches.empty()
New_Tai_Lue
n-gram counts out of bounds for 
Ngram results
ngram_counts
ngram_indexes
ngram_indexes must be non-empty with no negative values
NGRAPHExecutionProvider
NhH;Npt
njob_ = 
nL$8f
nL$Xf
no argument for repetition operator
No attribute with name:'
No attribute with this name is defined.
no buffer space
no child process
no error
No Graph instance was found for attribute 
No graph was found in the protobuf.
No hardware adapters available
No kernel shape is set.
no link
no lock available
no message
no message available
no name
No Op registered for 
No opset import for domain '
no protocol option
No provider specified.
No ranges in char class
no space on device
no state
no stream resources
no such device
no such device or address
no such file or directory
no such process
No suitable kernel definition found for op 
No support vectors.
NO_MODEL
NO_SUCHFILE
Node (
Node id for each node. Ids may restart at zero for each tree, but it not required to.
Node id for each node. Node ids must restart at zero for each tree and increase sequentially.
node id that this weight is for.
Node:
node_arg
node_compute_funcs.size() == nodes_need_compile.size()
node_index < nodes_.size()
node_index_info_
node_offsets_index < node_offsets_.size()
NodeProto (name: 
Nodes in a graph must be topologically sorted, however input '
nodes_.size() < std::numeric_limits<int>::max()
nodes_falsenodeids
nodes_featureids
nodes_hitrates
nodes_id_size == nodes_falsenodeids_.size()
nodes_id_size == nodes_featureids_.size()
nodes_id_size == nodes_modes_.size()
nodes_id_size == nodes_truenodeids_.size()
nodes_id_size == nodes_values_.size()
nodes_missing_value_tracks_true
nodes_modes
nodes_nodeids
nodes_nodeids_.size() == nodes_falsenodeids_.size()
nodes_nodeids_.size() == nodes_featureids_.size()
nodes_nodeids_.size() == nodes_modes_names_.size()
nodes_nodeids_.size() == nodes_truenodeids_.size()
nodes_nodeids_.size() == nodes_values_.size()
nodes_treeids
nodes_truenodeids
nodes_values
nominalpixelrange
NominalRange_0_255
NominalRange_16_235
Non concat axis dimensions must match: Axis 
Non per-tensor quantization is not supported now.
NONE3
NONED
Non-empty ngram_counts is required
Non-empty ngram_indexes is required
non-empty pool_int64s is required if pool_strings not provided
NonMaxSuppression
NonZero
Non-zero status code returned while running Node: 
normalize_variance
normalized exponential
Normalized_0_1
Normalized_1_1
Normalizer
NormalizeVariance
not a directory
not a socket
not a stream
not connected
not enough memory
Not implemented
Not implemented field number 
Not implemented fused activation: 
Not satsified: (iou_threshold >= 0 && iou_threshold <= 1)
Not satsified: boxes_dims[0] == scores_dims[0]
Not satsified: boxes_dims[1] == scores_dims[2]
Not satsified: boxes_dims[2] == 4
Not satsified: boxes_shape.NumDimensions() == 3
Not satsified: data_n.DataType() == concat_result.DataType()
Not satsified: I_shape == X_shape
Not satsified: inferredOutputShape[dim] <= shape[dim]
Not satsified: inferredPad <= kernel_shape_[dim - 2]
Not satsified: input_count >= 1
Not satsified: input_dims >= 3
Not satsified: inputs_0_rank > 0
Not satsified: inputs_n_dims[axis_index] == inputs_0_dims[axis_index]
Not satsified: K_ == right_shape[0]
Not satsified: K_ == right_shape[right_num_dims - 2]
Not satsified: left_num_dims >= 1 && right_num_dims >= 1
Not satsified: left_padded_dims_[idx_dim] == 1
Not satsified: M_ == 1 && N_ == 1
Not satsified: num_dims_with_pad - 1 == num_output_dims
Not satsified: num_dims_with_pad - 2 == num_output_dims
Not satsified: num_dims_with_pad == num_output_dims
Not satsified: pooling_dims == kernel_shape_.size()
Not satsified: ret.IsOK()
Not satsified: right_padded_dims_[idx_dim] == 1
Not satsified: scores_shape.NumDimensions() == 3
Not satsified: tensor_shape->Shape().GetDims().size() == 1
Not satsified: x_shape.NumDimensions() >= 3
Not satsified: X_shape.NumDimensions() >= 3
not support normalize yet.
not supported
NOT_IMPLEMENTED
Notations:
NOTSET
NPH+NHH
NpH+NhH
NPH+NHH
nT$(f
nT$pf
ntdll.dll
ntelA
nteltd
Null input ptr
Null input X ptr
Null rois_ptr
NULL state in RunStateOnByte
nullptr != ends_tensor && ends_tensor->Shape().NumDimensions() == 1
nullptr != graph_viewer
nullptr != start_tensor && start_tensor->Shape().NumDimensions() == 1
nullptr != sub_graph && nullptr != sub_graph->GetMetaDef()
nullptr != tensor_type_base
nullptr != type_proto
nullptr == axes_tensor || start_tensor->Shape() == axes_tensor->Shape()
nullptr == steps_tensor || start_tensor->Shape() == steps_tensor->Shape()
num_categories_ > 0
num_classes is < 1
num_entries < 0 || gsl::narrow_cast<int64_t>(directions.size()) == num_entries
num_entries == int_categories.size()
num_outputs == copy_info.size()
num_samples is < 1
num_scan_inputs
Number of dimensions for batch indices should be exactly 1
Number of dimensions for rois should be exactly 
Number of elements of input 'scales' must be same as rank of input 'X' and element type must be float.
Number of elements of input 'scales' must be same as rank of input 'X'.
Number of entries in '
Number of entries in 'scan_input_axes' was 
Number of entries in 'scan_output_axes' was 
number of groups input channels and output channels are divided into.
number of groups input channels and output channels are divided into. default is 1.
Number of inputs (
Number of items must compose whole 
Number of neurons in the hidden layer
Number of neurons in the hidden layer.
Number of repeated copies to make of the input tensor.
Number of sampling points in the interpolation grid used to compute the output value of each pooled output bin. If > 0, then exactly sampling_ratio x sampling_ratio grid points are used. If == 0, then an adaptive number of grid points are used (computed as ceil(roi_width / output_width), and likewise for height). Default is 0.
Number of scan input axes specified (
Number of scan output axes specified (
Number of times to sample.
Number of top elements to retrieve
NumCapturesWalker::ShortVisit called
NupharExecutionProvider
Nushu
NXH+NPH
NxH+NpI
NXH+NPL
NXI+NPH
NyRichv
O 9H(
O 9K t
O H;q
O H+O
O LcG
o%/M8
O(H+O H
O(t#H
O@H;H@t:3
O@H+O8H
O@I+O8H
o\$PH
O`H;O`
O0"l"
O0Hcw(H
oD$ f
oE fA
oE@fA
oE0fA
oEPfA
of dimensions [a_0, a_1 * ... * a_{n-1}], where a_0 is often the batch size.
offset
Offset
offset + size <= size_t(span.size())
offset >= 0 && static_cast<size_t>(offset) < node_values_.size()
Offsets
Ogham
OGLY0
OGLY0Q
oHeight
OhL;G
oI fD
oI@fD
oI0fD
oL$0f
Ol_Chiki
Old_Hungarian
Old_Italic
Old_North_Arabian
Old_Permic
Old_Persian
Old_Sogdian
Old_South_Arabian
Old_Turkic
OLEAUT32.dll
oLuid
omHou
One (or two if bidirectional) activation function for input gate. The activation function must be one of the activation functions specified above. Optional: Default `Tanh` if not specified.
One float, indicates the value to be filled, default is 0
One float, indicates the value to be filled.
One of 'MAX,' 'L1,' 'L2'
One or more missing required inputs. 
One or more outputs forming list of tensors after splitting
one_class
OneHot
OneHot node must have three inputs.
OneHotEncoder
Only bool
Only one instance of LoggingManager created with InstanceType::Default can exist at any point in time.
Only one of keys_*'s can be set in label encoder.
Only one of values_*'s can be set in label encoder.
Only ONNX MLDataType can be registered
Only supports `int32_t` or `int64_t` inputs for starts/ends/axes/steps
ONNX Schema 
onnx.AttributeProto
onnx.FunctionProto
onnx.GraphProto
onnx.ModelProto
onnx.NodeProto
onnx.OperatorSetIdProto
onnx.StringStringEntryProto
onnx.TensorAnnotation
onnx.TensorProto
onnx.TensorProto.Segment
onnx.TensorShapeProto
onnx.TensorShapeProto.Dimension
onnx.TypeProto
onnx.TypeProto.Map
onnx.TypeProto.Opaque
onnx.TypeProto.Sequence
onnx.TypeProto.SparseTensor
onnx.TypeProto.Tensor
onnx.ValueInfoProto
ONNX_NAMESPACE::TensorProto::DataType_IsValid(dtype_) && dtype_ != ONNX_NAMESPACE::TensorProto::UNDEFINED
ONNX_NAMESPACE::TensorProto::DataType_IsValid(output_dtype_) && output_dtype_ != ONNX_NAMESPACE::TensorProto::UNDEFINED
onnxruntime
onnxruntime::`anonymous-namespace'::GetCurrentTimeString
onnxruntime::`anonymous-namespace'::TraverseFormalParametersWithTypeProto
onnxruntime::`anonymous-namespace'::WindowsEnv::FormatLibraryFileName
onnxruntime::`anonymous-namespace'::WindowsEnv::GetNumCpuCores
onnxruntime::BatchNorm<float>::BatchNorm
onnxruntime::BFCArena::AllocateRawInternal
onnxruntime::BFCArena::AllocationRegion::AllocationRegion
onnxruntime::BFCArena::AllocationRegion::IndexFor
onnxruntime::BFCArena::BFCArena
onnxruntime::BFCArena::ChunkFromHandle
onnxruntime::BFCArena::DeallocateRawInternal
onnxruntime::BFCArena::Extend
onnxruntime::BFCArena::FindChunkPtr
onnxruntime::BFCArena::FreeAndMaybeCoalesce
onnxruntime::BFCArena::InsertFreeChunkIntoBin
onnxruntime::BFCArena::Merge
onnxruntime::BFCArena::RegionManager::RegionFor
onnxruntime::BFCArena::RemoveFreeChunkFromBin
onnxruntime::BFCArena::RemoveFreeChunkIterFromBin
onnxruntime::BFCArena::Reserve
onnxruntime::BFCArena::SplitChunk
onnxruntime::BroadcastIterator::Append
onnxruntime::BroadcastIterator::Init
onnxruntime::BroadcastVariadic
onnxruntime::Cast<__int64>::Cast
onnxruntime::Cast<__int64>::Compute
onnxruntime::Cast<bool>::Cast
onnxruntime::Cast<bool>::Compute
onnxruntime::Cast<class std::basic_string<char,struct std::char_traits<char>,class std::allocator<char> > >::Cast
onnxruntime::Cast<class std::basic_string<char,struct std::char_traits<char>,class std::allocator<char> > >::Compute
onnxruntime::Cast<double>::Cast
onnxruntime::Cast<double>::Compute
onnxruntime::Cast<float>::Cast
onnxruntime::Cast<float>::Compute
onnxruntime::Cast<int>::Cast
onnxruntime::Cast<int>::Compute
onnxruntime::Cast<short>::Cast
onnxruntime::Cast<short>::Compute
onnxruntime::Cast<signed char>::Cast
onnxruntime::Cast<signed char>::Compute
onnxruntime::Cast<union onnxruntime::MLFloat16>::Cast
onnxruntime::Cast<union onnxruntime::MLFloat16>::Compute
onnxruntime::Cast<unsigned __int64>::Cast
onnxruntime::Cast<unsigned __int64>::Compute
onnxruntime::Cast<unsigned char>::Cast
onnxruntime::Cast<unsigned char>::Compute
onnxruntime::Cast<unsigned int>::Cast
onnxruntime::Cast<unsigned int>::Compute
onnxruntime::Cast<unsigned short>::Cast
onnxruntime::Cast<unsigned short>::Compute
onnxruntime::CastFloat16Data
onnxruntime::CastFromStringData
onnxruntime::CastToStringData
onnxruntime::Clip<float>::Clip
onnxruntime::common::Status::Status
onnxruntime::Compress::Compute
onnxruntime::ComputePadAndOutputShape
onnxruntime::ComputeTransposePadAndOutputShape
onnxruntime::ConcatBase::ConcatBase
onnxruntime::ConcatBase::PrepareForCompute
onnxruntime::ConstantFolding::ApplyImpl
onnxruntime::ConstantFolding::BuildTensorProtoForInitializer
onnxruntime::ConstantOfShape::ConstantOfShape
onnxruntime::ConstantOfShape::DispatchTypeAndFillOutput
onnxruntime::ConstantOfShape::SetValue
onnxruntime::ConstPointerContainer<class std::vector<class onnxruntime::NodeArg *,class std::allocator<class onnxruntime::NodeArg *> > >::at
onnxruntime::contrib::Affine<float>::Affine
onnxruntime::contrib::BahdanauAttention<float>::BahdanauAttention
onnxruntime::contrib::BahdanauAttention<float>::PrepareMemory
onnxruntime::contrib::DeepCpuAttnLstmOp::Compute
onnxruntime::contrib::DeepCpuAttnLstmOp::DeepCpuAttnLstmOp
onnxruntime::contrib::ExpandDims::Compute
onnxruntime::contrib::GatherNDBase::PrepareForCompute
onnxruntime::contrib::ImageScaler<float>::ImageScaler
onnxruntime::contrib::MaxpoolWithMask::Compute
onnxruntime::contrib::MurmurHash3::Compute
onnxruntime::contrib::Pad<float>::Compute
onnxruntime::contrib::Scale<float>::Scale
onnxruntime::contrib::Tokenizer::Tokenizer
onnxruntime::ConvTransposeBase::ComputePadsAndOutputShape
onnxruntime::CPUDataTransfer::CopyTensor
onnxruntime::data_types_internal::DataTypeRegistry::RegisterDataType
onnxruntime::data_types_internal::IsCompatible
onnxruntime::data_types_internal::SetMapTypes<__int64,__int64>::Set
onnxruntime::data_types_internal::SetMapTypes<__int64,class std::basic_string<char,struct std::char_traits<char>,class std::allocator<char> > >::Set
onnxruntime::data_types_internal::SetMapTypes<__int64,double>::Set
onnxruntime::data_types_internal::SetMapTypes<__int64,float>::Set
onnxruntime::data_types_internal::SetMapTypes<class std::basic_string<char,struct std::char_traits<char>,class std::allocator<char> >,__int64>::Set
onnxruntime::data_types_internal::SetMapTypes<class std::basic_string<char,struct std::char_traits<char>,class std::allocator<char> >,class std::basic_string<char,struct std::char_traits<char>,class std::allocator<char> > >::Set
onnxruntime::data_types_internal::SetMapTypes<class std::basic_string<char,struct std::char_traits<char>,class std::allocator<char> >,double>::Set
onnxruntime::data_types_internal::SetMapTypes<class std::basic_string<char,struct std::char_traits<char>,class std::allocator<char> >,float>::Set
onnxruntime::data_types_internal::SetSequenceType<__int64>::Set
onnxruntime::data_types_internal::SetSequenceType<class std::basic_string<char,struct std::char_traits<char>,class std::allocator<char> > >::Set
onnxruntime::data_types_internal::SetSequenceType<class std::map<__int64,float,struct std::less<__int64>,class std::allocator<struct std::pair<__int64 const ,float> > > >::Set
onnxruntime::data_types_internal::SetSequenceType<class std::map<class std::basic_string<char,struct std::char_traits<char>,class std::allocator<char> >,float,struct std::less<class std::basic_string<char,struct std::char_traits<char>,class std::allocator<char> > >,class std::allocator<struct std::pair<class std::basic_string<char,struct std::char_traits<char>,class std::allocator<char> > const ,float> > > >::Set
onnxruntime::data_types_internal::SetSequenceType<double>::Set
onnxruntime::data_types_internal::SetSequenceType<float>::Set
onnxruntime::DataTypeImpl::GetType<T>() == type_
onnxruntime::DataTypeImpl::TypeFromProto
onnxruntime::DeepCpuGruOp::Compute
onnxruntime::DeepCpuGruOp::DeepCpuGruOp
onnxruntime::DeepCpuLstmOp::Compute
onnxruntime::DeepCpuLstmOp::DeepCpuLstmOp
onnxruntime::DepthToSpace<float>::Compute
onnxruntime::DequantizeLinear<signed char>::Compute
onnxruntime::DequantizeLinear<unsigned char>::Compute
onnxruntime::DummyArena::Max
onnxruntime::DummyArena::Used
onnxruntime::Erf<float>::Compute
onnxruntime::ExecutionFrame::AllocateAsPerAllocationPlan
onnxruntime::ExecutionFrame::AllocateMLValueTensorSelfOwnBufferHelper
onnxruntime::ExecutionFrame::ExecutionFrame
onnxruntime::ExecutionFrame::GetAllocationPlan
onnxruntime::ExecutionFrame::TraceAllocate
onnxruntime::ExecutionFrame::TraceFree
onnxruntime::ExecutionProviders::Add
onnxruntime::ExLibLoader::~ExLibLoader
onnxruntime::Expand_8<__int64>::Compute
onnxruntime::Expand_8<bool>::Compute
onnxruntime::Expand_8<double>::Compute
onnxruntime::Expand_8<float>::Compute
onnxruntime::Expand_8<int>::Compute
onnxruntime::Expand_8<short>::Compute
onnxruntime::Expand_8<signed char>::Compute
onnxruntime::Expand_8<union onnxruntime::MLFloat16>::Compute
onnxruntime::Expand_8<unsigned __int64>::Compute
onnxruntime::Expand_8<unsigned char>::Compute
onnxruntime::Expand_8<unsigned int>::Compute
onnxruntime::Expand_8<unsigned short>::Compute
onnxruntime::EyeLike::Compute
onnxruntime::FeedsFetchesManager::SetDeviceCopyChecks
onnxruntime::Flatten::Compute
onnxruntime::Flatten::Flatten
onnxruntime::FunctionImpl::FunctionImpl
onnxruntime::FunctionKernel::FunctionKernel
onnxruntime::GatherBase::GatherBase
onnxruntime::Gemm<float,float,float,float>::Gemm
onnxruntime::GemmHelper::GemmHelper
onnxruntime::Graph::AddEdge
onnxruntime::Graph::AllocateNode
onnxruntime::Graph::CleanUnusedInitializers
onnxruntime::Graph::FuseSubGraph
onnxruntime::Graph::Graph
onnxruntime::Graph::NodeAtIndexImpl
onnxruntime::Graph::RemoveEdge
onnxruntime::Graph::Resolve
onnxruntime::Graph::SetGraphInputsOutputs
onnxruntime::Graph::SetInputs
onnxruntime::Graph::SetOutputs
onnxruntime::graph_utils::CanUpdateImplicitInputNameInSubgraphs
onnxruntime::graph_utils::GetNodeInputName
onnxruntime::graph_utils::GetNodeOutputName
onnxruntime::graph_utils::RemoveNodeWithSingleInitializerIn
onnxruntime::graph_utils::UpdateImplicitInputNameInSubgraph
onnxruntime::GraphPartitioner::Partition
onnxruntime::HandleNegativeAxis
onnxruntime::IdentityOp<0>::Compute
onnxruntime::IdentityOp<1>::Compute
onnxruntime::IExecutionFrame::GetMLValue
onnxruntime::IExecutionFrame::GetNodeIdxToMLValueIdx
onnxruntime::IExecutionFrame::GetOrCreateNodeOutputMLValue
onnxruntime::IExecutionFrame::IExecutionFrame
onnxruntime::IExecutionProvider::InsertAllocator
onnxruntime::If::Compute
onnxruntime::If::If
onnxruntime::IfImpl::Execute
onnxruntime::InferenceSession::~InferenceSession
onnxruntime::InferenceSession::AddPredefinedTransformers
onnxruntime::InferenceSession::CreateSubgraphSessionState
onnxruntime::InferenceSession::EndProfiling
onnxruntime::InferenceSession::InferenceSession
onnxruntime::InferenceSession::Initialize
onnxruntime::InferenceSession::InitializeSubgraphSessions
onnxruntime::InferenceSession::Load
onnxruntime::InferenceSession::NewIOBinding
onnxruntime::InferenceSession::Run
onnxruntime::Initializer::Initializer
onnxruntime::Initializer::ToProto
onnxruntime::InstanceNorm<float>::InstanceNorm
onnxruntime::IsInf::Compute
onnxruntime::IsInf::IsInf
onnxruntime::KernelRegistry::TryFindKernel
onnxruntime::Loop::Compute
onnxruntime::Loop::Loop
onnxruntime::LoopImpl::CreateInitialFeeds
onnxruntime::LpNorm<float>::LpNorm
onnxruntime::LRN<float>::Compute
onnxruntime::LRN<float>::LRN
onnxruntime::math::Im2colNd<float,class onnxruntime::CPUMathUtil,2>::operator ()
onnxruntime::math::Im2colNd<unsigned char,class onnxruntime::CPUMathUtil,2>::operator ()
onnxruntime::MatMulComputeHelper::Compute
onnxruntime::MatMulInteger<unsigned char,unsigned char,int>::Compute
onnxruntime::Max_6<float>::Compute
onnxruntime::MaxUnpool::Compute
onnxruntime::MaxUnpool::MaxUnpool
onnxruntime::Mean_6<float>::Compute
onnxruntime::MeanVarianceNormalization_0<float>::MeanVarianceNormalization_0
onnxruntime::Min_6<float>::Compute
onnxruntime::ml::CastMap::CastMap
onnxruntime::ml::CastMap::ComputeImpl
onnxruntime::ml::CategoryMapper::CategoryMapper
onnxruntime::ml::DictVectorizerOp<__int64,class std::basic_string<char,struct std::char_traits<char>,class std::allocator<char> > >::DictVectorizerOp
onnxruntime::ml::DictVectorizerOp<__int64,double>::DictVectorizerOp
onnxruntime::ml::DictVectorizerOp<__int64,float>::DictVectorizerOp
onnxruntime::ml::DictVectorizerOp<class std::basic_string<char,struct std::char_traits<char>,class std::allocator<char> >,__int64>::DictVectorizerOp
onnxruntime::ml::DictVectorizerOp<class std::basic_string<char,struct std::char_traits<char>,class std::allocator<char> >,double>::DictVectorizerOp
onnxruntime::ml::DictVectorizerOp<class std::basic_string<char,struct std::char_traits<char>,class std::allocator<char> >,float>::DictVectorizerOp
onnxruntime::ml::FeatureVectorizer::Compute
onnxruntime::ml::FeatureVectorizer::FeatureVectorizer
onnxruntime::ml::ImputerOp::Compute
onnxruntime::ml::ImputerOp::ImputerOp
onnxruntime::ml::LabelEncoder::LabelEncoder
onnxruntime::ml::LinearClassifier<__int64>::LinearClassifier
onnxruntime::ml::LinearClassifier<double>::LinearClassifier
onnxruntime::ml::LinearClassifier<float>::LinearClassifier
onnxruntime::ml::LinearClassifier<int>::LinearClassifier
onnxruntime::ml::LinearRegressor<float>::LinearRegressor
onnxruntime::ml::MakeCast
onnxruntime::ml::MakeNormalize
onnxruntime::ml::MakePack
onnxruntime::ml::Normalizer::Compute
onnxruntime::ml::Normalizer::Normalize
onnxruntime::ml::Normalizer::Normalizer
onnxruntime::ml::OneHotEncoderOp<__int64>::Compute
onnxruntime::ml::OneHotEncoderOp<__int64>::OneHotEncoderOp
onnxruntime::ml::OneHotEncoderOp<class std::basic_string<char,struct std::char_traits<char>,class std::allocator<char> > >::Compute
onnxruntime::ml::OneHotEncoderOp<class std::basic_string<char,struct std::char_traits<char>,class std::allocator<char> > >::OneHotEncoderOp
onnxruntime::ml::OneHotEncoderOp<double>::Compute
onnxruntime::ml::OneHotEncoderOp<double>::OneHotEncoderOp
onnxruntime::ml::OneHotEncoderOp<float>::Compute
onnxruntime::ml::OneHotEncoderOp<float>::OneHotEncoderOp
onnxruntime::ml::ScalerOp<__int64>::ScalerOp
onnxruntime::ml::ScalerOp<double>::ScalerOp
onnxruntime::ml::ScalerOp<float>::ScalerOp
onnxruntime::ml::ScalerOp<int>::ScalerOp
onnxruntime::ml::SVMClassifier<__int64>::SVMClassifier
onnxruntime::ml::SVMClassifier<double>::SVMClassifier
onnxruntime::ml::SVMClassifier<float>::SVMClassifier
onnxruntime::ml::SVMClassifier<int>::SVMClassifier
onnxruntime::ml::SVMCommon<__int64>::SVMCommon
onnxruntime::ml::SVMCommon<double>::SVMCommon
onnxruntime::ml::SVMCommon<float>::SVMCommon
onnxruntime::ml::SVMCommon<int>::SVMCommon
onnxruntime::ml::SVMRegressor<float>::SVMRegressor
onnxruntime::ml::TreeEnsembleClassifier<__int64>::Initialize
onnxruntime::ml::TreeEnsembleClassifier<__int64>::ProcessTreeNode
onnxruntime::ml::TreeEnsembleClassifier<__int64>::TreeEnsembleClassifier
onnxruntime::ml::TreeEnsembleClassifier<double>::Initialize
onnxruntime::ml::TreeEnsembleClassifier<double>::ProcessTreeNode
onnxruntime::ml::TreeEnsembleClassifier<double>::TreeEnsembleClassifier
onnxruntime::ml::TreeEnsembleClassifier<float>::Initialize
onnxruntime::ml::TreeEnsembleClassifier<float>::ProcessTreeNode
onnxruntime::ml::TreeEnsembleClassifier<float>::TreeEnsembleClassifier
onnxruntime::ml::TreeEnsembleClassifier<int>::Initialize
onnxruntime::ml::TreeEnsembleClassifier<int>::ProcessTreeNode
onnxruntime::ml::TreeEnsembleClassifier<int>::TreeEnsembleClassifier
onnxruntime::ml::TreeEnsembleRegressor<float>::TreeEnsembleRegressor
onnxruntime::ml::write_scores
onnxruntime::ml::ZipMapOp::ZipMapOp
onnxruntime::MLValueTensorSlicer<struct OrtValue const >::Create
onnxruntime::MLValueTensorSlicer<struct OrtValue const >::Iterator::operator *
onnxruntime::MLValueTensorSlicer<struct OrtValue>::Create
onnxruntime::MLValueTensorSlicer<struct OrtValue>::Iterator::operator *
onnxruntime::Mod::Compute
onnxruntime::Mod::Mod
onnxruntime::mod_internal::BroadCastFMod
onnxruntime::mod_internal::BroadCastMFloat16FMod
onnxruntime::mod_internal::BroadCastMod
onnxruntime::Multinomial::Multinomial
onnxruntime::Node::ForEachWithIndex(node.InputDefs(), [this, &kci](const onnxruntime::NodeArg& arg, size_t index) { if (kci && kci->kernel_def->IsInputOnCpu(index)) non_provider_input_defs_.insert(&arg); else provider_input_defs_.insert(&arg); return Status::OK(); }).IsOK()
onnxruntime::NodeIndexInfo::GetMLValueIndex
onnxruntime::NodeIndexInfo::GetNodeOffset
onnxruntime::NodeIndexInfo::Init::<lambda_98e58702055b3dda6030ac966651b812>::operator ()
onnxruntime::NodeIndexInfo::Init::<lambda_bf5458cf82f5faac082f67dd8814164d>::operator ()
onnxruntime::NonMaxSuppression::Compute
onnxruntime::NonMaxSuppression::NonMaxSuppression
onnxruntime::NonMaxSuppression::ParepareCompute
onnxruntime::NonTensorTypeBase::IsMapCompatible
onnxruntime::NonTensorTypeBase::IsSequenceCompatible
onnxruntime::NonZero<__int64>::Compute
onnxruntime::NonZero<bool>::Compute
onnxruntime::NonZero<float>::Compute
onnxruntime::NonZero<int>::Compute
onnxruntime::OpKernel::ComputeAsync
onnxruntime::OpKernelContext::GetOrCreateOutputMLValue
onnxruntime::OpKernelContext::Input
onnxruntime::OpKernelContext::NumVariadicInputs
onnxruntime::OpKernelContext::OpKernelContext
onnxruntime::OpKernelContext::Output
onnxruntime::OpKernelContext::OutputMLValue
onnxruntime::OpKernelInfo::GetAllocatorInfo
onnxruntime::OpNodeProtoHelper<class onnxruntime::ProtoHelperNodeContext>::GetAttrs
onnxruntime::OpNodeProtoHelper<struct onnx::InferenceContext>::GetAttrs
onnxruntime::OptimizerExecutionFrame::Info::Info
onnxruntime::PadBase::PadBase
onnxruntime::PadCpuImpl
onnxruntime::ParallelExecutor::RunNodeAsyncInternal
onnxruntime::PlaceNode
onnxruntime::PlannerImpl::AllocPlan
onnxruntime::PlannerImpl::Buffer
onnxruntime::PlannerImpl::GetElementSize
onnxruntime::PlannerImpl::GetLocationForNodeInput
onnxruntime::PlannerImpl::Index
onnxruntime::PlannerImpl::ProcessDef
onnxruntime::PlannerImpl::Reuse
onnxruntime::PlannerImpl::UseCount
onnxruntime::Pool<float,class onnxruntime::LpPool>::Compute
onnxruntime::Pool<float,class onnxruntime::MaxPool<8> >::Compute
onnxruntime::PoolBase::Compute
onnxruntime::PoolBase::ComputeSizePadDilations
onnxruntime::PoolBase::InferOutputSize
onnxruntime::PoolBase::PoolBase
onnxruntime::PoolBase::SetOutputSize
onnxruntime::PoolProcessContext::init
onnxruntime::PrepareForReduce
onnxruntime::profiling::Profiler::EndTimeAndRecordEvent
onnxruntime::profiling::Profiler::Initialize
onnxruntime::profiling::Profiler::StartProfiling
onnxruntime::QLinearConv::ScaleAndZeropointPairValidationHelper
onnxruntime::QLinearMatMul<unsigned char,unsigned char,unsigned char>::Compute
onnxruntime::QuantizeLinear<signed char>::Compute
onnxruntime::QuantizeLinear<unsigned char>::Compute
onnxruntime::RandomNormal::RandomNormal
onnxruntime::RandomNormalCompute
onnxruntime::RandomNormalLike::RandomNormalLike
onnxruntime::RandomUniform::RandomUniform
onnxruntime::RandomUniformCompute
onnxruntime::RandomUniformLike::RandomUniformLike
onnxruntime::ReduceKernelBase<0>::ReduceKernelBase
onnxruntime::ReduceKernelBase<1>::ReduceKernelBase
onnxruntime::Reshape::Compute
onnxruntime::Reshape_1::Reshape_1
onnxruntime::ReshapeHelper::ReshapeHelper
onnxruntime::ReverseSequenceOp::Compute
onnxruntime::ReverseSequenceOp::ReverseSequenceOp
onnxruntime::rnn::detail::ComputeGemm
onnxruntime::rnn::detail::deepcpu::ActivationFuncByName
onnxruntime::rnn::detail::deepcpu::GruOutputGateFuncByName
onnxruntime::rnn::detail::deepcpu::GruResetGateFuncByName
onnxruntime::rnn::detail::deepcpu::LstmMergeGatesFuncByName
onnxruntime::rnn::detail::MakeDirection
onnxruntime::rnn::detail::NormalizeActivationArgumentAndGetAlphaBetaCount
onnxruntime::rnn::detail::SafeRawConstPointer
onnxruntime::rnn::detail::SafeRawPointer
onnxruntime::RNN<float>::RNN
onnxruntime::RoiAlign<double>::RoiAlign
onnxruntime::RoiAlign<float>::RoiAlign
onnxruntime::RoiPool<float>::Compute
onnxruntime::RoiPool<float>::RoiPool
onnxruntime::SaveInitializedTensors
onnxruntime::SaveInputOutputNamesToNodeMapping
onnxruntime::SaveKernels
onnxruntime::SaveMLValueNameIndexMapping
onnxruntime::ScaleAndZeropointPairValidationHelper
onnxruntime::scan::detail::CreateFeedsFetchesManager
onnxruntime::scan::detail::IterateSequence
onnxruntime::scan::detail::LoopStateVariable::Next
onnxruntime::scan::detail::OutputIterator::AllocateFinalOutput
onnxruntime::scan::detail::OutputIterator::GetOutput
onnxruntime::scan::detail::OutputIterator::operator *
onnxruntime::scan::detail::OutputIterator::operator ++
onnxruntime::scan::detail::ReadDirections
onnxruntime::Scan<8>::Compute
onnxruntime::Scan<8>::Scan
onnxruntime::Scan<9>::Compute
onnxruntime::Scan<9>::Scan
onnxruntime::Scan8Impl::CreateLoopStateVariables
onnxruntime::ScanImpl::CreateLoopStateVariables
onnxruntime::ScanImpl::TransposeOutput
onnxruntime::Scatter::Compute
onnxruntime::Scatter::Scatter
onnxruntime::SequentialExecutor::Execute
onnxruntime::SessionState::AddInitializedTensor
onnxruntime::SessionState::AddSubgraphSessionState
onnxruntime::SessionState::CalculateNodeIndexInfo
onnxruntime::SessionState::GetNodeIndexInfo
onnxruntime::SessionState::SetGraphViewer
onnxruntime::SessionStateInitializer::InitializeAndSave
onnxruntime::Shrink::Compute
onnxruntime::Shrink::Shrink
onnxruntime::SizeFromDim
onnxruntime::SizeToDim
onnxruntime::Slice<__int64,0>::Compute
onnxruntime::Slice<__int64,1>::Compute
onnxruntime::Slice<bool,0>::Compute
onnxruntime::Slice<bool,1>::Compute
onnxruntime::Slice<class std::basic_string<char,struct std::char_traits<char>,class std::allocator<char> >,0>::Compute
onnxruntime::Slice<class std::basic_string<char,struct std::char_traits<char>,class std::allocator<char> >,1>::Compute
onnxruntime::Slice<double,0>::Compute
onnxruntime::Slice<double,1>::Compute
onnxruntime::Slice<float,0>::Compute
onnxruntime::Slice<float,1>::Compute
onnxruntime::Slice<int,0>::Compute
onnxruntime::Slice<int,1>::Compute
onnxruntime::Slice<short,0>::Compute
onnxruntime::Slice<short,1>::Compute
onnxruntime::Slice<signed char,0>::Compute
onnxruntime::Slice<signed char,1>::Compute
onnxruntime::Slice<union onnxruntime::MLFloat16,0>::Compute
onnxruntime::Slice<union onnxruntime::MLFloat16,1>::Compute
onnxruntime::Slice<unsigned __int64,0>::Compute
onnxruntime::Slice<unsigned __int64,1>::Compute
onnxruntime::Slice<unsigned char,0>::Compute
onnxruntime::Slice<unsigned char,1>::Compute
onnxruntime::Slice<unsigned int,0>::Compute
onnxruntime::Slice<unsigned int,1>::Compute
onnxruntime::Slice<unsigned short,0>::Compute
onnxruntime::Slice<unsigned short,1>::Compute
onnxruntime::SliceBase::FillVectorsFromInput
onnxruntime::SliceBase::SliceBase
onnxruntime::SliceIterator<__int64>::Init
onnxruntime::SliceIterator<bool>::Init
onnxruntime::SliceIterator<class std::basic_string<char,struct std::char_traits<char>,class std::allocator<char> > >::Init
onnxruntime::SliceIterator<double>::Init
onnxruntime::SliceIterator<float>::Init
onnxruntime::SliceIterator<int>::Init
onnxruntime::SliceIterator<short>::Init
onnxruntime::SliceIterator<signed char>::Init
onnxruntime::SliceIterator<union onnxruntime::MLFloat16>::Init
onnxruntime::SliceIterator<unsigned __int64>::Init
onnxruntime::SliceIterator<unsigned char>::Init
onnxruntime::SliceIterator<unsigned int>::Init
onnxruntime::SliceIterator<unsigned short>::Init
onnxruntime::SliceSkips::SliceSkips
onnxruntime::SpaceDepthBase::SpaceDepthBase
onnxruntime::SpaceToDepth<float>::Compute
onnxruntime::Split::Compute
onnxruntime::SplitBase::SplitBase
onnxruntime::SqueezeBase::ComputeOutputShape
onnxruntime::SqueezeBase::SqueezeBase
onnxruntime::string_normalizer::Locale::Locale
onnxruntime::StringNormalizer::StringNormalizer
onnxruntime::StringToAutoPadType
onnxruntime::Sum_6<float>::Compute
onnxruntime::TaskThreadPool::~TaskThreadPool
onnxruntime::Tensor::Data
onnxruntime::Tensor::DataAsSpan
onnxruntime::Tensor::DataRaw
onnxruntime::Tensor::Init
onnxruntime::Tensor::MutableData
onnxruntime::Tensor::MutableDataAsSpan
onnxruntime::Tensor::MutableDataRaw
onnxruntime::Tensor::Size
onnxruntime::Tensor::Tensor
onnxruntime::TensorAllocator<class std::basic_string<char,struct std::char_traits<char>,class std::allocator<char> > >::TensorAllocator
onnxruntime::TensorAllocator<float>::TensorAllocator
onnxruntime::TensorAllocator<int>::TensorAllocator
onnxruntime::TensorShape::SizeFromDimension
onnxruntime::TensorShape::SizeToDimension
onnxruntime::TensorShape::Slice
onnxruntime::TensorTypeBase::GetElementType
onnxruntime::TensorTypeBase::IsCompatible
onnxruntime::TfIdfVectorizer::TfIdfVectorizer
onnxruntime::Tile::Compute
onnxruntime::TopK<10,float>::TopK
onnxruntime::TopK<9,float>::TopK
onnxruntime::transformer_utils::GenerateRewriteRules
onnxruntime::transformer_utils::GenerateTransformers
onnxruntime::TransformerMemcpyImpl::ProcessDefs
onnxruntime::TransformerMemcpyImpl::ProcessInitializers
onnxruntime::TransformerMemcpyImpl::ProcessInitializers::<lambda_23ae0d8678653f1ba32dea59d99f813c>::operator ()
onnxruntime::Transpose::Compute
onnxruntime::TransposeBase::TransposeBase
onnxruntime::UnsqueezeBase::PrepareCompute
onnxruntime::UnsqueezeBase::UnsqueezeBase
onnxruntime::Upsample<float>::BaseCompute
onnxruntime::Upsample<float>::Compute
onnxruntime::Upsample<int>::BaseCompute
onnxruntime::Upsample<int>::Compute
onnxruntime::Upsample<unsigned char>::BaseCompute
onnxruntime::Upsample<unsigned char>::Compute
onnxruntime::UpsampleBase::ParseScalesData
onnxruntime::UpsampleBase::ScalesValidation
onnxruntime::UpsampleBase::StringToUpsampleMode
onnxruntime::UpsampleBase::UpsampleBase
onnxruntime::utils::CachedCopyInputsAcrossDevices
onnxruntime::utils::CachedCopyOutputsAcrossDevices
onnxruntime::utils::CachedSetupFetchesForExecute
onnxruntime::utils::CopyInputsAcrossDevices
onnxruntime::utils::CopyOneInputAcrossDevices
onnxruntime::utils::ExecuteGraph
onnxruntime::utils::GetMLDataType
onnxruntime::utils::SetupFetchesForExecute
onnxruntime::Where<class std::basic_string<char,struct std::char_traits<char>,class std::allocator<char> > >::Compute
onnxruntime::Where<float>::Compute
onnxruntime::Where<int>::Compute
onnxruntime_profile_
OnnxRuntimeProfiling
Op registered for 
op_kernel_info.GetAttr<float>("bias", &bias_temp).IsOK()
op_kernel_info.GetAttr<float>("epsilon", &epsilon_).IsOK()
op_kernel_info.GetAttr<float>("lambd", &lambd_temp).IsOK()
op_kernel_info.GetAttr<int64_t>("axis", &axis_).IsOK()
op_kernel_info.GetAttr<int64_t>("axis", &axis_temp).IsOK()
op_kernel_info.GetAttr<int64_t>("k", &k_temp).IsOK()
op_kernel_info.GetAttr<int64_t>("p", &p_).IsOK()
op_name
op_type
opaque
opaque(
open file 
OpenProcess
OpenSemaphoreW
operation canceled
operation in progress
operation not permitted
operation not supported
operation would block
Operator '
Operator Name
OperatorPreference
OpH+OhH
OpKernel was null
Optional 1D bias to be added to the convolution, has size of M.
Optional initial value of the cell. If not specified - assumed to be 0. It has shape `[num_directions, batch_size, hidden_size]`.
Optional initial value of the hidden. If not specified - assumed to be 0. It has shape `[num_directions, batch_size, hidden_size]`.
Optional list of output lengths (see also arg 'split')
Optional scaling values used by some activation functions. The values are consumed in the order of activation functions, for example (f, g, h) in LSTM.
Optional scaling values used by some activation functions. The values are consumed in the order of activation functions, for example (f, g, h) in LSTM. Default values are the same as of corresponding ONNX operators.
Optional scaling values used by some activation functions. The values are consumed in the order of activation functions, for example (f, g, h) in LSTM. Default values are the same as of corresponding ONNX operators.For example with LeakyRelu, the default alpha is 0.01.
Optional tensor specifying lengths of the sequences in a batch. If not specified - assumed all sequences in the batch to have length `seq_length`. It has shape `[batch_size]` 
Optional tensor specifying lengths of the sequences in a batch. If not specified - assumed all sequences in the batch to have length `seq_length`. It has shape `[batch_size]`.
Optional tensor specifying lengths of the sequences in a batch. If this input is not specified, all sequences are assumed to be of the maximum sequence length (the dimension of the sequence axis of the scan_input tensors).
Original tensor
OriginalFilename
originatingContextId
originatingContextMessage
originatingContextName
Oriya
ort_value.Fence() == nullptr
ort_value.IsAllocated()
ort_value.IsTensor()
ort_value_idx == NodeIndexInfo::kInvalidEntry || (ort_value_idx >= 0 && static_cast<size_t>(ort_value_idx) < all_values_.size())
ort_value_idx >= 0 && static_cast<size_t>(ort_value_idx) < alloc_plan.size()
ort_value_index >= 0 && ort_value_index <= ort_value_name_idx_map_.MaxIdx()
ort_value_index >= 0 && static_cast<size_t>(ort_value_index) < all_values_.size()
ort_value_index >= 0 && static_cast<size_t>(ort_value_index) < alloc_plan.size()
ort_value_name_idx_map.MaxIdx() > 0
OrtAllocatorInfo: [
OrtValue has not been allocated so can't be sliced.
OrtValue indexes should have been populated.
OrtValue shape verification failed. Current shape:
OrtValue::Get
OrtValue::GetMutable
Osage
Osmanya
oT$@f
ot$`f
Out of bound access to array
outer_scope_node_args_consumed.empty()
Outgoing node could not be found.
output
output 
Output 
output (always 2D tensor)
output (floating tensor) and mask (`Tensor<bool>`). Depending on whether it is
output (Tensor<float>) and mask (Tensor<bool>). Depending on whether it is in
Output case #1: Y, mean, var, saved_mean, saved_var (training mode)
Output case #2: Y (test mode)
Output channels M is not divisible by group.
output data (Tensor<T>) where the function `f(x) = slope * x for x < 0`,
Output data after scaling
Output data tensor from average or max pooling across the input tensor. Dimensions will vary based on various kernel, stride, and pad sizes. Floor value of the dimension is used
Output data tensor from Lp pooling across the input tensor. Dimensions will vary based on various kernel, stride, and pad sizes.
Output data tensor from pooling across the input tensor. Dimensions will be N x C x 1 x 1
Output data tensor that contains the result of the convolution. The output dimensions are functions of the kernel size, stride size, and pad lengths.
Output data tensor that contains the result of the convolution. The output dimensions are functions of the kernel size, stride size, pad lengths and group count. The number of channels in the output should be equal to W.shape[1] * group (assuming zero based indices of the shape array)
Output data tensor that contains the result of the unpooling.
Output data.
Output data. If strings are input, the output values are integers, and vice versa.
Output height cannot be smaller than input height.
Output input image height provided. Height is set to zero.
Output input image width provided. Width is set to zero.
Output OrtValue has not been created for loop state variable output 
Output tensor
Output tensor (same size as X)
Output tensor containing the same value of the provided tensor.
Output tensor of [N, C * blocksize * blocksize, H/blocksize, W/blocksize].
Output tensor of [N, C/(blocksize * blocksize), H * blocksize, W * blocksize].
Output tensor of random values drawn from normal distribution
Output tensor of random values drawn from uniform distribution
Output tensor of same shape and type as input.
Output tensor of shape (M, N).
Output tensor of shape specified by 'input'.If attribute 'value' is specified, the value and datatype of the output tensor is taken from 'value'.If attribute 'value' is not specified, the value in the output defaults to 0, and the datatype defaults to float32.
Output tensor of the same dimension and type as tensor input. output_dim[i] = input_dim[i] * repeats[i]
Output tensor with clipped input elements
Output tensor with shape [batch_size, sample_size], where sample_size is the number of times to sample. Each value along the axis zero represents the outcome of the corresponding sample in a batch.
Output tensor with the same shape as input with type specified by the 'to' argument
Output tensor, same shape as input tensor T1.
Output tensor, which has the shape and type as input tensor
Output tensor.
Output tensor. Same dimension as inputs.
Output type is determined by the specified 'values_*' attribute.
Output type must be int32 or int64
Output vector incorrectly sized: output_names.size(): 
Output vector pointer is NULL
Output was expected to have tensor type. Got 
Output width cannot be smaller than input width.
Output:
output_height
output_height >= H
output_mlvalue
output_node
output_padding
output_sequence
output_shape
output_shape can also be explicitly specified in which case pads values are auto generated using these equations:
'output_shape' must be rank 1 tensor.
'output_shape' must have same number of elements as the shape of input tensor X.
output_width
output_width >= W
OutputCellSingleTensor
OutputCount
outputCount
OutputDebugStringA
OutputDebugStringW
OutputGateTensor
OutputIndexTensor
OutputIndicesTensor
OutputPadding
outputs
Outputs
Outputs from Scan are not optional and should never be null.
outputs...
OutputSequenceTensor
OutputSingleTensor
OutputTensor
OutputTensors
OutputValueTensor
oWidth
owner dead
OXI+OPI
OXI+OPL
p AWH
P H+P
p H9^
p p t y 
p value of the Lp norm used to pool over the input data, default is 2.0.
p value of the Lp norm used to pool over the input data.
p WATAUAVAWH
p WAVAWH
p.second
p_ == 1 || p_ == 2
p_fetches->size(): 
p_graph
p_input_provider
p_int < base_int + memory_size_
p_int >= base_int
p_ml_value
p_mlvalue
p_provider
p_type != nullptr
p< t <$
P0LcH(I
p7M}6p7M
PA^_]
pA^_]
pA^_^
PA^_^
pA^_^[]
PA^_^[]
pA^_^[]
PA^_^[]
pA^_^[]
pA^_^][
PA^_^][
pA^_^][
PA_A]A\_^
PA_A^_^[
pA_A^_^[
PA_A^_^[
PA_A^_^]
pA_A^_^]
PA_A^_^]
pA_A^_^]
PA_A^_^]
pA_A^_^]
PA_A^_^]
pA_A^_^]
PA_A^_^]
pA_A^_^]
pA_A^A\_^[]
PA_A^A\_^[]
pA_A^A\_^[]
pA_A^A]_^[]
PA_A^A]_^][
pA_A^A]A\_][
PA_A^A]A\_^[
pA_A^A]A\_^[
PA_A^A]A\_^[
pA_A^A]A\_^]
PA_A^A]A\_^]
pA_A^A]A\_^]
PA_A^A]A\_^]
pA_A^A]A\_^]
PA_A^A]A\_^]
pA_A^A]A\_^]
PA_A^A]A\_^]
pA_A^A]A\_^]
PA_A^A]A\_^]
pA_A^A]A\_^]
PA_A^A]A\_^]
pA_A^A]A\_^]
PA_A^A]A\_^]
pA_A^A]A\_^]
PA_A^A]A\_^]
pA_A^A]A\_^]
PA_A^A]A\_^]
pA_A^A]A\_^]
PA_A^A]A\_^]
pA_A^A]A\_^]
Pad should be smaller than kernel.
pad type not supported
pad type not supported.
pad_value
Padding for the beginning and ending along each axis, it can take any value greater than or equal to 0. The value represent the number of pixels added to the beginning and end part of the corresponding axis. `pads` format should be as follow [x1_begin, x2_begin...x1_end, x2_end,...], where xi_begin the number of pixels added at the beginning of axis `i` and xi_end, the number of pixels added at the end of axis `i`. This attribute cannot be used simultaneously with auto_pad attribute.
Padding for the beginning and ending along each axis, it can take any value greater than or equal to 0. The value represent the number of pixels added to the beginning and end part of the corresponding axis. `pads` format should be as follow [x1_begin, x2_begin...x1_end, x2_end,...], where xi_begin the number of pixels added at the beginning of axis `i` and xi_end, the number of pixels added at the end of axis `i`. This attribute cannot be used simultaneously with auto_pad attribute. If not present, the padding defaults to 0 along start and end of each axis.
Padding for the beginning and ending along each axis, it can take any value greater than or equal to 0.The value represent the number of pixels added to the beginning and end part of the corresponding axis.`pads` format should be as follow [x1_begin, x2_begin...x1_end, x2_end,...], where xi_begin the number ofpixels added at the beginning of axis `i` and xi_end, the number of pixels added at the end of axis `i`.This attribute cannot be used simultaneously with auto_pad attribute. If not present, the padding defaultsto 0 along start and end of each axis.
PaddingMode
paddings
PaddingValue
'pads' has wrong number of values
'pads' input must be a 1D (shape: [input_rank]) or 2D tensor (shape: [1, input_rank]) of type int64
Pads tensor should be a 1D tensor of shape [2 * input_rank] or a 2D tensor of shape [1, 2 * input_rank]
Pads tensor should be an INT64 tensor
Pads tensor size should be equal to twice the input dimension count 
pads@
pads_[dim] < kernel_shape_[dim] && pads_[dim + kernel_shape_.size()] < kernel_shape_[dim]
pads_size == 2 * dimension_count
pads_tensor.DataType() == DataTypeImpl::GetType<int64_t>()
pads_tensor_dims.size() == 1 || (pads_tensor_dims.size() == 2 && pads_tensor_dims[0] == 1)
Pahawh_Hmong
Palmyrene
Parallel execution is currently not supported for the registered CUDA Execution Provider.
ParallelExecutor::Execute
ParametricSoftplus
parse
parsing 
PartA_PrivTags
Pass 1 to enable broadcasting
pattern too large - compile failed
pattern too large - reverse compile failed
Pau_Cin_Hau
PCM>a
PeepholeTensor
Performs element-wise binary {name} (with limited broadcast support).
Performs element-wise binary {name} (with Numpy-style broadcasting support).
perm: 
permission denied
Phags_Pa
Phoenician
Please fetch output tensor with specified shape.
poll_strings duplicate 
pool_int64s
pool_int64s duplicate 
pool_strings
pool_strings must not be empty if specified
pooled_height_ > 0
pooled_shape
pooled_shape.size() == 2
pooled_width_ > 0
PooledSize
Popularity of each node, used for performance and may be omitted.
position_ >= 0 && position_ < sequence_length_
positive
positiveH
positiveI
post_transform
Pow takes input data (Tensor<T>) and exponent Tensor, and
Preferred Layout
PRelu
PRelu takes input data (Tensor<T>) and slope tensor as input, and produces one
PreviousTensor
prob_a
prob_b
proba_.size() == probb_.size()
Process ID
Processed_STD
ProcessInfo
Processing batch
producer_of_
produces one output data (Tensor<T>) where the function `f(x) = x^exponent`,
product
ProductName
ProductVersion
promise already satisfied
PropagatedOperatorPreference
proto != nullptr
protocol error
protocol not supported
provided axis. The resulted tensor has the same rank as the input if keepdims equal 1.
provider
Provider 
Provider doesn't return correct number of compiled functions
providerH
Psalter_Pahlavi
Q H+Q
Q t"H
q(D9q@~0L
q(Hci 3
q(Hci A
Q(t"H
q@D9q`~0L
Q@t"H
Q`H+QXH
Q03c3
Q0H+Q(H
q0I#p L
Qbr}X
QbreH
qHcC(I9E
QLinearConv
QLinearMatMul
QpD;Q`
QPH+QHH
qR;/(
Quantized matrix multiply results from a * b
QuantizeLinear
QueryPerformanceCounter
QueryPerformanceFrequency
R->Shape()[1] == 5
r3L;M
r5w,H
raB3G
RaiseException
RaiseFailFastException
RandomNormal
RandomNormalLike
RandomUniform
RandomUniformLike
Range
Rank 1 tensor containing exactly two elements, in the format [off_value, on_value], where 'on_value' is the value used for filling locations specified in 'indices' input tensor, and 'off_value' is the value used for filling locations other than those specified in 'indices' input tensor. 
Rank 1 tensor of booleans to indicate which slices or data elements to be selected. Its length can be less than the input length alone the axis or the flattened input size if axis is not specified. In such cases data slices or elements exceeding the condition length are discarded.
rank must be greater than axis
Ranks of input data are different, cannot concatenate them, expected rank: 
ratio
raw_data
RD11<
RDEF|
RE2: invalid startpos, endpos pair. [
RE2: unexpected op: 
read only file system
ReadFile
ReadFile 
ReadFileAsString: 'fname' cannot be NULL
ReadFileAsString: please specify length to read
Real memory steps 
Received nullptr for custom registry
Received nullptr for exec provider
Received nullptr for graph transformer
Reciprocal
RecurrenceTensor
reduced
Reduced output tensor with integer data type.
Reduced output tensor.
ReduceL1
ReduceL2
ReduceLogSum
ReduceLogSumExp
ReduceMax
ReduceMean
ReduceMin
ReduceProd
ReduceSum
ReduceSumInteger
ReduceSumSquare
reference(Lhs: %d cells %dx%d %s, Rhs: %d cells %dx%d %s)
reflect
Regexp not destroyed.
RegisterCustomRegistry
RegisterOperatorKernel
RegisterOperatorSetSchema
Regression outputs (one per target, per example).
Regression outputs (one score per target per example).
Rejang
reject this operator. Please update your model as soon 
Release_State_
ReleaseMutex
ReleaseSemaphore
ReleaseSRWLockExclusive
ReleaseSRWLockShared
ReluD
ReluE3
Remainder tensor
RemoveDuplicateCastTransformer
'repeat' input tensor must be 1 dimensional
'repeat' input tensor must have the same length as the 'input' tensor
repeats
Repeats
RepeatsCount
RepetitionWalker::ShortVisit called
replaced_value_float
replaced_value_int64
Requested size is too large to fit into size_t.
requested_shape[i] >= -1
Required attribute '
Required attribute axis is missing
Required inputs: 
Required min_gram_length must be positive: 
required_provider
REQUIREMENT_NOT_REGISTERED
reserved_chunks_.find(ptr) == reserved_chunks_.end()
ResetEvent
Reshape
Reshape_1
reshaped
Reshaped data.
Reshaped tensor with same data as input.
Resize
Resolve subgraph failed:
resource deadlock would occur
resource unavailable try again
result out of range
Result tensor.
Result, has same dimensions and type as A
Result, has same element type as two inputs
Result, has same shape and type as input
Result, has same type as input, with H and W dimensions reduced.
ReturnHr
Returns the tensor resulted from performing the `{name}` logical operation
reused != reused_for
reverse
ReverseSequence
Rgba8
RHcG(H;
Right input tensor for the logical operator.
right operand cannot broadcast on dim 
right.NumDimensions() == 2
rLH9r
RoGetActivationFactory
RoGetAgileReference
ROI pool output shape (height, width).
RoI pooled output 4-D tensor of shape (num_rois, channels, pooled_shape[0], pooled_shape[1]).
RoI pooled output, 4-D tensor of shape (num_rois, C, output_height, output_width). The r-th batch element Y[r-1] is a pooled feature map corresponding to the r-th RoI X[r-1].
roi_batch_id < batch_size
roi_batch_id >= 0
RoiAlign
RoIs (Regions of Interest) to pool over. Should be a 2-D tensor of shape (num_rois, 5) given as [[batch_id, x1, y1, x2, y2], ...].
RoIs (Regions of Interest) to pool over; rois is 2-D input of shape (num_rois, 4) given as [[x1, y1, x2, y2], ...]. The RoIs' coordinates are in the coordinate system of the input image. Each coordinate set has a 1:1 correspondence with the 'batch_indices' input.
rois input tensor has wrong dimension
RoIs tensor must have 2 dimensions
ROITensor
RoOriginateError
RoOriginateErrorW
RoOriginateLanguageException
RoTransformError
roundf
rt (.) (Ht-1 * (Rh^T) + Rbh)
rt (.) Ht-1
RtlCaptureContext
RtlDllShutdownInProgress
RtlLookupFunctionEntry
RtlPcToFileHeader
RtlVirtualUnwind
Runic
running (training) or estimated (testing) mean tensor of shape (C).
running (training) or estimated (testing) variance tensor of shape (C).
Running with tag: 
RunStateOnByteUnlocked failed after Reset
RunStateOnByteUnlocked failed after ResetCache
RUNTIME_EXCEPTION
RuntimeError
RuntimePerf
runtimeSessionId
rY1H+
s D9s8~!H
s D9s8~0L
S H9S(t,
S H9S(t7
s WATAVH
s&L9ox~ H
s@D9sX~!H
S@H+S8H
s@Hck83
s@Hck8A
s@Hck8I
s`HckXI
s|IcU
s8D9sP~!H
s8D9sP~0L
S8H9S@t,
S8H9S@t7
S8H9S0t:H+S0H
Samaritan
SAME_LOWER
SAME_UPPER
sample_size
SampleOp
Sampling ratio should be >=0, but it was 
sampling_ratio
sampling_ratio_ >= 0
Saurashtra
Saved mean used during training to speed up gradient computation.
Saved mean used during training to speed up gradient computation. Should not be used for testing.
Saved variance used during training to speed up gradient computation.
Saved variance used during training to speed up gradient computation. Should not be used for testing.
saved_mean
saved_var
SaveMLValueNameIndexMapping
Saving initialized tensors.
Saving kernels.
sbetu9
SbreH
Scalar multiplier for input tensor C, the default value is 1.0.
Scalar multiplier for input tensor C.
Scalar multiplier for the product of input tensors A * B, the default value is 1.0.
Scalar multiplier for the product of input tensors A * B.
Scalar specifying the number of classes in one-hot tensor. This is also the size of the one-hot dimension (specified by 'axis' attribute) added on in the output tensor and the values in the 'indices' input tensor are expected to be in the range [0, depth). TheIn case 'depth' is of non-integer type, it will be casted to int64 before use.
Scale
scale
scale > 0
scale >= 1
Scale for doing quantization to get 'y'. It could be a scalar or a 1-D tensor,which means a per-tensor or per-axis quantization. If it's a 1-D tensor, its number of elements should be equal to the dimension value of 'axis' dimension of input 'x'.
Scale for doing quantization to get 'y'. It's a scalar, which means a per-tensor/layer quantization.
Scale for input 'x'. It could be a scalar or a 1-D tensor, which means a per-tensor or per-axis quantization.If it's a 1-D tensor, its number of elements should be equal to the dimension value of 'axis' dimension of input 'x'.
Scale for input 'x'. It's a scalar, which means a per-tensor/layer quantization.
scale must be a scalar
scale of quantized input a
scale of quantized input b
scale of quantized output y
Scale size: (
Scale tensor for input 'B'. It's optional and default value is 0.  It could be a scalar or a 1-D tensor, which means a per-tensor or per-column quantization. If it's a 1-D tensor, its number of elements should be equal to the number of columns of input 'B'.
Scale tensor for input 'w'. It could be a scalar or a 1-D tensor, which means a per-tensor/layer or per output channel quantization. If it's a 1-D tensor, its number of elements should be equal to the number of output channels (M).
Scale tensor for input 'w'. It's optional and default value is 0.  It could be a scalar or a 1-D tensor, which means a per-tensor/layer or per output channel quantization. If it's a 1-D tensor, its number of elements should be equal to the number of output channels (M)
Scale tensor for input 'x'. It's a scalar, which means a per-tensor/layer quantization.
Scale tensor for output 'y'. It's a scalar, which means a per-tensor/layer quantization.
Scale tensor of shape (C).
Scale value should be greater than 0.
Scale value should be greater than or equal to 1.
scale_.size() == offset_.size()
scale->Shape().NumDimensions() == 0 || (scale->Shape().NumDimensions() == 1 && scale->Shape().GetDims().size() == 1)
ScaleBias
ScaleCount
Scaled output data.
scaledtanh
ScaledTanh
Scaler
Scales
scales
scales != nullptr
scales size should be greater than 0.
scales.size() == 4
scales_size > 0
ScaleSize
ScaleTensor
Scaling parameter.
Scaling value
Scan 'body' subgraph outputs should all be tensors but output 
Scan input 
Scan inputs have inconsistent batch size. Previous value was 
Scan inputs have inconsistent sequence lengths. Previous value was 
scan_input_axes
scan_input_directions
scan_output_axes
scan_output_directions
Scatter
Schema error: 
schemaVersion
score_threshold
scores
scores must be a 3D tensor.
SearchBitState inconsistency
SearchDFA inconsistency
SearchNFA inconsistency
SearchOnePass inconsistency
Second dimension for rois should be exactly 
Second input does not have rank 2
Second input operand for the logical operator.
Second input tensor has wrong dimension
Second operand, power of the exponent.
Second operand.
Second operand. With broadcasting can be of smaller size than A. If broadcasting is disabled it should be of the same size.
Second set of probability coefficients. This array must be same size as prob_a.<br>If these are provided then output Z are probability estimates, otherwise they are raw scores.
Second, multiply by this.<br>Can be length of features in an [N,F] tensor or length 1, in which case it applies to all features, regardless of dimension count.<br>Must be same length as 'offset'
sED;t$@}
Seed for the hashing algorithm, unsigned 32-bit integer, default to 0.
selected indices from the boxes tensor. [num_selected_indices, 3], the selected index format is [batch_index, class_index, box_index].
Selected output data as an array
selected_indices
separators
separators must not be empty
seq(map(int64, float))
seq(map(string, float))
seq_lengths
Sequence
sequence_lens
sequence_lens length of 
'sequence_lens' must have rank of 1
sequence_lens shape must be {batch_size}. Got:
Sequence<
SequenceIndex
SequenceLengthsTensor
SequentialExecutor::Execute
SESSION
Session
Session creation
Session has already been initialized.
Session not initialized.
Session successfully initialized.
Session was not initialized
session_initialization
session_logger != nullptr
session_state
SessionCreation
SetEvent
SetFilePointerEx
SetFilePointerEx 
SetLastError
setlocale
SetRestrictedErrorInfo
setting data_type field (tensor name: 
SetUnhandledExceptionFilter
setvbuf
sfH9_
Shape
shape
shape && tensor.Shape() == *shape
shape as a contiguous subset of the first tensor's shape. The starting of the
Shape input must be a one-dimensional tensor.
Shape must be 1 dimensional as it's tensor data is a shape
shape of left-hand-side argument. When broadcasting is specified, the second
Shape of the input tensor
shape.Size() must >=0
SHAPE_INFERENCE_NOT_REGISTERED
shapeTensor->Shape().NumDimensions() == 1
Sharada
Shavian
SHEX@
SHEX\
SHEX`
SHEX4
SHEXH
SHEXt
SHEXX
should never happen
Shouldn't be possible to have NodeArgs that haven't been handled already.
Shrink
Siddham
Sigmoid
sigmoid
SignWriting
Simplify case not handled: 
SimplifyWalker::ShortVisit called
Single dimension value must be greater than 0
Sinhala
sinhf
size is different
Size mismatch validating subgraph inputs. Got 
Size mismatch: feed_names has 
size overflow
size_ % 2 == 1
size_ == size
size_ > 0
size_t(impl_->max_gram_length_) <= impl_->ngram_counts_.size()
size_t(impl_->min_gram_length_) <= impl_->ngram_counts_.size()
Sizes
Sleep
SleepConditionVariableCS
SleepConditionVariableSRW
Slice
Slice op must have either three, four or five inputs.
Sliced data tensor.
slope
Slope tensor. If `Slope` is of size 1, the value is sharedacross different channels
Slope tensor. The shape of slope can be smaller then first input X; if so, its shape must be unidirectional broadcastable to X
SlopeTensor
SOFTMAX
softmax
Softmax
SOFTMAX_H9
SOFTMAX_ZERO
SoftmaxCPU inputs N, D and N * D must be < 
Softplus
softplus
SoftplusH
softplusH
Softsign
softsign
SoftsignH
softsignH
Sogdian
Sora_Sompeng
Soyombo
SpaceToDepth
SPARSE
sparse_tensor
sparse_tensor(
SparseTensor element type mismatch. 
spatial
Spatial
spatial == 1
spatial_scale
spatial_scale_ > 0
SpatialScale
SpD;S`|xA
sPD9sh~!H
Specified axis to insert a dimension
Specified shape for output.
Specify batchs of sequence words to embedding
Specify bias of conv
Specify embedding vector of char
Specify if the RNN is forward, reverse, or bidirectional. Must be one of forward (default), reverse, or bidirectional.
Specify weights of conv
spHckhI
Split
split
Split operator does not support 
sqrtf
Squeeze
squeezed
src.Size() == dst.Size()
st.IsOK()
Stack not empty.
Stacktrace:
start
start in Range operator should be scalar like tensor, yet got shape:
start_tensor->Shape() == ends_tensor->Shape()
started event
Starting indices of corresponding axis in `axes`
StartPadding
startpos: 
starts
Starts and axes shape mismatch
Starts and ends shape mismatch
Starts and steps shape mismatch
Starts must be a 1-D array
StartStopEvent::EventCategoryToString
state not recoverable
StateSaver failed to restore state.
static_cast<int>(activation_func_names.size()) == num_directions_ * 3
static_cast<ptrdiff_t>(dims.size()) == extents.size() && static_cast<ptrdiff_t>(dims.size()) >= steps.size()
static_cast<ptrdiff_t>(dims.size()) == starts.size() && static_cast<ptrdiff_t>(dims.size()) == extents_.size() && static_cast<ptrdiff_t>(dims.size()) >= steps.size()
static_cast<size_t>(num_variadic_inputs) == graph_inputs->size()
status.IsOK()
status.IsOK() && !impl_->ngram_counts_.empty()
status.IsOK() && !impl_->ngram_indexes_.empty()
status.IsOK() && !input_dimensions_.empty()
status.IsOK() && !pool_int64s.empty()
std::all_of( std::begin(missing_tracks_true_), std::end(missing_tracks_true_), [](int64_t elem) { return elem >= 0; })
std::all_of(impl_->ngram_indexes_.cbegin(), impl_->ngram_indexes_.cend(), [](int64_t i) { return i >= 0; })
std::all_of(split_sizes_.cbegin(), split_sizes_.cend(), [](int64_t value) { return value > 0; })
std::count_if(subgraph_node.InputEdgesBegin(), subgraph_node.InputEdgesEnd(), [input_slot_index](const Node::EdgeEnd& entry) { return entry.GetDstArgIndex() == input_slot_index; }) == 0
Steepness
'step' cannot be 0
'step' value cannot be 0
steps
stod argument out of range
stof argument out of range
stoi argument out of range
stol argument out of range
stoll argument out of range
stopped event
Stopword contains invalid utf8 chars
stopwords
storage_order
stoul argument out of range
stoull argument out of range
strchr
strcmp
strcspn
stream timeout
strerror_s
Stride along each axis.
Stride along each axis. If not present, the stride defaults to 1 along each axis.
strides
Strides
strides_.size() == kernel_shape_.size()
String
string
STRING data (tensor name: 
string enum that cases output to be lowercased/uppercases/unchanged. Valid values are "LOWER", "UPPER", "NONE". Default is "NONE"
string tensor can not have raw data
string tensor is not supported for copying between allocators
string too long
string_data
string_vocabulary
StringFileInfo
StringNormalizer
StringOutputStream.
Strings to tokenize
strstr
strtod
strtof
strtol
strtoll
strtoul
strtoull
sub_graph.Resolve().IsOK()
subgraph
Subgraph in 'body' produces 
Subgraph input missing type.
Subgraph must have the shape set for all outputs but 
Subgraph SessionState was not found for '
Subgraph SessionState was not found for 'body' attribute.
subgraph_session_state
SubmitThreadpoolWork
subtraction
SUCCESS
suffix matching is assumed. 1-dim expansion doesn't work yet.
sum square
Sundanese
Support vector coefficients.
support_vectors
SUVWATAUAVAWH
SUVWATAVAWH
SUVWAUAVAWH
SUVWAVH
SUVWH
SVATAUAVAWH
SVMClassifier
SVMRegressor
SVWATAUAVAWH
SVWATAVAWH
SVWAVAWH
SVWAVH
SWATAVAWH
sXD9sp~!H
sXHckPI
sxHckpI
sXHckPI
Syloti_Nagri
Syriac
system
SystemError
t @8x
t!HcSP;
t!HcV ;
t#D8=#pT
T$ 8\$(t
T$ D+
t$ D8t$XtQH
T$ D8zPtFH
T$ E3
t$ E3
T$ E3
T$ H;
T$ H;E
t$ H;t$8
t$ H+
T$ I;
T$ I+
T$ L)\$ 
T$ L;L$(
t$ UWATAVAWH
t$ UWAUAVAWH
t$ UWAVH
t$ UWAWH
t$ WATAUAVAWH
t$ WAVAWH
t$ WAVH
t$ WH
t$(E;n
T$(H;
T$(H9T$0t
T$(I;
t$(L;
T$(L;
t$@9t$8
t$@A8_pt
T$@E;S
T$@E3
t$@H!t$8L
T$@H;
t$@H;
T$@H;
t$@H;
T$@H;
t$@H;
T$@H;
T$@H+
t$@H+
T$@H+
t$@H+
T$@H+
T$@H+T$8H
t$@H9S
T$@H9T$Ht
t$@I;
T$@I+
T$@I9T$Ht
T$@I9Z
T$@Ic
t$@L+
T$@Lc
T$@M;
t$`@8p
t$`D8p
T$`E3
t$`E3
T$`E3
t$`E3
T$`E3
T$`H;
t$`H;
T$`H;
T$`H+
T$`H9T$ht
T$`Hc
T$`I;
t$`I;
T$`I;
t$`I;
T$`I;
t$`I+
t$`Ic
t$`L;
T$`L;
t$`L+
t$<;t$H
T$08MwI
t$0A;v8
t$0A^_
T$0A+
t$0E3
t$0H;
T$0H;
t$0H;
T$0H;
t$0H;
T$0H;
t$0H;
T$0H;
t$0H;
T$0H+
t$0H+
t$0H+t$(H
T$0H9\$Pt
t$0H9_
T$0H9L$Pt
T$0H9T$8t
t$0I;
T$0I+
t$0I+
T$0Ic
t$0L;
t$0L;m
t$0L+
t$4D;
t$4D8g
T$4Hc
t$4L91
T$88B8
T$89T$@
T$89T$<
t$8D!t$4A
t$8D#
t$8D8t$HtBH
T$8E3
t$8E3
T$8E3
T$8H!\$8
T$8H;
T$8H;AHtJ
T$8H;APtJ
T$8H+
t$8H+
T$8H+
t$8H+
T$8H+
T$8H9T$@t
t$8I;
T$8I+
t$8Ic
t$8L;
t$8L9 u
t$8M;
T$8M;
T$8M9
t$8t6H
T$DD9T$@
t$h@8p t4H
t$HA_A^A]A\_
t$hA8
t$HcS
T$hD;r`
t$hD8p t4H
T$HE3
t$HE3
T$HE3
t$HH;
T$hH;
t$hH;
t$HH;
T$hH+
T$HH+
T$hH+
T$HH+
T$hH+
T$HH+
T$hH+
T$HH+
T$hH+
T$HH+
T$hH+
T$HH+
T$hH+
T$HH+
T$hH+
T$HH+
T$hH+
T$HH+
t$hH+
T$HH+
T$hH+
T$HH+
T$hH+
T$HH+
T$hH+
T$HH+
t$hH+
T$hH+
T$HH+
T$hH+
T$HH+
T$hH+
T$HH+
T$hH+
T$HH+
T$hH+
T$HH+
T$hH+
T$HH+
T$hH+
T$HH+
T$hH+
T$HH+
T$hH+
t$hH+
T$HH+
t$hH+
T$HH+
t$hH+
T$HH+
T$hH+
T$HH+
T$hH+
T$HH+
T$hH+
t$hH+
T$hH+
T$HH+
T$hH+
T$HH+
T$hH+
T$HH+
T$hH+
T$HH+
T$hH+
t$hH+
t$HH9|$@t
T$HH9T$Pt
T$hH9T$pt
T$HH9T$Pt
T$HH9T$Pt&L
T$HH9T$Pt'H
T$HHc
t$HI;
T$hI;
t$HI+
t$HIc
t$HL;
t$hL+
t$HL+
T$HLc
t$HM;
t$hM;
t$HM;
t$hM;>
t$p;w
t$PA8
t$PA8_pt
t$PE3
T$pE3
t$PE3
T$PE3
t$PE3
T$PE3
T$pE3
T$PH;
t$PH;
T$PH;
T$pH;
t$PH;
t$pH;
T$pH;
T$PH;
T$pH;
T$PH;
T$PH+
T$pH+
T$PH+
T$pH+
T$PH+
T$pH+
T$PH+
T$pH+
T$PH+
T$pH+
T$PH+
T$pH+
T$PH+
T$pH+
T$PH+
T$pH+
T$PH+
T$pH+
T$PH+
T$pH+
T$PH+
T$pH+
T$PH+
T$pH+
T$PH+
T$pH+
T$PH+
T$pH+
T$PH+
T$pH+
T$PH+
T$pH+
T$PH+
T$pH+
T$PH+
T$pH+
T$PH+
T$pH+
T$PH+
T$pH+
T$PH+
T$pH+
T$PH+
T$pH+
T$PH+
T$pH+
T$PH+
T$pH+
T$PH+
T$pH+
T$PH+
t$PH+
T$PH+
T$pH+
T$PH+
t$PH+
T$PH+
T$pH+
T$PH+
T$pH+
T$PH+
T$pH+
T$PH+
T$pH+
T$PH+
t$PH+
t$PH+\$hH
T$PH+T$HH
t$pH9\$ u
T$PH9T$X
T$PH9T$Xt
T$pH9T$xt
t$PHc
T$pHcE
T$pHcM
t$PHcS
T$pI;
T$PI;
t$pI;
T$PI;UXt
t$pI+
T$PI9O
t$PIc
t$PL;
T$PL;
t$PL;
t$pL;
T$PL;:
T$PL;T$H
t$PL+
T$PM;
t$PM;
T$pM+
t$x9s0
t$XD8wPt2
T$xE3
t$XE3
T$XE3
t$XfA
t$xH;
t$XH;
T$xH+
T$XH+
T$xH+
T$XH+
T$xH+
T$XH+
T$xH+
T$XH+
T$xH+
T$XH+
T$xH+
T$XH+
T$xH+
T$XH+
T$xH+
T$XH+
T$xH+
T$XH+
T$xH+
T$XH+
T$xH+
T$XH+
T$xH+
t$xH+
T$xH+
T$XH+
T$xH+
T$XH+
T$xH+
T$XH+
T$xH+
T$XH+
T$xH+
T$XH+
T$xH+
T$XH+
T$xH+
T$XH+
T$xH+
T$XH+
T$xH+
T$XH+
T$xH+
T$XH+
T$xH+
T$XH+
T$xH+
T$XH+
T$xH+
T$XH+
T$xH+
T$XH+
T$xH+
T$XH+
T$xH+
T$XH+
T$xH+
T$XH+
T$xH+
T$XH+
T$xH+
T$XH+
T$xH+
T$XH+
T$xH+
T$XH+
T$xH+
T$XH+
T$xH+
T$XH+
T$xH+
T$XH+
T$xH+
T$XH+
T$xH+
T$XH+
T$xH+
T$XH+
T$xH+
T$XH+
T$xH+
T$XH+
T$xH+
T$XH+
T$xH+
T$XH+
T$xH+
T$XH+
T$XH9T$`
T$XH9T$`t
T$XI;
t$XI;
T$xI;
T$XI;VXt
T$XI+
T$xI+
T$XI+
t$xIc
T$XL!
t$XL;
t$xL;
t$xL;t$h
t$XLcL$TI
T$XM;
T$xM;
T$XM;
t%A9X H
t%L9+t
t*HcS@H
t*HcS`H
t*HcSPH
t*HcU
t.HcS
t.HcS0H
t.HcSHH
t.HcWxH
t/HcSpH
t:E9`
t:M;u
t;H;1u'L
t?H9t$Pu2H
t?L9_
t^I;7tt@
t_proto.dims()[0] == 1
t_proto.dims_size() == 1
t_proto.has_data_type()
t{HcL$ HcD$$H
t0D;`
t0H;Q`t*H
T1 != nullptr
t1E;`
t1HcU
t2A;~ },I
t2H9|$Pt
t2HcT$XH
t3H9Q
t3I;8
t4D9n@
t5H;=
t5HcU
t5L9I
t6H;=Ku
t6HcT$8H
t7L9>t
t8H9E
t8HcU@H
t9H9X
t9HcT$8H
t9L9S
Tagalog
Tagbanwa
tAH;s |;H
Tai_Le
Tai_Tham
Tai_Viet
Takri
tALcM
Tamil
Tangut
TanhD
tanhD
TanhD
tanhf
tanhH9\$Pt5H
Target shape may not have multiple -1 dimensions
Target tensor description expects IMG_TENSOR_CHANNEL_TYPE_BGR_8, but has %d channels specified instead of 3.
Target tensor description expects IMG_TENSOR_CHANNEL_TYPE_GRAY_8, but has %d channels specified instead of 1.
Target tensor description expects IMG_TENSOR_CHANNEL_TYPE_GRAY_8, IMG_TENSOR_CHANNEL_TYPE_BGR_8, or IMG_TENSOR_CHANNEL_TYPE_RGB_8 but has %d was specified.
Target tensor description expects IMG_TENSOR_CHANNEL_TYPE_RGB_8, but has %d channels specified instead of 3.
Target tensor description must either be IMG_TENSOR_DATA_TYPE_FLOAT32, or IMG_TENSOR_DATA_TYPE_FLOAT16. %d was supplied.
Target tensor height (%d) does not match input height (%d).
Target tensor width (%d) does not match input width (%d).
target_ids
target_nodeids
target_nodeids_.size() == target_ids_.size()
target_nodeids_.size() == target_weights_.size()
target_treeids
target_weights
targets
tb@8=0`T
tBD8o&tAD
tbL9Chu
tCH;2u/H
tCI;0u/
tcI9_
tCL;8u/H
tEH9t$Pu2H
teI;7
TelemetryNameFromEnum
Telugu
TempSpace allocator not found
tensor
tensor A * B
Tensor after padding.
tensor C
tensor can either be of element size 1 (including a scalar tensor and any
tensor can't contain negative dims
Tensor element type mismatch. 
tensor has the same rank as the input if keepdims equal 1. If keepdims equal 0, then
tensor of bool, which should be a scalar.
Tensor of data to extract slices from.
Tensor of int32/int64 indices, of any rank q.
Tensor of int32/int64 indices, of r >= 1 (same rank as input).
tensor of int64, which should be a scalar.
Tensor of integers indicating the number of padding elements to add or remove (if negative) at the beginning and end of each axis. For 2D input tensor, it is the number of pixels. `pads` should be a 1D tensor of shape [2 * input_rank] or a 2D tensor of shape [1, 2 * input_rank]. `pads` format (1D example) should be as follow [x1_begin, x2_begin,...,x1_end, x2_end,...], where xi_begin is the number of pixels added at the beginning of axis `i` and xi_end, the number of pixels added at the end of axis `i`.
Tensor of rank one greater than input tensor 'indices', i.e. rank(output) = rank(indices) + 1. The data type for the elements of the output tensor is the same as the type of input 'values' is used.
Tensor of rank q + (r - 1).
Tensor of rank q >= 1.
Tensor of rank q-1+r-indices[-1].
Tensor of rank r >= 1 (same rank as input).
Tensor of rank r >= 1.
Tensor of rank r >= 2.
Tensor of rank r >=1 (same rank and shape as indices)
Tensor of rank r if axis is specified. Otherwise output is a Tensor of rank 1.
Tensor of shape [a_1, a_2, ..., a_{axis-1}, k, a_{axis+1}, ... a_n] containing the corresponding input tensor indices for the top K values.
Tensor of shape [a_1, a_2, ..., a_{axis-1}, k, a_{axis+1}, ... a_n] containing top K values from the input tensor
Tensor of shape [a_1, a_2, ..., a_n, r]
Tensor of shape equal to the broadcasted shape of condition, X, and Y.
Tensor shape cannot contain any negative value
Tensor size mismatch
tensor size overflow
tensor slope
Tensor specifying lengths of the sequences in a batch. It has shape `[batch_size]`.
Tensor to copy input into.
tensor type 
Tensor type mismatch.
Tensor type mismatch. 
tensor with rank equal to or smaller than the first tensor), or having its
Tensor with same shape of input.
tensor(
tensor(bool)
tensor(complex128)
tensor(complex64)
tensor(complext128)
tensor(complext64)
tensor(double)
tensor(float)
tensor(float16)
tensor(int16)
tensor(int32)
tensor(int64)
tensor(int8)
Tensor(scalar, or dims=[1]). First entry in the range.
Tensor(scalar, or dims=[1]). Number that increments start. Defaults to 1.
Tensor(scalar, or dims=[1]). Upper limit of sequence, exclusive.
tensor(string)
tensor(string) expected as input
tensor(uint16)
tensor(uint32)
tensor(uint64)
tensor(uint8)
tensor_shape.Shape().GetDims().size() == 1
tensor_type.has_elem_type()
Tensorization conversion is only supported to IMG_TENSOR_DATA_TYPE_FLOAT32, or IMG_TENSOR_DATA_TYPE_FLOAT16.
Tensorize Descriptor Heap
Tensorize Rootsignature
TensorProto ( tensor name: 
TensorProto (tensor name: 
TensorProto::DataType_IsValid(t_proto.data_type())
TensorrtExecutionProvider
Tensors with at least max(dims) dimensions.
TensorString objects cannot be created from a ID3D12Resource!
ter!u13
terminate
TerminateProcess
test mode or not, the output Y will either be a random dropout, or a simple
text file busy
text size: 
TFIDF
TfIdfVectorizer
tFL;8u2
tfL+t$@I
tHA;y0t
Thaana
than the operator set version 
t'HcG<
The above behavior is similar to numpy, with the exception that numpy default keepdims to
The arccosine of the input tensor computed element-wise
The arcsine of the input tensor computed element-wise
The arctangent of the input tensor computed element-wise
The attention_v tensor in the attention mechanism. Should be of shape `[num_directions, am_attn_size]` 
The axis along which same quantization parameters are applied. It's optional.If it's not specified, it means per-tensor quantization and input 'x_scale' and 'x_zero_point' must be scalars.If it's specified, it means per 'axis' quantization and input 'x_scale' and 'x_zero_point' must be 1-D tensors.
The axis in which to compute the arg indices.
The axis on which to apply normalization, -1 mean last axis.
the axis provided, then input will be coerced into a 2-dimensional tensor with
The bias as a 1-dimensional tensor of size C to be applied to the output.
The bias tensor for input gate. Concatenation of `[Wb[iofc], Rb[iofc]]`, and `[WBb[iofc], RBb[iofc]]` (if bidirectional) along dimension 0. This tensor has shape `[num_directions, 8*hidden_size]`. Optional: If not specified - assumed to be 0.
The bias tensor for input gate. Concatenation of `[Wbi, Rbi]` and `[WBbi, RBbi]` (if bidirectional). The tensor has shape `[num_directions, 2*hidden_size]`. Optional: If not specified - assumed to be 0.
The bias tensor for the gates. Concatenation of `[Wb[zrh], Rb[zrh]]` and `[WBb[zrh], RBb[zrh]]` (if bidirectional) along dimension 0. This tensor has shape `[num_directions, 6*hidden_size]`. Optional: If not specified - assumed to be 0
The bias value added to output. Default is 0.
The binding collection does not contain a variable with name %s.
The buffer planner is not consistent with tensor buffer size, expected 
The class score for each class, for each point, a tensor of shape [N,E].
The convolution operator consumes an input tensor and {filter_desc}, and
The convolution transpose operator consumes an input tensor and {filter_desc},
The cosine of the input tensor computed element-wise
The data type for the elements of the output tensor. Default is TensorProto::FLOAT.
The data type for the elements of the output tensor. If not specified, default is TensorProto::FLOAT.
The data type to which the elements of the input tensor are cast. Strictly must be one of the types from DataType enum in TensorProto
The dimension with value zero exceeds the dimension size of the input tensor.
The engine produced an unexpected evaluation output %s, that is not a model variable output.
The engine produced an unexpected evaluation output %s, that is not a model variable.
The engine produced an unexpected evaluation output for unbound output variable %s.
The epsilon value to use to avoid division by zero, default is 1e-5f.
The epsilon value to use to avoid division by zero.
The error function of the input tensor computed element-wise. It has the same shape and type of the input.
The exponent.
The exponential of the input tensor computed element-wise
The filled tensor
The graph run each iteration. It has 2+N inputs: (iteration_num, condition, loop carried dependencies...). It has 1+N+K outputs: (condition, loop carried dependencies..., scan_outputs...). Each scan_output is created by concatenating the value of the specified output value at the end of each iteration of the loop. It is an error if the dimensions or data type of these scan_outputs change across loop iterations.
The graph run each iteration. It has N+M inputs: (loop state variables..., scan_input_elts...). It has N+K outputs: (loop state variables..., scan_output_elts...). Each scan_output is created by concatenating the value of the specified scan_output_elt value at the end of each iteration of the loop. It is an error if the dimensions of these values change across loop iterations.
The hyperbolic arccosine values of the input tensor computed element-wise
The hyperbolic arcsine values of the input tensor computed element-wise
The hyperbolic arctangent values of the input tensor computed element-wise
The hyperbolic cosine values of the input tensor computed element-wise
The hyperbolic sine values of the input tensor computed element-wise
The hyperbolic tangent values of the input tensor computed element-wise
The id of the tree that each node is in.
The id of the tree that this node is in.
The index of the class list that each weight is for.
The index of the target that each weight is for
The indices, based on 0 as the first index of any dimension.
The initial values of any loop-carried dependencies (values that change across loop iterations)
The input 1-dimensional bias tensor of size C.
The input 1-dimensional scale tensor of size C.
The input 4-dimensional tensor of shape NCHW.
The input data as Tensor.
The input map that is to be cast to a tensor
The input must be a map from strings or integers to either strings or a numeric type. The key and value types cannot be the same.
The input must be a tensor of a numeric type or string. The output will be of the same tensor type.
The input must be a tensor of a numeric type, and of of shape [N,C] or [C]. In the latter case, it will be treated as [1,C]
The input must be a tensor of a numeric type, either [C] or [N,C].
The input must be a tensor of a numeric type.
The input must be a tensor of a numeric type. The output will be of the same tensor type.
The input must be a tensor of strings or integers, either [N,C] or [C].
The input must be an integer map to either string or float.
The input sequences packed (and potentially padded) into one 3-D tensor with the shape of `[seq_length, batch_size, input_size]`
The input sequences packed (and potentially padded) into one 3-D tensor with the shape of `[seq_length, batch_size, input_size]`.
The input tensor cannot be reshaped to the requested shape. Input shape:
The input tensor that's coerced into a 2D matrix of size (NxD) as described above.
The input type is a tensor of any shape.
The input type must be a tensor of a numeric type, either [C] or [N,C].
The input type must be a tensor of a numeric type, either [N,C] or [C]. The output type will be of the same tensor type and shape.
The input type must be a tensor of a numeric type.
The input type must be a tensor of integers or strings, of any shape.
The input values
The integers of the map. This sequence must be the same length as the 'cats_strings' sequence.
The kernel type, one of 'LINEAR,' 'POLY,' 'RBF,' 'SIGMOID'.
The keys when using int keys.<br>One and only one of the 'classlabels_*' attributes must be defined.
The keys when using string keys.<br>One and only one of the 'classlabels_*' attributes must be defined.
The lambd value for the Shrink formulation. Default is 0.5.
The last output value of the cell. It has shape `[num_directions, batch_size, hidden_size]`.
The last output value of the hidden. It has shape `[num_directions, batch_size, hidden_size]`.
The last output value of the hidden. It has shape `[num_directions, batch_size, hidden_size]`. 
The mean of the normal distribution.
The model contains a 16-bit float Cast Op (%s), but the current device does not support 16-bit float.
The model contains a 16-bit float initializer (%s), but the current device does not support 16-bit float.
The model contains a 16-bit input (%ls), but the current device does not support 16-bit float.
The model contains a 16-bit output (%ls), but the current device does not support 16-bit float.
The model has been disposed.
The model has input %s with a fixed batch dimenions of size %lld not equal %d specified by the batch_size_override.
The model has no variable with name %s.
The model proto is null.
The model variable %s cannot be bound with the provided type.
The model variable %s failed tensorization.
The model variable %s is an input, but has no associated resources to bind.
The most inner dimension in boxes must have 4 data.
The natural log of the input tensor computed element-wise
The new GRU hidden state calculated by this op.
The node id of each weight
The node is not placed on any Execution Provider
The node is not placed on any Execution Provider, therefore, can't find a suitable kernel for it
The node kind, that is, the comparison to make at the node. There is no comparison to make at a leaf node.<br>One of 'BRANCH_LEQ', 'BRANCH_LT', 'BRANCH_GTE', 'BRANCH_GT', 'BRANCH_EQ', 'BRANCH_NEQ', 'LEAF'
The number of channels to sum over
The number of support vectors.
The operator computes the {name} ({description}) values for each layer in the batch
The order of the normalization, only 1 or 2 are supported.
The output 4-dimensional tensor of the same shape as input.
The output 4-dimensional tensor of the same shape as X.
The output array, elements ordered as the inputs.
The output is a 1-D tensor of string, float, or integer.
The output is a tensor of strings or integers. Its shape will be the same as the input shape.
The output map
The output mask.
The output mask. If is_test is nonzero, this output is not filled.
The output of each pooling window is divided by the number of elements (exclude pad when attribute count_include_pad is zero).
The output of each pooling window is divided by the number of elements exclude pad.
The output of each pooling window is maximum number of elements exclude pad.
The output tensor of the same shape as input.
The output tensor of the same shape as X
The output tensor of the same shape as X.
The output type will be a tensor of strings or integers, and will have the same shape as the input.
The output type will be a tensor of strings or integers, depending on which of the the classlabels_* attributes is used.
The output type will be a tensor of strings or integers, depending on which of the the classlabels_* attributes is used. Its size will match the bactch size of the input.
The output values with the same shape as input tensor (the original size without coercion).
The output will be a sequence of string or integer maps to float.
The output will be a tensor of strings or integers.
The output will be a tensor of the value type of the input map. It's shape will be [1,C], where C is the length of the input dictionary.
The output.
The pooling method. Two modes are supported: 'avg' and 'max'. Default is 'avg'.
The previous GRU hidden state.
The rank of input tensor must be >= axis
The ratio of random dropout
The recurrence weight tensor. Concatenation of `R[iofc]` and `RB[iofc]` (if bidirectional) along dimension 0. This tensor has shape `[num_directions, 4*hidden_size, hidden_size]`.
The recurrence weight tensor. Concatenation of `R[zrh]` and `RB[zrh]` (if bidirectional) along dimension 0. This tensor has shape `[num_directions, 3*hidden_size, hidden_size]`.
The recurrence weight tensor. Concatenation of `Ri` and `RBi` (if bidirectional). The tensor has shape `[num_directions, hidden_size, hidden_size]`.
the resulted tensor have the reduced dimension pruned.
The running mean (training) or the estimated mean (testing) as a 1-dimensional tensor of size C.
The running mean after the BatchNormalization operator.
The running mean after the BatchNormalization operator. Must be in-place with the input mean. Should not be used for testing.
The running variance (training) or the estimated variance (testing) as a 1-dimensional tensor of size C.
The running variance after the BatchNormalization operator.
The running variance after the BatchNormalization operator. Must be in-place with the input var. Should not be used for testing.
The scale along height dimension. It takes value greater than or equal to 1.
The scale along width dimension. It takes value greater than or equal to 1.
The scale array along each dimension. It takes value greater than 0. If it's less than 1, it's sampling down, otherwise, it's upsampling. The number of elements of 'scales' should be the same as the rank of input 'X'.
The scale array along each dimension. It takes value greater than or equal to 1. The number of elements of 'scales' should be the same as the rank of input 'X'.
The scale as a 1-dimensional tensor of size C to be applied to the output.
The scale to apply.
The scaled hyperbolic tangent values of the input tensor computed element-wise
The sequence length of the input memory for the attention mechanism. Should be of `[batch_size]` 
The sequence of the memory (input) for attention mechanism. Should be of `[batch_size, max_memory_step, memory_depth]` 
The sequence output for the hidden is optional if 0. Default 0.
The shape of filled tensor
The shape of the convolution kernel. If not present, should be inferred from input W.
The shape of the convolution kernel. If not present, should be inferred from input 'w'.
The shape of the output can be explicitly set which will cause pads values to be auto generated. If output_shape is specified pads values are ignored. See doc for details for equations to generate pads
The shape of the output can be explicitly set which will cause pads values to be auto generated. If 'output_shape' is specified, 'pads' values are ignored.
The shape of the output tensor.
The sign of the input tensor computed element-wise. It has the same shape and type of the input.
The sine of the input tensor computed element-wise
The size of each input in the input list
The size of the kernel along each axis.
The softsign (x/(1+|x|)) values of the input tensor computed element-wise
The standard deviation of the normal distribution.
The starting indexes of 1-grams, 2-grams, and so on in pool. It is useful when determining the boundary between two consecutive collections of n-grams. For example, if ngram_counts is [0, 17, 36], the first index (zero-based) of 1-gram/2-gram/3-gram in pool are 0/17/36. This format is essentially identical to CSR (or CSC) sparse matrix format, and we choose to use this due to its popularity.
The storage order of the tensor. 0 is row major, and 1 is column major.
The string used to pad output tensors when the tokens extracted doesn't match the maximum number of tokens found. If start/end markers are needed, padding will appear outside the markers.
The strings of the map. This sequence must be the same length as the 'cats_int64s' sequence
The subgraph in 'body' expects 
The subgraph in 'body' requires 
The tangent of the input tensor computed element-wise
The tensor has been closed and its resources are detached!
The tensor has been closed and its resources have been detached during evaluation!
The tensor has been closed and its resources have been detached!
The tensor has outstanding memory buffer references that must be closed prior to evaluation!
the tensor to be tiled using Tile OP must be atleast 1 dimensional
The tensor to split
The timestep for this operation.
The total number of regression targets, 1 if not defined.
The total number of targets.
the training phase, so during testing nothing needs to be done.
The type of the output tensor is integer.
The value for the elements of the output tensor.
The weight for each target
The weight for the class in class_id.
The weight tensor for input gate. Concatenation of `Wi` and `WBi` (if bidirectional). The tensor has shape `[num_directions, hidden_size, input_size]`.
The weight tensor for peepholes. Concatenation of `P[iof]` and `PB[iof]` (if bidirectional) along dimension 0. It has shape `[num_directions, 3*hidde_size]`. Optional: If not specified - assumed to be 0.
The weight tensor for the gates. Concatenation of `W[iofc]` and `WB[iofc]` (if bidirectional) along dimension 0. The tensor has shape `[num_directions, 4*hidden_size, input_size]`.
The weight tensor for the gates. Concatenation of `W[zrh]` and `WB[zrh]` (if bidirectional) along dimension 0. This tensor has shape `[num_directions, 3*hidden_size, input_size]`.
The weight tensor of the memory layer in the attention mechanism. Should be of shape `[num_directions, memory_depth, am_attn_size]` 
The weight tensor of the query layer in the attention mechanism. Should be of shape `[num_directions, am_query_depth(hidden_size of lstm), am_attn_size]` 
The weight tensor that will be used in the convolutions; has size (C x M/group x kH x kW), where C is the number of channels, and kH and kW are the height and width of the kernel, and M is the number of feature maps. For more than 2 dimensions, the weight shape will be (C x M/group x k1 x k2 x ... x kn), where (k1 x k2 x ... x kn) is the dimension of the kernel. The number of channels in the output should be equal to W.shape[1] * group (assuming zero based indices of the shape array)
The weight tensor that will be used in the convolutions; has size (M x C/group x kH x kW), where C is the number of channels, and kH and kW are the height and width of the kernel, and M is the number of feature maps. For more than 2 dimensions, the kernel shape will be (M x C/group x k1 x k2 x ... x kn), where (k1 x k2 x ... kn) is the dimension of the kernel. Optionally, if dimension denotation is in effect, the operation expects the weight tensor to arrive with the dimension denotation of [FILTER_OUT_CHANNEL, FILTER_IN_CHANNEL, FILTER_SPATIAL, FILTER_SPATIAL ...]. X.shape[1] == (W.shape[1] * group) == C (assuming zero based indices for the shape array). Or in other words FILTER_IN_CHANNEL should be equal to DATA_CHANNEL. 
The weighting criteria. It can be one of "TF" (term frequency), "IDF" (inverse document frequency), and "TFIDF" (the combination of TF and IDF)
The weights of attention layer in the attention wrapper. If exists, should be of shape `[num_directions, memory_depth+hidden_size, aw_attn_size]. Please note that attention mechanism context depth is also memory_depth in the attention mechanism.` 
The zero-padding added to one side of the output. This is also called adjs/adjustment in some frameworks.
then_branch
then_branch and else_branch produce different number of outputs. 
there are multiple cases for the number of outputs, which we list below:
There's no data transfer registered for copying tensors from 
This API is not supported when model is loaded from proto file right now.
This is an invalid model. At top level graph without matching NodeArg that subgraph consumes. Name=
This is an invalid model. Error in Node:
This is an invalid model. Error: Duplicate definition of name (
This is an invalid model. Error: the graph is not acyclic.
This is an invalid model. Error: two nodes with same node name (
This is an invalid model. Failed to find NodeArg in all parent graphs. Name=
This is an invalid model. Graph output (
This is an invalid model. Model input (
This is an invalid model. Node (
This is an invalid model. The sum of input arg count is not equal to size of input defs in node (
This is an invalid model. Type Error: Type '
This operator applies convolution to word from left to right with window equal to conv_window_size and stride to 1.Take word 'example' for example, with conv_window_size equal to 2, conv is applied to [ex],[xa], [am], [mp]...If not provide, use the first dimension of conv kernal shape.
This operator has **optional** inputs/outputs. See [the doc](IR.md) for more details about the representation of optional arguments. An empty string may be used in the place of an actual argument's name to indicate a missing argument. Trailing optional arguments (those not followed by an argument that is present) may also be simply omitted.
This operator supports **multidirectional (i.e., Numpy-style) broadcasting**; for more details please check [the doc](Broadcasting.md).
This operator supports **unidirectional broadcasting** (
This session already contains a loaded model.
This shouldn't be called if all the sizes are equal.
This transformer is already registered 
This ZeroCopyOutputStream doesn't support aliasing. Reaching here usually means a ZeroCopyOutputStream implementation bug.
thisProto->map_type().has_key_type()
thisProto->map_type().has_value_type()
thisProto->sequence_type().has_elem_type()
thisProto->tensor_type().has_elem_type()
thisProto->value_case() == TypeProto::ValueCase::kMapType
thisProto->value_case() == TypeProto::ValueCase::kSequenceType
thisProto->value_case() == TypeProto::ValueCase::kTensorType
Thread ID
threadId
Three modes: `constant`(default) - pads with a given constant value, `reflect` - pads with the reflection of the vector mirrored on the first and last values of the vector along each axis, `edge` - pads with the edge values of array
Three modes: constant(default), reflect, edge
Threshold
threshold
Threshold value
ThresholdedRelu
thresholdedrelu
Thresholds to do the splitting on for each node.
Tibetan
tiD91v
Tifinagh
Tile doesn't have an implementation yet for the type: 
tiles
Time Stamp (us)
time_axis
time_axis < 2
time_axis and batch_axis must have different values but both are 
timed out
Tirhuta
tKE;Y |E
tLH;>
tmp_cats_int64s.empty() || tmp_cats_strings.empty()
to flatten the input shape to (N x C*D1*D2 ..*Dn) before a BatchNormalization Op.
to match the shape of left-hand-side argument. See the doc of `Add` for a
TO_FLOAT
TO_FLOATH
TO_INT64
TO_STRING
tokenexp
Tokenized strings
Tokenizer
tolower
too many files open
too many files open in system
too many links
too many symbolic link levels
Total allocated bytes: 
Total number of elements of the input tensor
totalEvalCalls
tPH;>
tPH;L$`tBL
tQI;>
TraceAllocation for ort_value_idx=
TraceFree for ort_value_idx=
trailing \
transA
TransA
transB
TransB
Translation
Transpose
transposed
Transposed output.
Tree id for each node.
TreeEnsembleClassifier
TreeEnsembleRegressor
treeindex >= 0
treeindex evaluated to a negative value, which should not happen.
tRH;>
tRI9w
tried to allocate 0 bytes
Tried to allocate without valid type information, ort_value index=
trLcO$
TryAcquireSRWLockExclusive
Trying to allocate memory for unused optional inputs/outputs
Trying to register schema with name 
TrySubmitThreadpoolCallback
tSI;>tg
tSI;7
ttMcN
tuLcD$ E
TUUUUUU
tVHc^$
tvL9;t
tWH9]
tWI;>tq
Two interpolation modes: nearest (default), and linear (including bilinear, trilinear, etc)
Two interpolation modes: nearest(default), bilinear
tyI;6
tyM;}
type != nullptr
type == dtype_
Type Error: Shape of initializer 
Type Error: Type (
Type Error: Type parameter (
Type Error: Value of initializer 
type field and data field mismatch in attribute 
Type for Tind not supported yet in Gather.
Type mismatch. Current=
type mismatch. existing=
Type not supported.
type: 
typeConstraintCount
tzH;>
tZL9C
U IcE
u!9y }
u"9B }
u"9H }
u"9P }
u"9x }
u#D9R
u#E8t$d
u#E9P }
u#H9<
u#H9H s
u#H9p s
u#H9P s
u#H9q s
u#H9x s
u#H9Y }
u#J9<
u#L9@ }
u#L9@ s
u#L9A }
u#L9A s
u#L9p s
u#L9R s
u#L9X s
u$H9{(t
u$H9P s
u$I9Q s
u&9h }
u&H9u@t
u(D8gdtoH
u(D8odtoH
U(H9x 
U(LcM I
u)A8y
u,8QXt'H
u.A;h
u/9p |
U@LcM8I
u`8D$<t
U`I+UXH
u+99|'L
u<!T$`
u>Hc/H
U0I+U(H
u1</w
u1D;w
u1D8l
u2E9n
u4f9O
u4H!B
u5!D$4H
U7H;U?s H
u8A9]
u8D9R
u8L9t$ht
UATAUAVAWH
UATAUH
UATAVH
UATAWH
UAUAVH
UAUAWH
UAVAWH
uCL9w
udA8G
uE@8;
uEHc/H
Ugaritic
uhLcO$A
ui8Y$t
uint16
UInt16
UInt32
uint32
UInt64
uint64
uint64_data
UInt8
uint8
ulL;7
Unactivated gate outputs from forget, update, and output gates, pre-activation.
undefined
Undefined
Unexpected CAST_TO value of 
Unexpected descriptor LearningModelFeatureKind.
unexpected error
unexpected failure
Unexpected input data type. Actual: (
Unexpected NORMALIZE value of 
Unexpected op in Regexp::Equal: 
Unexpected opcode in IsMatch: 
Unexpected opcode in short circuit: 
Unexpected opcode: 
Unexpected special state in RunStateOnByte
Unexpected TensorKind Complex128.
Unexpected TensorKind Complex64.
Unexpected TensorKind Undefined.
Unexpected 'to' argument value: 
ungetc
unhandled 
Unhandled 
unhandled opcode: 
UnhandledExceptionFilter
Unique
unknown
Unknown AutoPadType String
Unknown Category and zeros = 0.
Unknown encoding 
unknown error
Unknown error during EndProfiling()
Unknown exception
Unknown exception in Load()
Unknown model file format version.
unknown round: 
Unknown tensor type of 
unknown_dim == -1
Unloading DSO 
unpack_status.IsOK()
UnpackTensor: the pre-allocate size does not match the size in proto
UnpackTensor: the pre-allocated size does not match the raw data size, expected 
Unrecognized attribute: 
Unrecognized data_type (tensor name: 
Unrecognized type value case (value_info name: 
Unsqueeze
UnsqueezeElimination
Unsupported 
Unsupported AutoPad Type.
Unsupported data type
Unsupported 'dtype' value: 
Unsupported image with 
Unsupported input datatype
Unsupported level
Unsupported level 
Unsupported non-raw-data data type!
Unsupported pooling size : 
Unsupported pooling size.
Unsupported type:
Unsupported value attribute datatype: 
Unsupportted tensor data type:
uOD9Bt~
UpA8F t;L
uPD9B,~
uPD9BD~
UpdateGateTensor
updates
UpdatesTensor
UPfA;
UPH9uhH
upHcG$L
UPPER
Upper boundary of the output values.
Upsample
Upsample: Input dims != attribute 'scales' dims
Upsample: input tensor's dimension does not match the scales.
Upsample: input/output value is nullptr
Upsample: input/output value's dimension mismatch
Upsample: linear mode upsample only support 4-D tensor with NCHW layout
Upsample: linear mode upsample only support bilinear with 4 dimension.
Upsample: linear mode upsample only support bilinear, the first 2 scales should be 1.
Upsample: unexpected mode
uQLcC0
urD9eW}%L
UseCellMemoryMinusOneTensor
UseClipThreshold
usefp16
UseRecurrenceTensor
Using an input in multiple nodes on different devices is not supported currently. Input:
USVATAUAVAWH
USVWATAUAVAWH
USVWATAUAVH
USVWATAUAWH
USVWATAVAWH
USVWATH
USVWAUAVAWH
USVWAVAWH
USVWAVH
USVWAWH
USVWH
UTCReplace_AppSessionGuid
UTF-8 Normalized strings
UTF-8 strings to normalize
uTHcW
uTL9d$0t
uUH9P
UUUUUUU
uvD9#~
UVWATAUAVAW
UVWATAUAVAWH
UVWATAVH
UVWATAWH
UVWAUAVH
UVWAVAWH
UWATAUAVH
UWATAUAWH
UWATAVAWH
UWATH
UWAUAVAWH
UWAUH
UWAVH
UWAWH
uWD9v(t
UwH;F
uwxUI
uwxvI
UxI+UpH
uzD8g
v >= 0 && static_cast<uint64_t>(v) <= std::numeric_limits<size_t>::max()
V H+V
V Lc2I;
V(I9V0t
v:fD;
v_final_and_scan_outputs
v_initial
V0H+V(H
v2H9p
v2L9`
VALID
valid
Validating no unexpected access using an invalid node_index.
Value
value
Value attribute unpacking failed:
Value of alpha
Value of alpha default to 0.2
Value of alpha.
Value of attribute 
Value of beta
Value of beta default to 0.5
Value of beta.
value of k must not be negative
Value tensor should be a 1D tensor of size 1 with the same type as that of the input tensor
value too large
Value(s) to change to
Value(s) to change to.
value_info
value_proto != nullptr
value_tensor->DataType() == DataTypeImpl::GetType<float>() && value_tensor->Shape().Size() == 1
value_type
values
Values
Values greater than this are mapped to 1, others to 0.
values of data_type '
values selected at indices where condition is False
values selected at indices where condition is True
Values that are live-out to the enclosing scope. The return values in the `then_branch` and `else_branch` must be of the same shape and same data type.
values.size() == attr->floats_size()
values.size() == attr->ints_size()
values_floats
values_int64s
values_strings
ValuesTensor
VarFileInfo
Variance
VarianceTensor
VbbeH
vb'vb'v
vector<bool> too long
vectors_per_class
version
VH9YXu,H
VHH9Z
via some custom implementation such as CuDNN.
VirtualAlloc
VirtualFree
VirtualProtect
VirtualQuery
VpI9Vxt
VS_VERSION_INFO
VUUUUUUUH
VWATAUAVAWH
VWATAUAVH
VWATAUAWH
VWATAVAWH
VWAUAVAWH
VWAVH
VWAWH
vWindows::AI::MachineLearning::TensorMemoryBufferReference<float>::Capacity
vxI+vpH
vXL+vPI
vXM9`
w @8q t.H
W D9P0t
W D9r
W H+W
w_scale
w_zero_point
W8HcH
WaitForSingleObject
WaitForSingleObjectEx
WaitForThreadpoolWorkCallbacks
WakeAllConditionVariable
WakeConditionVariable
Walk NULL
Warang_Citi
WARNING
Warning: 
WATAUAVAWH
WATAUAVAWL
WATAVH
WATAWH
WAVAWH
wcsftime
wcsnlen
We do not expect duplicate registration of types for: 
We don't expect custom allocators for non-tensor types, so a shape is mandatory here.
weight and zero_point pair is expected to have same type.
Weight buffer for initializer '
weights
Weights of the intercepts, if used.
Weights of the model(s).
WeightTensor
Wether to use ceil or floor (default) to compute the output shape.
When computing the output of the hidden gate, apply the linear transformation before multiplying by the output of the reset gate.
When True (nonzero), yield X, otherwise yield Y
Where
Whether A should be transposed
Whether B should be transposed
Whether C should be broadcasted
Whether include pad pixels when calculating values for the edges. Default is 0, doesn't count include pad.
Whether the operator should behave like fmod (default=0 meaning it will do integer mods); Set this to 1 to force fmod treatment
WhI+W`H
Which axis to concat on
Which axis to concat on.  Default value is 1.
Which axis to gather on. Negative value means counting dimensions from the back. Accepted range in [-r, r-1]
Which axis to scatter on. Negative value means counting dimensions from the back. Accepted range in [-r, r-1]
Which axis to split on
Which axis to split on.
WideCharToMultiByte
width
Width
width
Width
width
Width
width_scale
WidthMajor
WilError_02
will throw errors.
wilResult
Windows Machine Learning Runtime
windows.ai.machinelearning.dll
Windows.AI.MachineLearning.ILearningModelFeatureValue
Windows.AI.MachineLearning.ImageFeatureDescriptor
Windows.AI.MachineLearning.ImageFeatureValue
Windows.AI.MachineLearning.LearningModel
Windows.AI.MachineLearning.LearningModelBinding
Windows.AI.MachineLearning.LearningModelDevice
Windows.AI.MachineLearning.LearningModelEvaluationResult
Windows.AI.MachineLearning.LearningModelSession
Windows.AI.MachineLearning.LearningModelSessionOptions
Windows.AI.MachineLearning.MapFeatureDescriptor
windows.ai.machinelearning.pdb
Windows.AI.MachineLearning.Runtime
Windows.AI.MachineLearning.SequenceFeatureDescriptor
Windows.AI.MachineLearning.TensorBoolean
Windows.AI.MachineLearning.TensorDouble
Windows.AI.MachineLearning.TensorFeatureDescriptor
Windows.AI.MachineLearning.TensorFloat
Windows.AI.MachineLearning.TensorFloat16Bit
Windows.AI.MachineLearning.TensorInt16Bit
Windows.AI.MachineLearning.TensorInt32Bit
Windows.AI.MachineLearning.TensorInt64Bit
Windows.AI.MachineLearning.TensorInt8Bit
Windows.AI.MachineLearning.TensorString
Windows.AI.MachineLearning.TensorUInt16Bit
Windows.AI.MachineLearning.TensorUInt32Bit
Windows.AI.MachineLearning.TensorUInt64Bit
Windows.AI.MachineLearning.TensorUInt8Bit
Windows.AI.MachineLearning: Debug Output Enabled 
Windows.ApplicationModel.Core.CoreApplication
Windows.Foundation.Collections.IIterator`1<Boolean>
Windows.Foundation.Collections.IIterator`1<Double>
Windows.Foundation.Collections.IIterator`1<Int16>
Windows.Foundation.Collections.IIterator`1<Int32>
Windows.Foundation.Collections.IIterator`1<Int64>
Windows.Foundation.Collections.IIterator`1<Single>
Windows.Foundation.Collections.IIterator`1<String>
Windows.Foundation.Collections.IIterator`1<UInt16>
Windows.Foundation.Collections.IIterator`1<UInt32>
Windows.Foundation.Collections.IIterator`1<UInt64>
Windows.Foundation.Collections.IIterator`1<UInt8>
Windows.Foundation.Collections.IIterator`1<Windows.AI.MachineLearning.ILearningModelFeatureDescriptor>
Windows.Foundation.Collections.IIterator`1<Windows.Foundation.Collections.IKeyValuePair`2<Int64, Double>>
Windows.Foundation.Collections.IIterator`1<Windows.Foundation.Collections.IKeyValuePair`2<Int64, Int64>>
Windows.Foundation.Collections.IIterator`1<Windows.Foundation.Collections.IKeyValuePair`2<Int64, Single>>
Windows.Foundation.Collections.IIterator`1<Windows.Foundation.Collections.IKeyValuePair`2<Int64, String>>
Windows.Foundation.Collections.IIterator`1<Windows.Foundation.Collections.IKeyValuePair`2<String, Double>>
Windows.Foundation.Collections.IIterator`1<Windows.Foundation.Collections.IKeyValuePair`2<String, Int64>>
Windows.Foundation.Collections.IIterator`1<Windows.Foundation.Collections.IKeyValuePair`2<String, Object>>
Windows.Foundation.Collections.IIterator`1<Windows.Foundation.Collections.IKeyValuePair`2<String, Single>>
Windows.Foundation.Collections.IIterator`1<Windows.Foundation.Collections.IKeyValuePair`2<String, String>>
Windows.Foundation.Collections.IIterator`1<Windows.Foundation.Collections.IMap`2<Int64, Single>>
Windows.Foundation.Collections.IIterator`1<Windows.Foundation.Collections.IMap`2<String, Single>>
Windows.Foundation.Collections.IIterator`1<Windows.Media.VideoFrame>
Windows.Foundation.Collections.IKeyValuePair`2<Int64, Double>
Windows.Foundation.Collections.IKeyValuePair`2<Int64, Int64>
Windows.Foundation.Collections.IKeyValuePair`2<Int64, Single>
Windows.Foundation.Collections.IKeyValuePair`2<Int64, String>
Windows.Foundation.Collections.IKeyValuePair`2<String, Double>
Windows.Foundation.Collections.IKeyValuePair`2<String, Int64>
Windows.Foundation.Collections.IKeyValuePair`2<String, Object>
Windows.Foundation.Collections.IKeyValuePair`2<String, Single>
Windows.Foundation.Collections.IKeyValuePair`2<String, String>
Windows.Foundation.Collections.IMap`2<Int64, Double>
Windows.Foundation.Collections.IMap`2<Int64, Int64>
Windows.Foundation.Collections.IMap`2<Int64, Single>
Windows.Foundation.Collections.IMap`2<Int64, String>
Windows.Foundation.Collections.IMap`2<String, Double>
Windows.Foundation.Collections.IMap`2<String, Int64>
Windows.Foundation.Collections.IMap`2<String, Object>
Windows.Foundation.Collections.IMap`2<String, Single>
Windows.Foundation.Collections.IMap`2<String, String>
Windows.Foundation.Collections.IVector`1<Boolean>
Windows.Foundation.Collections.IVector`1<Double>
Windows.Foundation.Collections.IVector`1<Int16>
Windows.Foundation.Collections.IVector`1<Int32>
Windows.Foundation.Collections.IVector`1<Int64>
Windows.Foundation.Collections.IVector`1<Single>
Windows.Foundation.Collections.IVector`1<String>
Windows.Foundation.Collections.IVector`1<UInt16>
Windows.Foundation.Collections.IVector`1<UInt32>
Windows.Foundation.Collections.IVector`1<UInt64>
Windows.Foundation.Collections.IVector`1<UInt8>
Windows.Foundation.Collections.IVector`1<Windows.AI.MachineLearning.ILearningModelFeatureDescriptor>
Windows.Foundation.Collections.IVector`1<Windows.Foundation.Collections.IMap`2<Int64, Single>>
Windows.Foundation.Collections.IVector`1<Windows.Foundation.Collections.IMap`2<String, Single>>
Windows.Foundation.Collections.IVector`1<Windows.Media.VideoFrame>
Windows.Foundation.Collections.PropertySet
Windows.Foundation.IAsyncOperation`1<Windows.AI.MachineLearning.LearningModel>
Windows.Foundation.IAsyncOperation`1<Windows.AI.MachineLearning.LearningModelEvaluationResult>
Windows.Foundation.IMemoryBufferReference
Windows.Foundation.IReference`1<Windows.Graphics.Imaging.BitmapBounds>
Windows.Graphics.Imaging.SoftwareBitmap
Windows.Media.VideoFrame
Windows.Storage.Streams.Buffer
Windows.Storage.Streams.IBuffer
Windows::AI::MachineLearning::compatibility_details::not_compatible_hr
Windows::AI::MachineLearning::CpuOrtSessionBuilder::CreateSession
Windows::AI::MachineLearning::CpuOrtSessionBuilder::Initialize
Windows::AI::MachineLearning::CreateModelProto
Windows::AI::MachineLearning::DmlOrtSessionBuilder::CreateSession
Windows::AI::MachineLearning::DmlOrtSessionBuilder::Initialize
Windows::AI::MachineLearning::DmlOrtSessionBuilder::RegisterTransformers
Windows::AI::MachineLearning::GetTensorType
Windows::AI::MachineLearning::Internal::ImageConversionHelpers::GetBitmapPixelFormatFromChannelType
Windows::AI::MachineLearning::Internal::ImageConversionHelpers::GetChannelTypeFromSoftwareBitmap
Windows::AI::MachineLearning::Internal::ImageConversionHelpers::GetDeviceFromDirect3DSurface
Windows::AI::MachineLearning::Internal::ImageConversionHelpers::GetDirectXPixelFormatFromChannelType
Windows::AI::MachineLearning::Internal::ImageConversionHelpers::GetDXGIFormatFromDirectXPixelFormat
Windows::AI::MachineLearning::Internal::ImageConverter::CreateTextureFromUnsupportedColorFormat
Windows::AI::MachineLearning::Internal::ImageConverter::FetchOrCreateFenceOnDevice
Windows::AI::MachineLearning::Internal::ImageConverter::ResetAllocator
Windows::AI::MachineLearning::Internal::ImageConverter::ResetCommandList
Windows::AI::MachineLearning::Internal::TensorToVideoFrameConverter::ConvertCPUTensorToSoftwareBitmap
Windows::AI::MachineLearning::Internal::TensorToVideoFrameConverter::ConvertDX12TensorToUnsupportedVideoFrameFormat
Windows::AI::MachineLearning::Internal::TensorToVideoFrameConverter::ConvertGPUTensorToDX12Texture
Windows::AI::MachineLearning::Internal::TensorToVideoFrameConverter::ConvertGPUTensorToSoftwareBitmap
Windows::AI::MachineLearning::Internal::TensorToVideoFrameConverter::CreateShareableD3D12Texture
Windows::AI::MachineLearning::Internal::TensorToVideoFrameConverter::CreateSRVDescriptor
Windows::AI::MachineLearning::Internal::TensorToVideoFrameConverter::DX12TensorToVideoFrame
Windows::AI::MachineLearning::Internal::TensorToVideoFrameConverter::ShareD3D12Texture
Windows::AI::MachineLearning::Internal::TensorToVideoFrameConverter::SoftwareTensorToVideoFrame
Windows::AI::MachineLearning::Internal::VideoFrameToTensorConverter::ConvertDX12TextureToGPUTensor
Windows::AI::MachineLearning::Internal::VideoFrameToTensorConverter::ConvertSoftwareBitmapToCPUTensor
Windows::AI::MachineLearning::Internal::VideoFrameToTensorConverter::ConvertSoftwareBitmapToGPUTensor
Windows::AI::MachineLearning::Internal::VideoFrameToTensorConverter::CreateUAVDescription
Windows::AI::MachineLearning::Internal::VideoFrameToTensorConverter::ShareD3D11Texture
Windows::AI::MachineLearning::Internal::VideoFrameToTensorConverter::VideoFrameToDX12Tensor
Windows::AI::MachineLearning::Internal::VideoFrameToTensorConverter::VideoFrameToSoftwareTensor
Windows::AI::MachineLearning::TensorBase<__int64,__int64,struct winrt::Windows::AI::MachineLearning::implementation::TensorInt64Bit,struct winrt::Windows::AI::MachineLearning::ITensorInt64Bit,struct winrt::Windows::AI::MachineLearning::implementation::TensorInt64Bit_base<struct winrt::Windows::AI::MachineLearning::implementation::TensorInt64Bit,struct ITensorNative,struct Windows::AI::MachineLearning::ILotusValueProviderPrivate> >::CPUTensorize
Windows::AI::MachineLearning::TensorBase<__int64,__int64,struct winrt::Windows::AI::MachineLearning::implementation::TensorInt64Bit,struct winrt::Windows::AI::MachineLearning::ITensorInt64Bit,struct winrt::Windows::AI::MachineLearning::implementation::TensorInt64Bit_base<struct winrt::Windows::AI::MachineLearning::implementation::TensorInt64Bit,struct ITensorNative,struct Windows::AI::MachineLearning::ILotusValueProviderPrivate> >::EnsureBufferNotInUse
Windows::AI::MachineLearning::TensorBase<__int64,__int64,struct winrt::Windows::AI::MachineLearning::implementation::TensorInt64Bit,struct winrt::Windows::AI::MachineLearning::ITensorInt64Bit,struct winrt::Windows::AI::MachineLearning::implementation::TensorInt64Bit_base<struct winrt::Windows::AI::MachineLearning::implementation::TensorInt64Bit,struct ITensorNative,struct Windows::AI::MachineLearning::ILotusValueProviderPrivate> >::GetCpuResource
Windows::AI::MachineLearning::TensorBase<__int64,__int64,struct winrt::Windows::AI::MachineLearning::implementation::TensorInt64Bit,struct winrt::Windows::AI::MachineLearning::ITensorInt64Bit,struct winrt::Windows::AI::MachineLearning::implementation::TensorInt64Bit_base<struct winrt::Windows::AI::MachineLearning::implementation::TensorInt64Bit,struct ITensorNative,struct Windows::AI::MachineLearning::ILotusValueProviderPrivate> >::GetGpuResource
Windows::AI::MachineLearning::TensorBase<bool,bool,struct winrt::Windows::AI::MachineLearning::implementation::TensorBoolean,struct winrt::Windows::AI::MachineLearning::ITensorBoolean,struct winrt::Windows::AI::MachineLearning::implementation::TensorBoolean_base<struct winrt::Windows::AI::MachineLearning::implementation::TensorBoolean,struct ITensorNative,struct Windows::AI::MachineLearning::ILotusValueProviderPrivate> >::CPUTensorize
Windows::AI::MachineLearning::TensorBase<bool,bool,struct winrt::Windows::AI::MachineLearning::implementation::TensorBoolean,struct winrt::Windows::AI::MachineLearning::ITensorBoolean,struct winrt::Windows::AI::MachineLearning::implementation::TensorBoolean_base<struct winrt::Windows::AI::MachineLearning::implementation::TensorBoolean,struct ITensorNative,struct Windows::AI::MachineLearning::ILotusValueProviderPrivate> >::EnsureBufferNotInUse
Windows::AI::MachineLearning::TensorBase<bool,bool,struct winrt::Windows::AI::MachineLearning::implementation::TensorBoolean,struct winrt::Windows::AI::MachineLearning::ITensorBoolean,struct winrt::Windows::AI::MachineLearning::implementation::TensorBoolean_base<struct winrt::Windows::AI::MachineLearning::implementation::TensorBoolean,struct ITensorNative,struct Windows::AI::MachineLearning::ILotusValueProviderPrivate> >::GetCpuResource
Windows::AI::MachineLearning::TensorBase<bool,bool,struct winrt::Windows::AI::MachineLearning::implementation::TensorBoolean,struct winrt::Windows::AI::MachineLearning::ITensorBoolean,struct winrt::Windows::AI::MachineLearning::implementation::TensorBoolean_base<struct winrt::Windows::AI::MachineLearning::implementation::TensorBoolean,struct ITensorNative,struct Windows::AI::MachineLearning::ILotusValueProviderPrivate> >::GetGpuResource
Windows::AI::MachineLearning::TensorBase<class std::basic_string<char,struct std::char_traits<char>,class std::allocator<char> >,struct winrt::hstring,struct winrt::Windows::AI::MachineLearning::implementation::TensorString,struct winrt::Windows::AI::MachineLearning::ITensorString,struct winrt::Windows::AI::MachineLearning::implementation::TensorString_base<struct winrt::Windows::AI::MachineLearning::implementation::TensorString,struct ITensorNative,struct Windows::AI::MachineLearning::ILotusValueProviderPrivate> >::CPUTensorize
Windows::AI::MachineLearning::TensorBase<class std::basic_string<char,struct std::char_traits<char>,class std::allocator<char> >,struct winrt::hstring,struct winrt::Windows::AI::MachineLearning::implementation::TensorString,struct winrt::Windows::AI::MachineLearning::ITensorString,struct winrt::Windows::AI::MachineLearning::implementation::TensorString_base<struct winrt::Windows::AI::MachineLearning::implementation::TensorString,struct ITensorNative,struct Windows::AI::MachineLearning::ILotusValueProviderPrivate> >::EnsureBufferNotInUse
Windows::AI::MachineLearning::TensorBase<class std::basic_string<char,struct std::char_traits<char>,class std::allocator<char> >,struct winrt::hstring,struct winrt::Windows::AI::MachineLearning::implementation::TensorString,struct winrt::Windows::AI::MachineLearning::ITensorString,struct winrt::Windows::AI::MachineLearning::implementation::TensorString_base<struct winrt::Windows::AI::MachineLearning::implementation::TensorString,struct ITensorNative,struct Windows::AI::MachineLearning::ILotusValueProviderPrivate> >::GetCpuResource
Windows::AI::MachineLearning::TensorBase<class std::basic_string<char,struct std::char_traits<char>,class std::allocator<char> >,struct winrt::hstring,struct winrt::Windows::AI::MachineLearning::implementation::TensorString,struct winrt::Windows::AI::MachineLearning::ITensorString,struct winrt::Windows::AI::MachineLearning::implementation::TensorString_base<struct winrt::Windows::AI::MachineLearning::implementation::TensorString,struct ITensorNative,struct Windows::AI::MachineLearning::ILotusValueProviderPrivate> >::GetGpuResource
Windows::AI::MachineLearning::TensorBase<class std::basic_string<char,struct std::char_traits<char>,class std::allocator<char> >,struct winrt::hstring,struct winrt::Windows::AI::MachineLearning::implementation::TensorString,struct winrt::Windows::AI::MachineLearning::ITensorString,struct winrt::Windows::AI::MachineLearning::implementation::TensorString_base<struct winrt::Windows::AI::MachineLearning::implementation::TensorString,struct ITensorNative,struct Windows::AI::MachineLearning::ILotusValueProviderPrivate> >::TensorBase
Windows::AI::MachineLearning::TensorBase<double,double,struct winrt::Windows::AI::MachineLearning::implementation::TensorDouble,struct winrt::Windows::AI::MachineLearning::ITensorDouble,struct winrt::Windows::AI::MachineLearning::implementation::TensorDouble_base<struct winrt::Windows::AI::MachineLearning::implementation::TensorDouble,struct ITensorNative,struct Windows::AI::MachineLearning::ILotusValueProviderPrivate> >::CPUTensorize
Windows::AI::MachineLearning::TensorBase<double,double,struct winrt::Windows::AI::MachineLearning::implementation::TensorDouble,struct winrt::Windows::AI::MachineLearning::ITensorDouble,struct winrt::Windows::AI::MachineLearning::implementation::TensorDouble_base<struct winrt::Windows::AI::MachineLearning::implementation::TensorDouble,struct ITensorNative,struct Windows::AI::MachineLearning::ILotusValueProviderPrivate> >::EnsureBufferNotInUse
Windows::AI::MachineLearning::TensorBase<double,double,struct winrt::Windows::AI::MachineLearning::implementation::TensorDouble,struct winrt::Windows::AI::MachineLearning::ITensorDouble,struct winrt::Windows::AI::MachineLearning::implementation::TensorDouble_base<struct winrt::Windows::AI::MachineLearning::implementation::TensorDouble,struct ITensorNative,struct Windows::AI::MachineLearning::ILotusValueProviderPrivate> >::GetCpuResource
Windows::AI::MachineLearning::TensorBase<double,double,struct winrt::Windows::AI::MachineLearning::implementation::TensorDouble,struct winrt::Windows::AI::MachineLearning::ITensorDouble,struct winrt::Windows::AI::MachineLearning::implementation::TensorDouble_base<struct winrt::Windows::AI::MachineLearning::implementation::TensorDouble,struct ITensorNative,struct Windows::AI::MachineLearning::ILotusValueProviderPrivate> >::GetGpuResource
Windows::AI::MachineLearning::TensorBase<float,float,struct winrt::Windows::AI::MachineLearning::implementation::TensorFloat,struct winrt::Windows::AI::MachineLearning::ITensorFloat,struct winrt::Windows::AI::MachineLearning::implementation::TensorFloat_base<struct winrt::Windows::AI::MachineLearning::implementation::TensorFloat,struct ITensorNative,struct Windows::AI::MachineLearning::ILotusValueProviderPrivate> >::CPUTensorize
Windows::AI::MachineLearning::TensorBase<float,float,struct winrt::Windows::AI::MachineLearning::implementation::TensorFloat,struct winrt::Windows::AI::MachineLearning::ITensorFloat,struct winrt::Windows::AI::MachineLearning::implementation::TensorFloat_base<struct winrt::Windows::AI::MachineLearning::implementation::TensorFloat,struct ITensorNative,struct Windows::AI::MachineLearning::ILotusValueProviderPrivate> >::EnsureBufferNotInUse
Windows::AI::MachineLearning::TensorBase<float,float,struct winrt::Windows::AI::MachineLearning::implementation::TensorFloat,struct winrt::Windows::AI::MachineLearning::ITensorFloat,struct winrt::Windows::AI::MachineLearning::implementation::TensorFloat_base<struct winrt::Windows::AI::MachineLearning::implementation::TensorFloat,struct ITensorNative,struct Windows::AI::MachineLearning::ILotusValueProviderPrivate> >::GetCpuResource
Windows::AI::MachineLearning::TensorBase<float,float,struct winrt::Windows::AI::MachineLearning::implementation::TensorFloat,struct winrt::Windows::AI::MachineLearning::ITensorFloat,struct winrt::Windows::AI::MachineLearning::implementation::TensorFloat_base<struct winrt::Windows::AI::MachineLearning::implementation::TensorFloat,struct ITensorNative,struct Windows::AI::MachineLearning::ILotusValueProviderPrivate> >::GetGpuResource
Windows::AI::MachineLearning::TensorBase<int,int,struct winrt::Windows::AI::MachineLearning::implementation::TensorInt32Bit,struct winrt::Windows::AI::MachineLearning::ITensorInt32Bit,struct winrt::Windows::AI::MachineLearning::implementation::TensorInt32Bit_base<struct winrt::Windows::AI::MachineLearning::implementation::TensorInt32Bit,struct ITensorNative,struct Windows::AI::MachineLearning::ILotusValueProviderPrivate> >::CPUTensorize
Windows::AI::MachineLearning::TensorBase<int,int,struct winrt::Windows::AI::MachineLearning::implementation::TensorInt32Bit,struct winrt::Windows::AI::MachineLearning::ITensorInt32Bit,struct winrt::Windows::AI::MachineLearning::implementation::TensorInt32Bit_base<struct winrt::Windows::AI::MachineLearning::implementation::TensorInt32Bit,struct ITensorNative,struct Windows::AI::MachineLearning::ILotusValueProviderPrivate> >::EnsureBufferNotInUse
Windows::AI::MachineLearning::TensorBase<int,int,struct winrt::Windows::AI::MachineLearning::implementation::TensorInt32Bit,struct winrt::Windows::AI::MachineLearning::ITensorInt32Bit,struct winrt::Windows::AI::MachineLearning::implementation::TensorInt32Bit_base<struct winrt::Windows::AI::MachineLearning::implementation::TensorInt32Bit,struct ITensorNative,struct Windows::AI::MachineLearning::ILotusValueProviderPrivate> >::GetCpuResource
Windows::AI::MachineLearning::TensorBase<int,int,struct winrt::Windows::AI::MachineLearning::implementation::TensorInt32Bit,struct winrt::Windows::AI::MachineLearning::ITensorInt32Bit,struct winrt::Windows::AI::MachineLearning::implementation::TensorInt32Bit_base<struct winrt::Windows::AI::MachineLearning::implementation::TensorInt32Bit,struct ITensorNative,struct Windows::AI::MachineLearning::ILotusValueProviderPrivate> >::GetGpuResource
Windows::AI::MachineLearning::TensorBase<short,short,struct winrt::Windows::AI::MachineLearning::implementation::TensorInt16Bit,struct winrt::Windows::AI::MachineLearning::ITensorInt16Bit,struct winrt::Windows::AI::MachineLearning::implementation::TensorInt16Bit_base<struct winrt::Windows::AI::MachineLearning::implementation::TensorInt16Bit,struct ITensorNative,struct Windows::AI::MachineLearning::ILotusValueProviderPrivate> >::CPUTensorize
Windows::AI::MachineLearning::TensorBase<short,short,struct winrt::Windows::AI::MachineLearning::implementation::TensorInt16Bit,struct winrt::Windows::AI::MachineLearning::ITensorInt16Bit,struct winrt::Windows::AI::MachineLearning::implementation::TensorInt16Bit_base<struct winrt::Windows::AI::MachineLearning::implementation::TensorInt16Bit,struct ITensorNative,struct Windows::AI::MachineLearning::ILotusValueProviderPrivate> >::EnsureBufferNotInUse
Windows::AI::MachineLearning::TensorBase<short,short,struct winrt::Windows::AI::MachineLearning::implementation::TensorInt16Bit,struct winrt::Windows::AI::MachineLearning::ITensorInt16Bit,struct winrt::Windows::AI::MachineLearning::implementation::TensorInt16Bit_base<struct winrt::Windows::AI::MachineLearning::implementation::TensorInt16Bit,struct ITensorNative,struct Windows::AI::MachineLearning::ILotusValueProviderPrivate> >::GetGpuResource
Windows::AI::MachineLearning::TensorBase<signed char,unsigned char,struct winrt::Windows::AI::MachineLearning::implementation::TensorInt8Bit,struct winrt::Windows::AI::MachineLearning::ITensorInt8Bit,struct winrt::Windows::AI::MachineLearning::implementation::TensorInt8Bit_base<struct winrt::Windows::AI::MachineLearning::implementation::TensorInt8Bit,struct ITensorNative,struct Windows::AI::MachineLearning::ILotusValueProviderPrivate> >::CPUTensorize
Windows::AI::MachineLearning::TensorBase<signed char,unsigned char,struct winrt::Windows::AI::MachineLearning::implementation::TensorInt8Bit,struct winrt::Windows::AI::MachineLearning::ITensorInt8Bit,struct winrt::Windows::AI::MachineLearning::implementation::TensorInt8Bit_base<struct winrt::Windows::AI::MachineLearning::implementation::TensorInt8Bit,struct ITensorNative,struct Windows::AI::MachineLearning::ILotusValueProviderPrivate> >::EnsureBufferNotInUse
Windows::AI::MachineLearning::TensorBase<signed char,unsigned char,struct winrt::Windows::AI::MachineLearning::implementation::TensorInt8Bit,struct winrt::Windows::AI::MachineLearning::ITensorInt8Bit,struct winrt::Windows::AI::MachineLearning::implementation::TensorInt8Bit_base<struct winrt::Windows::AI::MachineLearning::implementation::TensorInt8Bit,struct ITensorNative,struct Windows::AI::MachineLearning::ILotusValueProviderPrivate> >::GetCpuResource
Windows::AI::MachineLearning::TensorBase<signed char,unsigned char,struct winrt::Windows::AI::MachineLearning::implementation::TensorInt8Bit,struct winrt::Windows::AI::MachineLearning::ITensorInt8Bit,struct winrt::Windows::AI::MachineLearning::implementation::TensorInt8Bit_base<struct winrt::Windows::AI::MachineLearning::implementation::TensorInt8Bit,struct ITensorNative,struct Windows::AI::MachineLearning::ILotusValueProviderPrivate> >::GetGpuResource
Windows::AI::MachineLearning::TensorBase<union onnxruntime::MLFloat16,float,struct winrt::Windows::AI::MachineLearning::implementation::TensorFloat16Bit,struct winrt::Windows::AI::MachineLearning::ITensorFloat16Bit,struct winrt::Windows::AI::MachineLearning::implementation::TensorFloat16Bit_base<struct winrt::Windows::AI::MachineLearning::implementation::TensorFloat16Bit,struct ITensorNative,struct Windows::AI::MachineLearning::ILotusValueProviderPrivate> >::CPUTensorize
Windows::AI::MachineLearning::TensorBase<union onnxruntime::MLFloat16,float,struct winrt::Windows::AI::MachineLearning::implementation::TensorFloat16Bit,struct winrt::Windows::AI::MachineLearning::ITensorFloat16Bit,struct winrt::Windows::AI::MachineLearning::implementation::TensorFloat16Bit_base<struct winrt::Windows::AI::MachineLearning::implementation::TensorFloat16Bit,struct ITensorNative,struct Windows::AI::MachineLearning::ILotusValueProviderPrivate> >::EnsureBufferNotInUse
Windows::AI::MachineLearning::TensorBase<union onnxruntime::MLFloat16,float,struct winrt::Windows::AI::MachineLearning::implementation::TensorFloat16Bit,struct winrt::Windows::AI::MachineLearning::ITensorFloat16Bit,struct winrt::Windows::AI::MachineLearning::implementation::TensorFloat16Bit_base<struct winrt::Windows::AI::MachineLearning::implementation::TensorFloat16Bit,struct ITensorNative,struct Windows::AI::MachineLearning::ILotusValueProviderPrivate> >::GetCpuResource
Windows::AI::MachineLearning::TensorBase<union onnxruntime::MLFloat16,float,struct winrt::Windows::AI::MachineLearning::implementation::TensorFloat16Bit,struct winrt::Windows::AI::MachineLearning::ITensorFloat16Bit,struct winrt::Windows::AI::MachineLearning::implementation::TensorFloat16Bit_base<struct winrt::Windows::AI::MachineLearning::implementation::TensorFloat16Bit,struct ITensorNative,struct Windows::AI::MachineLearning::ILotusValueProviderPrivate> >::GetGpuResource
Windows::AI::MachineLearning::TensorBase<unsigned __int64,unsigned __int64,struct winrt::Windows::AI::MachineLearning::implementation::TensorUInt64Bit,struct winrt::Windows::AI::MachineLearning::ITensorUInt64Bit,struct winrt::Windows::AI::MachineLearning::implementation::TensorUInt64Bit_base<struct winrt::Windows::AI::MachineLearning::implementation::TensorUInt64Bit,struct ITensorNative,struct Windows::AI::MachineLearning::ILotusValueProviderPrivate> >::CPUTensorize
Windows::AI::MachineLearning::TensorBase<unsigned __int64,unsigned __int64,struct winrt::Windows::AI::MachineLearning::implementation::TensorUInt64Bit,struct winrt::Windows::AI::MachineLearning::ITensorUInt64Bit,struct winrt::Windows::AI::MachineLearning::implementation::TensorUInt64Bit_base<struct winrt::Windows::AI::MachineLearning::implementation::TensorUInt64Bit,struct ITensorNative,struct Windows::AI::MachineLearning::ILotusValueProviderPrivate> >::EnsureBufferNotInUse
Windows::AI::MachineLearning::TensorBase<unsigned __int64,unsigned __int64,struct winrt::Windows::AI::MachineLearning::implementation::TensorUInt64Bit,struct winrt::Windows::AI::MachineLearning::ITensorUInt64Bit,struct winrt::Windows::AI::MachineLearning::implementation::TensorUInt64Bit_base<struct winrt::Windows::AI::MachineLearning::implementation::TensorUInt64Bit,struct ITensorNative,struct Windows::AI::MachineLearning::ILotusValueProviderPrivate> >::GetCpuResource
Windows::AI::MachineLearning::TensorBase<unsigned __int64,unsigned __int64,struct winrt::Windows::AI::MachineLearning::implementation::TensorUInt64Bit,struct winrt::Windows::AI::MachineLearning::ITensorUInt64Bit,struct winrt::Windows::AI::MachineLearning::implementation::TensorUInt64Bit_base<struct winrt::Windows::AI::MachineLearning::implementation::TensorUInt64Bit,struct ITensorNative,struct Windows::AI::MachineLearning::ILotusValueProviderPrivate> >::GetGpuResource
Windows::AI::MachineLearning::TensorBase<unsigned char,unsigned char,struct winrt::Windows::AI::MachineLearning::implementation::TensorUInt8Bit,struct winrt::Windows::AI::MachineLearning::ITensorUInt8Bit,struct winrt::Windows::AI::MachineLearning::implementation::TensorUInt8Bit_base<struct winrt::Windows::AI::MachineLearning::implementation::TensorUInt8Bit,struct ITensorNative,struct Windows::AI::MachineLearning::ILotusValueProviderPrivate> >::CPUTensorize
Windows::AI::MachineLearning::TensorBase<unsigned char,unsigned char,struct winrt::Windows::AI::MachineLearning::implementation::TensorUInt8Bit,struct winrt::Windows::AI::MachineLearning::ITensorUInt8Bit,struct winrt::Windows::AI::MachineLearning::implementation::TensorUInt8Bit_base<struct winrt::Windows::AI::MachineLearning::implementation::TensorUInt8Bit,struct ITensorNative,struct Windows::AI::MachineLearning::ILotusValueProviderPrivate> >::EnsureBufferNotInUse
Windows::AI::MachineLearning::TensorBase<unsigned char,unsigned char,struct winrt::Windows::AI::MachineLearning::implementation::TensorUInt8Bit,struct winrt::Windows::AI::MachineLearning::ITensorUInt8Bit,struct winrt::Windows::AI::MachineLearning::implementation::TensorUInt8Bit_base<struct winrt::Windows::AI::MachineLearning::implementation::TensorUInt8Bit,struct ITensorNative,struct Windows::AI::MachineLearning::ILotusValueProviderPrivate> >::GetCpuResource
Windows::AI::MachineLearning::TensorBase<unsigned char,unsigned char,struct winrt::Windows::AI::MachineLearning::implementation::TensorUInt8Bit,struct winrt::Windows::AI::MachineLearning::ITensorUInt8Bit,struct winrt::Windows::AI::MachineLearning::implementation::TensorUInt8Bit_base<struct winrt::Windows::AI::MachineLearning::implementation::TensorUInt8Bit,struct ITensorNative,struct Windows::AI::MachineLearning::ILotusValueProviderPrivate> >::GetGpuResource
Windows::AI::MachineLearning::TensorBase<unsigned int,unsigned int,struct winrt::Windows::AI::MachineLearning::implementation::TensorUInt32Bit,struct winrt::Windows::AI::MachineLearning::ITensorUInt32Bit,struct winrt::Windows::AI::MachineLearning::implementation::TensorUInt32Bit_base<struct winrt::Windows::AI::MachineLearning::implementation::TensorUInt32Bit,struct ITensorNative,struct Windows::AI::MachineLearning::ILotusValueProviderPrivate> >::CPUTensorize
Windows::AI::MachineLearning::TensorBase<unsigned int,unsigned int,struct winrt::Windows::AI::MachineLearning::implementation::TensorUInt32Bit,struct winrt::Windows::AI::MachineLearning::ITensorUInt32Bit,struct winrt::Windows::AI::MachineLearning::implementation::TensorUInt32Bit_base<struct winrt::Windows::AI::MachineLearning::implementation::TensorUInt32Bit,struct ITensorNative,struct Windows::AI::MachineLearning::ILotusValueProviderPrivate> >::EnsureBufferNotInUse
Windows::AI::MachineLearning::TensorBase<unsigned int,unsigned int,struct winrt::Windows::AI::MachineLearning::implementation::TensorUInt32Bit,struct winrt::Windows::AI::MachineLearning::ITensorUInt32Bit,struct winrt::Windows::AI::MachineLearning::implementation::TensorUInt32Bit_base<struct winrt::Windows::AI::MachineLearning::implementation::TensorUInt32Bit,struct ITensorNative,struct Windows::AI::MachineLearning::ILotusValueProviderPrivate> >::GetGpuResource
Windows::AI::MachineLearning::TensorBase<unsigned short,unsigned short,struct winrt::Windows::AI::MachineLearning::implementation::TensorUInt16Bit,struct winrt::Windows::AI::MachineLearning::ITensorUInt16Bit,struct winrt::Windows::AI::MachineLearning::implementation::TensorUInt16Bit_base<struct winrt::Windows::AI::MachineLearning::implementation::TensorUInt16Bit,struct ITensorNative,struct Windows::AI::MachineLearning::ILotusValueProviderPrivate> >::CPUTensorize
Windows::AI::MachineLearning::TensorBase<unsigned short,unsigned short,struct winrt::Windows::AI::MachineLearning::implementation::TensorUInt16Bit,struct winrt::Windows::AI::MachineLearning::ITensorUInt16Bit,struct winrt::Windows::AI::MachineLearning::implementation::TensorUInt16Bit_base<struct winrt::Windows::AI::MachineLearning::implementation::TensorUInt16Bit,struct ITensorNative,struct Windows::AI::MachineLearning::ILotusValueProviderPrivate> >::EnsureBufferNotInUse
Windows::AI::MachineLearning::TensorBase<unsigned short,unsigned short,struct winrt::Windows::AI::MachineLearning::implementation::TensorUInt16Bit,struct winrt::Windows::AI::MachineLearning::ITensorUInt16Bit,struct winrt::Windows::AI::MachineLearning::implementation::TensorUInt16Bit_base<struct winrt::Windows::AI::MachineLearning::implementation::TensorUInt16Bit,struct ITensorNative,struct Windows::AI::MachineLearning::ILotusValueProviderPrivate> >::GetGpuResource
Windows::AI::MachineLearning::TensorBaseHelpers::CreateGPUMLValue
Windows::AI::MachineLearning::TensorBuffer<__int64>::Set
Windows::AI::MachineLearning::TensorBuffer<bool>::Set
Windows::AI::MachineLearning::TensorBuffer<class std::basic_string<char,struct std::char_traits<char>,class std::allocator<char> > >::Set
Windows::AI::MachineLearning::TensorBuffer<double>::Set
Windows::AI::MachineLearning::TensorBuffer<float>::Set
Windows::AI::MachineLearning::TensorBuffer<int>::Set
Windows::AI::MachineLearning::TensorBuffer<short>::Set
Windows::AI::MachineLearning::TensorBuffer<signed char>::Set
Windows::AI::MachineLearning::TensorBuffer<union onnxruntime::MLFloat16>::Set
Windows::AI::MachineLearning::TensorBuffer<unsigned __int64>::Set
Windows::AI::MachineLearning::TensorBuffer<unsigned char>::Set
Windows::AI::MachineLearning::TensorBuffer<unsigned int>::Set
Windows::AI::MachineLearning::TensorBuffer<unsigned short>::Set
Windows::AI::MachineLearning::TensorMemoryBufferReference<__int64>::Capacity
Windows::AI::MachineLearning::TensorMemoryBufferReference<bool>::Capacity
Windows::AI::MachineLearning::TensorMemoryBufferReference<double>::Capacity
Windows::AI::MachineLearning::TensorMemoryBufferReference<int>::Capacity
Windows::AI::MachineLearning::TensorMemoryBufferReference<short>::Capacity
Windows::AI::MachineLearning::TensorMemoryBufferReference<signed char>::Capacity
Windows::AI::MachineLearning::TensorMemoryBufferReference<union onnxruntime::MLFloat16>::Capacity
Windows::AI::MachineLearning::TensorMemoryBufferReference<unsigned __int64>::Capacity
Windows::AI::MachineLearning::TensorMemoryBufferReference<unsigned short>::Capacity
Windows::AI::MachineLearning::ZeroCopyInputStreamWrapper::ByteCount
Windows::AI::MachineLearning::ZeroCopyInputStreamWrapper::Next
Windows::AI::MachineLearning::ZeroCopyInputStreamWrapper::Skip
WindowsCreateString
WindowsCreateStringReference
WindowsDeleteString
WindowsDeleteStringBuffer
WindowsDuplicateString
WindowsGetStringLen
WindowsGetStringRawBuffer
WindowsIsStringEmpty
WindowSize
WindowsPreallocateStringBuffer
WindowsPromoteStringBuffer
WindowsStringHasEmbeddedNull
WinMLInputValidation
WinMLLogSink
WinmlRuleTransformer
winrt::hresult_error: %ls
winrt::Windows::AI::MachineLearning::factory_implementation::LearningModel::Load
winrt::Windows::AI::MachineLearning::factory_implementation::LearningModelDevice::CreateFromD3D12CommandQueue
winrt::Windows::AI::MachineLearning::implementation::AbiCustomRegistry::RegisterOperatorSetSchema
winrt::Windows::AI::MachineLearning::implementation::ApplyBatchSizeOverride
winrt::Windows::AI::MachineLearning::implementation::CreateUnboundOuputFeatureValue
winrt::Windows::AI::MachineLearning::implementation::D3DDeviceCache::CreateDetensorizePipelineState
winrt::Windows::AI::MachineLearning::implementation::D3DDeviceCache::CreateTensorizePipelineState
winrt::Windows::AI::MachineLearning::implementation::D3DDeviceCache::D3DDeviceCache
winrt::Windows::AI::MachineLearning::implementation::D3DDeviceCache::EnsureD3D11FromD3D12
winrt::Windows::AI::MachineLearning::implementation::D3DDeviceCache::EnsureSharedFences
winrt::Windows::AI::MachineLearning::implementation::D3DDeviceCache::GetConverterFenceHandle
winrt::Windows::AI::MachineLearning::implementation::D3DDeviceCache::GetDetensorizeRootSignature
winrt::Windows::AI::MachineLearning::implementation::D3DDeviceCache::GetTensorizeRootSignature
winrt::Windows::AI::MachineLearning::implementation::D3DDeviceCache::GPUSyncD3D11ToD3D12
winrt::Windows::AI::MachineLearning::implementation::D3DDeviceCache::GPUSyncD3D12ToD3D11
winrt::Windows::AI::MachineLearning::implementation::D3DDeviceCache::InitializeCommandQueue
winrt::Windows::AI::MachineLearning::implementation::D3DDeviceCache::QueueFenceToD3D12
winrt::Windows::AI::MachineLearning::implementation::D3DDeviceCache::SyncConverterToD3D11Device
winrt::Windows::AI::MachineLearning::implementation::D3DDeviceCache::SyncD3D11DeviceToConverter
winrt::Windows::AI::MachineLearning::implementation::D3DDeviceCache::WaitForFenceValue
winrt::Windows::AI::MachineLearning::implementation::EnsureModelDeviceCompatibility
winrt::Windows::AI::MachineLearning::implementation::FindValidBinding
winrt::Windows::AI::MachineLearning::implementation::GetBitmapPixelFormatFromMetadata
winrt::Windows::AI::MachineLearning::implementation::GetBoundsFromMetadata
winrt::Windows::AI::MachineLearning::implementation::GetIOBinding
winrt::Windows::AI::MachineLearning::implementation::GetIOBinding::<lambda_552d815e3906a62ac3328e8dbc72783f>::operator ()
winrt::Windows::AI::MachineLearning::implementation::GetSizeFromTensorDataType
winrt::Windows::AI::MachineLearning::implementation::GetTensorDataTypeFromTensorKind
winrt::Windows::AI::MachineLearning::implementation::ImageFeatureValue::CenterAndCropBounds
winrt::Windows::AI::MachineLearning::implementation::LearningModelBinding::Bind
winrt::Windows::AI::MachineLearning::implementation::LearningModelBinding::CreateBinding
winrt::Windows::AI::MachineLearning::implementation::LearningModelBinding::CreateUnboundOutput
winrt::Windows::AI::MachineLearning::implementation::LearningModelBinding::Lookup
winrt::Windows::AI::MachineLearning::implementation::LearningModelBinding::UpdateProviders
winrt::Windows::AI::MachineLearning::implementation::LearningModelSession::CheckClosed
winrt::Windows::AI::MachineLearning::implementation::LearningModelSession::CreateSessionBinding
winrt::Windows::AI::MachineLearning::implementation::LearningModelSession::GetOptimizedModel
winrt::Windows::AI::MachineLearning::implementation::LearningModelSession::Initialize
winrt::Windows::AI::MachineLearning::implementation::LearningModelSession::Run
winrt::Windows::AI::MachineLearning::implementation::OpKernelContextWrapper::AllocateTemporaryData
winrt::Windows::AI::MachineLearning::implementation::OpNodeInfoWrapper<class onnxruntime::ProtoHelperNodeContext,class Microsoft::WRL::RuntimeClass<struct Microsoft::WRL::RuntimeClassFlags<2>,struct Microsoft::WRL::ChainInterfaces<struct IMLOperatorKernelCreationContextPrivate,struct IMLOperatorKernelCreationContext,class Microsoft::WRL::Details::Nil,class Microsoft::WRL::Details::Nil,class Microsoft::WRL::Details::Nil,class Microsoft::WRL::Details::Nil,class Microsoft::WRL::Details::Nil,class Microsoft::WRL::Details::Nil,class Microsoft::WRL::Details::Nil,class Microsoft::WRL::Details::Nil>,struct IMLOperatorTensorShapeDescription,struct IMLOperatorAttributes1>,struct onnxruntime::null_type>::GetAttributeArrayHelper
winrt::Windows::AI::MachineLearning::implementation::OpNodeInfoWrapper<class onnxruntime::ProtoHelperNodeContext,class Microsoft::WRL::RuntimeClass<struct Microsoft::WRL::RuntimeClassFlags<2>,struct Microsoft::WRL::ChainInterfaces<struct IMLOperatorKernelCreationContextPrivate,struct IMLOperatorKernelCreationContext,class Microsoft::WRL::Details::Nil,class Microsoft::WRL::Details::Nil,class Microsoft::WRL::Details::Nil,class Microsoft::WRL::Details::Nil,class Microsoft::WRL::Details::Nil,class Microsoft::WRL::Details::Nil,class Microsoft::WRL::Details::Nil,class Microsoft::WRL::Details::Nil>,struct IMLOperatorTensorShapeDescription,struct IMLOperatorAttributes1>,struct onnxruntime::null_type>::GetAttributeHelper
winrt::Windows::AI::MachineLearning::implementation::OpNodeInfoWrapper<class onnxruntime::ProtoHelperNodeContext,class Microsoft::WRL::RuntimeClass<struct Microsoft::WRL::RuntimeClassFlags<2>,struct Microsoft::WRL::ChainInterfaces<struct IMLOperatorShapeInferenceContextPrivate,struct IMLOperatorShapeInferenceContext,class Microsoft::WRL::Details::Nil,class Microsoft::WRL::Details::Nil,class Microsoft::WRL::Details::Nil,class Microsoft::WRL::Details::Nil,class Microsoft::WRL::Details::Nil,class Microsoft::WRL::Details::Nil,class Microsoft::WRL::Details::Nil,class Microsoft::WRL::Details::Nil>,struct IMLOperatorAttributes,struct IMLOperatorAttributes1>,struct onnxruntime::null_type>::GetAttributeArrayHelper
winrt::Windows::AI::MachineLearning::implementation::OpNodeInfoWrapper<class onnxruntime::ProtoHelperNodeContext,class Microsoft::WRL::RuntimeClass<struct Microsoft::WRL::RuntimeClassFlags<2>,struct Microsoft::WRL::ChainInterfaces<struct IMLOperatorShapeInferenceContextPrivate,struct IMLOperatorShapeInferenceContext,class Microsoft::WRL::Details::Nil,class Microsoft::WRL::Details::Nil,class Microsoft::WRL::Details::Nil,class Microsoft::WRL::Details::Nil,class Microsoft::WRL::Details::Nil,class Microsoft::WRL::Details::Nil,class Microsoft::WRL::Details::Nil,class Microsoft::WRL::Details::Nil>,struct IMLOperatorAttributes,struct IMLOperatorAttributes1>,struct onnxruntime::null_type>::GetAttributeHelper
winrt::Windows::AI::MachineLearning::implementation::OpNodeInfoWrapper<struct onnx::InferenceContext,class Microsoft::WRL::RuntimeClass<struct Microsoft::WRL::RuntimeClassFlags<2>,struct Microsoft::WRL::ChainInterfaces<struct IMLOperatorShapeInferenceContextPrivate,struct IMLOperatorShapeInferenceContext,class Microsoft::WRL::Details::Nil,class Microsoft::WRL::Details::Nil,class Microsoft::WRL::Details::Nil,class Microsoft::WRL::Details::Nil,class Microsoft::WRL::Details::Nil,class Microsoft::WRL::Details::Nil,class Microsoft::WRL::Details::Nil,class Microsoft::WRL::Details::Nil>,struct IMLOperatorTypeInferenceContext,struct IMLOperatorAttributes,struct IMLOperatorAttributes1>,struct onnxruntime::null_type>::GetAttributeArrayHelper
winrt::Windows::AI::MachineLearning::implementation::OpNodeInfoWrapper<struct onnx::InferenceContext,class Microsoft::WRL::RuntimeClass<struct Microsoft::WRL::RuntimeClassFlags<2>,struct Microsoft::WRL::ChainInterfaces<struct IMLOperatorShapeInferenceContextPrivate,struct IMLOperatorShapeInferenceContext,class Microsoft::WRL::Details::Nil,class Microsoft::WRL::Details::Nil,class Microsoft::WRL::Details::Nil,class Microsoft::WRL::Details::Nil,class Microsoft::WRL::Details::Nil,class Microsoft::WRL::Details::Nil,class Microsoft::WRL::Details::Nil,class Microsoft::WRL::Details::Nil>,struct IMLOperatorTypeInferenceContext,struct IMLOperatorAttributes,struct IMLOperatorAttributes1>,struct onnxruntime::null_type>::GetAttributeHelper
winrt::Windows::AI::MachineLearning::implementation::RegisterCustomRegistry
with activation 
wjH9Q
WordConvEmbedding
WpH9Wxt
WPI+WHH
wrong protocol type
wstr != wconv_error
X != nullptr
x 9s(t
X and Y input types do not match: 
x ATAUAVAWD
x ATAUAVAWL
x ATAVAWH
x AUAVAWH
x AVAWH
x AVAWL
x AVH
x AVL
x AVM
x AWH
X dims is empty.
X H+X
x H+x
X I+X
X input is required!
x L+x
X L9{
x L9o
X L9s
X num_dims does not match W num_dims.
x UATAUAVAWH
x UAVAWH
X UVWATAUAVAWH
x(\$P
x(D$ 
x(D$ H
x(d$`
x(L$0
x(l$p
x(T$@
x)\$P
x)D$ 
x)D$ H
x)d$`
x)L$0
x)l$p
x)T$@
x*;CP}%L
x.H;A0}(H;AXt
x@D8gDt
x]I;>tX
x_^[]
X_^[]
x_^[]
X_^[]
x_^[]
x_I;?tZ
X_ptr != nullptr
X_RMD
x_scale
x_scale must be 1D tensor with size 
x_scale must be a scalar or 1D tensor or size 1.
x_scale.Shape().NumDimensions() == 1 && x_scale.Shape().Size() == broadcastDim
X_squared
X_variance
x_zero_point
x_zero_point must be 1D tensor with size 
x_zero_point must be a scalar or 1D tensor or size 1.
x_zero_point.Shape().NumDimensions() == 1 && x_zero_point.Shape().Size() == broadcastDim
x`H;>t[
x{I;?tv
x{I;6tv
x}I;>tx
X->Shape().NumDimensions() == 4
x4D;d$0
x4H;Q(}.H
x9y,~
XA_A^_^[]
XA_A^A\_^[
xA_A^A]A\_^[]
XA_A^A]A\_^[]
xA_A^A]A\_^[]
XA_A^A]A\_^[]
XA_A^A]A\_^][
xbH;>t]
xdI;7t_@
xhH;_
xHH;>tC
x'I;6t"H
xi9\$pv;H
xiH;>td
xiI;>td
xjI;7te@
xl9\$pv:H
xMI;6tH@
xnD8ePu
xPE8T$
xPHc.A
xPL9eot
xQD8M
xSD8N
xsI;6tn@
xsI;7tn@
xuI;6tp
xuI;6tp@
XunH;
xvD8|$0u
xvD8ewu
y @8z t
Y,e^h
Y@ffn@
y_scale
y_scale.Shape().NumDimensions() == 1 && y_scale.Shape().Size() == broadcastDim
y_zero_point
y_zero_point.Shape().NumDimensions() == 1 && y_zero_point.Shape().Size() == broadcastDim
y0H+y(H
yC:\apilot\agent\_work\2\s\engine\DmlExecutionProvider\src\Operators\DmlOperatorMaxUnpool.cpp
YE9`@
yP@8zPt
Yt$pH
yXH+yPH
z%u#L
z)u'L9L
z*u(L9L
z>2?~>
Zanabazar_Square
zCuAH
ZE9XD~
Zero point for doing quantization to get 'y'. It could be a scalar or a 1-D tensor, which means a per-tensoror per-axis quantization. If it's a 1-D tensor, its number of elements should be equal to the dimension value of 'axis' dimension of input 'x'.
Zero point for doing quantization to get 'y'. It's a scalar, which means a per-tensor/layer quantization. Default value is 0 if it's not specified.
Zero point for input 'x'. It could be a scalar or a 1-D tensor, which means a per-tensor or per-axis quantization.If it's a 1-D tensor, its number of elements should be equal to the dimension value of 'axis' dimension of input 'x'.
Zero point for input 'x'. It's a scalar, which means a per-tensor/layer quantization. It's optional. 0 is the default value when it's not specified.
zero point of quantized input a
zero point of quantized input b
zero point of quantized output y
Zero point tensor for input 'A'. It's optional and default value is 0. It could be a scalar or a 1-D tensor, which means a per-tensor or per-row quantization. If it's a 1-D tensor, its number of elements should be equal to the number of rows of input 'A'.
Zero point tensor for input 'x'. It's a scalar, which means a per-tensor/layer quantization.
Zero point tensor for input 'x'. It's optional and default value is 0. It's a scalar, which means a per-tensor/layer quantization.
zeropoint must be a scalar
zeropoint->Shape().NumDimensions() == 0 || (zeropoint->Shape().NumDimensions() == 1 && zeropoint->Shape().GetDims().size() == 1)
ZeroPointTensor
zeros
zEuCH
ZipMap
Zipmap does not support empty dim count
Zipmap only supports 1D or 2D input tensors
Zvector<T> too long
zWuUH
